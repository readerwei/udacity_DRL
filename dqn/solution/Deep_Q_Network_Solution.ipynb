{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network (DQN)\n",
    "---\n",
    "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent\n",
    "\n",
    "Initialize the environment in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the instructions in `Deep_Q_Network.ipynb` if you would like to write your own DQN agent.  Otherwise, run the code cell below to load the solution files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "\n",
    "# watch an untrained agent\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = agent.act(state)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.qnetwork_local.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DQN\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!\n",
    "\n",
    "Alternatively, you can skip to the next step below (**4. Watch a Smart Agent!**), to load the saved model weights from a pre-trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-50-4b71072aa82e>(27)dqn()\n",
      "-> scores_window.append(score)       # save most recent score\n",
      "(Pdb) action\n",
      "1\n",
      "(Pdb) l\n",
      " 22  \t            state = next_state\n",
      " 23  \t            score += reward\n",
      " 24  \t            if done:\n",
      " 25  \t                break\n",
      " 26  \t        pdb.set_trace()\n",
      " 27  ->\t        scores_window.append(score)       # save most recent score\n",
      " 28  \t        scores.append(score)              # save most recent score\n",
      " 29  \t        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
      " 30  \t        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
      " 31  \t        if i_episode % 100 == 0:\n",
      " 32  \t            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
      "(Pdb) s\n",
      "> <ipython-input-50-4b71072aa82e>(28)dqn()\n",
      "-> scores.append(score)              # save most recent score\n",
      "(Pdb) ?\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    c          d        h         list      q        rv       undisplay\n",
      "a      cl         debug    help      ll        quit     s        unt      \n",
      "alias  clear      disable  ignore    longlist  r        source   until    \n",
      "args   commands   display  interact  n         restart  step     up       \n",
      "b      condition  down     j         next      return   tbreak   w        \n",
      "break  cont       enable   jump      p         retval   u        whatis   \n",
      "bt     continue   exit     l         pp        run      unalias  where    \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "(Pdb) w\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\runpy.py(193)_run_module_as_main()\n",
      "-> \"__main__\", mod_spec)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\runpy.py(85)_run_code()\n",
      "-> exec(code, run_globals)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py(16)<module>()\n",
      "-> app.launch_new_instance()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\traitlets\\config\\application.py(664)launch_instance()\n",
      "-> app.start()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelapp.py(583)start()\n",
      "-> self.io_loop.start()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\platform\\asyncio.py(149)start()\n",
      "-> self.asyncio_loop.run_forever()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\asyncio\\base_events.py(442)run_forever()\n",
      "-> self._run_once()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\asyncio\\base_events.py(1462)_run_once()\n",
      "-> handle._run()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\asyncio\\events.py(145)_run()\n",
      "-> self._callback(*self._args)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\ioloop.py(690)<lambda>()\n",
      "-> lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\ioloop.py(743)_run_callback()\n",
      "-> ret = callback()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\gen.py(787)inner()\n",
      "-> self.run()\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\gen.py(748)run()\n",
      "-> yielded = self.gen.send(value)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py(361)process_one()\n",
      "-> yield gen.maybe_future(dispatch(*args))\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\gen.py(209)wrapper()\n",
      "-> yielded = next(result)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py(268)dispatch_shell()\n",
      "-> yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\gen.py(209)wrapper()\n",
      "-> yielded = next(result)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py(541)execute_request()\n",
      "-> user_expressions, allow_stdin,\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\tornado\\gen.py(209)wrapper()\n",
      "-> yielded = next(result)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\ipkernel.py(300)do_execute()\n",
      "-> res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipykernel\\zmqshell.py(536)run_cell()\n",
      "-> return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\interactiveshell.py(2858)run_cell()\n",
      "-> raw_cell, store_history, silent, shell_futures)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\interactiveshell.py(2886)_run_cell()\n",
      "-> return runner(coro)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\async_helpers.py(68)_pseudo_sync_runner()\n",
      "-> coro.send(None)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\interactiveshell.py(3063)run_cell_async()\n",
      "-> interactivity=interactivity, compiler=compiler, result=result)\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\interactiveshell.py(3254)run_ast_nodes()\n",
      "-> if (await self.run_code(code, result,  async_=asy)):\n",
      "  e:\\anaconda2\\envs\\pytorch\\lib\\site-packages\\ipython\\core\\interactiveshell.py(3331)run_code()\n",
      "-> exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  <ipython-input-50-4b71072aa82e>(39)<module>()\n",
      "-> scores = dqn()\n",
      "> <ipython-input-50-4b71072aa82e>(28)dqn()\n",
      "-> scores.append(score)              # save most recent score\n",
      "(Pdb) l\n",
      " 23  \t            score += reward\n",
      " 24  \t            if done:\n",
      " 25  \t                break\n",
      " 26  \t        pdb.set_trace()\n",
      " 27  \t        scores_window.append(score)       # save most recent score\n",
      " 28  ->\t        scores.append(score)              # save most recent score\n",
      " 29  \t        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
      " 30  \t        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
      " 31  \t        if i_episode % 100 == 0:\n",
      " 32  \t            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
      " 33  \t        if np.mean(scores_window)>=200.0:\n",
      "(Pdb) scores\n",
      "[]\n",
      "(Pdb) score\n",
      "-235.09993284107057\n",
      "(Pdb) agent\n",
      "<dqn_agent.Agent object at 0x0000021D7CF38048>\n",
      "(Pdb) agent.memory.memory\n",
      "deque([Experience(state=array([-0.0039978 ,  1.4096019 , -0.40494928, -0.05858942,  0.00463924,\n",
      "        0.091727  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5824295677944622, next_state=array([-0.00805674,  1.4077108 , -0.41201314, -0.0840809 ,  0.0106981 ,\n",
      "        0.12118918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00805674,  1.4077108 , -0.41201314, -0.0840809 ,  0.0106981 ,\n",
      "        0.12118918,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.482985402772971, next_state=array([-0.01224699,  1.406481  , -0.42455563, -0.05471122,  0.01616612,\n",
      "        0.10937051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01224699,  1.406481  , -0.42455563, -0.05471122,  0.01616612,\n",
      "        0.10937051,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7918073269283354, next_state=array([-0.01643744,  1.4046513 , -0.42457142, -0.08139511,  0.02163426,\n",
      "        0.10937275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01643744,  1.4046513 , -0.42457142, -0.08139511,  0.02163426,\n",
      "        0.10937275,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3003693838325305, next_state=array([-0.02072086,  1.4022074 , -0.43623534, -0.10874867,  0.02944216,\n",
      "        0.15617213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02072086,  1.4022074 , -0.43623534, -0.10874867,  0.02944216,\n",
      "        0.15617213,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.204128878793, next_state=array([-0.02500448,  1.3991642 , -0.43625945, -0.13542104,  0.03724776,\n",
      "        0.15612659,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02500448,  1.3991642 , -0.43625945, -0.13542104,  0.03724776,\n",
      "        0.15612659,  0.        ,  0.        ], dtype=float32), action=3, reward=0.10547721963124104, next_state=array([-0.02919054,  1.3955374 , -0.42399344, -0.16133958,  0.04257967,\n",
      "        0.10664828,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02919054,  1.3955374 , -0.42399344, -0.16133958,  0.04257967,\n",
      "        0.10664828,  0.        ,  0.        ], dtype=float32), action=2, reward=0.11467967623194114, next_state=array([-0.03331375,  1.391967  , -0.41810113, -0.1588555 ,  0.0483003 ,\n",
      "        0.11442293,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03331375,  1.391967  , -0.41810113, -0.1588555 ,  0.0483003 ,\n",
      "        0.11442293,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.333490834233173, next_state=array([-0.03751574,  1.3877872 , -0.42798123, -0.18603428,  0.05600348,\n",
      "        0.15407762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03751574,  1.3877872 , -0.42798123, -0.18603428,  0.05600348,\n",
      "        0.15407762,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.18302623769127876, next_state=array([-0.04162436,  1.3830042 , -0.41626677, -0.21279901,  0.06135749,\n",
      "        0.10709012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04162436,  1.3830042 , -0.41626677, -0.21279901,  0.06135749,\n",
      "        0.10709012,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.32089143659328445, next_state=array([-0.04566078,  1.3776311 , -0.4071992 , -0.23895036,  0.06488303,\n",
      "        0.07051735,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04566078,  1.3776311 , -0.4071992 , -0.23895036,  0.06488303,\n",
      "        0.07051735,  0.        ,  0.        ], dtype=float32), action=2, reward=0.40496759023603773, next_state=array([-0.04971075,  1.3725806 , -0.4086737 , -0.22462751,  0.06853356,\n",
      "        0.07301723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04971075,  1.3725806 , -0.4086737 , -0.22462751,  0.06853356,\n",
      "        0.07301723,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.158405954757626, next_state=array([-0.05376091,  1.3669301 , -0.4086834 , -0.25130475,  0.07218307,\n",
      "        0.07299663,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05376091,  1.3669301 , -0.4086834 , -0.25130475,  0.07218307,\n",
      "        0.07299663,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9833210029802217, next_state=array([-0.05801773,  1.3616457 , -0.4286089 , -0.2350122 ,  0.07507774,\n",
      "        0.05789874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05801773,  1.3616457 , -0.4286089 , -0.2350122 ,  0.07507774,\n",
      "        0.05789874,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3284245691745284, next_state=array([-0.06236734,  1.3557578 , -0.44022113, -0.26195237,  0.08029938,\n",
      "        0.10444184,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06236734,  1.3557578 , -0.44022113, -0.26195237,  0.08029938,\n",
      "        0.10444184,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.25196170877682106, next_state=array([-0.06672478,  1.3499138 , -0.44113427, -0.26002648,  0.08564433,\n",
      "        0.10690872,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06672478,  1.3499138 , -0.44113427, -0.26002648,  0.08564433,\n",
      "        0.10690872,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4340311427407344, next_state=array([-0.07116489,  1.3434696 , -0.45148247, -0.28685537,  0.09305692,\n",
      "        0.14826554,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07116489,  1.3434696 , -0.45148247, -0.28685537,  0.09305692,\n",
      "        0.14826554,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5663560214673837, next_state=array([-0.07568197,  1.3364241 , -0.46110868, -0.31373844,  0.10239105,\n",
      "        0.18669942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07568197,  1.3364241 , -0.46110868, -0.31373844,  0.10239105,\n",
      "        0.18669942,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7417624839288521, next_state=array([-0.08019944,  1.3287798 , -0.46113548, -0.34041542,  0.11172337,\n",
      "        0.18666327,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08019944,  1.3287798 , -0.46113548, -0.34041542,  0.11172337,\n",
      "        0.18666327,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.795456555105487, next_state=array([-0.08479366,  1.3205197 , -0.4707392 , -0.36799893,  0.12300026,\n",
      "        0.22555809,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08479366,  1.3205197 , -0.4707392 , -0.36799893,  0.12300026,\n",
      "        0.22555809,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.136328969859419, next_state=array([-0.08947887,  1.3116491 , -0.4821271 , -0.39543056,  0.13656774,\n",
      "        0.27137363,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08947887,  1.3116491 , -0.4821271 , -0.39543056,  0.13656774,\n",
      "        0.27137363,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.173162563006059, next_state=array([-0.09416475,  1.3021809 , -0.4821635 , -0.42211738,  0.15013246,\n",
      "        0.27131897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09416475,  1.3021809 , -0.4821635 , -0.42211738,  0.15013246,\n",
      "        0.27131897,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.180330280620693, next_state=array([-0.09892654,  1.2920923 , -0.49168414, -0.45001185,  0.16564298,\n",
      "        0.31023803,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09892654,  1.2920923 , -0.49168414, -0.45001185,  0.16564298,\n",
      "        0.31023803,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.356191780298616, next_state=array([-0.10368929,  1.2814069 , -0.49172387, -0.47670463,  0.18115017,\n",
      "        0.31017163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10368929,  1.2814069 , -0.49172387, -0.47670463,  0.18115017,\n",
      "        0.31017163,  0.        ,  0.        ], dtype=float32), action=2, reward=1.034874856422175, next_state=array([-0.10845013,  1.2713962 , -0.4922145 , -0.4469695 ,  0.19737461,\n",
      "        0.3245182 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10845013,  1.2713962 , -0.4922145 , -0.4469695 ,  0.19737461,\n",
      "        0.3245182 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.475876765849989, next_state=array([-0.11320896,  1.2607677 , -0.49196973, -0.4746055 ,  0.21359767,\n",
      "        0.32446072,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11320896,  1.2607677 , -0.49196973, -0.4746055 ,  0.21359767,\n",
      "        0.32446072,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4268827533443584, next_state=array([-0.11796828,  1.2495426 , -0.49196297, -0.5012938 ,  0.22982042,\n",
      "        0.32445493,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11796828,  1.2495426 , -0.49196297, -0.5012938 ,  0.22982042,\n",
      "        0.32445493,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.2850678393635904, next_state=array([-0.12279616,  1.2377036 , -0.500481  , -0.5290423 ,  0.24779645,\n",
      "        0.3595206 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12279616,  1.2377036 , -0.500481  , -0.5290423 ,  0.24779645,\n",
      "        0.3595206 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7527551376996076, next_state=array([-0.12756053,  1.2253023 , -0.4923439 , -0.5539398 ,  0.26402757,\n",
      "        0.32462236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12756053,  1.2253023 , -0.4923439 , -0.5539398 ,  0.26402757,\n",
      "        0.32462236,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.395990749363392, next_state=array([-0.13232537,  1.2123042 , -0.4923355 , -0.58062774,  0.2802584 ,\n",
      "        0.3246165 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13232537,  1.2123042 , -0.4923355 , -0.58062774,  0.2802584 ,\n",
      "        0.3246165 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.37896568175168, next_state=array([-0.13709088,  1.1987098 , -0.4923266 , -0.60731566,  0.29648894,\n",
      "        0.32461086,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13709088,  1.1987098 , -0.4923266 , -0.60731566,  0.29648894,\n",
      "        0.32461086,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3590990343771523, next_state=array([-0.14185706,  1.1845186 , -0.49231714, -0.63400346,  0.31271923,\n",
      "        0.32460558,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14185706,  1.1845186 , -0.49231714, -0.63400346,  0.31271923,\n",
      "        0.32460558,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3367073186698235, next_state=array([-0.146624  ,  1.1697305 , -0.49230725, -0.66069114,  0.32894924,\n",
      "        0.3246004 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.146624  ,  1.1697305 , -0.49230725, -0.66069114,  0.32894924,\n",
      "        0.3246004 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.20476761319075648, next_state=array([-0.15158148,  1.1553879 , -0.51147854, -0.6411183 ,  0.34538537,\n",
      "        0.32872337,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15158148,  1.1553879 , -0.51147854, -0.6411183 ,  0.34538537,\n",
      "        0.32872337,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.3452607223388484, next_state=array([-0.15662089,  1.1404169 , -0.5215937 , -0.6697275 ,  0.36397487,\n",
      "        0.37178993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15662089,  1.1404169 , -0.5215937 , -0.6697275 ,  0.36397487,\n",
      "        0.37178993,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7196132016462957, next_state=array([-0.16159754,  1.1248862 , -0.5135448 , -0.6943809 ,  0.380786  ,\n",
      "        0.33622256,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16159754,  1.1248862 , -0.5135448 , -0.6943809 ,  0.380786  ,\n",
      "        0.33622256,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3170961156782255, next_state=array([-0.16657524,  1.1087588 , -0.51353186, -0.72106946,  0.39759678,\n",
      "        0.336216  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16657524,  1.1087588 , -0.51353186, -0.72106946,  0.39759678,\n",
      "        0.336216  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.545343976617828, next_state=array([-0.17149821,  1.0920813 , -0.50638974, -0.74524134,  0.41272247,\n",
      "        0.30251437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17149821,  1.0920813 , -0.50638974, -0.74524134,  0.41272247,\n",
      "        0.30251437,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8447544199604977, next_state=array([-0.17674646,  1.0754542 , -0.53828925, -0.7429864 ,  0.42727396,\n",
      "        0.29103008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17674646,  1.0754542 , -0.53828925, -0.7429864 ,  0.42727396,\n",
      "        0.29103008,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1855480032710364, next_state=array([-0.18193035,  1.0582732 , -0.5300236 , -0.76718575,  0.43993193,\n",
      "        0.25315958,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18193035,  1.0582732 , -0.5300236 , -0.76718575,  0.43993193,\n",
      "        0.25315958,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.774396307149799, next_state=array([-0.18718576,  1.040446  , -0.5390116 , -0.7966087 ,  0.45466137,\n",
      "        0.29458833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18718576,  1.040446  , -0.5390116 , -0.7966087 ,  0.45466137,\n",
      "        0.29458833,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0901806254707638, next_state=array([-0.19252177,  1.02196   , -0.54913175, -0.8267686 ,  0.47179043,\n",
      "        0.34258145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19252177,  1.02196   , -0.54913175, -0.8267686 ,  0.47179043,\n",
      "        0.34258145,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.173167377910289, next_state=array([-0.197859  ,  1.0028771 , -0.5491152 , -0.8534573 ,  0.48891917,\n",
      "        0.34257454,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.197859  ,  1.0028771 , -0.5491152 , -0.8534573 ,  0.48891917,\n",
      "        0.34257454,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0925460988756854, next_state=array([-0.20326352,  0.98314136, -0.557532  , -0.88333   ,  0.50810385,\n",
      "        0.38369256,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20326352,  0.98314136, -0.557532  , -0.88333   ,  0.50810385,\n",
      "        0.38369256,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.242737499852626, next_state=array([-0.20890942,  0.9632459 , -0.58121324, -0.8905305 ,  0.5269731 ,\n",
      "        0.3773857 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20890942,  0.9632459 , -0.58121324, -0.8905305 ,  0.5269731 ,\n",
      "        0.3773857 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.252955072436521, next_state=array([-0.21455698,  0.9427547 , -0.581191  , -0.91722304,  0.54584193,\n",
      "        0.37737647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21455698,  0.9427547 , -0.581191  , -0.91722304,  0.54584193,\n",
      "        0.37737647,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.360120115442412, next_state=array([-0.22014275,  0.9217238 , -0.5731044 , -0.94068396,  0.5626964 ,\n",
      "        0.33708978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22014275,  0.9217238 , -0.5731044 , -0.94068396,  0.5626964 ,\n",
      "        0.33708978,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.004154406780856, next_state=array([-0.2257299 ,  0.9000961 , -0.57308555, -0.9673708 ,  0.57955056,\n",
      "        0.33708316,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2257299 ,  0.9000961 , -0.57308555, -0.9673708 ,  0.57955056,\n",
      "        0.33708316,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9260911977118258, next_state=array([-0.23124257,  0.8779432 , -0.5634073 , -0.9899427 ,  0.59393483,\n",
      "        0.28768483,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23124257,  0.8779432 , -0.5634073 , -0.9899427 ,  0.59393483,\n",
      "        0.28768483,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9266081350815967, next_state=array([-0.23712263,  0.85568047, -0.5995644 , -0.9947236 ,  0.60775596,\n",
      "        0.27642268,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23712263,  0.85568047, -0.5995644 , -0.9947236 ,  0.60775596,\n",
      "        0.27642268,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8627974682245554, next_state=array([-0.24294786,  0.8328731 , -0.59246254, -1.0183173 ,  0.6197461 ,\n",
      "        0.2398026 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24294786,  0.8328731 , -0.59246254, -1.0183173 ,  0.6197461 ,\n",
      "        0.2398026 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.43255823440103996, next_state=array([-0.24928208,  0.8107936 , -0.64364827, -0.9862326 ,  0.6321975 ,\n",
      "        0.24902765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24928208,  0.8107936 , -0.64364827, -0.9862326 ,  0.6321975 ,\n",
      "        0.24902765,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5156956398071202, next_state=array([-0.25561708,  0.78811586, -0.6436368 , -1.0129097 ,  0.64464873,\n",
      "        0.24902496,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25561708,  0.78811586, -0.6436368 , -1.0129097 ,  0.64464873,\n",
      "        0.24902496,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4966337294399068, next_state=array([-0.26195297,  0.7648396 , -0.64362514, -1.0395867 ,  0.65709984,\n",
      "        0.24902228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26195297,  0.7648396 , -0.64362514, -1.0395867 ,  0.65709984,\n",
      "        0.24902228,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4792029224656176, next_state=array([-0.26828963,  0.7409649 , -0.64361334, -1.0662637 ,  0.66955084,\n",
      "        0.24901965,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26828963,  0.7409649 , -0.64361334, -1.0662637 ,  0.66955084,\n",
      "        0.24901965,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5151489129702598, next_state=array([-0.2746864 ,  0.71640915, -0.6513387 , -1.0976123 ,  0.68431216,\n",
      "        0.29522675,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2746864 ,  0.71640915, -0.6513387 , -1.0976123 ,  0.68431216,\n",
      "        0.29522675,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5826649802805537, next_state=array([-0.28102058,  0.6913485 , -0.64296716, -1.1190556 ,  0.696526  ,\n",
      "        0.24427612,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28102058,  0.6913485 , -0.64296716, -1.1190556 ,  0.696526  ,\n",
      "        0.24427612,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.20969336002353883, next_state=array([-0.28751913,  0.66634285, -0.65984714, -1.1170033 ,  0.7094523 ,\n",
      "        0.25852516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28751913,  0.66634285, -0.65984714, -1.1170033 ,  0.7094523 ,\n",
      "        0.25852516,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.293889225750745, next_state=array([-0.2940659 ,  0.6406845 , -0.66585577, -1.1468556 ,  0.72407424,\n",
      "        0.2924396 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2940659 ,  0.6406845 , -0.66585577, -1.1468556 ,  0.72407424,\n",
      "        0.2924396 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6370519953011058, next_state=array([-0.30054942,  0.61451286, -0.6575284 , -1.1686524 ,  0.7362277 ,\n",
      "        0.24306944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30054942,  0.61451286, -0.6575284 , -1.1686524 ,  0.7362277 ,\n",
      "        0.24306944,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4492984307316306, next_state=array([-0.30703378,  0.58774275, -0.657516  , -1.1953284 ,  0.748381  ,\n",
      "        0.24306698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30703378,  0.58774275, -0.657516  , -1.1953284 ,  0.748381  ,\n",
      "        0.24306698,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4521584592971792, next_state=array([-0.3135756 ,  0.56029564, -0.6647951 , -1.2265242 ,  0.7627658 ,\n",
      "        0.28769648,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3135756 ,  0.56029564, -0.6647951 , -1.2265242 ,  0.7627658 ,\n",
      "        0.28769648,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.893365522335016, next_state=array([-0.3201809 ,  0.532147  , -0.6729632 , -1.2590998 ,  0.77987456,\n",
      "        0.34217358,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3201809 ,  0.532147  , -0.6729632 , -1.2590998 ,  0.77987456,\n",
      "        0.34217358,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8751473863162278, next_state=array([-0.32672247,  0.50349534, -0.66450584, -1.2803136 ,  0.7943297 ,\n",
      "        0.2891031 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32672247,  0.50349534, -0.66450584, -1.2803136 ,  0.7943297 ,\n",
      "        0.2891031 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6120797676728376, next_state=array([-0.3332041 ,  0.47435197, -0.65641433, -1.3009243 ,  0.8060166 ,\n",
      "        0.23373792,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3332041 ,  0.47435197, -0.65641433, -1.3009243 ,  0.8060166 ,\n",
      "        0.23373792,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5501559542916812, next_state=array([-0.33962575,  0.4446931 , -0.6486518 , -1.3227156 ,  0.8152986 ,\n",
      "        0.18564007,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33962575,  0.4446931 , -0.6486518 , -1.3227156 ,  0.8152986 ,\n",
      "        0.18564007,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3632916386354736, next_state=array([-0.34604797,  0.41443506, -0.64864385, -1.349387  ,  0.82458055,\n",
      "        0.1856389 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34604797,  0.41443506, -0.64864385, -1.349387  ,  0.82458055,\n",
      "        0.1856389 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4377789404024952, next_state=array([-0.3524708 ,  0.3835777 , -0.648636  , -1.3760587 ,  0.8338624 ,\n",
      "        0.18563776,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3524708 ,  0.3835777 , -0.648636  , -1.3760587 ,  0.8338624 ,\n",
      "        0.18563776,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.558895768074619, next_state=array([-0.3589511 ,  0.35203537, -0.6559291 , -1.4077435 ,  0.8455284 ,\n",
      "        0.23332027,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3589511 ,  0.35203537, -0.6559291 , -1.4077435 ,  0.8455284 ,\n",
      "        0.23332027,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7937905457527836, next_state=array([-0.36536923,  0.31999075, -0.64783293, -1.4287708 ,  0.85452527,\n",
      "        0.17993681,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36536923,  0.31999075, -0.64783293, -1.4287708 ,  0.85452527,\n",
      "        0.17993681,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0548647880322892, next_state=array([-0.3717509 ,  0.28741452, -0.6429744 , -1.4515351 ,  0.8617714 ,\n",
      "        0.14492434,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3717509 ,  0.28741452, -0.6429744 , -1.4515351 ,  0.8617714 ,\n",
      "        0.14492434,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7138128413518985, next_state=array([-0.37851653,  0.2550037 , -0.68174404, -1.4445301 ,  0.86965257,\n",
      "        0.15762316,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37851653,  0.2550037 , -0.68174404, -1.4445301 ,  0.86965257,\n",
      "        0.15762316,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.879728832011351, next_state=array([-0.38533098,  0.22192541, -0.6878396 , -1.4752423 ,  0.8794876 ,\n",
      "        0.19670042,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38533098,  0.22192541, -0.6878396 , -1.4752423 ,  0.8794876 ,\n",
      "        0.19670042,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.2993839551095605, next_state=array([-0.3921904 ,  0.18817364, -0.6935369 , -1.5062597 ,  0.89131504,\n",
      "        0.23654993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3921904 ,  0.18817364, -0.6935369 , -1.5062597 ,  0.89131504,\n",
      "        0.23654993,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.876230397888378, next_state=array([-0.39905086,  0.15382305, -0.6935232 , -1.5329337 ,  0.90314245,\n",
      "        0.23654768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39905086,  0.15382305, -0.6935232 , -1.5329337 ,  0.90314245,\n",
      "        0.23654768,  0.        ,  0.        ], dtype=float32), action=0, reward=6.855140233853433, next_state=array([-0.40591225,  0.11887366, -0.69350946, -1.5596077 ,  0.91496974,\n",
      "        0.2365454 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.40591225,  0.11887366, -0.69350946, -1.5596077 ,  0.91496974,\n",
      "        0.2365454 ,  0.        ,  1.        ], dtype=float32), action=2, reward=38.01540664791817, next_state=array([-0.4100863 ,  0.10182232, -0.54904383, -0.93766457,  1.1525029 ,\n",
      "        4.4252205 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.4100863 ,  0.10182232, -0.54904383, -0.93766457,  1.1525029 ,\n",
      "        4.4252205 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-35.87776597042391, next_state=array([-0.41513333,  0.08541936, -0.5747081 , -0.9317486 ,  1.398837  ,\n",
      "        4.571439  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41513333,  0.08541936, -0.5747081 , -0.9317486 ,  1.398837  ,\n",
      "        4.571439  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-16.896985857538567, next_state=array([-0.42075187,  0.06788407, -0.568488  , -0.9660256 ,  1.638994  ,\n",
      "        4.5903444 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.42075187,  0.06788407, -0.568488  , -0.9660256 ,  1.638994  ,\n",
      "        4.5903444 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.4223837 ,  0.06850992, -0.12499443,  0.0688941 ,  1.6812543 ,\n",
      "        0.48705775,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([ 0.00194321,  1.4018925 ,  0.19679943, -0.4012257 , -0.00224479,\n",
      "       -0.04457801,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.187215561378507, next_state=array([ 0.0039609 ,  1.3922869 ,  0.2058971 , -0.42692786, -0.00632564,\n",
      "       -0.08162431,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0039609 ,  1.3922869 ,  0.2058971 , -0.42692786, -0.00632564,\n",
      "       -0.08162431,  0.        ,  0.        ], dtype=float32), action=2, reward=1.013890219034505, next_state=array([ 0.00609655,  1.3829949 ,  0.217128  , -0.41300043, -0.00985691,\n",
      "       -0.07063166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00609655,  1.3829949 ,  0.217128  , -0.41300043, -0.00985691,\n",
      "       -0.07063166,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7427890093979386, next_state=array([ 0.00823231,  1.3731027 ,  0.21713814, -0.43968084, -0.01338849,\n",
      "       -0.07063778,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00823231,  1.3731027 ,  0.21713814, -0.43968084, -0.01338849,\n",
      "       -0.07063778,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1046406961355604, next_state=array([ 0.01028919,  1.3626173 ,  0.20726666, -0.46603307, -0.01493628,\n",
      "       -0.03095864,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01028919,  1.3626173 ,  0.20726666, -0.46603307, -0.01493628,\n",
      "       -0.03095864,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.495913237345576, next_state=array([ 0.01234627,  1.3515317 ,  0.20727067, -0.49270153, -0.0164847 ,\n",
      "       -0.03097121,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01234627,  1.3515317 ,  0.20727067, -0.49270153, -0.0164847 ,\n",
      "       -0.03097121,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.068318743303165, next_state=array([ 0.01448698,  1.3398533 ,  0.21775563, -0.5190933 , -0.02013174,\n",
      "       -0.07294776,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01448698,  1.3398533 ,  0.21775563, -0.5190933 , -0.02013174,\n",
      "       -0.07294776,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6081151076817832, next_state=array([ 0.01662779,  1.3275748 ,  0.217767  , -0.54576284, -0.02377734,\n",
      "       -0.07291811,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01662779,  1.3275748 ,  0.217767  , -0.54576284, -0.02377734,\n",
      "       -0.07291811,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1698885821238307, next_state=array([ 0.01884947,  1.3146964 ,  0.22790153, -0.5724806 , -0.02945233,\n",
      "       -0.11351045,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01884947,  1.3146964 ,  0.22790153, -0.5724806 , -0.02945233,\n",
      "       -0.11351045,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7092207621870443, next_state=array([ 0.02107124,  1.3012183 ,  0.22791871, -0.5991516 , -0.03512556,\n",
      "       -0.11347511,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02107124,  1.3012183 ,  0.22791871, -0.5991516 , -0.03512556,\n",
      "       -0.11347511,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.663680263720778, next_state=array([ 0.02329331,  1.2871406 ,  0.22793558, -0.6258226 , -0.04079835,\n",
      "       -0.11346613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02329331,  1.2871406 ,  0.22793558, -0.6258226 , -0.04079835,\n",
      "       -0.11346613,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9369961243859393, next_state=array([ 0.02544184,  1.2731153 ,  0.22102149, -0.6235336 , -0.0469025 ,\n",
      "       -0.12209408,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02544184,  1.2731153 ,  0.22102149, -0.6235336 , -0.0469025 ,\n",
      "       -0.12209408,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1762309102597317, next_state=array([ 0.0275177 ,  1.2585016 ,  0.21188807, -0.64963406, -0.05116292,\n",
      "       -0.08521625,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0275177 ,  1.2585016 ,  0.21188807, -0.64963406, -0.05116292,\n",
      "       -0.08521625,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0870019776876905, next_state=array([ 0.02953405,  1.2432926 ,  0.20442219, -0.6760558 , -0.05392225,\n",
      "       -0.05519154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02953405,  1.2432926 ,  0.20442219, -0.6760558 , -0.05392225,\n",
      "       -0.05519154,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6999794846691134, next_state=array([ 0.0314517 ,  1.2274823 ,  0.1920474 , -0.70269245, -0.05420276,\n",
      "       -0.00561091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0314517 ,  1.2274823 ,  0.1920474 , -0.70269245, -0.05420276,\n",
      "       -0.00561091,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3889501542567746, next_state=array([ 0.03343086,  1.2110648 ,  0.19977657, -0.7297242 , -0.056038  ,\n",
      "       -0.03670833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03343086,  1.2110648 ,  0.19977657, -0.7297242 , -0.056038  ,\n",
      "       -0.03670833,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.06363941100048, next_state=array([ 0.03541021,  1.1940478 ,  0.19978234, -0.7563937 , -0.05787181,\n",
      "       -0.03667936,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03541021,  1.1940478 ,  0.19978234, -0.7563937 , -0.05787181,\n",
      "       -0.03667936,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0100461088350983, next_state=array([ 0.03738947,  1.1764305 ,  0.19978751, -0.7830628 , -0.05970567,\n",
      "       -0.03668067,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03738947,  1.1764305 ,  0.19978751, -0.7830628 , -0.05970567,\n",
      "       -0.03668067,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9559749543113583, next_state=array([ 0.03936892,  1.1582131 ,  0.19979244, -0.8097319 , -0.06153924,\n",
      "       -0.0366748 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03936892,  1.1582131 ,  0.19979244, -0.8097319 , -0.06153924,\n",
      "       -0.0366748 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5028683447080755, next_state=array([ 0.0414423 ,  1.1393857 ,  0.21158044, -0.8369559 , -0.06574174,\n",
      "       -0.08405761,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0414423 ,  1.1393857 ,  0.21158044, -0.8369559 , -0.06574174,\n",
      "       -0.08405761,  0.        ,  0.        ], dtype=float32), action=2, reward=3.324364102927274, next_state=array([ 0.04342251,  1.1210401 ,  0.202914  , -0.8155803 , -0.07059821,\n",
      "       -0.09713838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04342251,  1.1210401 ,  0.202914  , -0.8155803 , -0.07059821,\n",
      "       -0.09713838,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6034229216489553, next_state=array([ 0.04546709,  1.1020902 ,  0.21098773, -0.8425408 , -0.07707223,\n",
      "       -0.12949173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04546709,  1.1020902 ,  0.21098773, -0.8425408 , -0.07707223,\n",
      "       -0.12949173,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8128361193451485, next_state=array([ 0.04742479,  1.0825473 ,  0.20009382, -0.86880183, -0.08135353,\n",
      "       -0.08563365,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04742479,  1.0825473 ,  0.20009382, -0.86880183, -0.08135353,\n",
      "       -0.08563365,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5354409325607878, next_state=array([ 0.04946556,  1.0623982 ,  0.21048215, -0.8958768 , -0.08771965,\n",
      "       -0.1273336 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04946556,  1.0623982 ,  0.21048215, -0.8958768 , -0.08771965,\n",
      "       -0.1273336 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1727576916711087, next_state=array([ 0.05150642,  1.0416497 ,  0.21050063, -0.9225506 , -0.09408354,\n",
      "       -0.1272889 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05150642,  1.0416497 ,  0.21050063, -0.9225506 , -0.09408354,\n",
      "       -0.1272889 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2050221201161833, next_state=array([ 0.05354614,  1.0202801 ,  0.21038213, -0.9501733 , -0.10044752,\n",
      "       -0.12727958,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05354614,  1.0202801 ,  0.21038213, -0.9501733 , -0.10044752,\n",
      "       -0.12727958,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0593133795482856, next_state=array([ 0.05558576,  0.9983112 ,  0.21038163, -0.9768434 , -0.10681146,\n",
      "       -0.12727897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05558576,  0.9983112 ,  0.21038163, -0.9768434 , -0.10681146,\n",
      "       -0.12727897,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0036834884841142, next_state=array([ 0.05762548,  0.97574276,  0.2103811 , -1.0035135 , -0.11317539,\n",
      "       -0.12727857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05762548,  0.97574276,  0.2103811 , -1.0035135 , -0.11317539,\n",
      "       -0.12727857,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7087851029420562, next_state=array([ 0.05975199,  0.9533089 ,  0.21890673, -0.9975469 , -0.11939626,\n",
      "       -0.12441745,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05975199,  0.9533089 ,  0.21890673, -0.9975469 , -0.11939626,\n",
      "       -0.12441745,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5306911118995277, next_state=array([ 0.06181402,  0.9302981 ,  0.21078165, -1.0230788 , -0.12395029,\n",
      "       -0.09108089,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06181402,  0.9302981 ,  0.21078165, -1.0230788 , -0.12395029,\n",
      "       -0.09108089,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7094712001607038, next_state=array([ 0.0639184 ,  0.90759104,  0.21516383, -1.0096053 , -0.1286543 ,\n",
      "       -0.0940799 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0639184 ,  0.90759104,  0.21516383, -1.0096053 , -0.1286543 ,\n",
      "       -0.0940799 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7707713625117094, next_state=array([ 0.06602287,  0.88428414,  0.21516344, -1.0362738 , -0.13335828,\n",
      "       -0.09407978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06602287,  0.88428414,  0.21516344, -1.0362738 , -0.13335828,\n",
      "       -0.09407978,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7154353750466385, next_state=array([ 0.06812716,  0.8603777 ,  0.21516311, -1.0629424 , -0.13806225,\n",
      "       -0.09407973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06812716,  0.8603777 ,  0.21516311, -1.0629424 , -0.13806225,\n",
      "       -0.09407973,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2124334972938005, next_state=array([ 0.07031889,  0.83585674,  0.22610298, -1.0904735 , -0.14498115,\n",
      "       -0.13837755,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07031889,  0.83585674,  0.22610298, -1.0904735 , -0.14498115,\n",
      "       -0.13837755,  0.        ,  0.        ], dtype=float32), action=2, reward=2.432561632713356, next_state=array([ 0.07261439,  0.811621  ,  0.23640859, -1.0778291 , -0.15181826,\n",
      "       -0.13674226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07261439,  0.811621  ,  0.23640859, -1.0778291 , -0.15181826,\n",
      "       -0.13674226,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.45288759140336654, next_state=array([ 0.07485008,  0.78680634,  0.22885709, -1.1034204 , -0.15709883,\n",
      "       -0.1056116 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07485008,  0.78680634,  0.22885709, -1.1034204 , -0.15709883,\n",
      "       -0.1056116 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.633190283109542, next_state=array([ 0.07708578,  0.76139206,  0.22885653, -1.1300892 , -0.16237941,\n",
      "       -0.10561135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07708578,  0.76139206,  0.22885653, -1.1300892 , -0.16237941,\n",
      "       -0.10561135,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5790319056131921, next_state=array([ 0.07932158,  0.7353782 ,  0.228856  , -1.1567582 , -0.16765997,\n",
      "       -0.10561117,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07932158,  0.7353782 ,  0.228856  , -1.1567582 , -0.16765997,\n",
      "       -0.10561117,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.09193381008591814, next_state=array([ 0.08149242,  0.70879257,  0.22064802, -1.1819932 , -0.17122933,\n",
      "       -0.07138725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08149242,  0.70879257,  0.22064802, -1.1819932 , -0.17122933,\n",
      "       -0.07138725,  0.        ,  0.        ], dtype=float32), action=1, reward=0.041590575368048804, next_state=array([ 0.08359356,  0.68161327,  0.21192321, -1.2081752 , -0.17304595,\n",
      "       -0.03633157,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08359356,  0.68161327,  0.21192321, -1.2081752 , -0.17304595,\n",
      "       -0.03633157,  0.        ,  0.        ], dtype=float32), action=1, reward=0.33186491075457636, next_state=array([ 8.5625365e-02,  6.5385634e-01,  2.0318885e-01, -1.2336464e+00,\n",
      "       -1.7306161e-01, -3.1332247e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 8.5625365e-02,  6.5385634e-01,  2.0318885e-01, -1.2336464e+00,\n",
      "       -1.7306161e-01, -3.1332247e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-0.3385135309658256, next_state=array([ 0.08773021,  0.625477  ,  0.21238914, -1.2615285 , -0.17497142,\n",
      "       -0.03819541,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08773021,  0.625477  ,  0.21238914, -1.2615285 , -0.17497142,\n",
      "       -0.03819541,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5752122981270691, next_state=array([ 0.08992662,  0.5964733 ,  0.22390413, -1.2895561 , -0.17924155,\n",
      "       -0.0854027 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08992662,  0.5964733 ,  0.22390413, -1.2895561 , -0.17924155,\n",
      "       -0.0854027 ,  0.        ,  0.        ], dtype=float32), action=2, reward=5.6863217407983315, next_state=array([ 0.09212647,  0.5683325 ,  0.22501524, -1.2513204 , -0.18430057,\n",
      "       -0.10118041,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09212647,  0.5683325 ,  0.22501524, -1.2513204 , -0.18430057,\n",
      "       -0.10118041,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3338937504110504, next_state=array([ 0.09432621,  0.539592  ,  0.22501466, -1.2779891 , -0.18935956,\n",
      "       -0.10118015,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09432621,  0.539592  ,  0.22501466, -1.2779891 , -0.18935956,\n",
      "       -0.10118015,  0.        ,  0.        ], dtype=float32), action=2, reward=3.034905270467374, next_state=array([ 0.09655905,  0.5111225 ,  0.2286675 , -1.2660098 , -0.19477375,\n",
      "       -0.10828386,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09655905,  0.5111225 ,  0.2286675 , -1.2660098 , -0.19477375,\n",
      "       -0.10828386,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7865167062222713, next_state=array([ 0.09885387,  0.4820351 ,  0.23645225, -1.2937068 , -0.20179276,\n",
      "       -0.14038028,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09885387,  0.4820351 ,  0.23645225, -1.2937068 , -0.20179276,\n",
      "       -0.14038028,  0.        ,  0.        ], dtype=float32), action=2, reward=4.9974833016948255, next_state=array([ 0.10133848,  0.45378542,  0.2554549 , -1.2565153 , -0.20883952,\n",
      "       -0.14093539,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10133848,  0.45378542,  0.2554549 , -1.2565153 , -0.20883952,\n",
      "       -0.14093539,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.20617477689736916, next_state=array([ 0.10376358,  0.4249524 ,  0.24795893, -1.2822475 , -0.21434447,\n",
      "       -0.1100994 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10376358,  0.4249524 ,  0.24795893, -1.2822475 , -0.21434447,\n",
      "       -0.1100994 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9392830365841565, next_state=array([ 0.10627498,  0.3955031 ,  0.25875717, -1.3099848 , -0.22204827,\n",
      "       -0.15407583,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10627498,  0.3955031 ,  0.25875717, -1.3099848 , -0.22204827,\n",
      "       -0.15407583,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1822488647822798, next_state=array([ 0.10886774,  0.36542195,  0.2690154 , -1.3384336 , -0.23190422,\n",
      "       -0.19711955,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10886774,  0.36542195,  0.2690154 , -1.3384336 , -0.23190422,\n",
      "       -0.19711955,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2058764056089888, next_state=array([ 0.11152716,  0.33472776,  0.27730578, -1.3660214 , -0.24345565,\n",
      "       -0.23102835,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11152716,  0.33472776,  0.27730578, -1.3660214 , -0.24345565,\n",
      "       -0.23102835,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.909516824014446, next_state=array([ 0.11418676,  0.30343524,  0.2773018 , -1.3926988 , -0.25500697,\n",
      "       -0.2310262 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11418676,  0.30343524,  0.2773018 , -1.3926988 , -0.25500697,\n",
      "       -0.2310262 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.32522303066966063, next_state=array([ 0.11676578,  0.27158332,  0.26707882, -1.4172629 , -0.2643763 ,\n",
      "       -0.18738666,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11676578,  0.27158332,  0.26707882, -1.4172629 , -0.2643763 ,\n",
      "       -0.18738666,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.31964065366417915, next_state=array([ 0.11927585,  0.23914813,  0.2584377 , -1.4429225 , -0.27197585,\n",
      "       -0.1519914 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11927585,  0.23914813,  0.2584377 , -1.4429225 , -0.27197585,\n",
      "       -0.1519914 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1754918614252279, next_state=array([ 0.12186222,  0.20608313,  0.26801533, -1.4713289 , -0.2815994 ,\n",
      "       -0.19247136,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12186222,  0.20608313,  0.26801533, -1.4713289 , -0.2815994 ,\n",
      "       -0.19247136,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9095736387111799, next_state=array([ 0.12444878,  0.17241926,  0.26801217, -1.498003  , -0.2912229 ,\n",
      "       -0.19247012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12444878,  0.17241926,  0.26801217, -1.498003  , -0.2912229 ,\n",
      "       -0.19247012,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.701638172932461, next_state=array([ 0.12697211,  0.13817604,  0.26005563, -1.523486  , -0.29919165,\n",
      "       -0.15937525,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12697211,  0.13817604,  0.26005563, -1.523486  , -0.29919165,\n",
      "       -0.15937525,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.819076065901753, next_state=array([ 0.12957497,  0.10330275,  0.27002725, -1.5519602 , -0.30926967,\n",
      "       -0.20156021,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12957497,  0.10330275,  0.27002725, -1.5519602 , -0.30926967,\n",
      "       -0.20156021,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9216607437024038, next_state=array([ 0.13217811,  0.06783071,  0.27002344, -1.5786351 , -0.31934762,\n",
      "       -0.20155887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13217811,  0.06783071,  0.27002344, -1.5786351 , -0.31934762,\n",
      "       -0.20155887,  0.        ,  0.        ], dtype=float32), action=0, reward=7.371734335412839, next_state=array([ 0.13478155,  0.03176001,  0.27001947, -1.60531   , -0.3294255 ,\n",
      "       -0.20155743,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13478155,  0.03176001,  0.27001947, -1.60531   , -0.3294255 ,\n",
      "       -0.20155743,  1.        ,  0.        ], dtype=float32), action=1, reward=7.070657149485215, next_state=array([ 0.13684683, -0.00284939,  0.2106345 , -1.5505855 , -0.3230495 ,\n",
      "        0.1476571 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13684683, -0.00284939,  0.2106345 , -1.5505855 , -0.3230495 ,\n",
      "        0.1476571 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.14030543, -0.02920596,  0.12509108, -0.77970594, -0.15904877,\n",
      "        5.6437697 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00529709,  1.4073092 , -0.5365586 , -0.16051188,  0.00614486,\n",
      "        0.12153853,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9049162544220621, next_state=array([-0.01059465,  1.4031212 , -0.53583306, -0.18617296,  0.01215052,\n",
      "        0.12012519,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01059465,  1.4031212 , -0.53583306, -0.18617296,  0.01215052,\n",
      "        0.12012519,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.20495755575517477, next_state=array([-0.0159256 ,  1.3993813 , -0.5390467 , -0.16627881,  0.01803379,\n",
      "        0.11767659,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0159256 ,  1.3993813 , -0.5390467 , -0.16627881,  0.01803379,\n",
      "        0.11767659,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0063076103670596, next_state=array([-0.02125683,  1.3950415 , -0.53906345, -0.19296147,  0.02391645,\n",
      "        0.11766404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02125683,  1.3950415 , -0.53906345, -0.19296147,  0.02391645,\n",
      "        0.11766404,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.619489026372338, next_state=array([-0.02668238,  1.3912127 , -0.5481379 , -0.17026663,  0.02943119,\n",
      "        0.11030523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02668238,  1.3912127 , -0.5481379 , -0.17026663,  0.02943119,\n",
      "        0.11030523,  0.        ,  0.        ], dtype=float32), action=3, reward=0.16963170147039477, next_state=array([-0.03202572,  1.3867759 , -0.5378175 , -0.19726716,  0.03287738,\n",
      "        0.06893038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03202572,  1.3867759 , -0.5378175 , -0.19726716,  0.03287738,\n",
      "        0.06893038,  0.        ,  0.        ], dtype=float32), action=3, reward=0.38798008160958486, next_state=array([-0.03728266,  1.3817539 , -0.52697104, -0.22322702,  0.03413931,\n",
      "        0.02524071,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03728266,  1.3817539 , -0.52697104, -0.22322702,  0.03413931,\n",
      "        0.02524071,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1795811837766734, next_state=array([-0.04239006,  1.3766689 , -0.5127982 , -0.22604375,  0.03617168,\n",
      "        0.04065097,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04239006,  1.3766689 , -0.5127982 , -0.22604375,  0.03617168,\n",
      "        0.04065097,  0.        ,  0.        ], dtype=float32), action=2, reward=1.327267465665625, next_state=array([-0.04747515,  1.3723313 , -0.51082623, -0.1928402 ,  0.03846316,\n",
      "        0.04583416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04747515,  1.3723313 , -0.51082623, -0.1928402 ,  0.03846316,\n",
      "        0.04583416,  0.        ,  0.        ], dtype=float32), action=2, reward=1.400731752154013, next_state=array([-0.05244493,  1.3683891 , -0.49996543, -0.17529355,  0.04142299,\n",
      "        0.05920186,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05244493,  1.3683891 , -0.49996543, -0.17529355,  0.04142299,\n",
      "        0.05920186,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8040390147472465, next_state=array([-0.05741482,  1.3638468 , -0.49997395, -0.20196535,  0.04438192,\n",
      "        0.05918407,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05741482,  1.3638468 , -0.49997395, -0.20196535,  0.04438192,\n",
      "        0.05918407,  0.        ,  0.        ], dtype=float32), action=3, reward=0.48963706870688495, next_state=array([-0.0622879 ,  1.3587198 , -0.4878243 , -0.2278807 ,  0.04489321,\n",
      "        0.01022654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0622879 ,  1.3587198 , -0.4878243 , -0.2278807 ,  0.04489321,\n",
      "        0.01022654,  0.        ,  0.        ], dtype=float32), action=3, reward=0.19091583784890645, next_state=array([-0.06709671,  1.3530059 , -0.47975808, -0.2539155 ,  0.04377956,\n",
      "       -0.02227514,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06709671,  1.3530059 , -0.47975808, -0.2539155 ,  0.04377956,\n",
      "       -0.02227514,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.579989459186919, next_state=array([-0.07190552,  1.3466921 , -0.4797538 , -0.28058413,  0.04266625,\n",
      "       -0.02226836,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07190552,  1.3466921 , -0.4797538 , -0.28058413,  0.04266625,\n",
      "       -0.02226836,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6384942487010494, next_state=array([-0.076789  ,  1.3397744 , -0.4891172 , -0.30747917,  0.04343199,\n",
      "        0.01531632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.076789  ,  1.3397744 , -0.4891172 , -0.30747917,  0.04343199,\n",
      "        0.01531632,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8175901285504494, next_state=array([-0.08167247,  1.3322566 , -0.48912054, -0.33414793,  0.04419681,\n",
      "        0.01529814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08167247,  1.3322566 , -0.48912054, -0.33414793,  0.04419681,\n",
      "        0.01529814,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.142036160370877, next_state=array([-0.08665247,  1.324122  , -0.5012396 , -0.36164054,  0.04740167,\n",
      "        0.06410281,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08665247,  1.324122  , -0.5012396 , -0.36164054,  0.04740167,\n",
      "        0.06410281,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.020933673387161, next_state=array([-0.09170685,  1.3153938 , -0.51054305, -0.38808572,  0.05246095,\n",
      "        0.10119464,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09170685,  1.3153938 , -0.51054305, -0.38808572,  0.05246095,\n",
      "        0.10119464,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.410644070660793, next_state=array([-0.09685135,  1.3060634 , -0.52184945, -0.41495803,  0.05978278,\n",
      "        0.14645001,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09685135,  1.3060634 , -0.52184945, -0.41495803,  0.05978278,\n",
      "        0.14645001,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4747954121851876, next_state=array([-0.10199614,  1.2961336 , -0.5218711 , -0.44163162,  0.06710295,\n",
      "        0.14641674,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10199614,  1.2961336 , -0.5218711 , -0.44163162,  0.06710295,\n",
      "        0.14641674,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4782323359370366, next_state=array([-0.10714121,  1.2856045 , -0.52189195, -0.4683055 ,  0.07442248,\n",
      "        0.14640382,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10714121,  1.2856045 , -0.52189195, -0.4683055 ,  0.07442248,\n",
      "        0.14640382,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.530183387753907, next_state=array([-0.11220188,  1.2744733 , -0.5113172 , -0.49498716,  0.07962439,\n",
      "        0.10404769,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11220188,  1.2744733 , -0.5113172 , -0.49498716,  0.07962439,\n",
      "        0.10404769,  0.        ,  0.        ], dtype=float32), action=2, reward=2.922550794585317, next_state=array([-0.11715631,  1.2640364 , -0.50151247, -0.46419516,  0.08563783,\n",
      "        0.12027968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11715631,  1.2640364 , -0.50151247, -0.46419516,  0.08563783,\n",
      "        0.12027968,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4685829507595998, next_state=array([-0.12230358,  1.2535071 , -0.5200218 , -0.46828255,  0.09089257,\n",
      "        0.10510401,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12230358,  1.2535071 , -0.5200218 , -0.46828255,  0.09089257,\n",
      "        0.10510401,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2595287306046132, next_state=array([-0.12753105,  1.2423756 , -0.53005826, -0.49519432,  0.09815494,\n",
      "        0.14526019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12753105,  1.2423756 , -0.53005826, -0.49519432,  0.09815494,\n",
      "        0.14526019,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.47784892229682785, next_state=array([-0.13267127,  1.2306468 , -0.5191278 , -0.5216231 ,  0.10321787,\n",
      "        0.1012586 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13267127,  1.2306468 , -0.5191278 , -0.5216231 ,  0.10321787,\n",
      "        0.1012586 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2510353465340813, next_state=array([-0.13781147,  1.2183185 , -0.5191275 , -0.5482919 ,  0.10828076,\n",
      "        0.10125822,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13781147,  1.2183185 , -0.5191275 , -0.5482919 ,  0.10828076,\n",
      "        0.10125822,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.46395418345244255, next_state=array([-0.14288339,  1.2054052 , -0.5105375 , -0.57417196,  0.11160129,\n",
      "        0.06641071,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14288339,  1.2054052 , -0.5105375 , -0.57417196,  0.11160129,\n",
      "        0.06641071,  0.        ,  0.        ], dtype=float32), action=3, reward=0.001204997414818082, next_state=array([-0.14786176,  1.1919172 , -0.49876326, -0.59953994,  0.11252377,\n",
      "        0.01844967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14786176,  1.1919172 , -0.49876326, -0.59953994,  0.11252377,\n",
      "        0.01844967,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8255162736987245, next_state=array([-0.15284014,  1.177829  , -0.49876332, -0.62620664,  0.11344625,\n",
      "        0.01844965,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15284014,  1.177829  , -0.49876332, -0.62620664,  0.11344625,\n",
      "        0.01844965,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.12652332258445995, next_state=array([-0.15775375,  1.163153  , -0.49063796, -0.65221065,  0.1127236 ,\n",
      "       -0.01445298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15775375,  1.163153  , -0.49063796, -0.65221065,  0.1127236 ,\n",
      "       -0.01445298,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3300180892828155, next_state=array([-0.16273299,  1.1478734 , -0.49884415, -0.679165  ,  0.11364608,\n",
      "        0.01844932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16273299,  1.1478734 , -0.49884415, -0.679165  ,  0.11364608,\n",
      "        0.01844932,  0.        ,  0.        ], dtype=float32), action=3, reward=0.1329741797866302, next_state=array([-0.16762868,  1.1320186 , -0.48834723, -0.7045652 ,  0.11242557,\n",
      "       -0.02441036,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16762868,  1.1320186 , -0.48834723, -0.7045652 ,  0.11242557,\n",
      "       -0.02441036,  0.        ,  0.        ], dtype=float32), action=2, reward=2.8194206647075477, next_state=array([-0.17243595,  1.1164777 , -0.48022518, -0.6906664 ,  0.11192755,\n",
      "       -0.00996035,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17243595,  1.1164777 , -0.48022518, -0.6906664 ,  0.11192755,\n",
      "       -0.00996035,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1302487542457245, next_state=array([-0.17712994,  1.1010494 , -0.46966204, -0.68573153,  0.11219554,\n",
      "        0.00535985,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17712994,  1.1010494 , -0.46966204, -0.68573153,  0.11219554,\n",
      "        0.00535985,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5206335141992031, next_state=array([-0.18189764,  1.0850089 , -0.478926  , -0.71306586,  0.11433536,\n",
      "        0.04279621,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18189764,  1.0850089 , -0.478926  , -0.71306586,  0.11433536,\n",
      "        0.04279621,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5427095388291991, next_state=array([-0.18673047,  1.0683659 , -0.48709202, -0.73998815,  0.11811078,\n",
      "        0.07550872,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18673047,  1.0683659 , -0.48709202, -0.73998815,  0.11811078,\n",
      "        0.07550872,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9218917190253935, next_state=array([-0.1914978 ,  1.0525048 , -0.48132738, -0.70530593,  0.12268952,\n",
      "        0.09157483,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1914978 ,  1.0525048 , -0.48132738, -0.70530593,  0.12268952,\n",
      "        0.09157483,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9152002933372614, next_state=array([-0.19649334,  1.0373371 , -0.50359255, -0.67445767,  0.1267074 ,\n",
      "        0.0803576 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19649334,  1.0373371 , -0.50359255, -0.67445767,  0.1267074 ,\n",
      "        0.0803576 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1000969491168462, next_state=array([-0.20148893,  1.0215696 , -0.50359225, -0.7011257 ,  0.1307253 ,\n",
      "        0.08035751,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20148893,  1.0215696 , -0.50359225, -0.7011257 ,  0.1307253 ,\n",
      "        0.08035751,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.075484446423559, next_state=array([-0.20648447,  1.0052024 , -0.503592  , -0.72779363,  0.13474317,\n",
      "        0.08035742,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20648447,  1.0052024 , -0.503592  , -0.72779363,  0.13474317,\n",
      "        0.08035742,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8372705626595962, next_state=array([-0.21155648,  0.9882311 , -0.5131582 , -0.7548295 ,  0.14067803,\n",
      "        0.11869727,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21155648,  0.9882311 , -0.5131582 , -0.7548295 ,  0.14067803,\n",
      "        0.11869727,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.44884564609483735, next_state=array([-0.21655703,  0.970685  , -0.5041442 , -0.78021824,  0.14475763,\n",
      "        0.08159228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21655703,  0.970685  , -0.5041442 , -0.78021824,  0.14475763,\n",
      "        0.08159228,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6052111662000756, next_state=array([-0.22156405,  0.9539276 , -0.5053813 , -0.7452324 ,  0.14942445,\n",
      "        0.09333678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22156405,  0.9539276 , -0.5053813 , -0.7452324 ,  0.14942445,\n",
      "        0.09333678,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3729622210726109, next_state=array([-0.22649927,  0.9365912 , -0.4963464 , -0.7707945 ,  0.15223983,\n",
      "        0.05630773,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22649927,  0.9365912 , -0.4963464 , -0.7707945 ,  0.15223983,\n",
      "        0.05630773,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.911626501962985, next_state=array([-0.23143454,  0.91865486, -0.4963463 , -0.7974617 ,  0.15505521,\n",
      "        0.05630757,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23143454,  0.91865486, -0.4963463 , -0.7974617 ,  0.15505521,\n",
      "        0.05630757,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9092454262304546, next_state=array([-0.23646383,  0.9000884 , -0.50818133, -0.8257343 ,  0.16030613,\n",
      "        0.1050182 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23646383,  0.9000884 , -0.50818133, -0.8257343 ,  0.16030613,\n",
      "        0.1050182 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.950375396428824, next_state=array([-0.24157014,  0.8808922 , -0.5178933 , -0.85396534,  0.16757156,\n",
      "        0.14530858,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24157014,  0.8808922 , -0.5178933 , -0.85396534,  0.16757156,\n",
      "        0.14530858,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2480766984297702, next_state=array([-0.24667653,  0.8610967 , -0.5178922 , -0.8806363 ,  0.17483696,\n",
      "        0.14530808,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24667653,  0.8610967 , -0.5178922 , -0.8806363 ,  0.17483696,\n",
      "        0.14530808,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2205609234302983, next_state=array([-0.25178304,  0.8407019 , -0.51789105, -0.90730727,  0.18210234,\n",
      "        0.14530757,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25178304,  0.8407019 , -0.51789105, -0.90730727,  0.18210234,\n",
      "        0.14530757,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1315886878137165, next_state=array([-0.25698152,  0.81968665, -0.5294281 , -0.93521494,  0.19172473,\n",
      "        0.19244808,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25698152,  0.81968665, -0.5294281 , -0.93521494,  0.19172473,\n",
      "        0.19244808,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.47044021804558045, next_state=array([-0.2620844 ,  0.7980984 , -0.5173992 , -0.96042055,  0.19887696,\n",
      "        0.143045  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2620844 ,  0.7980984 , -0.5173992 , -0.96042055,  0.19887696,\n",
      "        0.143045  ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.404283537804088, next_state=array([-0.26733097,  0.77710336, -0.5318309 , -0.93409   ,  0.20610413,\n",
      "        0.1445433 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26733097,  0.77710336, -0.5318309 , -0.93409   ,  0.20610413,\n",
      "        0.1445433 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.25822795303591195, next_state=array([-0.2724854 ,  0.7555418 , -0.5202086 , -0.95896477,  0.2109143 ,\n",
      "        0.09620328,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2724854 ,  0.7555418 , -0.5202086 , -0.95896477,  0.2109143 ,\n",
      "        0.09620328,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9323155040051461, next_state=array([-0.27763993,  0.7333805 , -0.520208  , -0.98563325,  0.21572445,\n",
      "        0.09620307,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27763993,  0.7333805 , -0.520208  , -0.98563325,  0.21572445,\n",
      "        0.09620307,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5236492150399659, next_state=array([-0.28285295,  0.71060145, -0.527573  , -1.0133306 ,  0.22205867,\n",
      "        0.12668444,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28285295,  0.71060145, -0.527573  , -1.0133306 ,  0.22205867,\n",
      "        0.12668444,  0.        ,  0.        ], dtype=float32), action=2, reward=2.478723140876707, next_state=array([-0.2881894 ,  0.68837714, -0.54012907, -0.988739  ,  0.22861959,\n",
      "        0.13121855,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2881894 ,  0.68837714, -0.54012907, -0.988739  ,  0.22861959,\n",
      "        0.13121855,  0.        ,  0.        ], dtype=float32), action=2, reward=2.015809434998528, next_state=array([-0.29350868,  0.6664613 , -0.5390922 , -0.97516835,  0.23589288,\n",
      "        0.1454656 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29350868,  0.6664613 , -0.5390922 , -0.97516835,  0.23589288,\n",
      "        0.1454656 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3319783787262454, next_state=array([-0.29897118,  0.64516443, -0.5536418 , -0.9477284 ,  0.24339938,\n",
      "        0.15013012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29897118,  0.64516443, -0.5536418 , -0.9477284 ,  0.24339938,\n",
      "        0.15013012,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5845597128414954, next_state=array([-0.3043661 ,  0.62330276, -0.5450655 , -0.97256434,  0.24907197,\n",
      "        0.11345148,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3043661 ,  0.62330276, -0.5450655 , -0.97256434,  0.24907197,\n",
      "        0.11345148,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1355251463092486, next_state=array([-0.3097611 ,  0.60084146, -0.54506457, -0.9992336 ,  0.25474453,\n",
      "        0.11345126,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3097611 ,  0.60084146, -0.54506457, -0.9992336 ,  0.25474453,\n",
      "        0.11345126,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4016975271507863, next_state=array([-0.3150805 ,  0.57780296, -0.5355691 , -1.0245669 ,  0.25844997,\n",
      "        0.07410907,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3150805 ,  0.57780296, -0.5355691 , -1.0245669 ,  0.25844997,\n",
      "        0.07410907,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7578031164617574, next_state=array([-0.320479  ,  0.55414075, -0.54549444, -1.0526592 ,  0.26421455,\n",
      "        0.115292  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.320479  ,  0.55414075, -0.54549444, -1.0526592 ,  0.26421455,\n",
      "        0.115292  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7940206890241075, next_state=array([-0.32593846,  0.52985716, -0.55314696, -1.0805855 ,  0.27158266,\n",
      "        0.14736243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32593846,  0.52985716, -0.55314696, -1.0805855 ,  0.27158266,\n",
      "        0.14736243,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3093951615107073, next_state=array([-0.3313981 ,  0.50497437, -0.5531452 , -1.1072565 ,  0.27895075,\n",
      "        0.1473616 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3313981 ,  0.50497437, -0.5531452 , -1.1072565 ,  0.27895075,\n",
      "        0.1473616 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5773538392613886, next_state=array([-0.33726364,  0.4807816 , -0.59303653, -1.0764863 ,  0.28560808,\n",
      "        0.13314654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33726364,  0.4807816 , -0.59303653, -1.0764863 ,  0.28560808,\n",
      "        0.13314654,  0.        ,  0.        ], dtype=float32), action=2, reward=1.544121877557285, next_state=array([-0.34335226,  0.45712018, -0.6153182 , -1.0528967 ,  0.2922579 ,\n",
      "        0.13299644,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34335226,  0.45712018, -0.6153182 , -1.0528967 ,  0.2922579 ,\n",
      "        0.13299644,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7795902238583199, next_state=array([-0.34937915,  0.4328863 , -0.6075226 , -1.0780395 ,  0.29724678,\n",
      "        0.09977755,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34937915,  0.4328863 , -0.6075226 , -1.0780395 ,  0.29724678,\n",
      "        0.09977755,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2780002503269245, next_state=array([-0.3554895 ,  0.40801278, -0.61805475, -1.1069432 ,  0.30449998,\n",
      "        0.14506422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3554895 ,  0.40801278, -0.61805475, -1.1069432 ,  0.30449998,\n",
      "        0.14506422,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9326067310002191, next_state=array([-0.361542  ,  0.38257515, -0.6106875 , -1.1317132 ,  0.31013048,\n",
      "        0.11260972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.361542  ,  0.38257515, -0.6106875 , -1.1317132 ,  0.31013048,\n",
      "        0.11260972,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6761718136881416, next_state=array([-0.36751762,  0.35657382, -0.60098255, -1.156348  ,  0.31367582,\n",
      "        0.07090659,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36751762,  0.35657382, -0.60098255, -1.156348  ,  0.31367582,\n",
      "        0.07090659,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0396009035810594, next_state=array([-0.37355247,  0.32994297, -0.6084576 , -1.1846776 ,  0.31883895,\n",
      "        0.10326307,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37355247,  0.32994297, -0.6084576 , -1.1846776 ,  0.31883895,\n",
      "        0.10326307,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4837106246600613, next_state=array([-0.37966838,  0.30268013, -0.61862504, -1.2132443 ,  0.32616046,\n",
      "        0.14643039,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37966838,  0.30268013, -0.61862504, -1.2132443 ,  0.32616046,\n",
      "        0.14643039,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3177598776481705, next_state=array([-0.3857247 ,  0.27484468, -0.61110693, -1.2383784 ,  0.33187017,\n",
      "        0.1141939 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3857247 ,  0.27484468, -0.61110693, -1.2383784 ,  0.33187017,\n",
      "        0.1141939 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2828883263061346, next_state=array([-0.39172372,  0.24644108, -0.6038477 , -1.2632937 ,  0.3359897 ,\n",
      "        0.08239092,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39172372,  0.24644108, -0.6038477 , -1.2632937 ,  0.3359897 ,\n",
      "        0.08239092,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8997975445771533, next_state=array([-0.39763457,  0.21749312, -0.59263325, -1.2869393 ,  0.33761236,\n",
      "        0.03245281,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39763457,  0.21749312, -0.59263325, -1.2869393 ,  0.33761236,\n",
      "        0.03245281,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.555415341885548, next_state=array([-0.4036095 ,  0.18790092, -0.60080737, -1.3159883 ,  0.341078  ,\n",
      "        0.0693136 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4036095 ,  0.18790092, -0.60080737, -1.3159883 ,  0.341078  ,\n",
      "        0.0693136 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.036464309597504, next_state=array([-0.40966287,  0.1576639 , -0.61073476, -1.3451556 ,  0.3467334 ,\n",
      "        0.11310749,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40966287,  0.1576639 , -0.61073476, -1.3451556 ,  0.3467334 ,\n",
      "        0.11310749,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5656009077380872, next_state=array([-0.4157164 ,  0.1268273 , -0.61073333, -1.3718247 ,  0.35238874,\n",
      "        0.11310723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4157164 ,  0.1268273 , -0.61073333, -1.3718247 ,  0.35238874,\n",
      "        0.11310723,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.459006015809648, next_state=array([-0.4218293 ,  0.09535748, -0.61823153, -1.4003748 ,  0.359699  ,\n",
      "        0.14620528,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4218293 ,  0.09535748, -0.61823153, -1.4003748 ,  0.359699  ,\n",
      "        0.14620528,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5219715916494736, next_state=array([-0.42787766,  0.06332418, -0.6100572 , -1.425023  ,  0.36520842,\n",
      "        0.11018827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42787766,  0.06332418, -0.6100572 , -1.425023  ,  0.36520842,\n",
      "        0.11018827,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.434530091589606, next_state=array([-0.43384767,  0.0307372 , -0.60012573, -1.4491098 ,  0.36851192,\n",
      "        0.06606923,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43384767,  0.0307372 , -0.60012573, -1.4491098 ,  0.36851192,\n",
      "        0.06606923,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.240023312381992, next_state=array([-0.43990558, -0.00249698, -0.6112145 , -1.4784813 ,  0.374255  ,\n",
      "        0.11486163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43990558, -0.00249698, -0.6112145 , -1.4784813 ,  0.374255  ,\n",
      "        0.11486163,  0.        ,  0.        ], dtype=float32), action=0, reward=11.399680710752676, next_state=array([-0.4461568 , -0.03563482, -0.61096156, -1.468771  ,  0.36165982,\n",
      "       -0.24864161,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.4461568 , -0.03563482, -0.61096156, -1.468771  ,  0.36165982,\n",
      "       -0.24864161,  0.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-4.5522586e-01, -5.3044427e-02, -1.1365930e+00, -3.1962642e-01,\n",
      "        3.9936048e-01, -5.0213049e-07,  1.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([-0.00584488,  1.4083649 , -0.5920402 , -0.11357979,  0.00677956,\n",
      "        0.13410594,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1722240724630695, next_state=array([-0.01177673,  1.4061533 , -0.59949195, -0.09833387,  0.01300956,\n",
      "        0.12461229,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01177673,  1.4061533 , -0.59949195, -0.09833387,  0.01300956,\n",
      "        0.12461229,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8381225502936047, next_state=array([-0.01770887,  1.4033419 , -0.5995114 , -0.12501337,  0.01923606,\n",
      "        0.12454146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01770887,  1.4033419 , -0.5995114 , -0.12501337,  0.01923606,\n",
      "        0.12454146,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4962605873092809, next_state=array([-0.02354565,  1.3999455 , -0.58754146, -0.15101057,  0.02305297,\n",
      "        0.0763452 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02354565,  1.3999455 , -0.58754146, -0.15101057,  0.02305297,\n",
      "        0.0763452 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9775969286215787, next_state=array([-0.02946682,  1.3959408 , -0.59811693, -0.1780872 ,  0.02899186,\n",
      "        0.11878874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02946682,  1.3959408 , -0.59811693, -0.1780872 ,  0.02899186,\n",
      "        0.11878874,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6775590777928813, next_state=array([-0.03544617,  1.3922509 , -0.60373914, -0.16411823,  0.03473533,\n",
      "        0.11488005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03544617,  1.3922509 , -0.60373914, -0.16411823,  0.03473533,\n",
      "        0.11488005,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9157793406336907, next_state=array([-0.04142561,  1.3879611 , -0.6037555 , -0.19079652,  0.04047853,\n",
      "        0.11487458,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04142561,  1.3879611 , -0.6037555 , -0.19079652,  0.04047853,\n",
      "        0.11487458,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.960268423425191, next_state=array([-0.04740534,  1.383072  , -0.60377234, -0.21746412,  0.04622075,\n",
      "        0.11485492,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04740534,  1.383072  , -0.60377234, -0.21746412,  0.04622075,\n",
      "        0.11485492,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.093701378809402, next_state=array([-0.05350437,  1.3784446 , -0.61525834, -0.20584247,  0.05152172,\n",
      "        0.10602902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05350437,  1.3784446 , -0.61525834, -0.20584247,  0.05152172,\n",
      "        0.10602902,  0.        ,  0.        ], dtype=float32), action=3, reward=0.2736425535176761, next_state=array([-0.05951691,  1.3732147 , -0.604404  , -0.23254323,  0.05464677,\n",
      "        0.06250683,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05951691,  1.3732147 , -0.604404  , -0.23254323,  0.05464677,\n",
      "        0.06250683,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.46839431357493594, next_state=array([-0.06562634,  1.3683338 , -0.6138046 , -0.2170403 ,  0.05747662,\n",
      "        0.0566024 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06562634,  1.3683338 , -0.6138046 , -0.2170403 ,  0.05747662,\n",
      "        0.0566024 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.088828830322966, next_state=array([-0.07183151,  1.3628554 , -0.6257934 , -0.24369507,  0.06270295,\n",
      "        0.10453603,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07183151,  1.3628554 , -0.6257934 , -0.24369507,  0.06270295,\n",
      "        0.10453603,  0.        ,  0.        ], dtype=float32), action=3, reward=0.15561620019508496, next_state=array([-0.07795668,  1.3567891 , -0.61573863, -0.2697579 ,  0.06589834,\n",
      "        0.06391361,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07795668,  1.3567891 , -0.61573863, -0.2697579 ,  0.06589834,\n",
      "        0.06391361,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.01762953136355236, next_state=array([-0.08402185,  1.3501165 , -0.6082335 , -0.2966357 ,  0.06759746,\n",
      "        0.0339854 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08402185,  1.3501165 , -0.6082335 , -0.2966357 ,  0.06759746,\n",
      "        0.0339854 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5931899959886107, next_state=array([-0.08999338,  1.3428621 , -0.59646624, -0.3223831 ,  0.0669189 ,\n",
      "       -0.01357226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08999338,  1.3428621 , -0.59646624, -0.3223831 ,  0.0669189 ,\n",
      "       -0.01357226,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.468858004590827, next_state=array([-0.09603348,  1.3349993 , -0.6050808 , -0.34951097,  0.06797586,\n",
      "        0.0211411 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09603348,  1.3349993 , -0.6050808 , -0.34951097,  0.06797586,\n",
      "        0.0211411 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7435126617188075, next_state=array([-0.10210352,  1.3274634 , -0.6081308 , -0.33498225,  0.06908794,\n",
      "        0.02224378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10210352,  1.3274634 , -0.6081308 , -0.33498225,  0.06908794,\n",
      "        0.02224378,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5717111909099504, next_state=array([-0.10823889,  1.3193295 , -0.6163142 , -0.36163816,  0.07183506,\n",
      "        0.05494753,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10823889,  1.3193295 , -0.6163142 , -0.36163816,  0.07183506,\n",
      "        0.05494753,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8067484084084129, next_state=array([-0.11449728,  1.3111911 , -0.62817246, -0.36182135,  0.07414009,\n",
      "        0.04610509,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11449728,  1.3111911 , -0.62817246, -0.36182135,  0.07414009,\n",
      "        0.04610509,  0.        ,  0.        ], dtype=float32), action=3, reward=0.3569676648115785, next_state=array([-0.1206707 ,  1.3024706 , -0.61748177, -0.38758442,  0.0742828 ,\n",
      "        0.00285416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1206707 ,  1.3024706 , -0.61748177, -0.38758442,  0.0742828 ,\n",
      "        0.00285416,  0.        ,  0.        ], dtype=float32), action=2, reward=1.404778485069454, next_state=array([-0.12689266,  1.2943578 , -0.62238467, -0.36056882,  0.07447863,\n",
      "        0.0039169 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12689266,  1.2943578 , -0.62238467, -0.36056882,  0.07447863,\n",
      "        0.0039169 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5886683339565479, next_state=array([-0.13311453,  1.285645  , -0.62238395, -0.38724694,  0.07467397,\n",
      "        0.00390716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13311453,  1.285645  , -0.62238395, -0.38724694,  0.07467397,\n",
      "        0.00390716,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.653325363943735, next_state=array([-0.13941412,  1.2763296 , -0.63213253, -0.4141217 ,  0.07682257,\n",
      "        0.04297605,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13941412,  1.2763296 , -0.63213253, -0.4141217 ,  0.07682257,\n",
      "        0.04297605,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5940689589868497, next_state=array([-0.14578009,  1.2678237 , -0.6387928 , -0.37815478,  0.07899722,\n",
      "        0.0434971 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14578009,  1.2678237 , -0.6387928 , -0.37815478,  0.07899722,\n",
      "        0.0434971 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.38654723974272653, next_state=array([-0.15205574,  1.2587216 , -0.6274715 , -0.40452754,  0.07890133,\n",
      "       -0.0019179 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15205574,  1.2587216 , -0.6274715 , -0.40452754,  0.07890133,\n",
      "       -0.0019179 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.890446464476297, next_state=array([-0.15842552,  1.2489976 , -0.6393    , -0.43230408,  0.08119532,\n",
      "        0.04588011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15842552,  1.2489976 , -0.6393    , -0.43230408,  0.08119532,\n",
      "        0.04588011,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8124878552026757, next_state=array([-0.16479531,  1.2386736 , -0.6393    , -0.4589712 ,  0.08348933,\n",
      "        0.04588006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16479531,  1.2386736 , -0.6393    , -0.4589712 ,  0.08348933,\n",
      "        0.04588006,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1283747160781672, next_state=array([-0.17132464,  1.2291703 , -0.65486836, -0.4224802 ,  0.08541286,\n",
      "        0.03847063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17132464,  1.2291703 , -0.65486836, -0.4224802 ,  0.08541286,\n",
      "        0.03847063,  0.        ,  0.        ], dtype=float32), action=3, reward=0.23801047836329417, next_state=array([-1.7777625e-01,  1.2190770e+00, -6.4512712e-01, -4.4858834e-01,\n",
      "        8.5374638e-02, -7.6407427e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.7777625e-01,  1.2190770e+00, -6.4512712e-01, -4.4858834e-01,\n",
      "        8.5374638e-02, -7.6407427e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.12225070123246268, next_state=array([-0.18430205,  1.2089195 , -0.65234286, -0.45142528,  0.08513506,\n",
      "       -0.00479156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18430205,  1.2089195 , -0.65234286, -0.45142528,  0.08513506,\n",
      "       -0.00479156,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.523849062392485, next_state=array([-0.19089994,  1.1981565 , -0.66137254, -0.47845164,  0.08670879,\n",
      "        0.03147463,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19089994,  1.1981565 , -0.66137254, -0.47845164,  0.08670879,\n",
      "        0.03147463,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1548654384493602, next_state=array([-0.19760208,  1.1880006 , -0.6716484 , -0.45145622,  0.08812317,\n",
      "        0.02828779,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19760208,  1.1880006 , -0.6716484 , -0.45145622,  0.08812317,\n",
      "        0.02828779,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6917523205895282, next_state=array([-0.20437793,  1.1772425 , -0.6808734 , -0.47833312,  0.09138477,\n",
      "        0.06523181,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20437793,  1.1772425 , -0.6808734 , -0.47833312,  0.09138477,\n",
      "        0.06523181,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.88719453888109, next_state=array([-0.21115375,  1.1658846 , -0.6808733 , -0.5050007 ,  0.09464633,\n",
      "        0.06523151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21115375,  1.1658846 , -0.6808733 , -0.5050007 ,  0.09464633,\n",
      "        0.06523151,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8887652628432647, next_state=array([-0.21792956,  1.1539268 , -0.6808731 , -0.5316683 ,  0.09790791,\n",
      "        0.06523154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21792956,  1.1539268 , -0.6808731 , -0.5316683 ,  0.09790791,\n",
      "        0.06523154,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.887763659653217, next_state=array([-0.22470541,  1.1413692 , -0.6808729 , -0.5583357 ,  0.10116947,\n",
      "        0.06523128,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22470541,  1.1413692 , -0.6808729 , -0.5583357 ,  0.10116947,\n",
      "        0.06523128,  0.        ,  0.        ], dtype=float32), action=2, reward=0.740313085841035, next_state=array([-0.2317307 ,  1.1296124 , -0.7051009 , -0.52270335,  0.10371828,\n",
      "        0.05097598,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2317307 ,  1.1296124 , -0.7051009 , -0.52270335,  0.10371828,\n",
      "        0.05097598,  0.        ,  0.        ], dtype=float32), action=3, reward=0.38401442174708333, next_state=array([-0.23865958,  1.1172602 , -0.6930167 , -0.54899424,  0.10384544,\n",
      "        0.00254324,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23865958,  1.1172602 , -0.6930167 , -0.54899424,  0.10384544,\n",
      "        0.00254324,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3962492035243759, next_state=array([-0.24565268,  1.1043072 , -0.7010566 , -0.57580906,  0.10557974,\n",
      "        0.03468617,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24565268,  1.1043072 , -0.7010566 , -0.57580906,  0.10557974,\n",
      "        0.03468617,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7221168523959136, next_state=array([-0.25264573,  1.0907544 , -0.7010566 , -0.60247594,  0.10731406,\n",
      "        0.03468626,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25264573,  1.0907544 , -0.7010566 , -0.60247594,  0.10731406,\n",
      "        0.03468626,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7167434487729452, next_state=array([-0.25963885,  1.0766015 , -0.70105654, -0.6291428 ,  0.10904837,\n",
      "        0.03468645,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25963885,  1.0766015 , -0.70105654, -0.6291428 ,  0.10904837,\n",
      "        0.03468645,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7083283276117232, next_state=array([-0.26670733,  1.0618255 , -0.7105491 , -0.656987  ,  0.11272098,\n",
      "        0.07345208,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26670733,  1.0618255 , -0.7105491 , -0.656987  ,  0.11272098,\n",
      "        0.07345208,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.11748275608769518, next_state=array([-0.2737115 ,  1.0464629 , -0.7024635 , -0.68293154,  0.11475386,\n",
      "        0.04065762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2737115 ,  1.0464629 , -0.7024635 , -0.68293154,  0.11475386,\n",
      "        0.04065762,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6641108092286447, next_state=array([-0.28078994,  1.030483  , -0.711801  , -0.71053344,  0.11868494,\n",
      "        0.07862159,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28078994,  1.030483  , -0.711801  , -0.71053344,  0.11868494,\n",
      "        0.07862159,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0761273836160954, next_state=array([-0.28796586,  1.0138896 , -0.724032  , -0.7380103 ,  0.12508442,\n",
      "        0.1279896 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28796586,  1.0138896 , -0.724032  , -0.7380103 ,  0.12508442,\n",
      "        0.1279896 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.33316478788199677, next_state=array([-0.2950779 ,  0.9967203 , -0.7159652 , -0.76348346,  0.12982458,\n",
      "        0.09480322,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2950779 ,  0.9967203 , -0.7159652 , -0.76348346,  0.12982458,\n",
      "        0.09480322,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9398676588115507, next_state=array([-0.30218998,  0.9789514 , -0.71596485, -0.79015195,  0.13456473,\n",
      "        0.09480305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30218998,  0.9789514 , -0.71596485, -0.79015195,  0.13456473,\n",
      "        0.09480305,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8552728911329257, next_state=array([-0.30937743,  0.9605636 , -0.7254429 , -0.81785434,  0.14123838,\n",
      "        0.13347284,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30937743,  0.9605636 , -0.7254429 , -0.81785434,  0.14123838,\n",
      "        0.13347284,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.0919416919754201, next_state=array([-0.31647366,  0.9415893 , -0.7140023 , -0.8437253 ,  0.14560139,\n",
      "        0.08726022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31647366,  0.9415893 , -0.7140023 , -0.8437253 ,  0.14560139,\n",
      "        0.08726022,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.12166627954590467, next_state=array([-0.32350206,  0.9220286 , -0.70547616, -0.869623  ,  0.14823282,\n",
      "        0.05262846,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32350206,  0.9220286 , -0.70547616, -0.869623  ,  0.14823282,\n",
      "        0.05262846,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2556936580648255, next_state=array([-0.33078045,  0.90298605, -0.72983783, -0.84653026,  0.1502291 ,\n",
      "        0.03992555,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33078045,  0.90298605, -0.72983783, -0.84653026,  0.1502291 ,\n",
      "        0.03992555,  0.        ,  0.        ], dtype=float32), action=3, reward=0.11419645996980535, next_state=array([-0.33798814,  0.8833529 , -0.72097576, -0.87260336,  0.15043713,\n",
      "        0.00416056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33798814,  0.8833529 , -0.72097576, -0.87260336,  0.15043713,\n",
      "        0.00416056,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2332898025781833, next_state=array([-0.34526062,  0.86310667, -0.72911483, -0.90002185,  0.1522993 ,\n",
      "        0.03724335,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34526062,  0.86310667, -0.72911483, -0.90002185,  0.1522993 ,\n",
      "        0.03724335,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7325287873166078, next_state=array([-0.35246858,  0.84326047, -0.7234263 , -0.8823296 ,  0.15492365,\n",
      "        0.05248708,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35246858,  0.84326047, -0.7234263 , -0.8823296 ,  0.15492365,\n",
      "        0.05248708,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7401984866098132, next_state=array([-0.35967654,  0.82281417, -0.72342616, -0.9089969 ,  0.157548  ,\n",
      "        0.05248708,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35967654,  0.82281417, -0.72342616, -0.9089969 ,  0.157548  ,\n",
      "        0.05248708,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7337669420030579, next_state=array([-0.36688456,  0.80176806, -0.723426  , -0.9356641 ,  0.16017234,\n",
      "        0.05248705,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36688456,  0.80176806, -0.723426  , -0.9356641 ,  0.16017234,\n",
      "        0.05248705,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.728759518401688, next_state=array([-0.37409252,  0.780122  , -0.72342587, -0.96233135,  0.16279666,\n",
      "        0.05248674,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37409252,  0.780122  , -0.72342587, -0.96233135,  0.16279666,\n",
      "        0.05248674,  0.        ,  0.        ], dtype=float32), action=3, reward=0.029202936443341515, next_state=array([-0.38122553,  0.75788283, -0.71403563, -0.9884888 ,  0.16353428,\n",
      "        0.01475253,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38122553,  0.75788283, -0.71403563, -0.9884888 ,  0.16353428,\n",
      "        0.01475253,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5520070159884642, next_state=array([-0.38845077,  0.73502916, -0.7256003 , -1.0160633 ,  0.16661271,\n",
      "        0.06156894,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38845077,  0.73502916, -0.7256003 , -1.0160633 ,  0.16661271,\n",
      "        0.06156894,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7699369694111624, next_state=array([-0.395676  ,  0.71157545, -0.72560006, -1.0427308 ,  0.16969116,\n",
      "        0.06156892,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.395676  ,  0.71157545, -0.72560006, -1.0427308 ,  0.16969116,\n",
      "        0.06156892,  0.        ,  0.        ], dtype=float32), action=2, reward=2.045340622639242, next_state=array([-0.40293527,  0.68846786, -0.7293354 , -1.0273998 ,  0.17310664,\n",
      "        0.06830953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40293527,  0.68846786, -0.7293354 , -1.0273998 ,  0.17310664,\n",
      "        0.06830953,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8195682909200286, next_state=array([-0.41033715,  0.66584   , -0.7435204 , -1.0060781 ,  0.17644496,\n",
      "        0.06676649,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41033715,  0.66584   , -0.7435204 , -1.0060781 ,  0.17644496,\n",
      "        0.06676649,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7646373934688426, next_state=array([-0.41801533,  0.6439326 , -0.7706017 , -0.9740001 ,  0.17923912,\n",
      "        0.05588318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41801533,  0.6439326 , -0.7706017 , -0.9740001 ,  0.17923912,\n",
      "        0.05588318,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9350151044450854, next_state=array([-0.4256935 ,  0.6214252 , -0.7706016 , -1.0006673 ,  0.18203329,\n",
      "        0.05588332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4256935 ,  0.6214252 , -0.7706016 , -1.0006673 ,  0.18203329,\n",
      "        0.05588332,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.046651973738902, next_state=array([-0.43346897,  0.5983035 , -0.7827816 , -1.0282847 ,  0.18729122,\n",
      "        0.10515833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43346897,  0.5983035 , -0.7827816 , -1.0282847 ,  0.18729122,\n",
      "        0.10515833,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.221099938172273, next_state=array([-0.44124445,  0.5745821 , -0.78278095, -1.0549535 ,  0.19254911,\n",
      "        0.10515821,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44124445,  0.5745821 , -0.78278095, -1.0549535 ,  0.19254911,\n",
      "        0.10515821,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0999700366831164, next_state=array([-0.4490888 ,  0.55023235, -0.79146427, -1.0831416 ,  0.19962397,\n",
      "        0.14149693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4490888 ,  0.55023235, -0.79146427, -1.0831416 ,  0.19962397,\n",
      "        0.14149693,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.553936304352645, next_state=array([-0.45702845,  0.5252602 , -0.8034091 , -1.1111737 ,  0.20914543,\n",
      "        0.19042912,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45702845,  0.5252602 , -0.8034091 , -1.1111737 ,  0.20914543,\n",
      "        0.19042912,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.23018129440977758, next_state=array([-0.46502382,  0.5003037 , -0.8091008 , -1.1105645 ,  0.21880847,\n",
      "        0.19326106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46502382,  0.5003037 , -0.8091008 , -1.1105645 ,  0.21880847,\n",
      "        0.19326106,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.843789983019576, next_state=array([-0.4730193 ,  0.47474828, -0.80909836, -1.1372386 ,  0.22847147,\n",
      "        0.1932599 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4730193 ,  0.47474828, -0.80909836, -1.1372386 ,  0.22847147,\n",
      "        0.1932599 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9039158493630453, next_state=array([-0.48101506,  0.44859418, -0.8090957 , -1.1639129 ,  0.23813441,\n",
      "        0.19325843,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48101506,  0.44859418, -0.8090957 , -1.1639129 ,  0.23813441,\n",
      "        0.19325843,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0818202637655918, next_state=array([-0.48893076,  0.42187142, -0.79899406, -1.1888973 ,  0.24568127,\n",
      "        0.15093711,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48893076,  0.42187142, -0.79899406, -1.1888973 ,  0.24568127,\n",
      "        0.15093711,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8430214555712325, next_state=array([-0.4968466 ,  0.39454946, -0.79899234, -1.2155684 ,  0.25322813,\n",
      "        0.15093657,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4968466 ,  0.39454946, -0.79899234, -1.2155684 ,  0.25322813,\n",
      "        0.15093657,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9686552790031431, next_state=array([-0.50467616,  0.36666477, -0.7880917 , -1.240214  ,  0.25847003,\n",
      "        0.10483825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.50467616,  0.36666477, -0.7880917 , -1.240214  ,  0.25847003,\n",
      "        0.10483825,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8033267754294968, next_state=array([-0.51250577,  0.33818042, -0.7880909 , -1.2668828 ,  0.26371193,\n",
      "        0.10483807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.51250577,  0.33818042, -0.7880909 , -1.2668828 ,  0.26371193,\n",
      "        0.10483807,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.707372825143635, next_state=array([-0.5204054 ,  0.30907333, -0.796878  , -1.2949109 ,  0.27078667,\n",
      "        0.14149502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5204054 ,  0.30907333, -0.796878  , -1.2949109 ,  0.27078667,\n",
      "        0.14149502,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.245347428987485, next_state=array([-0.52839357,  0.2793305 , -0.8080095 , -1.3236345 ,  0.28021723,\n",
      "        0.18861106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.52839357,  0.2793305 , -0.8080095 , -1.3236345 ,  0.28021723,\n",
      "        0.18861106,  0.        ,  0.        ], dtype=float32), action=0, reward=7.407059295043126, next_state=array([-0.5363819 ,  0.24898876, -0.80800664, -1.3503083 ,  0.28964773,\n",
      "        0.18860993,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.5363819 ,  0.24898876, -0.80800664, -1.3503083 ,  0.28964773,\n",
      "        0.18860993,  0.        ,  1.        ], dtype=float32), action=0, reward=6.667267674083064, next_state=array([-0.54388547,  0.22028512, -0.7727006 , -1.3039758 ,  0.28540096,\n",
      "       -0.13174807,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.54388547,  0.22028512, -0.7727006 , -1.3039758 ,  0.28540096,\n",
      "       -0.13174807,  0.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.55018556,  0.2061777 , -0.32243213, -0.34051052,  0.12927885,\n",
      "       -4.163306  ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-1.8196106e-04,  1.4173199e+00, -1.8439729e-02,  2.8443399e-01,\n",
      "        2.1756347e-04,  4.1768798e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.547721813194232, next_state=array([-3.5810471e-04,  1.4240698e+00, -1.7856965e-02,  2.9999205e-01,\n",
      "        4.5292461e-04,  4.7083134e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.5810471e-04,  1.4240698e+00, -1.7856965e-02,  2.9999205e-01,\n",
      "        4.5292461e-04,  4.7083134e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=1.7280491917028382, next_state=array([-6.1740878e-04,  1.4302125e+00, -2.8287685e-02,  2.7301124e-01,\n",
      "        2.7798121e-03,  4.6542190e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-6.1740878e-04,  1.4302125e+00, -2.8287685e-02,  2.7301124e-01,\n",
      "        2.7798121e-03,  4.6542190e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.624883926665734, next_state=array([-1.0034561e-03,  1.4366639e+00, -4.0357102e-02,  2.8671771e-01,\n",
      "        4.5059221e-03,  3.4525417e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.0034561e-03,  1.4366639e+00, -4.0357102e-02,  2.8671771e-01,\n",
      "        4.5059221e-03,  3.4525417e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=1.8810340055383676, next_state=array([-1.3895988e-03,  1.4425149e+00, -4.0361814e-02,  2.6004180e-01,\n",
      "        6.2326961e-03,  3.4539115e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.3895988e-03,  1.4425149e+00, -4.0361814e-02,  2.6004180e-01,\n",
      "        6.2326961e-03,  3.4539115e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.6858772927475796, next_state=array([-0.0018836 ,  1.4487019 , -0.05065159,  0.2749713 ,  0.00746189,\n",
      "        0.02458641,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0018836 ,  1.4487019 , -0.05065159,  0.2749713 ,  0.00746189,\n",
      "        0.02458641,  0.        ,  0.        ], dtype=float32), action=0, reward=1.9370894993299999, next_state=array([-0.0023778 ,  1.4542886 , -0.05065497,  0.24829537,  0.00869134,\n",
      "        0.02459107,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0023778 ,  1.4542886 , -0.05065497,  0.24829537,  0.00869134,\n",
      "        0.02459107,  0.        ,  0.        ], dtype=float32), action=1, reward=1.5725802355046892, next_state=array([-0.0029356 ,  1.4592829 , -0.05862896,  0.2219498 ,  0.01151719,\n",
      "        0.05652202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0029356 ,  1.4592829 , -0.05862896,  0.2219498 ,  0.01151719,\n",
      "        0.05652202,  0.        ,  0.        ], dtype=float32), action=0, reward=1.8448055030002024, next_state=array([-0.0034934 ,  1.4636773 , -0.05863756,  0.19528073,  0.01434191,\n",
      "        0.0564994 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0034934 ,  1.4636773 , -0.05863756,  0.19528073,  0.01434191,\n",
      "        0.0564994 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8403204526194543, next_state=array([-0.00408163,  1.4682426 , -0.061567  ,  0.20287906,  0.01705755,\n",
      "        0.05431793,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00408163,  1.4682426 , -0.061567  ,  0.20287906,  0.01705755,\n",
      "        0.05431793,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.114649801649608, next_state=array([-0.00468311,  1.4730492 , -0.06287739,  0.21359253,  0.01975569,\n",
      "        0.0539676 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00468311,  1.4730492 , -0.06287739,  0.21359253,  0.01975569,\n",
      "        0.0539676 ,  0.        ,  0.        ], dtype=float32), action=3, reward=2.282442028153413, next_state=array([-0.00520887,  1.4772584 , -0.05337378,  0.1870638 ,  0.02054619,\n",
      "        0.0158117 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00520887,  1.4772584 , -0.05337378,  0.1870638 ,  0.02054619,\n",
      "        0.0158117 ,  0.        ,  0.        ], dtype=float32), action=3, reward=2.6858289148086683, next_state=array([-0.00563622,  1.4808642 , -0.04103293,  0.16027571,  0.01886499,\n",
      "       -0.03362751,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00563622,  1.4808642 , -0.04103293,  0.16027571,  0.01886499,\n",
      "       -0.03362751,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.4367819859312645, next_state=array([-0.00613747,  1.4853306 , -0.04816131,  0.19852884,  0.0169223 ,\n",
      "       -0.03885765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00613747,  1.4853306 , -0.04816131,  0.19852884,  0.0169223 ,\n",
      "       -0.03885765,  0.        ,  0.        ], dtype=float32), action=1, reward=1.9484795553259755, next_state=array([-0.00670948,  1.4891909 , -0.05703058,  0.1715717 ,  0.01675985,\n",
      "       -0.00324931,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00670948,  1.4891909 , -0.05703058,  0.1715717 ,  0.01675985,\n",
      "       -0.00324931,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.6263564933664325, next_state=array([-0.00741882,  1.4936522 , -0.07018425,  0.19829322,  0.01601329,\n",
      "       -0.01493233,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00741882,  1.4936522 , -0.07018425,  0.19829322,  0.01601329,\n",
      "       -0.01493233,  0.        ,  0.        ], dtype=float32), action=3, reward=2.7153148315556463, next_state=array([-0.00804548,  1.4975157 , -0.05981444,  0.17173247,  0.01318991,\n",
      "       -0.05647276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00804548,  1.4975157 , -0.05981444,  0.17173247,  0.01318991,\n",
      "       -0.05647276,  0.        ,  0.        ], dtype=float32), action=3, reward=2.9184247279555975, next_state=array([-0.008599  ,  1.5007815 , -0.05063611,  0.14518109,  0.00852972,\n",
      "       -0.09321225,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.008599  ,  1.5007815 , -0.05063611,  0.14518109,  0.00852972,\n",
      "       -0.09321225,  0.        ,  0.        ], dtype=float32), action=0, reward=2.6878076663087427, next_state=array([-0.00915232,  1.5034475 , -0.05062245,  0.11851088,  0.00387056,\n",
      "       -0.09319156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00915232,  1.5034475 , -0.05062245,  0.11851088,  0.00387056,\n",
      "       -0.09319156,  0.        ,  0.        ], dtype=float32), action=1, reward=1.9312263450146656, next_state=array([-9.7791674e-03,  1.5055237e+00, -5.9846502e-02,  9.2278965e-02,\n",
      "        1.0618231e-03, -5.6179751e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.7791674e-03,  1.5055237e+00, -5.9846502e-02,  9.2278965e-02,\n",
      "        1.0618231e-03, -5.6179751e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.48177608921769205, next_state=array([-1.0303879e-02,  1.5077119e+00, -5.0107736e-02,  9.7256847e-02,\n",
      "       -1.2682695e-03, -4.6605971e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.0303879e-02,  1.5077119e+00, -5.0107736e-02,  9.7256847e-02,\n",
      "       -1.2682695e-03, -4.6605971e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=1.375857681236455, next_state=array([-1.0925102e-02,  1.5092928e+00, -6.2228840e-02,  7.0268147e-02,\n",
      "       -1.1685678e-03,  1.9943507e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.0925102e-02,  1.5092928e+00, -6.2228840e-02,  7.0268147e-02,\n",
      "       -1.1685678e-03,  1.9943507e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=1.699048183848646, next_state=array([-1.1546421e-02,  1.5102739e+00, -6.2229574e-02,  4.3602053e-02,\n",
      "       -1.0696667e-03,  1.9781906e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.1546421e-02,  1.5102739e+00, -6.2229574e-02,  4.3602053e-02,\n",
      "       -1.0696667e-03,  1.9781906e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=1.6948168144435283, next_state=array([-0.01210508,  1.5106494 , -0.05437991,  0.01668987, -0.00254278,\n",
      "       -0.02946484,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01210508,  1.5106494 , -0.05437991,  0.01668987, -0.00254278,\n",
      "       -0.02946484,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6241239572717052, next_state=array([-0.01272688,  1.5104134 , -0.06229173, -0.01048828, -0.00242984,\n",
      "        0.0022589 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01272688,  1.5104134 , -0.06229173, -0.01048828, -0.00242984,\n",
      "        0.0022589 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8896180941268881, next_state=array([-0.01334867,  1.5095559 , -0.06229602, -0.03811099, -0.00231756,\n",
      "        0.0022456 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01334867,  1.5095559 , -0.06229602, -0.03811099, -0.00231756,\n",
      "        0.0022456 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5278610990432355, next_state=array([-0.01397047,  1.5080984 , -0.06229603, -0.06477766, -0.00220527,\n",
      "        0.0022456 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01397047,  1.5080984 , -0.06229603, -0.06477766, -0.00220527,\n",
      "        0.0022456 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6102182421326006, next_state=array([-1.4610862e-02,  1.5073838e+00, -6.4054541e-02, -3.1758741e-02,\n",
      "       -2.1878663e-03,  3.4810993e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.4610862e-02,  1.5073838e+00, -6.4054541e-02, -3.1758741e-02,\n",
      "       -2.1878663e-03,  3.4810993e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=1.7451939780872407, next_state=array([-0.01511888,  1.5072443 , -0.05142775, -0.00619897, -0.00156585,\n",
      "        0.01244047,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01511888,  1.5072443 , -0.05142775, -0.00619897, -0.00156585,\n",
      "        0.01244047,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.19623562694942961, next_state=array([-0.01554718,  1.5065073 , -0.04142364, -0.03276236, -0.00294723,\n",
      "       -0.02762789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01554718,  1.5065073 , -0.04142364, -0.03276236, -0.00294723,\n",
      "       -0.02762789,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8094798764867732, next_state=array([-1.5964603e-02,  1.5065039e+00, -4.0374421e-02, -1.4988307e-04,\n",
      "       -4.2903814e-03, -2.6862973e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.5964603e-02,  1.5065039e+00, -4.0374421e-02, -1.4988307e-04,\n",
      "       -4.2903814e-03, -2.6862973e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.40641258656536366, next_state=array([-0.01619711,  1.5070196 , -0.02274324,  0.02292069, -0.00479328,\n",
      "       -0.01005801,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01619711,  1.5070196 , -0.02274324,  0.02292069, -0.00479328,\n",
      "       -0.01005801,  0.        ,  0.        ], dtype=float32), action=1, reward=0.02447729147195446, next_state=array([-0.01651306,  1.5069351 , -0.03320762, -0.00374906, -0.00320056,\n",
      "        0.03185455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01651306,  1.5069351 , -0.03320762, -0.00374906, -0.00320056,\n",
      "        0.03185455,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5463197524867656, next_state=array([-1.6901206e-02,  1.5062435e+00, -4.2268392e-02, -3.0738208e-02,\n",
      "        2.0632576e-04,  6.8137787e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.6901206e-02,  1.5062435e+00, -4.2268392e-02, -3.0738208e-02,\n",
      "        2.0632576e-04,  6.8137787e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.7064783892694095, next_state=array([-0.01735382,  1.5057185 , -0.04840929, -0.0233318 ,  0.00331569,\n",
      "        0.06218717,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01735382,  1.5057185 , -0.04840929, -0.0233318 ,  0.00331569,\n",
      "        0.06218717,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2179886254427686, next_state=array([-0.01774282,  1.5060472 , -0.04236325,  0.01459523,  0.00673413,\n",
      "        0.06836896,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01774282,  1.5060472 , -0.04236325,  0.01459523,  0.00673413,\n",
      "        0.06836896,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9028670111754196, next_state=array([-0.01822529,  1.5066203 , -0.05128633,  0.02544856,  0.00973791,\n",
      "        0.06007544,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01822529,  1.5066203 , -0.05128633,  0.02544856,  0.00973791,\n",
      "        0.06007544,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7371895783137916, next_state=array([-0.01884604,  1.507154  , -0.06448558,  0.02370002,  0.01211874,\n",
      "        0.04761637,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01884604,  1.507154  , -0.06448558,  0.02370002,  0.01211874,\n",
      "        0.04761637,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9789979320657085, next_state=array([-0.01954193,  1.5070887 , -0.07392056, -0.00294632,  0.01638881,\n",
      "        0.08540169,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01954193,  1.5070887 , -0.07392056, -0.00294632,  0.01638881,\n",
      "        0.08540169,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9266928196224171, next_state=array([-0.02023792,  1.5064235 , -0.07392053, -0.02961452,  0.02065888,\n",
      "        0.08540156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02023792,  1.5064235 , -0.07392053, -0.02961452,  0.02065888,\n",
      "        0.08540156,  0.        ,  0.        ], dtype=float32), action=2, reward=0.804165236019952, next_state=array([-0.02082377,  1.5065119 , -0.06351123,  0.00385626,  0.02552457,\n",
      "        0.09731364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02082377,  1.5065119 , -0.06351123,  0.00385626,  0.02552457,\n",
      "        0.09731364,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.4100983051266267, next_state=array([-0.02145052,  1.507437  , -0.06752495,  0.04101614,  0.03031411,\n",
      "        0.09579068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02145052,  1.507437  , -0.06752495,  0.04101614,  0.03031411,\n",
      "        0.09579068,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7830377329797489, next_state=array([-0.02216053,  1.5077691 , -0.0779608 ,  0.01461288,  0.03718957,\n",
      "        0.13750918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02216053,  1.5077691 , -0.0779608 ,  0.01461288,  0.03718957,\n",
      "        0.13750918,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5566293721984448, next_state=array([-0.02278996,  1.5075076 , -0.06784587, -0.01175856,  0.04203656,\n",
      "        0.09693999,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02278996,  1.5075076 , -0.06784587, -0.01175856,  0.04203656,\n",
      "        0.09693999,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.157995802051714, next_state=array([-0.02347917,  1.5066445 , -0.07534825, -0.03855507,  0.04838675,\n",
      "        0.12700364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02347917,  1.5066445 , -0.07534825, -0.03855507,  0.04838675,\n",
      "        0.12700364,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9526064021908371, next_state=array([-0.02408018,  1.505192  , -0.0642647 , -0.06468964,  0.05251011,\n",
      "        0.08246695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02408018,  1.505192  , -0.0642647 , -0.06468964,  0.05251011,\n",
      "        0.08246695,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4517046417244035, next_state=array([-0.02459564,  1.5031492 , -0.05354057, -0.09086687,  0.05447901,\n",
      "        0.03937798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02459564,  1.5031492 , -0.05354057, -0.09086687,  0.05447901,\n",
      "        0.03937798,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.06598783724442, next_state=array([-0.02519541,  1.5004958 , -0.06412455, -0.11808599,  0.05857575,\n",
      "        0.08193497,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02519541,  1.5004958 , -0.06412455, -0.11808599,  0.05857575,\n",
      "        0.08193497,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7573068746029026, next_state=array([-0.02570305,  1.4972615 , -0.05254375, -0.143813  ,  0.0603364 ,\n",
      "        0.0352127 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02570305,  1.4972615 , -0.05254375, -0.143813  ,  0.0603364 ,\n",
      "        0.0352127 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.321819834478589, next_state=array([-0.02621078,  1.4934274 , -0.05254372, -0.17047994,  0.06209704,\n",
      "        0.03521268,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02621078,  1.4934274 , -0.05254372, -0.17047994,  0.06209704,\n",
      "        0.03521268,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.13416565470454883, next_state=array([-0.02668924,  1.4895713 , -0.04987594, -0.17146976,  0.06410293,\n",
      "        0.04011778,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02668924,  1.4895713 , -0.04987594, -0.17146976,  0.06410293,\n",
      "        0.04011778,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8728428875174756, next_state=array([-0.02740383,  1.4863942 , -0.07264389, -0.14125866,  0.06527131,\n",
      "        0.02336763,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02740383,  1.4863942 , -0.07264389, -0.14125866,  0.06527131,\n",
      "        0.02336763,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5690296095384884, next_state=array([-0.02804422,  1.4826336 , -0.06331693, -0.16710371,  0.06455548,\n",
      "       -0.01431637,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02804422,  1.4826336 , -0.06331693, -0.16710371,  0.06455548,\n",
      "       -0.01431637,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4868596438336954, next_state=array([-0.02859659,  1.4782747 , -0.05228256, -0.19360314,  0.06163041,\n",
      "       -0.05850119,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02859659,  1.4782747 , -0.05228256, -0.19360314,  0.06163041,\n",
      "       -0.05850119,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4372786780833153, next_state=array([-0.02924013,  1.4732972 , -0.06372042, -0.22119713,  0.06101326,\n",
      "       -0.01234317,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02924013,  1.4732972 , -0.06372042, -0.22119713,  0.06101326,\n",
      "       -0.01234317,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9550505344366513, next_state=array([-0.02988357,  1.4677197 , -0.06372043, -0.24786384,  0.06039611,\n",
      "       -0.0123432 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02988357,  1.4677197 , -0.06372043, -0.24786384,  0.06039611,\n",
      "       -0.0123432 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4999603529525973, next_state=array([-0.03044758,  1.4615483 , -0.05374893, -0.27418122,  0.05777769,\n",
      "       -0.05236852,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03044758,  1.4615483 , -0.05374893, -0.27418122,  0.05777769,\n",
      "       -0.05236852,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3297625674112499, next_state=array([-0.03092785,  1.4547766 , -0.04325503, -0.3007811 ,  0.05305978,\n",
      "       -0.09435818,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03092785,  1.4547766 , -0.04325503, -0.3007811 ,  0.05305978,\n",
      "       -0.09435818,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.434175997221729, next_state=array([-0.03140821,  1.4474056 , -0.04325487, -0.32744965,  0.04834188,\n",
      "       -0.09435804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03140821,  1.4474056 , -0.04325487, -0.32744965,  0.04834188,\n",
      "       -0.09435804,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0271567280542786, next_state=array([-0.031808  ,  1.4394492 , -0.03314602, -0.35341337,  0.04158903,\n",
      "       -0.13505732,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.031808  ,  1.4394492 , -0.03314602, -0.35341337,  0.04158903,\n",
      "       -0.13505732,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1264360205948662, next_state=array([-0.03220787,  1.4308933 , -0.03314576, -0.38008386,  0.03483617,\n",
      "       -0.13505688,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03220787,  1.4308933 , -0.03314576, -0.38008386,  0.03483617,\n",
      "       -0.13505688,  0.        ,  0.        ], dtype=float32), action=2, reward=5.022639329151258, next_state=array([-0.03271427,  1.423234  , -0.04347075, -0.34026518,  0.02775115,\n",
      "       -0.14170045,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03271427,  1.423234  , -0.04347075, -0.34026518,  0.02775115,\n",
      "       -0.14170045,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1141523122181525, next_state=array([-0.03322077,  1.4149753 , -0.04347055, -0.3669361 ,  0.02066614,\n",
      "       -0.14169994,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03322077,  1.4149753 , -0.04347055, -0.3669361 ,  0.02066614,\n",
      "       -0.14169994,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0569731383826877, next_state=array([-0.03372717,  1.4061174 , -0.0434704 , -0.39360696,  0.01358116,\n",
      "       -0.14169946,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03372717,  1.4061174 , -0.0434704 , -0.39360696,  0.01358116,\n",
      "       -0.14169946,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8113731130433155, next_state=array([-0.03416653,  1.3966532 , -0.03505009, -0.42057624,  0.00481164,\n",
      "       -0.17539063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03416653,  1.3966532 , -0.03505009, -0.42057624,  0.00481164,\n",
      "       -0.17539063,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7096482689505297, next_state=array([-0.0345272 ,  1.3865948 , -0.02517647, -0.44704485, -0.00593553,\n",
      "       -0.21494333,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0345272 ,  1.3865948 , -0.02517647, -0.44704485, -0.00593553,\n",
      "       -0.21494333,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.610045249449142, next_state=array([-0.03495598,  1.3759319 , -0.03372878, -0.4739689 , -0.01497046,\n",
      "       -0.18069868,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03495598,  1.3759319 , -0.03372878, -0.4739689 , -0.01497046,\n",
      "       -0.18069868,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3187807644184886, next_state=array([-0.03537684,  1.3653743 , -0.03293652, -0.46933824, -0.02400098,\n",
      "       -0.18061057,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03537684,  1.3653743 , -0.03293652, -0.46933824, -0.02400098,\n",
      "       -0.18061057,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4500651891948166, next_state=array([-0.03579769,  1.354218  , -0.03293672, -0.49601176, -0.03303145,\n",
      "       -0.18060961,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03579769,  1.354218  , -0.03293672, -0.49601176, -0.03303145,\n",
      "       -0.18060961,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6122533804955013, next_state=array([-0.03614969,  1.342449  , -0.02429646, -0.5233503 , -0.04379965,\n",
      "       -0.2153645 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03614969,  1.342449  , -0.02429646, -0.5233503 , -0.04379965,\n",
      "       -0.2153645 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.692315221685361, next_state=array([-0.03643532,  1.3300781 , -0.01598653, -0.5502292 , -0.05623385,\n",
      "       -0.24868388,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03643532,  1.3300781 , -0.01598653, -0.5502292 , -0.05623385,\n",
      "       -0.24868388,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.614701539387056, next_state=array([-0.03672094,  1.3171093 , -0.01598749, -0.57690877, -0.06866792,\n",
      "       -0.24868122,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03672094,  1.3171093 , -0.01598749, -0.57690877, -0.06866792,\n",
      "       -0.24868122,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.805844628907549, next_state=array([-0.0369236 ,  1.3035381 , -0.00559396, -0.60390407, -0.08318681,\n",
      "       -0.29037797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0369236 ,  1.3035381 , -0.00559396, -0.60390407, -0.08318681,\n",
      "       -0.29037797,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.704491305888638, next_state=array([-0.03712606,  1.2893696 , -0.00559596, -0.63058835, -0.0977055 ,\n",
      "       -0.29037374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03712606,  1.2893696 , -0.00559596, -0.63058835, -0.0977055 ,\n",
      "       -0.29037374,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9365171211811956, next_state=array([-0.0372385 ,  1.2745994 ,  0.00564936, -0.65764105, -0.11447925,\n",
      "       -0.33547527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0372385 ,  1.2745994 ,  0.00564936, -0.65764105, -0.11447925,\n",
      "       -0.33547527,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5298120165873272, next_state=array([-0.03744144,  1.2592472 , -0.00574126, -0.68350655, -0.12895164,\n",
      "       -0.2894477 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03744144,  1.2592472 , -0.00574126, -0.68350655, -0.12895164,\n",
      "       -0.2894477 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7880019685833006, next_state=array([-0.03757668,  1.2432861 ,  0.00272832, -0.7108675 , -0.14513941,\n",
      "       -0.32375553,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03757668,  1.2432861 ,  0.00272832, -0.7108675 , -0.14513941,\n",
      "       -0.32375553,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.447809955556379, next_state=array([-0.03777752,  1.226736  , -0.00553943, -0.7370442 , -0.15966156,\n",
      "       -0.29044294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03777752,  1.226736  , -0.00553943, -0.7370442 , -0.15966156,\n",
      "       -0.29044294,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4072502987640405, next_state=array([-0.03797808,  1.2095885 , -0.00554345, -0.7637283 , -0.17418352,\n",
      "       -0.2904387 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03797808,  1.2095885 , -0.00554345, -0.7637283 , -0.17418352,\n",
      "       -0.2904387 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6966965507218377, next_state=array([-0.0381012 ,  1.1918219 ,  0.00414288, -0.7916447 , -0.19069728,\n",
      "       -0.330276  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0381012 ,  1.1918219 ,  0.00414288, -0.7916447 , -0.19069728,\n",
      "       -0.330276  ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1722380648242394, next_state=array([-0.03797388,  1.1745996 ,  0.02866492, -0.76757044, -0.20674233,\n",
      "       -0.3209012 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03797388,  1.1745996 ,  0.02866492, -0.76757044, -0.20674233,\n",
      "       -0.3209012 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8522297942891712, next_state=array([-0.03778095,  1.1567571 ,  0.03685878, -0.7955608 , -0.22449544,\n",
      "       -0.35506234,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03778095,  1.1567571 ,  0.03685878, -0.7955608 , -0.22449544,\n",
      "       -0.35506234,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.05298652680325516, next_state=array([-0.03747883,  1.1389867 ,  0.04767531, -0.7925604 , -0.2422172 ,\n",
      "       -0.35443482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03747883,  1.1389867 ,  0.04767531, -0.7925604 , -0.2422172 ,\n",
      "       -0.35443482,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6000048856996614, next_state=array([-0.03717613,  1.1206203 ,  0.04766621, -0.81925267, -0.25993857,\n",
      "       -0.35442716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03717613,  1.1206203 ,  0.04766621, -0.81925267, -0.25993857,\n",
      "       -0.35442716,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.214777540114311, next_state=array([-0.03694105,  1.101681  ,  0.03908166, -0.84458894, -0.27586842,\n",
      "       -0.318597  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03694105,  1.101681  ,  0.03908166, -0.84458894, -0.27586842,\n",
      "       -0.318597  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.804729121918426, next_state=array([-0.03661957,  1.0821117 ,  0.04983651, -0.87318766, -0.29406866,\n",
      "       -0.3640051 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03661957,  1.0821117 ,  0.04983651, -0.87318766, -0.29406866,\n",
      "       -0.3640051 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1532495806751215, next_state=array([-0.03635778,  1.0619724 ,  0.04222105, -0.89840525, -0.31064957,\n",
      "       -0.3316174 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03635778,  1.0619724 ,  0.04222105, -0.89840525, -0.31064957,\n",
      "       -0.3316174 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9588027636996628, next_state=array([-0.03580999,  1.042073  ,  0.07028759, -0.8878249 , -0.32676205,\n",
      "       -0.32224914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03580999,  1.042073  ,  0.07028759, -0.8878249 , -0.32676205,\n",
      "       -0.32224914,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.221494909176613, next_state=array([-0.03526144,  1.0215768 ,  0.07027739, -0.9145123 , -0.3428742 ,\n",
      "       -0.3222434 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03526144,  1.0215768 ,  0.07027739, -0.9145123 , -0.3428742 ,\n",
      "       -0.3222434 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4684316166748603, next_state=array([-0.03423605,  1.0017127 ,  0.11712372, -0.8863959 , -0.35818556,\n",
      "       -0.3062272 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03423605,  1.0017127 ,  0.11712372, -0.8863959 , -0.35818556,\n",
      "       -0.3062272 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.128728724700636, next_state=array([-0.0332099 ,  0.98125136,  0.11711361, -0.91308105, -0.37349668,\n",
      "       -0.3062223 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0332099 ,  0.98125136,  0.11711361, -0.91308105, -0.37349668,\n",
      "       -0.3062223 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7174088640029026, next_state=array([-0.03174009,  0.9612774 ,  0.16073765, -0.8913987 , -0.38812053,\n",
      "       -0.2924776 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03174009,  0.9612774 ,  0.16073765, -0.8913987 , -0.38812053,\n",
      "       -0.2924776 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5699459096028636, next_state=array([-0.03033209,  0.94073814,  0.15285027, -0.91619265, -0.40101397,\n",
      "       -0.25786895,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03033209,  0.94073814,  0.15285027, -0.91619265, -0.40101397,\n",
      "       -0.25786895,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.240293531226796, next_state=array([-0.02899427,  0.9196471 ,  0.1438941 , -0.94027424, -0.41187426,\n",
      "       -0.21720573,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02899427,  0.9196471 ,  0.1438941 , -0.94027424, -0.41187426,\n",
      "       -0.21720573,  0.        ,  0.        ], dtype=float32), action=2, reward=2.373511417802246, next_state=array([-0.02713842,  0.899136  ,  0.19495954, -0.91436976, -0.42199546,\n",
      "       -0.20242345,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02713842,  0.899136  ,  0.19495954, -0.91436976, -0.42199546,\n",
      "       -0.20242345,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8081158267224839, next_state=array([-0.02535582,  0.87808645,  0.18553302, -0.93773234, -0.42988253,\n",
      "       -0.15774056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02535582,  0.87808645,  0.18553302, -0.93773234, -0.42988253,\n",
      "       -0.15774056,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9615565396072145, next_state=array([-0.02349548,  0.8563866 ,  0.19534454, -0.96731067, -0.4400139 ,\n",
      "       -0.2026269 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02349548,  0.8563866 ,  0.19534454, -0.96731067, -0.4400139 ,\n",
      "       -0.2026269 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6134819364663417, next_state=array([-0.02171822,  0.83415514,  0.18468341, -0.99026746, -0.44761595,\n",
      "       -0.15204152,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02171822,  0.83415514,  0.18468341, -0.99026746, -0.44761595,\n",
      "       -0.15204152,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7565595241770768, next_state=array([-0.01987228,  0.81127524,  0.19337237, -1.0197266 , -0.45724314,\n",
      "       -0.19254357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01987228,  0.81127524,  0.19337237, -1.0197266 , -0.45724314,\n",
      "       -0.19254357,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2328253888739766, next_state=array([-0.01802607,  0.78779626,  0.19336727, -1.0464003 , -0.46687025,\n",
      "       -0.19254236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01802607,  0.78779626,  0.19336727, -1.0464003 , -0.46687025,\n",
      "       -0.19254236,  0.        ,  0.        ], dtype=float32), action=2, reward=3.1954227643255537, next_state=array([-0.01592999,  0.7649516 ,  0.21891451, -1.0184776 , -0.4771788 ,\n",
      "       -0.20617154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01592999,  0.7649516 ,  0.21891451, -1.0184776 , -0.4771788 ,\n",
      "       -0.20617154,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7122959863703613, next_state=array([-0.01342983,  0.7424977 ,  0.25904438, -1.0010905 , -0.48723018,\n",
      "       -0.20102727,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01342983,  0.7424977 ,  0.25904438, -1.0010905 , -0.48723018,\n",
      "       -0.20102727,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2803585869487222, next_state=array([-0.0109293 ,  0.71944517,  0.2590385 , -1.0277647 , -0.49728146,\n",
      "       -0.20102592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0109293 ,  0.71944517,  0.2590385 , -1.0277647 , -0.49728146,\n",
      "       -0.20102592,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7288132322644116, next_state=array([-0.00828819,  0.6964252 ,  0.27336273, -1.0264848 , -0.5076922 ,\n",
      "       -0.20821516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00828819,  0.6964252 ,  0.27336273, -1.0264848 , -0.5076922 ,\n",
      "       -0.20821516,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6807577123968371, next_state=array([-0.00539131,  0.67375845,  0.29922536, -1.0109901 , -0.5184982 ,\n",
      "       -0.21611929,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00539131,  0.67375845,  0.29922536, -1.0109901 , -0.5184982 ,\n",
      "       -0.21611929,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3491317257917617, next_state=array([-0.00225105,  0.6516511 ,  0.3241993 , -0.986468  , -0.5300981 ,\n",
      "       -0.23199753,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00225105,  0.6516511 ,  0.3241993 , -0.986468  , -0.5300981 ,\n",
      "       -0.23199753,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2314938089381813, next_state=array([ 9.5653534e-04,  6.2888819e-01,  3.3268172e-01, -1.0164065e+00,\n",
      "       -5.4378796e-01, -2.7379712e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 9.5653534e-04,  6.2888819e-01,  3.3268172e-01, -1.0164065e+00,\n",
      "       -5.4378796e-01, -2.7379712e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.8510957091493025, next_state=array([ 0.0046545 ,  0.6065775 ,  0.38138106, -0.9963215 , -0.557216  ,\n",
      "       -0.26856017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0046545 ,  0.6065775 ,  0.38138106, -0.9963215 , -0.557216  ,\n",
      "       -0.26856017,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5515041345838085, next_state=array([ 0.00835314,  0.5836689 ,  0.3813692 , -1.023001  , -0.57064384,\n",
      "       -0.26855686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00835314,  0.5836689 ,  0.3813692 , -1.023001  , -0.57064384,\n",
      "       -0.26855686,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5910525409268519, next_state=array([ 0.01197872,  0.5602343 ,  0.37190545, -1.0455812 , -0.58164215,\n",
      "       -0.21996596,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01197872,  0.5602343 ,  0.37190545, -1.0455812 , -0.58164215,\n",
      "       -0.21996596,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6104673232441076, next_state=array([ 0.01555948,  0.5362569 ,  0.36599272, -1.0691626 , -0.5910099 ,\n",
      "       -0.18735503,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01555948,  0.5362569 ,  0.36599272, -1.0691626 , -0.5910099 ,\n",
      "       -0.18735503,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.692320392460316, next_state=array([ 0.01918592,  0.5116239 ,  0.37188214, -1.0989687 , -0.60201794,\n",
      "       -0.22016041,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01918592,  0.5116239 ,  0.37188214, -1.0989687 , -0.60201794,\n",
      "       -0.22016041,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0929611323548898, next_state=array([ 0.023174  ,  0.4867324 ,  0.4073193 , -1.1102282 , -0.61224353,\n",
      "       -0.20451239,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.023174  ,  0.4867324 ,  0.4073193 , -1.1102282 , -0.61224353,\n",
      "       -0.20451239,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2138103604102912, next_state=array([ 0.02710619,  0.46131328,  0.39996496, -1.1329163 , -0.6203994 ,\n",
      "       -0.16311756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02710619,  0.46131328,  0.39996496, -1.1329163 , -0.6203994 ,\n",
      "       -0.16311756,  0.        ,  0.        ], dtype=float32), action=1, reward=0.08239331917229833, next_state=array([ 0.03096895,  0.4353616 ,  0.39110374, -1.155722  , -0.6262636 ,\n",
      "       -0.1172846 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03096895,  0.4353616 ,  0.39110374, -1.155722  , -0.6262636 ,\n",
      "       -0.1172846 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2387392430206592, next_state=array([ 0.03489008,  0.4087571 ,  0.3984422 , -1.1855006 , -0.63400704,\n",
      "       -0.15486778,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03489008,  0.4087571 ,  0.3984422 , -1.1855006 , -0.63400704,\n",
      "       -0.15486778,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3380850591970852, next_state=array([ 0.03874226,  0.3816421 ,  0.38943556, -1.2071893 , -0.6391828 ,\n",
      "       -0.10351507,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03874226,  0.3816421 ,  0.38943556, -1.2071893 , -0.6391828 ,\n",
      "       -0.10351507,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1758053681464264, next_state=array([ 0.04265509,  0.35386127,  0.39718634, -1.2376429 , -0.64645755,\n",
      "       -0.14549348,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04265509,  0.35386127,  0.39718634, -1.2376429 , -0.64645755,\n",
      "       -0.14549348,  0.        ,  0.        ], dtype=float32), action=1, reward=0.22408017841161268, next_state=array([ 0.04651308,  0.3255468 ,  0.39007407, -1.2605815 , -0.65174675,\n",
      "       -0.10578372,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04651308,  0.3255468 ,  0.39007407, -1.2605815 , -0.65174675,\n",
      "       -0.10578372,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5018801353838296, next_state=array([ 0.05030441,  0.29669574,  0.38161296, -1.2835376 , -0.6548391 ,\n",
      "       -0.06184725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05030441,  0.29669574,  0.38161296, -1.2835376 , -0.6548391 ,\n",
      "       -0.06184725,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.040979079029369814, next_state=array([ 0.05409565,  0.26724482,  0.3816122 , -1.3102052 , -0.65793145,\n",
      "       -0.06184713,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05409565,  0.26724482,  0.3816122 , -1.3102052 , -0.65793145,\n",
      "       -0.06184713,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8375464940714881, next_state=array([ 0.05794811,  0.23712817,  0.38940507, -1.340671  , -0.6631359 ,\n",
      "       -0.10408839,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05794811,  0.23712817,  0.38940507, -1.340671  , -0.6631359 ,\n",
      "       -0.10408839,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.266609094381663, next_state=array([ 0.06187858,  0.20632611,  0.3993613 , -1.3722888 , -0.67106247,\n",
      "       -0.1585317 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06187858,  0.20632611,  0.3993613 , -1.3722888 , -0.67106247,\n",
      "       -0.1585317 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4785834877575155, next_state=array([ 0.06600495,  0.17563263,  0.41942248, -1.3677741 , -0.679638  ,\n",
      "       -0.17151114,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06600495,  0.17563263,  0.41942248, -1.3677741 , -0.679638  ,\n",
      "       -0.17151114,  0.        ,  0.        ], dtype=float32), action=1, reward=0.22877553538592224, next_state=array([ 0.07006655,  0.14442602,  0.4109516 , -1.3895589 , -0.6857348 ,\n",
      "       -0.12193545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07006655,  0.14442602,  0.4109516 , -1.3895589 , -0.6857348 ,\n",
      "       -0.12193545,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4345940101220094, next_state=array([ 0.07461405,  0.11353713,  0.45956087, -1.375482  , -0.69188386,\n",
      "       -0.12298243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07461405,  0.11353713,  0.45956087, -1.375482  , -0.69188386,\n",
      "       -0.12298243,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9618115594008998, next_state=array([ 0.07916174,  0.0820485 ,  0.45955786, -1.402151  , -0.698033  ,\n",
      "       -0.12298217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07916174,  0.0820485 ,  0.45955786, -1.402151  , -0.698033  ,\n",
      "       -0.12298217,  0.        ,  0.        ], dtype=float32), action=0, reward=8.5012150691947, next_state=array([ 0.08370972,  0.04996034,  0.45955485, -1.42882   , -0.70418215,\n",
      "       -0.12298181,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08370972,  0.04996034,  0.45955485, -1.42882   , -0.70418215,\n",
      "       -0.12298181,  1.        ,  0.        ], dtype=float32), action=0, reward=45.614355852080394, next_state=array([ 0.08670606,  0.02766181,  0.29959422, -0.992224  , -0.71895   ,\n",
      "       -0.31257737,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08670606,  0.02766181,  0.29959422, -0.992224  , -0.71895   ,\n",
      "       -0.31257737,  1.        ,  0.        ], dtype=float32), action=1, reward=-0.1755483214732567, next_state=array([ 0.0904233 ,  0.00512964,  0.35507303, -0.99576086, -0.7001422 ,\n",
      "        0.32617804,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0904233 ,  0.00512964,  0.35507303, -0.99576086, -0.7001422 ,\n",
      "        0.32617804,  1.        ,  0.        ], dtype=float32), action=2, reward=-100, next_state=array([ 0.09433527, -0.00287593,  0.28046808, -0.1153527 , -0.6107378 ,\n",
      "        2.0831628 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00430613,  1.4220967 , -0.43618435,  0.49673167,  0.00499656,\n",
      "        0.09880225,  0.        ,  0.        ], dtype=float32), action=3, reward=1.4305590231455494, next_state=array([-0.00851641,  1.4326938 , -0.42350855,  0.47096655,  0.00745516,\n",
      "        0.04917689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00851641,  1.4326938 , -0.42350855,  0.47096655,  0.00745516,\n",
      "        0.04917689,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7038896101735475, next_state=array([-0.01272669,  1.4426922 , -0.42351705,  0.4443535 ,  0.00991223,\n",
      "        0.04914593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01272669,  1.4426922 , -0.42351705,  0.4443535 ,  0.00991223,\n",
      "        0.04914593,  0.        ,  0.        ], dtype=float32), action=3, reward=1.5029386131963076, next_state=array([-0.01686506,  1.45209   , -0.41449618,  0.41767624,  0.01055807,\n",
      "        0.01291816,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01686506,  1.45209   , -0.41449618,  0.41767624,  0.01055807,\n",
      "        0.01291816,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9939405444903173, next_state=array([-0.02090492,  1.4618759 , -0.4051466 ,  0.43491945,  0.01170981,\n",
      "        0.02303697,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02090492,  1.4618759 , -0.4051466 ,  0.43491945,  0.01170981,\n",
      "        0.02303697,  0.        ,  0.        ], dtype=float32), action=0, reward=0.8830959193134618, next_state=array([-0.02494478,  1.4710615 , -0.4051501 ,  0.4082431 ,  0.0128606 ,\n",
      "        0.02301798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02494478,  1.4710615 , -0.4051501 ,  0.4082431 ,  0.0128606 ,\n",
      "        0.02301798,  0.        ,  0.        ], dtype=float32), action=3, reward=1.786328728479192, next_state=array([-0.02890129,  1.4796561 , -0.3946991 ,  0.3819941 ,  0.0119134 ,\n",
      "       -0.01894578,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02890129,  1.4796561 , -0.3946991 ,  0.3819941 ,  0.0119134 ,\n",
      "       -0.01894578,  0.        ,  0.        ], dtype=float32), action=0, reward=1.10741228522852, next_state=array([-0.03285789,  1.4876509 , -0.3946956 ,  0.35532555,  0.01096727,\n",
      "       -0.01892452,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03285789,  1.4876509 , -0.3946956 ,  0.35532555,  0.01096727,\n",
      "       -0.01892452,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2302670026950875, next_state=array([-0.0368823 ,  1.495047  , -0.4032132 ,  0.32871094,  0.01172877,\n",
      "        0.01523151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0368823 ,  1.495047  , -0.4032132 ,  0.32871094,  0.01172877,\n",
      "        0.01523151,  0.        ,  0.        ], dtype=float32), action=1, reward=0.008910034240785764, next_state=array([-0.04097452,  1.5018375 , -0.411717  ,  0.30178162,  0.01419468,\n",
      "        0.04932276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04097452,  1.5018375 , -0.411717  ,  0.30178162,  0.01419468,\n",
      "        0.04932276,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2610627895434616, next_state=array([-0.04516058,  1.5087534 , -0.42068353,  0.30735084,  0.01624755,\n",
      "        0.04106126,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04516058,  1.5087534 , -0.42068353,  0.30735084,  0.01624755,\n",
      "        0.04106126,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4241013396984943, next_state=array([-0.0494317 ,  1.5150563 , -0.43136114,  0.28007576,  0.02044342,\n",
      "        0.08392529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0494317 ,  1.5150563 , -0.43136114,  0.28007576,  0.02044342,\n",
      "        0.08392529,  0.        ,  0.        ], dtype=float32), action=3, reward=1.1791686283322644, next_state=array([-0.05364294,  1.5207533 , -0.42384395,  0.25316176,  0.0231304 ,\n",
      "        0.05374447,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05364294,  1.5207533 , -0.42384395,  0.25316176,  0.0231304 ,\n",
      "        0.05374447,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5659979621663058, next_state=array([-0.05793133,  1.5258551 , -0.43349767,  0.2266654 ,  0.02774953,\n",
      "        0.09239075,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05793133,  1.5258551 , -0.43349767,  0.2266654 ,  0.02774953,\n",
      "        0.09239075,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.885598680221807, next_state=array([-0.06211357,  1.5311489 , -0.4234733 ,  0.23518178,  0.03293531,\n",
      "        0.1037254 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06211357,  1.5311489 , -0.4234733 ,  0.23518178,  0.03293531,\n",
      "        0.1037254 ,  0.        ,  0.        ], dtype=float32), action=3, reward=1.3561787394433804, next_state=array([-0.06621017,  1.5358545 , -0.41270986,  0.20906742,  0.03595444,\n",
      "        0.06038768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06621017,  1.5358545 , -0.41270986,  0.20906742,  0.03595444,\n",
      "        0.06038768,  0.        ,  0.        ], dtype=float32), action=0, reward=0.41133382326324863, next_state=array([-0.07030697,  1.5399601 , -0.41271704,  0.18240087,  0.03897426,\n",
      "        0.06040146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07030697,  1.5399601 , -0.41271704,  0.18240087,  0.03897426,\n",
      "        0.06040146,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4324125918156085, next_state=array([-0.07426681,  1.5443211 , -0.3997887 ,  0.19370776,  0.04273833,\n",
      "        0.07528818,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07426681,  1.5443211 , -0.3997887 ,  0.19370776,  0.04273833,\n",
      "        0.07528818,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9774479592040164, next_state=array([-0.07832365,  1.5491757 , -0.4091607 ,  0.21565644,  0.0461943 ,\n",
      "        0.06912527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07832365,  1.5491757 , -0.4091607 ,  0.21565644,  0.0461943 ,\n",
      "        0.06912527,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4792468285165501, next_state=array([-0.08244181,  1.5534223 , -0.41688055,  0.1885731 ,  0.05120086,\n",
      "        0.10013988,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08244181,  1.5534223 , -0.41688055,  0.1885731 ,  0.05120086,\n",
      "        0.10013988,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.982594191105618, next_state=array([-0.08663845,  1.5570617 , -0.42669815,  0.16149451,  0.05817541,\n",
      "        0.13950345,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08663845,  1.5570617 , -0.42669815,  0.16149451,  0.05817541,\n",
      "        0.13950345,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2400175095465886, next_state=array([-0.09090872,  1.560098  , -0.43593892,  0.13458219,  0.06699763,\n",
      "        0.17646009,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09090872,  1.560098  , -0.43593892,  0.13458219,  0.06699763,\n",
      "        0.17646009,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.520341384582166, next_state=array([-0.09525184,  1.5625234 , -0.44506297,  0.10727505,  0.07765289,\n",
      "        0.21312451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09525184,  1.5625234 , -0.44506297,  0.10727505,  0.07765289,\n",
      "        0.21312451,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7269067112440268, next_state=array([-0.09959545,  1.5643501 , -0.44509324,  0.08059552,  0.08830615,\n",
      "        0.21308427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09959545,  1.5643501 , -0.44509324,  0.08059552,  0.08830615,\n",
      "        0.21308427,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8203829944362155, next_state=array([-0.10393934,  1.5655781 , -0.44512257,  0.05391558,  0.09895812,\n",
      "        0.21305828,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10393934,  1.5655781 , -0.44512257,  0.05391558,  0.09895812,\n",
      "        0.21305828,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9632002529813224, next_state=array([-0.10835113,  1.5661685 , -0.45369482,  0.02536815,  0.11137505,\n",
      "        0.24833854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10835113,  1.5661685 , -0.45369482,  0.02536815,  0.11137505,\n",
      "        0.24833854,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.3946275486088267, next_state=array([-0.11294289,  1.5669643 , -0.47111097,  0.03442677,  0.12324046,\n",
      "        0.23730806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11294289,  1.5669643 , -0.47111097,  0.03442677,  0.12324046,\n",
      "        0.23730806,  0.        ,  0.        ], dtype=float32), action=3, reward=0.24086400696188662, next_state=array([-0.11744251,  1.5671803 , -0.45951605,  0.00878013,  0.13275377,\n",
      "        0.1902664 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11744251,  1.5671803 , -0.45951605,  0.00878013,  0.13275377,\n",
      "        0.1902664 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3369292977574774, next_state=array([-0.12202988,  1.5667697 , -0.4705545 , -0.01934187,  0.144531  ,\n",
      "        0.23554488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12202988,  1.5667697 , -0.4705545 , -0.01934187,  0.144531  ,\n",
      "        0.23554488,  0.        ,  0.        ], dtype=float32), action=3, reward=0.025635832636852457, next_state=array([-0.12652817,  1.5657793 , -0.45933446, -0.04496634,  0.15402772,\n",
      "        0.18993439,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12652817,  1.5657793 , -0.45933446, -0.04496634,  0.15402772,\n",
      "        0.18993439,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.58894323953196, next_state=array([-0.13129082,  1.5651083 , -0.4850019 , -0.03075241,  0.1627494 ,\n",
      "        0.17443396,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13129082,  1.5651083 , -0.4850019 , -0.03075241,  0.1627494 ,\n",
      "        0.17443396,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2655747694719808, next_state=array([-0.13613348,  1.5638229 , -0.49501508, -0.05835271,  0.17350686,\n",
      "        0.21514952,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13613348,  1.5638229 , -0.49501508, -0.05835271,  0.17350686,\n",
      "        0.21514952,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3629919187664143, next_state=array([-0.14098501,  1.5628068 , -0.49630323, -0.04649702,  0.18468645,\n",
      "        0.22359195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14098501,  1.5628068 , -0.49630323, -0.04649702,  0.18468645,\n",
      "        0.22359195,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.15787859013596403, next_state=array([-0.14575748,  1.561203  , -0.486374  , -0.07245245,  0.19386193,\n",
      "        0.18350981,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14575748,  1.561203  , -0.486374  , -0.07245245,  0.19386193,\n",
      "        0.18350981,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4190874552972432, next_state=array([-0.15060654,  1.5589658 , -0.49603397, -0.10091714,  0.20506668,\n",
      "        0.22409467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15060654,  1.5589658 , -0.49603397, -0.10091714,  0.20506668,\n",
      "        0.22409467,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.924022047725798, next_state=array([-0.15554886,  1.5561035 , -0.50771695, -0.12914893,  0.21868221,\n",
      "        0.27231055,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15554886,  1.5561035 , -0.50771695, -0.12914893,  0.21868221,\n",
      "        0.27231055,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5529345100075591, next_state=array([-0.16040888,  1.5526757 , -0.49728483, -0.15405923,  0.23011377,\n",
      "        0.22863135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16040888,  1.5526757 , -0.49728483, -0.15405923,  0.23011377,\n",
      "        0.22863135,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7186654666471088, next_state=array([-0.16520509,  1.5486679 , -0.4892543 , -0.17966482,  0.23988782,\n",
      "        0.19548094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16520509,  1.5486679 , -0.4892543 , -0.17966482,  0.23988782,\n",
      "        0.19548094,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.39875470831273563, next_state=array([-0.16992226,  1.5440869 , -0.47928864, -0.20485161,  0.24759021,\n",
      "        0.15404806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16992226,  1.5440869 , -0.47928864, -0.20485161,  0.24759021,\n",
      "        0.15404806,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.512694078151212, next_state=array([-0.17471036,  1.5388746 , -0.48823318, -0.23328392,  0.2571928 ,\n",
      "        0.19205125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17471036,  1.5388746 , -0.48823318, -0.23328392,  0.2571928 ,\n",
      "        0.19205125,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7967883073837914, next_state=array([-0.1794385 ,  1.5330813 , -0.4806711 , -0.25887665,  0.26522747,\n",
      "        0.16069274,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1794385 ,  1.5330813 , -0.4806711 , -0.25887665,  0.26522747,\n",
      "        0.16069274,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5383524501389445, next_state=array([-0.18416671,  1.5266889 , -0.48066896, -0.28554854,  0.27326205,\n",
      "        0.16069199,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18416671,  1.5266889 , -0.48066896, -0.28554854,  0.27326205,\n",
      "        0.16069199,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9624826397904642, next_state=array([-0.18898821,  1.5196567 , -0.49241298, -0.3144963 ,  0.2837938 ,\n",
      "        0.21063487,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18898821,  1.5196567 , -0.49241298, -0.3144963 ,  0.2837938 ,\n",
      "        0.21063487,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9597818736586123, next_state=array([-0.19374447,  1.5120437 , -0.48421836, -0.34004834,  0.29263213,\n",
      "        0.1767666 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19374447,  1.5120437 , -0.48421836, -0.34004834,  0.29263213,\n",
      "        0.1767666 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.948574165046351, next_state=array([-0.19858494,  1.5037892 , -0.49483252, -0.36906898,  0.30376223,\n",
      "        0.22260205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19858494,  1.5037892 , -0.49483252, -0.36906898,  0.30376223,\n",
      "        0.22260205,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9175038845765457, next_state=array([-0.2034903 ,  1.4948951 , -0.5030209 , -0.39795354,  0.3167077 ,\n",
      "        0.2589094 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2034903 ,  1.4948951 , -0.5030209 , -0.39795354,  0.3167077 ,\n",
      "        0.2589094 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5859876337053038, next_state=array([-0.20843382,  1.4862368 , -0.5074047 , -0.38772258,  0.33028707,\n",
      "        0.27158782,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20843382,  1.4862368 , -0.5074047 , -0.38772258,  0.33028707,\n",
      "        0.27158782,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1010460234475363, next_state=array([-0.2133008 ,  1.4770181 , -0.49767876, -0.41226837,  0.34176353,\n",
      "        0.22952986,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2133008 ,  1.4770181 , -0.49767876, -0.41226837,  0.34176353,\n",
      "        0.22952986,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6425620361681468, next_state=array([-0.21846405,  1.468279  , -0.527091  , -0.39099824,  0.35306406,\n",
      "        0.22601059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21846405,  1.468279  , -0.527091  , -0.39099824,  0.35306406,\n",
      "        0.22601059,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.906931422688615, next_state=array([-0.22362766,  1.4589415 , -0.5270856 , -0.417675  ,  0.3643645 ,\n",
      "        0.22600861,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22362766,  1.4589415 , -0.5270856 , -0.417675  ,  0.3643645 ,\n",
      "        0.22600861,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.892723412234999, next_state=array([-0.22871609,  1.4490386 , -0.5175927 , -0.44237787,  0.37362415,\n",
      "        0.18519261,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22871609,  1.4490386 , -0.5175927 , -0.44237787,  0.37362415,\n",
      "        0.18519261,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6218228994480899, next_state=array([-0.23372264,  1.4385762 , -0.507265  , -0.4667421 ,  0.38064063,\n",
      "        0.14033048,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23372264,  1.4385762 , -0.507265  , -0.4667421 ,  0.38064063,\n",
      "        0.14033048,  0.        ,  0.        ], dtype=float32), action=2, reward=0.12609326305415608, next_state=array([-0.23894505,  1.4287901 , -0.52933204, -0.43685073,  0.38819188,\n",
      "        0.15102571,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23894505,  1.4287901 , -0.52933204, -0.43685073,  0.38819188,\n",
      "        0.15102571,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5716683557678537, next_state=array([-0.24423489,  1.4183606 , -0.5378624 , -0.46598658,  0.39767742,\n",
      "        0.18971084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24423489,  1.4183606 , -0.5378624 , -0.46598658,  0.39767742,\n",
      "        0.18971084,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7273714870706272, next_state=array([-0.24952507,  1.4073322 , -0.53785807, -0.49266016,  0.4071629 ,\n",
      "        0.18970965,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24952507,  1.4073322 , -0.53785807, -0.49266016,  0.4071629 ,\n",
      "        0.18970965,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.245588516126918, next_state=array([-0.25504583,  1.3961841 , -0.56051886, -0.49793148,  0.41625494,\n",
      "        0.18184078,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25504583,  1.3961841 , -0.56051886, -0.49793148,  0.41625494,\n",
      "        0.18184078,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.651875238025923, next_state=array([-0.2605669 ,  1.3844368 , -0.5605146 , -0.5246045 ,  0.4253469 ,\n",
      "        0.18183973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2605669 ,  1.3844368 , -0.5605146 , -0.5246045 ,  0.4253469 ,\n",
      "        0.18183973,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6777540297559015, next_state=array([-0.26615992,  1.372052  , -0.5695131 , -0.55356616,  0.43643764,\n",
      "        0.22181404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26615992,  1.372052  , -0.5695131 , -0.55356616,  0.43643764,\n",
      "        0.22181404,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5930578428224453, next_state=array([-0.27166408,  1.3591225 , -0.55824625, -0.5771031 ,  0.4449835 ,\n",
      "        0.17091742,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27166408,  1.3591225 , -0.55824625, -0.5771031 ,  0.4449835 ,\n",
      "        0.17091742,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4948253322186518, next_state=array([-0.27722654,  1.3455428 , -0.56569225, -0.60657966,  0.45533234,\n",
      "        0.20697662,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27722654,  1.3455428 , -0.56569225, -0.60657966,  0.45533234,\n",
      "        0.20697662,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5094120881072104, next_state=array([-0.2827049 ,  1.3314321 , -0.55489814, -0.62946683,  0.46311128,\n",
      "        0.15557897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2827049 ,  1.3314321 , -0.55489814, -0.62946683,  0.46311128,\n",
      "        0.15557897,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5102859864387483, next_state=array([-0.28850842,  1.3174601 , -0.5870891 , -0.62324613,  0.47056156,\n",
      "        0.1490056 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28850842,  1.3174601 , -0.5870891 , -0.62324613,  0.47056156,\n",
      "        0.1490056 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4089334685665449, next_state=array([-0.29431215,  1.3028886 , -0.587086  , -0.6499169 ,  0.47801182,\n",
      "        0.149005  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29431215,  1.3028886 , -0.587086  , -0.6499169 ,  0.47801182,\n",
      "        0.149005  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5349339465970389, next_state=array([-0.30034035,  1.2882248 , -0.6093366 , -0.65399224,  0.48525947,\n",
      "        0.14495286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30034035,  1.2882248 , -0.6093366 , -0.65399224,  0.48525947,\n",
      "        0.14495286,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.43111864453888304, next_state=array([-0.30630916,  1.2730213 , -0.60162795, -0.677393  ,  0.4905655 ,\n",
      "        0.1061206 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30630916,  1.2730213 , -0.60162795, -0.677393  ,  0.4905655 ,\n",
      "        0.1061206 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0124551916286917, next_state=array([-0.31275135,  1.257997  , -0.64823544, -0.6691801 ,  0.49507207,\n",
      "        0.09013088,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31275135,  1.257997  , -0.64823544, -0.6691801 ,  0.49507207,\n",
      "        0.09013088,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.16814836613539683, next_state=array([-0.3191379 ,  1.2424285 , -0.64105415, -0.6928013 ,  0.49776614,\n",
      "        0.05388149,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3191379 ,  1.2424285 , -0.64105415, -0.6928013 ,  0.49776614,\n",
      "        0.05388149,  0.        ,  0.        ], dtype=float32), action=3, reward=0.018995955738462272, next_state=array([-0.32546276,  1.2263044 , -0.6332526 , -0.7169108 ,  0.49862638,\n",
      "        0.01720511,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32546276,  1.2263044 , -0.6332526 , -0.7169108 ,  0.49862638,\n",
      "        0.01720511,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9189257204778005, next_state=array([-0.3318719 ,  1.2095133 , -0.6439576 , -0.74738276,  0.50205684,\n",
      "        0.06860884,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3318719 ,  1.2095133 , -0.6439576 , -0.74738276,  0.50205684,\n",
      "        0.06860884,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7266207703189866, next_state=array([-0.33833647,  1.1920764 , -0.65102136, -0.7766542 ,  0.50720084,\n",
      "        0.10287968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33833647,  1.1920764 , -0.65102136, -0.7766542 ,  0.50720084,\n",
      "        0.10287968,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.817124686354332, next_state=array([-0.34485164,  1.1739933 , -0.65749276, -0.80592567,  0.5139557 ,\n",
      "        0.13509765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34485164,  1.1739933 , -0.65749276, -0.80592567,  0.5139557 ,\n",
      "        0.13509765,  0.        ,  0.        ], dtype=float32), action=2, reward=0.43359815459758694, next_state=array([-0.351614  ,  1.1563883 , -0.68274987, -0.7849112 ,  0.5213491 ,\n",
      "        0.1478689 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.351614  ,  1.1563883 , -0.68274987, -0.7849112 ,  0.5213491 ,\n",
      "        0.1478689 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2267061641472878, next_state=array([-0.3583766 ,  1.1381841 , -0.68274647, -0.8115818 ,  0.5287425 ,\n",
      "        0.14786837,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3583766 ,  1.1381841 , -0.68274647, -0.8115818 ,  0.5287425 ,\n",
      "        0.14786837,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2094420454531019, next_state=array([-0.36513942,  1.1193804 , -0.68274295, -0.83825237,  0.5361359 ,\n",
      "        0.1478678 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36513942,  1.1193804 , -0.68274295, -0.83825237,  0.5361359 ,\n",
      "        0.1478678 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0169461589200908, next_state=array([-0.37195772,  1.0999341 , -0.68971   , -0.8674285 ,  0.5452127 ,\n",
      "        0.1815343 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37195772,  1.0999341 , -0.68971   , -0.8674285 ,  0.5452127 ,\n",
      "        0.1815343 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3356747321394935, next_state=array([-0.3788429 ,  1.0798339 , -0.6981373 , -0.89728194,  0.55635625,\n",
      "        0.22287083,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3788429 ,  1.0798339 , -0.6981373 , -0.89728194,  0.55635625,\n",
      "        0.22287083,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.42761047223771587, next_state=array([-0.38565835,  1.0592105 , -0.6890644 , -0.91973776,  0.565116  ,\n",
      "        0.17519529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38565835,  1.0592105 , -0.6890644 , -0.91973776,  0.565116  ,\n",
      "        0.17519529,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.29033311013213736, next_state=array([-0.3924106 ,  1.0380573 , -0.6808569 , -0.9425335 ,  0.57170403,\n",
      "        0.1317607 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3924106 ,  1.0380573 , -0.6808569 , -0.9425335 ,  0.57170403,\n",
      "        0.1317607 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0438726085653798, next_state=array([-0.39916307,  1.0163049 , -0.68085396, -0.9692032 ,  0.5782921 ,\n",
      "        0.13176033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39916307,  1.0163049 , -0.68085396, -0.9692032 ,  0.5782921 ,\n",
      "        0.13176033,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6365061435728989, next_state=array([-0.40638137,  0.9953306 , -0.7278479 , -0.93482786,  0.58539844,\n",
      "        0.14212772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40638137,  0.9953306 , -0.7278479 , -0.93482786,  0.58539844,\n",
      "        0.14212772,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1118898267774284, next_state=array([-0.4135999 ,  0.97375673, -0.72784436, -0.9614981 ,  0.5925048 ,\n",
      "        0.14212719,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4135999 ,  0.97375673, -0.72784436, -0.9614981 ,  0.5925048 ,\n",
      "        0.14212719,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2521178169173184, next_state=array([-0.4208924 ,  0.951513  , -0.7372243 , -0.99222386,  0.60202533,\n",
      "        0.1904109 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4208924 ,  0.951513  , -0.7372243 , -0.99222386,  0.60202533,\n",
      "        0.1904109 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3210867755270215, next_state=array([-0.4281853 ,  0.92867005, -0.7372179 , -1.0188967 ,  0.6115458 ,\n",
      "        0.1904097 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4281853 ,  0.92867005, -0.7372179 , -1.0188967 ,  0.6115458 ,\n",
      "        0.1904097 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.407579091038001, next_state=array([-0.4355465 ,  0.9051563 , -0.7458996 , -1.0496786 ,  0.6233819 ,\n",
      "        0.23672259,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4355465 ,  0.9051563 , -0.7458996 , -1.0496786 ,  0.6233819 ,\n",
      "        0.23672259,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3761783349437153, next_state=array([-0.44296384,  0.88099396, -0.7528936 , -1.0792981 ,  0.63700545,\n",
      "        0.27247062,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44296384,  0.88099396, -0.7528936 , -1.0792981 ,  0.63700545,\n",
      "        0.27247062,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5915233887450015, next_state=array([-0.45044166,  0.8561813 , -0.7603543 , -1.109078  ,  0.6525283 ,\n",
      "        0.3104563 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45044166,  0.8561813 , -0.7603543 , -1.109078  ,  0.6525283 ,\n",
      "        0.3104563 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5482250292535469, next_state=array([-0.4582328 ,  0.8317715 , -0.792121  , -1.0916046 ,  0.66877663,\n",
      "        0.32496554,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4582328 ,  0.8317715 , -0.792121  , -1.0916046 ,  0.66877663,\n",
      "        0.32496554,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0906183524632795, next_state=array([-0.46609434,  0.80669576, -0.8008135 , -1.1223323 ,  0.68734014,\n",
      "        0.37126973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46609434,  0.80669576, -0.8008135 , -1.1223323 ,  0.68734014,\n",
      "        0.37126973,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.227569887932418, next_state=array([-0.47395784,  0.7810238 , -0.8007862 , -1.1490214 ,  0.7059032 ,\n",
      "        0.37126094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47395784,  0.7810238 , -0.8007862 , -1.1490214 ,  0.7059032 ,\n",
      "        0.37126094,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.237940872694594, next_state=array([-0.48182327,  0.7547552 , -0.8007585 , -1.1757102 ,  0.7244658 ,\n",
      "        0.37125212,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48182327,  0.7547552 , -0.8007585 , -1.1757102 ,  0.7244658 ,\n",
      "        0.37125212,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1846038663421996, next_state=array([-0.48962873,  0.72797626, -0.79269516, -1.1974449 ,  0.740583  ,\n",
      "        0.32234377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48962873,  0.72797626, -0.79269516, -1.1974449 ,  0.740583  ,\n",
      "        0.32234377,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0344966046840227, next_state=array([-0.4974358 ,  0.70059985, -0.7926733 , -1.2241275 ,  0.7566999 ,\n",
      "        0.32233793,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4974358 ,  0.70059985, -0.7926733 , -1.2241275 ,  0.7566999 ,\n",
      "        0.32233793,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9152188504961305, next_state=array([-0.5051745 ,  0.67271435, -0.7837377 , -1.2456449 ,  0.7701798 ,\n",
      "        0.2695982 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5051745 ,  0.67271435, -0.7837377 , -1.2456449 ,  0.7701798 ,\n",
      "        0.2695982 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0751584873343518, next_state=array([-0.5131944 ,  0.64496344, -0.81219864, -1.240065  ,  0.78430223,\n",
      "        0.28244814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5131944 ,  0.64496344, -0.81219864, -1.240065  ,  0.78430223,\n",
      "        0.28244814,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9493234326510263, next_state=array([-0.52126783,  0.61653715, -0.8189286 , -1.2712083 ,  0.80057186,\n",
      "        0.32539412,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.52126783,  0.61653715, -0.8189286 , -1.2712083 ,  0.80057186,\n",
      "        0.32539412,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.854582821360043, next_state=array([-0.5298833,  0.5879305, -0.8723675, -1.2789441,  0.8160242,\n",
      "        0.3090464,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([-0.5298833,  0.5879305, -0.8723675, -1.2789441,  0.8160242,\n",
      "        0.3090464,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.206243437426849, next_state=array([-0.5385003 ,  0.55872613, -0.87234575, -1.3056245 ,  0.8314763 ,\n",
      "        0.3090413 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5385003 ,  0.55872613, -0.87234575, -1.3056245 ,  0.8314763 ,\n",
      "        0.3090413 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.269059672352739, next_state=array([-0.5471189 ,  0.5289239 , -0.87232363, -1.3323046 ,  0.84692806,\n",
      "        0.3090362 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5471189 ,  0.5289239 , -0.87232363, -1.3323046 ,  0.84692806,\n",
      "        0.3090362 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3414266951937748, next_state=array([-0.55573905,  0.49852374, -0.8723014 , -1.3589846 ,  0.8623796 ,\n",
      "        0.3090313 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.55573905,  0.49852374, -0.8723014 , -1.3589846 ,  0.8623796 ,\n",
      "        0.3090313 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.7040242723222034, next_state=array([-0.5647561 ,  0.4678287 , -0.91149294, -1.3719488 ,  0.87735057,\n",
      "        0.29941958,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5647561 ,  0.4678287 , -0.91149294, -1.3719488 ,  0.87735057,\n",
      "        0.29941958,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4846430112709754, next_state=array([-0.57377464,  0.43653554, -0.91147125, -1.3986278 ,  0.8923213 ,\n",
      "        0.29941478,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.57377464,  0.43653554, -0.91147125, -1.3986278 ,  0.8923213 ,\n",
      "        0.29941478,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.790043811532057, next_state=array([-0.5828524 ,  0.40454265, -0.9188956 , -1.4312451 ,  0.9099732 ,\n",
      "        0.35303867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5828524 ,  0.40454265, -0.9188956 , -1.4312451 ,  0.9099732 ,\n",
      "        0.35303867,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.566847419573196, next_state=array([-0.59236467,  0.3725344 , -0.9622072 , -1.4321605 ,  0.92781425,\n",
      "        0.35682088,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.59236467,  0.3725344 , -0.9622072 , -1.4321605 ,  0.92781425,\n",
      "        0.35682088,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.031900145968818, next_state=array([-0.6018237 ,  0.340029  , -0.9550468 , -1.4529445 ,  0.9430168 ,\n",
      "        0.30405116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6018237 ,  0.340029  , -0.9550468 , -1.4529445 ,  0.9430168 ,\n",
      "        0.30405116,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8344504920833902, next_state=array([-0.611225  ,  0.30703297, -0.94744146, -1.4732805 ,  0.9553898 ,\n",
      "        0.24745901,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.611225  ,  0.30703297, -0.94744146, -1.4732805 ,  0.9553898 ,\n",
      "        0.24745901,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9045581267757825, next_state=array([-0.6206275 ,  0.27343813, -0.94742584, -1.4999547 ,  0.9677626 ,\n",
      "        0.2474564 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6206275 ,  0.27343813, -0.94742584, -1.4999547 ,  0.9677626 ,\n",
      "        0.2474564 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8888924431123815, next_state=array([-0.6299799 ,  0.23935963, -0.94067717, -1.5199116 ,  0.9772818 ,\n",
      "        0.19038476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6299799 ,  0.23935963, -0.94067717, -1.5199116 ,  0.9772818 ,\n",
      "        0.19038476,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8026482843647773, next_state=array([-0.6392777 ,  0.20478931, -0.9335805 , -1.5402387 ,  0.98402214,\n",
      "        0.13480654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6392777 ,  0.20478931, -0.9335805 , -1.5402387 ,  0.98402214,\n",
      "        0.13480654,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.870724807183592, next_state=array([-0.64857584,  0.16961934, -0.9335758 , -1.5669075 ,  0.9907624 ,\n",
      "        0.13480595,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.64857584,  0.16961934, -0.9335758 , -1.5669075 ,  0.9907624 ,\n",
      "        0.13480595,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9127848114863353, next_state=array([-0.65853995,  0.1346655 , -1.0003668 , -1.5575502 ,  0.99791914,\n",
      "        0.14313482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.65853995,  0.1346655 , -1.0003668 , -1.5575502 ,  0.99791914,\n",
      "        0.14313482,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.581728504133507, next_state=array([-0.6684762 ,  0.09919082, -0.99652565, -1.579666  ,  1.0032147 ,\n",
      "        0.10591072,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6684762 ,  0.09919082, -0.99652565, -1.579666  ,  1.0032147 ,\n",
      "        0.10591072,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.3449381414404797, next_state=array([-0.6784127 ,  0.06311625, -0.9965227 , -1.6063339 ,  1.0085102 ,\n",
      "        0.10591109,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6784127 ,  0.06311625, -0.9965227 , -1.6063339 ,  1.0085102 ,\n",
      "        0.10591109,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.597812758909384, next_state=array([-0.688393  ,  0.0263466 , -1.002159  , -1.6386079 ,  1.0161983 ,\n",
      "        0.15376003,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.688393  ,  0.0263466 , -1.002159  , -1.6386079 ,  1.0161983 ,\n",
      "        0.15376003,  0.        ,  0.        ], dtype=float32), action=1, reward=-5.174714945020326, next_state=array([-0.6984169 , -0.01113584, -1.0079043 , -1.6718826 ,  1.0266128 ,\n",
      "        0.2082905 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6984169 , -0.01113584, -1.0079043 , -1.6718826 ,  1.0266128 ,\n",
      "        0.2082905 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.4243052302636827, next_state=array([-0.7083951 , -0.04911342, -1.0018948 , -1.6924137 ,  1.0344224 ,\n",
      "        0.15619203,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7083951 , -0.04911342, -1.0018948 , -1.6924137 ,  1.0344224 ,\n",
      "        0.15619203,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.5040897969439286, next_state=array([-0.71833867, -0.08759286, -0.99718285, -1.713383  ,  1.0399007 ,\n",
      "        0.10956506,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.71833867, -0.08759286, -0.99718285, -1.713383  ,  1.0399007 ,\n",
      "        0.10956506,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.909951099104194, next_state=array([-0.7286371 , -0.12623286, -1.0328128 , -1.7207271 ,  1.0457162 ,\n",
      "        0.11630963,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7286371 , -0.12623286, -1.0328128 , -1.7207271 ,  1.0457162 ,\n",
      "        0.11630963,  0.        ,  0.        ], dtype=float32), action=0, reward=5.352879960832922, next_state=array([-0.7389358 , -0.16547269, -1.0328091 , -1.747395  ,  1.0515317 ,\n",
      "        0.1163093 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.7389358 , -0.16547269, -1.0328091 , -1.747395  ,  1.0515317 ,\n",
      "        0.1163093 ,  0.        ,  1.        ], dtype=float32), action=0, reward=45.963286037102876, next_state=array([-0.74637   , -0.18539567, -0.8328117 , -1.0639075 ,  1.258782  ,\n",
      "        4.03903   ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.74637   , -0.18539567, -0.8328117 , -1.0639075 ,  1.258782  ,\n",
      "        4.03903   ,  0.        ,  1.        ], dtype=float32), action=2, reward=0.24256877692051831, next_state=array([-0.75383246, -0.19296283, -0.7929846 , -0.6049231 ,  1.5979965 ,\n",
      "        6.497995  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.75383246, -0.19296283, -0.7929846 , -0.6049231 ,  1.5979965 ,\n",
      "        6.497995  ,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.758521  , -0.1855235 , -0.45737296,  0.2502921 ,  1.6881262 ,\n",
      "        1.612804  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00274649,  1.4046497 ,  0.27816808, -0.27869183, -0.00317563,\n",
      "       -0.0630092 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5007206572422818, next_state=array([ 0.00558548,  1.3978059 ,  0.2894004 , -0.30418795, -0.0086171 ,\n",
      "       -0.10883883,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00558548,  1.3978059 ,  0.2894004 , -0.30418795, -0.0086171 ,\n",
      "       -0.10883883,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7367158278236716, next_state=array([ 0.00851049,  1.390363  ,  0.3001989 , -0.33086437, -0.01621724,\n",
      "       -0.15201683,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00851049,  1.390363  ,  0.3001989 , -0.33086437, -0.01621724,\n",
      "       -0.15201683,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.833751742669192, next_state=array([ 0.01151562,  1.3823261 ,  0.31022543, -0.35732806, -0.02582018,\n",
      "       -0.1920772 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01151562,  1.3823261 ,  0.31022543, -0.35732806, -0.02582018,\n",
      "       -0.1920772 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2426733485898296, next_state=array([ 0.01459951,  1.3749803 ,  0.3178148 , -0.32667002, -0.03515234,\n",
      "       -0.18666023,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01459951,  1.3749803 ,  0.3178148 , -0.32667002, -0.03515234,\n",
      "       -0.18666023,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0932076425324055, next_state=array([ 0.0176836 ,  1.3670354 ,  0.3178415 , -0.353355  , -0.04448359,\n",
      "       -0.18664208,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0176836 ,  1.3670354 ,  0.3178415 , -0.353355  , -0.04448359,\n",
      "       -0.18664208,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2559745286295925, next_state=array([ 0.02068338,  1.3584865 ,  0.30726388, -0.38018745, -0.05169183,\n",
      "       -0.14417797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02068338,  1.3584865 ,  0.30726388, -0.38018745, -0.05169183,\n",
      "       -0.14417797,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0522329256901617, next_state=array([ 0.02359428,  1.3493369 ,  0.2961077 , -0.40683255, -0.05666146,\n",
      "       -0.09940188,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02359428,  1.3493369 ,  0.2961077 , -0.40683255, -0.05666146,\n",
      "       -0.09940188,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0714455933473335, next_state=array([ 0.02643747,  1.3395913 ,  0.28760356, -0.4332595 , -0.05992075,\n",
      "       -0.06519148,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02643747,  1.3395913 ,  0.28760356, -0.4332595 , -0.05992075,\n",
      "       -0.06519148,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5400269619580342, next_state=array([ 0.02928066,  1.329246  ,  0.2876124 , -0.4599291 , -0.06317977,\n",
      "       -0.06518643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02928066,  1.329246  ,  0.2876124 , -0.4599291 , -0.06317977,\n",
      "       -0.06518643,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2664431689942703, next_state=array([ 0.03220501,  1.318305  ,  0.2977796 , -0.48650134, -0.06846766,\n",
      "       -0.10576751,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03220501,  1.318305  ,  0.2977796 , -0.48650134, -0.06846766,\n",
      "       -0.10576751,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2123058752267015, next_state=array([ 0.03520288,  1.3080053 ,  0.30502835, -0.45801142, -0.07367617,\n",
      "       -0.10417962,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03520288,  1.3080053 ,  0.30502835, -0.45801142, -0.07367617,\n",
      "       -0.10417962,  0.        ,  0.        ], dtype=float32), action=2, reward=3.5572425387737043, next_state=array([ 0.03817406,  1.2986311 ,  0.30285457, -0.41692775, -0.07936349,\n",
      "       -0.11375656,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03817406,  1.2986311 ,  0.30285457, -0.41692775, -0.07936349,\n",
      "       -0.11375656,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.763043478571035, next_state=array([ 0.04114542,  1.2886571 ,  0.3028701 , -0.44360647, -0.08504944,\n",
      "       -0.11372957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04114542,  1.2886571 ,  0.3028701 , -0.44360647, -0.08504944,\n",
      "       -0.11372957,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9774243796703093, next_state=array([ 0.04403649,  1.2780948 ,  0.29276767, -0.46964848, -0.08869402,\n",
      "       -0.07289793,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04403649,  1.2780948 ,  0.29276767, -0.46964848, -0.08869402,\n",
      "       -0.07289793,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5403321217306427, next_state=array([ 0.04692755,  1.2669326 ,  0.2927772 , -0.49631843, -0.09233892,\n",
      "       -0.07290418,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04692755,  1.2669326 ,  0.2927772 , -0.49631843, -0.09233892,\n",
      "       -0.07290418,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2573997904137684, next_state=array([ 0.05004845,  1.2560146 ,  0.31493646, -0.48542914, -0.09515142,\n",
      "       -0.05625498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05004845,  1.2560146 ,  0.31493646, -0.48542914, -0.09515142,\n",
      "       -0.05625498,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3991089375923593, next_state=array([ 0.05316963,  1.2444963 ,  0.31494293, -0.5121057 , -0.09796416,\n",
      "       -0.05626024,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05316963,  1.2444963 ,  0.31494293, -0.5121057 , -0.09796416,\n",
      "       -0.05626024,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3594279362332715, next_state=array([ 0.05618344,  1.2333491 ,  0.30500552, -0.49567756, -0.10157275,\n",
      "       -0.07217834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05618344,  1.2333491 ,  0.30500552, -0.49567756, -0.10157275,\n",
      "       -0.07217834,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6903878256089502, next_state=array([ 0.05910654,  1.2216079 ,  0.29365858, -0.52192694, -0.10290015,\n",
      "       -0.02655041,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05910654,  1.2216079 ,  0.29365858, -0.52192694, -0.10290015,\n",
      "       -0.02655041,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4694300924937354, next_state=array([ 0.06203651,  1.2103536 ,  0.2946477 , -0.50030684, -0.10454457,\n",
      "       -0.03289125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06203651,  1.2103536 ,  0.2946477 , -0.50030684, -0.10454457,\n",
      "       -0.03289125,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3100473885143344, next_state=array([ 0.0649664 ,  1.198499  ,  0.2946511 , -0.52698475, -0.10618794,\n",
      "       -0.03287063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0649664 ,  1.198499  ,  0.2946511 , -0.52698475, -0.10618794,\n",
      "       -0.03287063,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2783992991917899, next_state=array([ 0.06789637,  1.1860445 ,  0.2946559 , -0.5536515 , -0.10783125,\n",
      "       -0.03286896,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06789637,  1.1860445 ,  0.2946559 , -0.5536515 , -0.10783125,\n",
      "       -0.03286896,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.837819154676281, next_state=array([ 0.07088566,  1.1729739 ,  0.3020936 , -0.58114296, -0.11098827,\n",
      "       -0.06314588,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07088566,  1.1729739 ,  0.3020936 , -0.58114296, -0.11098827,\n",
      "       -0.06314588,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5707117703296081, next_state=array([ 0.07378712,  1.1593246 ,  0.29106295, -0.6067046 , -0.1119001 ,\n",
      "       -0.0182382 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07378712,  1.1593246 ,  0.29106295, -0.6067046 , -0.1119001 ,\n",
      "       -0.0182382 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1796632311311441, next_state=array([ 0.07668696,  1.1450541 ,  0.29090342, -0.63432133, -0.11281272,\n",
      "       -0.01825252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07668696,  1.1450541 ,  0.29090342, -0.63432133, -0.11281272,\n",
      "       -0.01825252,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6901773154195314, next_state=array([ 0.07966204,  1.1301801 ,  0.30033135, -0.6612758 , -0.11561356,\n",
      "       -0.05601689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07966204,  1.1301801 ,  0.30033135, -0.6612758 , -0.11561356,\n",
      "       -0.05601689,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1943421774253409, next_state=array([ 0.08263712,  1.1147065 ,  0.30033123, -0.68794316, -0.1184144 ,\n",
      "       -0.05601697,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08263712,  1.1147065 ,  0.30033123, -0.68794316, -0.1184144 ,\n",
      "       -0.05601697,  0.        ,  0.        ], dtype=float32), action=2, reward=4.077939707737653, next_state=array([ 0.08568783,  1.100115  ,  0.30807555, -0.64875567, -0.12140784,\n",
      "       -0.05986867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08568783,  1.100115  ,  0.30807555, -0.64875567, -0.12140784,\n",
      "       -0.05986867,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2270259668136987, next_state=array([ 0.08873844,  1.0849235 ,  0.3080754 , -0.675423  , -0.12440126,\n",
      "       -0.05986841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08873844,  1.0849235 ,  0.3080754 , -0.675423  , -0.12440126,\n",
      "       -0.05986841,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9311882081419867, next_state=array([ 0.09176683,  1.0699894 ,  0.3062858 , -0.66402555, -0.12782438,\n",
      "       -0.06846228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09176683,  1.0699894 ,  0.3062858 , -0.66402555, -0.12782438,\n",
      "       -0.06846228,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.127454593433326, next_state=array([ 0.09489326,  1.054438  ,  0.31858635, -0.69169533, -0.13373904,\n",
      "       -0.11829334,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09489326,  1.054438  ,  0.31858635, -0.69169533, -0.13373904,\n",
      "       -0.11829334,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.274946175927282, next_state=array([ 0.09811316,  1.0382712 ,  0.33029592, -0.71929383, -0.14202465,\n",
      "       -0.16571227,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09811316,  1.0382712 ,  0.33029592, -0.71929383, -0.14202465,\n",
      "       -0.16571227,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5344893402654223, next_state=array([ 0.10142765,  1.0214739 ,  0.3422043 , -0.74761707, -0.15275973,\n",
      "       -0.21470146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10142765,  1.0214739 ,  0.3422043 , -0.74761707, -0.15275973,\n",
      "       -0.21470146,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6367797761516543, next_state=array([ 0.10483398,  1.0040607 ,  0.35371166, -0.77531445, -0.16583149,\n",
      "       -0.26143545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10483398,  1.0040607 ,  0.35371166, -0.77531445, -0.16583149,\n",
      "       -0.26143545,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.473711302659807, next_state=array([ 0.10817985,  0.98606586,  0.34608084, -0.80109364, -0.17734031,\n",
      "       -0.23017618,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10817985,  0.98606586,  0.34608084, -0.80109364, -0.17734031,\n",
      "       -0.23017618,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9983826640199698, next_state=array([ 0.11143646,  0.9675064 ,  0.33479136, -0.82598084, -0.18650466,\n",
      "       -0.18328674,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11143646,  0.9675064 ,  0.33479136, -0.82598084, -0.18650466,\n",
      "       -0.18328674,  0.        ,  0.        ], dtype=float32), action=2, reward=2.84000968219699, next_state=array([ 0.11486502,  0.9496801 ,  0.3519547 , -0.7934526 , -0.19564892,\n",
      "       -0.18288536,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11486502,  0.9496801 ,  0.3519547 , -0.7934526 , -0.19564892,\n",
      "       -0.18288536,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.963255397243272, next_state=array([ 0.11822148,  0.9312737 ,  0.34287852, -0.8190387 , -0.20293073,\n",
      "       -0.14563608,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11822148,  0.9312737 ,  0.34287852, -0.8190387 , -0.20293073,\n",
      "       -0.14563608,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.107846607752974, next_state=array([ 0.12165985,  0.9122446 ,  0.35316402, -0.8470418 , -0.21233174,\n",
      "       -0.18802017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12165985,  0.9122446 ,  0.35316402, -0.8470418 , -0.21233174,\n",
      "       -0.18802017,  0.        ,  0.        ], dtype=float32), action=2, reward=0.701938749495082, next_state=array([ 0.12524661,  0.8933827 ,  0.36780193, -0.83964705, -0.22156048,\n",
      "       -0.18457495,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12524661,  0.8933827 ,  0.36780193, -0.83964705, -0.22156048,\n",
      "       -0.18457495,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7016053875330772, next_state=array([ 0.12874421,  0.8739528 ,  0.35656267, -0.8645932 , -0.22845034,\n",
      "       -0.13779771,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12874421,  0.8739528 ,  0.35656267, -0.8645932 , -0.22845034,\n",
      "       -0.13779771,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.231694129023765, next_state=array([ 0.13224182,  0.8539234 ,  0.35656133, -0.89126366, -0.23534021,\n",
      "       -0.13779725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13224182,  0.8539234 ,  0.35656133, -0.89126366, -0.23534021,\n",
      "       -0.13779725,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.984415606047462, next_state=array([ 0.1358242 ,  0.83326507,  0.3672151 , -0.91960603, -0.24445236,\n",
      "       -0.18224299,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1358242 ,  0.83326507,  0.3672151 , -0.91960603, -0.24445236,\n",
      "       -0.18224299,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3556179485627808, next_state=array([ 0.13940677,  0.81200784,  0.3672126 , -0.9462794 , -0.25356445,\n",
      "       -0.1822419 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13940677,  0.81200784,  0.3672126 , -0.9462794 , -0.25356445,\n",
      "       -0.1822419 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7429427173998124, next_state=array([ 0.14292869,  0.7901848 ,  0.35948807, -0.97119623, -0.2610128 ,\n",
      "       -0.14896724,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14292869,  0.7901848 ,  0.35948807, -0.97119623, -0.2610128 ,\n",
      "       -0.14896724,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1098783505868255, next_state=array([ 0.14645071,  0.76776236,  0.35948628, -0.99786735, -0.2684611 ,\n",
      "       -0.14896667,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14645071,  0.76776236,  0.35948628, -0.99786735, -0.2684611 ,\n",
      "       -0.14896667,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8225279313317333, next_state=array([ 0.15005493,  0.74471027,  0.3698089 , -1.0262868 , -0.27807814,\n",
      "       -0.19234072,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15005493,  0.74471027,  0.3698089 , -1.0262868 , -0.27807814,\n",
      "       -0.19234072,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.232022202297287, next_state=array([ 0.15365943,  0.7210596 ,  0.36980575, -1.052961  , -0.28769514,\n",
      "       -0.1923395 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15365943,  0.7210596 ,  0.36980575, -1.052961  , -0.28769514,\n",
      "       -0.1923395 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.004530355378802, next_state=array([ 0.15730906,  0.69772196,  0.37486848, -1.0392216 , -0.29791075,\n",
      "       -0.20431201,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15730906,  0.69772196,  0.37486848, -1.0392216 , -0.29791075,\n",
      "       -0.20431201,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9562509794228322, next_state=array([ 0.16103382,  0.6737629 ,  0.38423914, -1.0673006 , -0.31007633,\n",
      "       -0.24331221,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16103382,  0.6737629 ,  0.38423914, -1.0673006 , -0.31007633,\n",
      "       -0.24331221,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.142761565521282, next_state=array([ 0.16483602,  0.64917886,  0.39387837, -1.0956047 , -0.3242684 ,\n",
      "       -0.28384143,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16483602,  0.64917886,  0.39387837, -1.0956047 , -0.3242684 ,\n",
      "       -0.28384143,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5937043235514352, next_state=array([ 0.1686387 ,  0.6239973 ,  0.39387044, -1.1222873 , -0.33846027,\n",
      "       -0.28383747,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1686387 ,  0.6239973 ,  0.39387044, -1.1222873 , -0.33846027,\n",
      "       -0.28383747,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5432011829372925, next_state=array([ 0.17270117,  0.5990106 ,  0.4194623 , -1.1136911 , -0.3523324 ,\n",
      "       -0.2774431 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17270117,  0.5990106 ,  0.4194623 , -1.1136911 , -0.3523324 ,\n",
      "       -0.2774431 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4103023399901233, next_state=array([ 0.17683992,  0.5733722 ,  0.42912015, -1.1433045 , -0.3684038 ,\n",
      "       -0.32142788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17683992,  0.5733722 ,  0.42912015, -1.1433045 , -0.3684038 ,\n",
      "       -0.32142788,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7355969697607918, next_state=array([ 0.18097953,  0.54713696,  0.42910862, -1.1699913 , -0.38447487,\n",
      "       -0.3214224 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18097953,  0.54713696,  0.42910862, -1.1699913 , -0.38447487,\n",
      "       -0.3214224 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8167209621805955, next_state=array([ 0.18502903,  0.52035826,  0.4176002 , -1.193636  , -0.39798042,\n",
      "       -0.2701107 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18502903,  0.52035826,  0.4176002 , -1.193636  , -0.39798042,\n",
      "       -0.2701107 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0351955143231337, next_state=array([ 0.18913755,  0.49295306,  0.4249317 , -1.2220299 , -0.41309148,\n",
      "       -0.30222198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18913755,  0.49295306,  0.4249317 , -1.2220299 , -0.41309148,\n",
      "       -0.30222198,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.58593030676019, next_state=array([ 0.19324693,  0.46495065,  0.42492038, -1.2487142 , -0.4282023 ,\n",
      "       -0.30221725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19324693,  0.46495065,  0.42492038, -1.2487142 , -0.4282023 ,\n",
      "       -0.30221725,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6219442894228393, next_state=array([ 0.19767657,  0.43721238,  0.45663196, -1.2370425 , -0.44307137,\n",
      "       -0.2973821 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19767657,  0.43721238,  0.45663196, -1.2370425 , -0.44307137,\n",
      "       -0.2973821 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9221826982960681, next_state=array([ 0.20203876,  0.40892094,  0.44797444, -1.2611763 , -0.45596316,\n",
      "       -0.25783622,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20203876,  0.40892094,  0.44797444, -1.2611763 , -0.45596316,\n",
      "       -0.25783622,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4413161676345112, next_state=array([ 0.20640154,  0.3800314 ,  0.44796538, -1.2878556 , -0.4688548 ,\n",
      "       -0.2578333 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20640154,  0.3800314 ,  0.44796538, -1.2878556 , -0.4688548 ,\n",
      "       -0.2578333 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.53113771219044, next_state=array([ 0.2109561 ,  0.35152826,  0.46758327, -1.2709688 , -0.48232928,\n",
      "       -0.26948932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2109561 ,  0.35152826,  0.46758327, -1.2709688 , -0.48232928,\n",
      "       -0.26948932,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4932089081106426, next_state=array([ 0.21570253,  0.32320234,  0.4869848 , -1.2633051 , -0.49612835,\n",
      "       -0.27598056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21570253,  0.32320234,  0.4869848 , -1.2633051 , -0.49612835,\n",
      "       -0.27598056,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.784533407101378, next_state=array([ 0.22044984,  0.29427862,  0.48697346, -1.2899858 , -0.5099272 ,\n",
      "       -0.27597672,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22044984,  0.29427862,  0.48697346, -1.2899858 , -0.5099272 ,\n",
      "       -0.27597672,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.888158158663258, next_state=array([ 0.22527905,  0.2646867 ,  0.49732384, -1.3206581 , -0.5262731 ,\n",
      "       -0.32691765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22527905,  0.2646867 ,  0.49732384, -1.3206581 , -0.5262731 ,\n",
      "       -0.32691765,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.20647571706496, next_state=array([ 0.23018742,  0.23443137,  0.5072068 , -1.3511425 , -0.5450536 ,\n",
      "       -0.37561035,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23018742,  0.23443137,  0.5072068 , -1.3511425 , -0.5450536 ,\n",
      "       -0.37561035,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6233957955835763, next_state=array([ 0.23509732,  0.20358017,  0.5071842 , -1.3778344 , -0.5638336 ,\n",
      "       -0.3756012 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23509732,  0.20358017,  0.5071842 , -1.3778344 , -0.5638336 ,\n",
      "       -0.3756012 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.46287659703115763, next_state=array([ 0.2402238 ,  0.17299119,  0.5291281 , -1.3665946 , -0.5831875 ,\n",
      "       -0.38707823,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2402238 ,  0.17299119,  0.5291281 , -1.3665946 , -0.5831875 ,\n",
      "       -0.38707823,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2706157843340677, next_state=array([ 0.24528399,  0.141878  ,  0.5203595 , -1.3892249 , -0.60023415,\n",
      "       -0.34093302,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24528399,  0.141878  ,  0.5203595 , -1.3892249 , -0.60023415,\n",
      "       -0.34093302,  0.        ,  0.        ], dtype=float32), action=3, reward=5.850571028924834, next_state=array([ 0.25041828,  0.11010526,  0.52951145, -1.4195956 , -0.61958176,\n",
      "       -0.38695273,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25041828,  0.11010526,  0.52951145, -1.4195956 , -0.61958176,\n",
      "       -0.38695273,  1.        ,  0.        ], dtype=float32), action=3, reward=-4.042262087711605, next_state=array([ 0.25551233,  0.07821608,  0.5332809 , -1.4395163 , -0.646058  ,\n",
      "       -0.50783765,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25551233,  0.07821608,  0.5332809 , -1.4395163 , -0.646058  ,\n",
      "       -0.50783765,  1.        ,  0.        ], dtype=float32), action=1, reward=28.526907248146415, next_state=array([ 0.25645226,  0.06173667,  0.286631  , -0.98253167, -0.8755598 ,\n",
      "       -4.0018992 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25645226,  0.06173667,  0.286631  , -0.98253167, -0.8755598 ,\n",
      "       -4.0018992 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-3.357719674364944, next_state=array([ 0.25631532,  0.05057495,  0.15074137, -0.7531396 , -1.1670685 ,\n",
      "       -5.3531404 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25631532,  0.05057495,  0.15074137, -0.7531396 , -1.1670685 ,\n",
      "       -5.3531404 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.25473326,  0.04448055, -0.26684564, -0.10842711, -1.283704  ,\n",
      "        0.12553738,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-1.3140679e-03,  1.4016218e+00, -1.3311782e-01, -4.1325778e-01,\n",
      "        1.5294764e-03,  3.0153189e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.074655543431503, next_state=array([-2.54306803e-03,  1.39175761e+00, -1.22244895e-01, -4.38408345e-01,\n",
      "        8.74534831e-04, -1.30991507e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.54306803e-03,  1.39175761e+00, -1.22244895e-01, -4.38408345e-01,\n",
      "        8.74534831e-04, -1.30991507e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=2, reward=3.414500687003806, next_state=array([-3.74479289e-03,  1.38251758e+00, -1.19650446e-01, -4.10669625e-01,\n",
      "        3.54517513e-04, -1.04013523e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.74479289e-03,  1.38251758e+00, -1.19650446e-01, -4.10669625e-01,\n",
      "        3.54517513e-04, -1.04013523e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.5679600771160824, next_state=array([-0.00487595,  1.3726722 , -0.11077546, -0.43757138, -0.00194529,\n",
      "       -0.04600065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00487595,  1.3726722 , -0.11077546, -0.43757138, -0.00194529,\n",
      "       -0.04600065,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7749221549804304, next_state=array([-0.00600691,  1.362227  , -0.11076826, -0.46423477, -0.00424393,\n",
      "       -0.04597721,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00600691,  1.362227  , -0.11076826, -0.46423477, -0.00424393,\n",
      "       -0.04597721,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7575789233045203, next_state=array([-0.00720158,  1.3511859 , -0.11876168, -0.49071676, -0.0049382 ,\n",
      "       -0.01388699,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00720158,  1.3511859 , -0.11876168, -0.49071676, -0.0049382 ,\n",
      "       -0.01388699,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5373662360924516, next_state=array([-0.00848179,  1.3395517 , -0.12950616, -0.5170725 , -0.00347789,\n",
      "        0.0292089 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00848179,  1.3395517 , -0.12950616, -0.5170725 , -0.00347789,\n",
      "        0.0292089 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.501588929206844, next_state=array([-0.00981894,  1.328312  , -0.13490385, -0.49954095, -0.00229997,\n",
      "        0.02356077,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00981894,  1.328312  , -0.13490385, -0.49954095, -0.00229997,\n",
      "        0.02356077,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4138876930915945, next_state=array([-1.1215592e-02,  1.3164747e+00, -1.4236310e-01, -5.2610624e-01,\n",
      "        3.7336280e-04,  5.3471476e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.1215592e-02,  1.3164747e+00, -1.4236310e-01, -5.2610624e-01,\n",
      "        3.7336280e-04,  5.3471476e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.217808779925689, next_state=array([-1.2538528e-02,  1.3040388e+00, -1.3312788e-01, -5.5270278e-01,\n",
      "        1.1925501e-03,  1.6385164e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.2538528e-02,  1.3040388e+00, -1.3312788e-01, -5.5270278e-01,\n",
      "        1.1925501e-03,  1.6385164e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.3758692201701592, next_state=array([-0.01386156,  1.291003  , -0.13312973, -0.5793713 ,  0.00201273,\n",
      "        0.01640506,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01386156,  1.291003  , -0.13312973, -0.5793713 ,  0.00201273,\n",
      "        0.01640506,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9433100520598134, next_state=array([-1.51037220e-02,  1.27736604e+00, -1.22985065e-01, -6.06087446e-01,\n",
      "        7.98467838e-04, -2.42872573e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.51037220e-02,  1.27736604e+00, -1.22985065e-01, -6.06087446e-01,\n",
      "        7.98467838e-04, -2.42872573e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.1552544935752849, next_state=array([-1.6345788e-02,  1.2631290e+00, -1.2298105e-01, -6.3275588e-01,\n",
      "       -4.1473904e-04, -2.4266288e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.6345788e-02,  1.2631290e+00, -1.2298105e-01, -6.3275588e-01,\n",
      "       -4.1473904e-04, -2.4266288e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.4196068933999004, next_state=array([-1.7674923e-02,  1.2482853e+00, -1.3389410e-01, -6.5972155e-01,\n",
      "        5.5965094e-04,  1.9489339e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.7674923e-02,  1.2482853e+00, -1.3389410e-01, -6.5972155e-01,\n",
      "        5.5965094e-04,  1.9489339e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=3.561138438254841, next_state=array([-1.9103145e-02,  1.2340606e+00, -1.4333436e-01, -6.3220894e-01,\n",
      "        1.0682635e-03,  1.0173174e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.9103145e-02,  1.2340606e+00, -1.4333436e-01, -6.3220894e-01,\n",
      "        1.0682635e-03,  1.0173174e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=2.5218364862058253, next_state=array([-0.02040205,  1.2201306 , -0.13102353, -0.61910975,  0.00218868,\n",
      "        0.02241047,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02040205,  1.2201306 , -0.13102353, -0.61910975,  0.00218868,\n",
      "        0.02241047,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7768559366500358, next_state=array([-0.02178869,  1.2055948 , -0.1420345 , -0.6460458 ,  0.00551419,\n",
      "        0.0665161 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02178869,  1.2055948 , -0.1420345 , -0.6460458 ,  0.00551419,\n",
      "        0.0665161 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0074647480420242, next_state=array([-0.02308044,  1.1904532 , -0.13012075, -0.6729642 ,  0.00644987,\n",
      "        0.01871499,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02308044,  1.1904532 , -0.13012075, -0.6729642 ,  0.00644987,\n",
      "        0.01871499,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4916083188687697, next_state=array([-0.02444611,  1.1747216 , -0.13939059, -0.6991938 ,  0.0092427 ,\n",
      "        0.05586193,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02444611,  1.1747216 , -0.13939059, -0.6991938 ,  0.0092427 ,\n",
      "        0.05586193,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2667906665446367, next_state=array([-0.02581196,  1.1583902 , -0.13939926, -0.7258634 ,  0.01203387,\n",
      "        0.05582825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02581196,  1.1583902 , -0.13939926, -0.7258634 ,  0.01203387,\n",
      "        0.05582825,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9527197957408748, next_state=array([-0.02710772,  1.1414483 , -0.1306269 , -0.7529817 ,  0.01306809,\n",
      "        0.02068655,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02710772,  1.1414483 , -0.1306269 , -0.7529817 ,  0.01306809,\n",
      "        0.02068655,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5475514748723913, next_state=array([-0.02830706,  1.123913  , -0.11853242, -0.7793319 ,  0.01167803,\n",
      "       -0.02780362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02830706,  1.123913  , -0.11853242, -0.7793319 ,  0.01167803,\n",
      "       -0.02780362,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0442369040523818, next_state=array([-0.02958326,  1.1057813 , -0.12816465, -0.80586076,  0.01221853,\n",
      "        0.0108106 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02958326,  1.1057813 , -0.12816465, -0.80586076,  0.01221853,\n",
      "        0.0108106 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2171376913688892, next_state=array([-0.03094406,  1.087053  , -0.13877551, -0.83239156,  0.01488193,\n",
      "        0.05327293,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03094406,  1.087053  , -0.13877551, -0.83239156,  0.01488193,\n",
      "        0.05327293,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9701151945830304, next_state=array([-0.03230486,  1.0677247 , -0.13878326, -0.85906094,  0.01754446,\n",
      "        0.05325558,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03230486,  1.0677247 , -0.13878326, -0.85906094,  0.01754446,\n",
      "        0.05325558,  0.        ,  0.        ], dtype=float32), action=2, reward=1.216082833737073, next_state=array([-0.03374214,  1.0483831 , -0.14609101, -0.85965884,  0.01988626,\n",
      "        0.04683593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03374214,  1.0483831 , -0.14609101, -0.85965884,  0.01988626,\n",
      "        0.04683593,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.47620443988091554, next_state=array([-0.03509064,  1.0284482 , -0.13496412, -0.8859931 ,  0.01999767,\n",
      "        0.00222811,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03509064,  1.0284482 , -0.13496412, -0.8859931 ,  0.01999767,\n",
      "        0.00222811,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2679098915767044, next_state=array([-0.03638802,  1.0088742 , -0.13015148, -0.86996233,  0.02040464,\n",
      "        0.00813956,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03638802,  1.0088742 , -0.13015148, -0.86996233,  0.02040464,\n",
      "        0.00813956,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6676573748405019, next_state=array([-0.0376853 ,  0.98870015, -0.13015148, -0.896629  ,  0.02081162,\n",
      "        0.00813964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0376853 ,  0.98870015, -0.13015148, -0.896629  ,  0.02081162,\n",
      "        0.00813964,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6097608520022391, next_state=array([-0.03898268,  0.96792614, -0.13015148, -0.9232956 ,  0.02121859,\n",
      "        0.00813963,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03898268,  0.96792614, -0.13015148, -0.9232956 ,  0.02121859,\n",
      "        0.00813963,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5517770265626609, next_state=array([-0.04028006,  0.94655216, -0.13015148, -0.94996226,  0.02162556,\n",
      "        0.00813972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04028006,  0.94655216, -0.13015148, -0.94996226,  0.02162556,\n",
      "        0.00813972,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2151957665867019, next_state=array([-0.04150105,  0.92457604, -0.12056838, -0.97668785,  0.02011434,\n",
      "       -0.03022452,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04150105,  0.92457604, -0.12056838, -0.97668785,  0.02011434,\n",
      "       -0.03022452,  0.        ,  0.        ], dtype=float32), action=2, reward=4.711148448460119, next_state=array([-0.04289188,  0.90325415, -0.13683054, -0.94761616,  0.01789556,\n",
      "       -0.04437612,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04289188,  0.90325415, -0.13683054, -0.94761616,  0.01789556,\n",
      "       -0.04437612,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.582939587940358, next_state=array([-0.04435797,  0.8813344 , -0.14627612, -0.97420293,  0.01756751,\n",
      "       -0.00656065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04435797,  0.8813344 , -0.14627612, -0.97420293,  0.01756751,\n",
      "       -0.00656065,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.36371378278067823, next_state=array([-0.04582405,  0.8588147 , -0.14627612, -1.0008695 ,  0.01723947,\n",
      "       -0.00656064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04582405,  0.8588147 , -0.14627612, -1.0008695 ,  0.01723947,\n",
      "       -0.00656064,  0.        ,  0.        ], dtype=float32), action=3, reward=0.02375762789284977, next_state=array([-0.04720955,  0.83569896, -0.13616176, -1.0273402 ,  0.01488491,\n",
      "       -0.04709125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04720955,  0.83569896, -0.13616176, -1.0273402 ,  0.01488491,\n",
      "       -0.04709125,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.04919709803189676, next_state=array([-0.04859505,  0.81198335, -0.13616176, -1.0540072 ,  0.01253035,\n",
      "       -0.04709142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04859505,  0.81198335, -0.13616176, -1.0540072 ,  0.01253035,\n",
      "       -0.04709142,  0.        ,  0.        ], dtype=float32), action=0, reward=0.008608439657905365, next_state=array([-0.04998054,  0.7876678 , -0.13616174, -1.0806744 ,  0.01017578,\n",
      "       -0.04709144,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04998054,  0.7876678 , -0.13616174, -1.0806744 ,  0.01017578,\n",
      "       -0.04709144,  0.        ,  0.        ], dtype=float32), action=3, reward=0.41336605866953957, next_state=array([-0.05128203,  0.7627616 , -0.12561709, -1.1069162 ,  0.00570796,\n",
      "       -0.08935656,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05128203,  0.7627616 , -0.12561709, -1.1069162 ,  0.00570796,\n",
      "       -0.08935656,  0.        ,  0.        ], dtype=float32), action=0, reward=0.332050375855232, next_state=array([-0.05258341,  0.7372559 , -0.12561706, -1.1335845 ,  0.00124014,\n",
      "       -0.08935647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05258341,  0.7372559 , -0.12561706, -1.1335845 ,  0.00124014,\n",
      "       -0.08935647,  0.        ,  0.        ], dtype=float32), action=2, reward=2.542349198973466, next_state=array([-0.05388737,  0.71186846, -0.12585868, -1.1283292 , -0.0032366 ,\n",
      "       -0.08953491,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05388737,  0.71186846, -0.12585868, -1.1283292 , -0.0032366 ,\n",
      "       -0.08953491,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6629985735959554, next_state=array([-0.0551013 ,  0.6858802 , -0.11457416, -1.1550668 , -0.00997331,\n",
      "       -0.13473402,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0551013 ,  0.6858802 , -0.11457416, -1.1550668 , -0.00997331,\n",
      "       -0.13473402,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6585939739248079, next_state=array([-0.05639277,  0.6592836 , -0.12429696, -1.1821123 , -0.01476438,\n",
      "       -0.09582135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05639277,  0.6592836 , -0.12429696, -1.1821123 , -0.01476438,\n",
      "       -0.09582135,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.43395435695083506, next_state=array([-0.05768423,  0.63208723, -0.12429699, -1.2087809 , -0.01955545,\n",
      "       -0.09582122,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05768423,  0.63208723, -0.12429699, -1.2087809 , -0.01955545,\n",
      "       -0.09582122,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.37712474407413765, next_state=array([-0.0589757 ,  0.60429126, -0.12429704, -1.2354496 , -0.02434652,\n",
      "       -0.09582102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0589757 ,  0.60429126, -0.12429704, -1.2354496 , -0.02434652,\n",
      "       -0.09582102,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3206650085766114, next_state=array([-0.06026716,  0.5758956 , -0.1242971 , -1.2621181 , -0.02913758,\n",
      "       -0.09582102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06026716,  0.5758956 , -0.1242971 , -1.2621181 , -0.02913758,\n",
      "       -0.09582102,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.21402531150729828, next_state=array([-0.06163788,  0.54689497, -0.13424039, -1.2889731 , -0.03194028,\n",
      "       -0.05605378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06163788,  0.54689497, -0.13424039, -1.2889731 , -0.03194028,\n",
      "       -0.05605378,  0.        ,  0.        ], dtype=float32), action=2, reward=4.74553383783329, next_state=array([-0.06303072,  0.5184743 , -0.13622615, -1.2632099 , -0.03496128,\n",
      "       -0.06042029,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06303072,  0.5184743 , -0.13622615, -1.2632099 , -0.03496128,\n",
      "       -0.06042029,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.026577498158046636, next_state=array([-0.06449012,  0.48945725, -0.14457609, -1.2896783 , -0.0363085 ,\n",
      "       -0.02694422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06449012,  0.48945725, -0.14457609, -1.2896783 , -0.0363085 ,\n",
      "       -0.02694422,  0.        ,  0.        ], dtype=float32), action=1, reward=0.20638936886771944, next_state=array([-0.06601629,  0.4598472 , -0.15295108, -1.3159938 , -0.03597477,\n",
      "        0.00667452,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06601629,  0.4598472 , -0.15295108, -1.3159938 , -0.03597477,\n",
      "        0.00667452,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3988394645293465, next_state=array([-0.06761589,  0.4296371 , -0.1621718 , -1.3426213 , -0.03379513,\n",
      "        0.04359269,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06761589,  0.4296371 , -0.1621718 , -1.3426213 , -0.03379513,\n",
      "        0.04359269,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5837849074728467, next_state=array([-0.06921558,  0.39882705, -0.16217181, -1.3692886 , -0.03161549,\n",
      "        0.04359263,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06921558,  0.39882705, -0.16217181, -1.3692886 , -0.03161549,\n",
      "        0.04359263,  0.        ,  0.        ], dtype=float32), action=2, reward=5.7354006479302315, next_state=array([-0.07082482,  0.3686758 , -0.16296592, -1.340015  , -0.02960326,\n",
      "        0.04024462,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07082482,  0.3686758 , -0.16296592, -1.340015  , -0.02960326,\n",
      "        0.04024462,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6065884547664393, next_state=array([-0.07251243,  0.33792967, -0.17279929, -1.3664182 , -0.02561966,\n",
      "        0.07967202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07251243,  0.33792967, -0.17279929, -1.3664182 , -0.02561966,\n",
      "        0.07967202,  0.        ,  0.        ], dtype=float32), action=2, reward=4.221586805753486, next_state=array([-0.07426663,  0.3074816 , -0.1790757 , -1.3531908 , -0.02201508,\n",
      "        0.07209168,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07426663,  0.3074816 , -0.1790757 , -1.3531908 , -0.02201508,\n",
      "        0.07209168,  0.        ,  0.        ], dtype=float32), action=0, reward=0.6790110338257307, next_state=array([-0.07602091,  0.27643362, -0.17907575, -1.3798584 , -0.01841051,\n",
      "        0.07209161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07602091,  0.27643362, -0.17907575, -1.3798584 , -0.01841051,\n",
      "        0.07209161,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7471082738646555, next_state=array([-0.07785349,  0.24478771, -0.18891467, -1.4064294 , -0.01283522,\n",
      "        0.11150599,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07785349,  0.24478771, -0.18891467, -1.4064294 , -0.01283522,\n",
      "        0.11150599,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8044998119736715, next_state=array([-0.07960796,  0.21254268, -0.17909592, -1.4330847 , -0.00922605,\n",
      "        0.07218313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07960796,  0.21254268, -0.17909592, -1.4330847 , -0.00922605,\n",
      "        0.07218313,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7528976931354532, next_state=array([-0.08144274,  0.17970373, -0.189185  , -1.459488  , -0.00359558,\n",
      "        0.11260957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08144274,  0.17970373, -0.189185  , -1.459488  , -0.00359558,\n",
      "        0.11260957,  0.        ,  0.        ], dtype=float32), action=3, reward=0.718451761059357, next_state=array([-8.3179191e-02,  1.4627045e-01, -1.7684604e-01, -1.4859176e+00,\n",
      "       -4.3582916e-04,  6.3194819e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-8.3179191e-02,  1.4627045e-01, -1.7684604e-01, -1.4859176e+00,\n",
      "       -4.3582916e-04,  6.3194819e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-0.5324791509585498, next_state=array([-0.08501406,  0.11224294, -0.18919449, -1.5123425 ,  0.00519689,\n",
      "        0.11265472,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08501406,  0.11224294, -0.18919449, -1.5123425 ,  0.00519689,\n",
      "        0.11265472,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7772242411680281, next_state=array([-0.08684893,  0.07761592, -0.18919447, -1.5390117 ,  0.0108296 ,\n",
      "        0.11265449,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08684893,  0.07761592, -0.18919447, -1.5390117 ,  0.0108296 ,\n",
      "        0.11265449,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3922575317189967, next_state=array([-0.0886837 ,  0.04238921, -0.18919444, -1.5656812 ,  0.01646231,\n",
      "        0.11265425,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0886837 ,  0.04238921, -0.18919444, -1.5656812 ,  0.01646231,\n",
      "        0.11265425,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9010316304650403, next_state=array([-0.09061174,  0.00655747, -0.20087807, -1.5926337 ,  0.0244363 ,\n",
      "        0.15947965,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09061174,  0.00655747, -0.20087807, -1.5926337 ,  0.0244363 ,\n",
      "        0.15947965,  0.        ,  0.        ], dtype=float32), action=3, reward=16.28459107422418, next_state=array([-0.09244271, -0.02987468, -0.18870683, -1.619309  ,  0.02997358,\n",
      "        0.11074557,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.09244271, -0.02987468, -0.18870683, -1.619309  ,  0.02997358,\n",
      "        0.11074557,  1.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-9.3559071e-02, -4.2821135e-02,  8.8919975e-08, -1.0559714e-07,\n",
      "        3.1934259e-04, -4.0761057e-07,  0.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([-0.00196438,  1.4144435 , -0.19899316,  0.15659794,  0.00228309,\n",
      "        0.04507489,  0.        ,  0.        ], dtype=float32), action=1, reward=0.10103616519623529, next_state=array([-0.00399485,  1.4173967 , -0.20697078,  0.13123943,  0.00616412,\n",
      "        0.07762864,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00399485,  1.4173967 , -0.20697078,  0.13123943,  0.00616412,\n",
      "        0.07762864,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.752575881384405, next_state=array([-0.00613689,  1.4203156 , -0.21758866,  0.12971018,  0.00951901,\n",
      "        0.0671038 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00613689,  1.4203156 , -0.21758866,  0.12971018,  0.00951901,\n",
      "        0.0671038 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.6873231453884614, next_state=array([-0.00827894,  1.4226345 , -0.2175982 ,  0.10303352,  0.01287423,\n",
      "        0.06711052,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00827894,  1.4226345 , -0.2175982 ,  0.10303352,  0.01287423,\n",
      "        0.06711052,  0.        ,  0.        ], dtype=float32), action=0, reward=0.505240906111112, next_state=array([-0.01042118,  1.4243534 , -0.21760821,  0.07636655,  0.01622872,\n",
      "        0.0670959 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01042118,  1.4243534 , -0.21760821,  0.07636655,  0.01622872,\n",
      "        0.0670959 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.2908201988821588, next_state=array([-0.01256351,  1.4254725 , -0.21761802,  0.0496976 ,  0.01958269,\n",
      "        0.06708536,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01256351,  1.4254725 , -0.21761802,  0.0496976 ,  0.01958269,\n",
      "        0.06708536,  0.        ,  0.        ], dtype=float32), action=0, reward=0.04845134423817399, next_state=array([-0.01470594,  1.4259918 , -0.21762793,  0.02302849,  0.02293614,\n",
      "        0.06707489,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01470594,  1.4259918 , -0.21762793,  0.02302849,  0.02293614,\n",
      "        0.06707489,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.21211111173442987, next_state=array([-0.01684847,  1.425911  , -0.2176378 , -0.00364072,  0.02628905,\n",
      "        0.06706436,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01684847,  1.425911  , -0.2176378 , -0.00364072,  0.02628905,\n",
      "        0.06706436,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.912526933532347, next_state=array([-0.01908464,  1.4252223 , -0.22939534, -0.03071919,  0.03199992,\n",
      "        0.11422762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01908464,  1.4252223 , -0.22939534, -0.03071919,  0.03199992,\n",
      "        0.11422762,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.796544895110958, next_state=array([-0.02143707,  1.4247012 , -0.24053617, -0.02328242,  0.03723573,\n",
      "        0.10472591,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02143707,  1.4247012 , -0.24053617, -0.02328242,  0.03723573,\n",
      "        0.10472591,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.093104089508414, next_state=array([-0.0238739 ,  1.4235828 , -0.2511086 , -0.04991077,  0.04458587,\n",
      "        0.14701618,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0238739 ,  1.4235828 , -0.2511086 , -0.04991077,  0.04458587,\n",
      "        0.14701618,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.479201479942445, next_state=array([-0.02639475,  1.4218562 , -0.2616274 , -0.07704835,  0.05404364,\n",
      "        0.18917237,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02639475,  1.4218562 , -0.2616274 , -0.07704835,  0.05404364,\n",
      "        0.18917237,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.05919784836338521, next_state=array([-0.02886105,  1.4207389 , -0.25664532, -0.05003964,  0.06396341,\n",
      "        0.19841355,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02886105,  1.4207389 , -0.25664532, -0.05003964,  0.06396341,\n",
      "        0.19841355,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6430530894545996, next_state=array([-0.0313817 ,  1.4196968 , -0.26195568, -0.04676818,  0.07376265,\n",
      "        0.19600272,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0313817 ,  1.4196968 , -0.26195568, -0.04676818,  0.07376265,\n",
      "        0.19600272,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9923874862717126, next_state=array([-0.03412972,  1.419525  , -0.2839426 , -0.00810669,  0.0828344 ,\n",
      "        0.18145153,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03412972,  1.419525  , -0.2839426 , -0.00810669,  0.0828344 ,\n",
      "        0.18145153,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0400877373965898, next_state=array([-0.03687792,  1.4187541 , -0.28396675, -0.03479183,  0.09190533,\n",
      "        0.18143517,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03687792,  1.4187541 , -0.28396675, -0.03479183,  0.09190533,\n",
      "        0.18143517,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2251552305970677, next_state=array([-0.0396265 ,  1.4173844 , -0.28399283, -0.06146233,  0.10097455,\n",
      "        0.18140063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0396265 ,  1.4173844 , -0.28399283, -0.06146233,  0.10097455,\n",
      "        0.18140063,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.399120149451818, next_state=array([-0.04237537,  1.4154155 , -0.28401783, -0.08813868,  0.11004234,\n",
      "        0.18137239,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04237537,  1.4154155 , -0.28401783, -0.08813868,  0.11004234,\n",
      "        0.18137239,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.71462681175787, next_state=array([-0.04508762,  1.4134724 , -0.2807333 , -0.08709074,  0.11949463,\n",
      "        0.18906273,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04508762,  1.4134724 , -0.2807333 , -0.08709074,  0.11949463,\n",
      "        0.18906273,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.616311954147817, next_state=array([-0.04786749,  1.4109137 , -0.28919578, -0.11464839,  0.1306631 ,\n",
      "        0.2233892 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04786749,  1.4109137 , -0.28919578, -0.11464839,  0.1306631 ,\n",
      "        0.2233892 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8708676349210009, next_state=array([-0.05073299,  1.4092777 , -0.29795408, -0.07375596,  0.14205189,\n",
      "        0.22779632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05073299,  1.4092777 , -0.29795408, -0.07375596,  0.14205189,\n",
      "        0.22779632,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9410641890038276, next_state=array([-0.05383196,  1.4084263 , -0.32082134, -0.03891857,  0.15297233,\n",
      "        0.2184278 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05383196,  1.4084263 , -0.32082134, -0.03891857,  0.15297233,\n",
      "        0.2184278 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.834400984392373, next_state=array([-0.05702505,  1.4069548 , -0.3326007 , -0.06681775,  0.16628832,\n",
      "        0.26634327,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05702505,  1.4069548 , -0.3326007 , -0.06681775,  0.16628832,\n",
      "        0.26634327,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.839884174463718, next_state=array([-0.06028729,  1.4048605 , -0.3412681 , -0.09483457,  0.18138981,\n",
      "        0.30205652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06028729,  1.4048605 , -0.3412681 , -0.09483457,  0.18138981,\n",
      "        0.30205652,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5176004274253387, next_state=array([-0.06360598,  1.403676  , -0.347462  , -0.05461696,  0.19707431,\n",
      "        0.31371847,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06360598,  1.403676  , -0.347462  , -0.05461696,  0.19707431,\n",
      "        0.31371847,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9414241056552715, next_state=array([-0.06685705,  1.4018968 , -0.3389607 , -0.08098393,  0.21104251,\n",
      "        0.2793638 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06685705,  1.4018968 , -0.3389607 , -0.08098393,  0.21104251,\n",
      "        0.2793638 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9790624168945772, next_state=array([-0.07004471,  1.3995293 , -0.33097807, -0.10700826,  0.22339638,\n",
      "        0.2470775 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07004471,  1.3995293 , -0.33097807, -0.10700826,  0.22339638,\n",
      "        0.2470775 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.773179893944841, next_state=array([-0.07329178,  1.3965477 , -0.33840004, -0.13465102,  0.23728095,\n",
      "        0.27769142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07329178,  1.3965477 , -0.33840004, -0.13465102,  0.23728095,\n",
      "        0.27769142,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.116507319062748, next_state=array([-0.07653923,  1.3929685 , -0.33839452, -0.1613334 ,  0.25116536,\n",
      "        0.27768773,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07653923,  1.3929685 , -0.33839452, -0.1613334 ,  0.25116536,\n",
      "        0.27768773,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8947032512580211, next_state=array([-0.07969742,  1.3888372 , -0.3270466 , -0.18557024,  0.26261953,\n",
      "        0.22908333,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07969742,  1.3888372 , -0.3270466 , -0.18557024,  0.26261953,\n",
      "        0.22908333,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.15197471958072, next_state=array([-0.08292675,  1.3840727 , -0.33599186, -0.2141601 ,  0.27599216,\n",
      "        0.2674529 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08292675,  1.3840727 , -0.33599186, -0.2141601 ,  0.27599216,\n",
      "        0.2674529 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3166224813334395, next_state=array([-0.08615647,  1.3787103 , -0.3359859 , -0.2408412 ,  0.28936464,\n",
      "        0.2674494 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08615647,  1.3787103 , -0.3359859 , -0.2408412 ,  0.28936464,\n",
      "        0.2674494 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.365100443575176, next_state=array([-0.08953295,  1.3737783 , -0.35084885, -0.2218752 ,  0.30299333,\n",
      "        0.27257374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08953295,  1.3737783 , -0.35084885, -0.2218752 ,  0.30299333,\n",
      "        0.27257374,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6925946972003942, next_state=array([-0.09298162,  1.3694391 , -0.35877723, -0.195823  ,  0.31739956,\n",
      "        0.288124  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09298162,  1.3694391 , -0.35877723, -0.195823  ,  0.31739956,\n",
      "        0.288124  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0331699468828492, next_state=array([-0.09634133,  1.3645407 , -0.34749308, -0.2202757 ,  0.32939723,\n",
      "        0.23995352,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09634133,  1.3645407 , -0.34749308, -0.2202757 ,  0.32939723,\n",
      "        0.23995352,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.608659427675195, next_state=array([-0.10005484,  1.3603497 , -0.3825909 , -0.18888007,  0.34115002,\n",
      "        0.23505482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10005484,  1.3603497 , -0.3825909 , -0.18888007,  0.34115002,\n",
      "        0.23505482,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.142124276209897, next_state=array([-0.10384531,  1.3555263 , -0.3922118 , -0.217541  ,  0.35496995,\n",
      "        0.27639884,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10384531,  1.3555263 , -0.3922118 , -0.217541  ,  0.35496995,\n",
      "        0.27639884,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0262467819145786, next_state=array([-0.10755406,  1.3501467 , -0.38182786, -0.24185205,  0.36653015,\n",
      "        0.23120427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10755406,  1.3501467 , -0.38182786, -0.24185205,  0.36653015,\n",
      "        0.23120427,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0001647519642052, next_state=array([-0.11119099,  1.3442163 , -0.37267205, -0.26589563,  0.3760228 ,\n",
      "        0.18985298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11119099,  1.3442163 , -0.37267205, -0.26589563,  0.3760228 ,\n",
      "        0.18985298,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9614431295769803, next_state=array([-0.11522464,  1.3386867 , -0.41175714, -0.24799189,  0.38494226,\n",
      "        0.17839046,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11522464,  1.3386867 , -0.41175714, -0.24799189,  0.38494226,\n",
      "        0.17839046,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.93030462442175, next_state=array([-0.11933651,  1.3325192 , -0.4215571 , -0.2769529 ,  0.39600578,\n",
      "        0.22127016,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11933651,  1.3325192 , -0.4215571 , -0.2769529 ,  0.39600578,\n",
      "        0.22127016,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.163793747773609, next_state=array([-0.12339316,  1.3257899 , -0.41450697, -0.30157137,  0.40546772,\n",
      "        0.18923858,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12339316,  1.3257899 , -0.41450697, -0.30157137,  0.40546772,\n",
      "        0.18923858,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6112227985639993, next_state=array([-0.12736158,  1.3185087 , -0.4033463 , -0.325481  ,  0.4124649 ,\n",
      "        0.13994406,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12736158,  1.3185087 , -0.4033463 , -0.325481  ,  0.4124649 ,\n",
      "        0.13994406,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.49157280530840697, next_state=array([-0.13124914,  1.3106834 , -0.39305496, -0.3490568 ,  0.41710562,\n",
      "        0.09281467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13124914,  1.3106834 , -0.39305496, -0.3490568 ,  0.41710562,\n",
      "        0.09281467,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.580428435748216, next_state=array([-0.13521194,  1.3022132 , -0.4025486 , -0.37832364,  0.42388237,\n",
      "        0.13553472,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13521194,  1.3022132 , -0.4025486 , -0.37832364,  0.42388237,\n",
      "        0.13553472,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6767880260854042, next_state=array([-0.13917494,  1.2931435 , -0.40254623, -0.40499383,  0.4306591 ,\n",
      "        0.13553426,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13917494,  1.2931435 , -0.40254623, -0.40499383,  0.4306591 ,\n",
      "        0.13553426,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7001234776399758, next_state=array([-0.14307193,  1.283533  , -0.39405245, -0.4284727 ,  0.4353868 ,\n",
      "        0.0945543 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14307193,  1.283533  , -0.39405245, -0.4284727 ,  0.4353868 ,\n",
      "        0.0945543 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4921225603802668, next_state=array([-0.14696904,  1.2733228 , -0.39405128, -0.45514107,  0.44011453,\n",
      "        0.09455417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14696904,  1.2733228 , -0.39405128, -0.45514107,  0.44011453,\n",
      "        0.09455417,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.53545078970822, next_state=array([-0.15093927,  1.2624624 , -0.4033092 , -0.4846776 ,  0.4469814 ,\n",
      "        0.1373376 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15093927,  1.2624624 , -0.4033092 , -0.4846776 ,  0.4469814 ,\n",
      "        0.1373376 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.20884905598503, next_state=array([-0.15517274,  1.251406  , -0.42909807, -0.4932534 ,  0.45328876,\n",
      "        0.12614748,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15517274,  1.251406  , -0.42909807, -0.4932534 ,  0.45328876,\n",
      "        0.12614748,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5620837502990241, next_state=array([-0.15940638,  1.2397499 , -0.4290959 , -0.5199231 ,  0.45959613,\n",
      "        0.1261471 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15940638,  1.2397499 , -0.4290959 , -0.5199231 ,  0.45959613,\n",
      "        0.1261471 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7707481109398191, next_state=array([-0.16358633,  1.2275445 , -0.42218527, -0.5438474 ,  0.46420312,\n",
      "        0.09213988,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16358633,  1.2275445 , -0.42218527, -0.5438474 ,  0.46420312,\n",
      "        0.09213988,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6473261328854847, next_state=array([-0.16804838,  1.2152311 , -0.44992632, -0.5485156 ,  0.4683231 ,\n",
      "        0.0823999 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16804838,  1.2152311 , -0.44992632, -0.5485156 ,  0.4683231 ,\n",
      "        0.0823999 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2513577064395054, next_state=array([-0.17243223,  1.2023677 , -0.44007248, -0.572274  ,  0.47018656,\n",
      "        0.03726853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17243223,  1.2023677 , -0.44007248, -0.572274  ,  0.47018656,\n",
      "        0.03726853,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.114275701885076, next_state=array([-0.17689343,  1.1888542 , -0.44982275, -0.60185814,  0.47428977,\n",
      "        0.08206432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17689343,  1.1888542 , -0.44982275, -0.60185814,  0.47428977,\n",
      "        0.08206432,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2343278138566802, next_state=array([-0.18135461,  1.1747409 , -0.44982177, -0.62852603,  0.478393  ,\n",
      "        0.08206423,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18135461,  1.1747409 , -0.44982177, -0.62852603,  0.478393  ,\n",
      "        0.08206423,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2099346350408382, next_state=array([-0.185816  ,  1.160028  , -0.44982082, -0.655194  ,  0.4824962 ,\n",
      "        0.08206447,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.185816  ,  1.160028  , -0.44982082, -0.655194  ,  0.4824962 ,\n",
      "        0.08206447,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.38137574151339776, next_state=array([-0.19075975,  1.1458156 , -0.49769434, -0.63282216,  0.48619738,\n",
      "        0.0740237 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19075975,  1.1458156 , -0.49769434, -0.63282216,  0.48619738,\n",
      "        0.0740237 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1166923507415434, next_state=array([-0.19577551,  1.130955  , -0.5067681 , -0.66232187,  0.49200493,\n",
      "        0.11615058,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19577551,  1.130955  , -0.5067681 , -0.66232187,  0.49200493,\n",
      "        0.11615058,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.22463910583539246, next_state=array([-0.20071197,  1.1155503 , -0.49672866, -0.6857537 ,  0.49546328,\n",
      "        0.06916706,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20071197,  1.1155503 , -0.49672866, -0.6857537 ,  0.49546328,\n",
      "        0.06916706,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.26281202219365585, next_state=array([-0.20558938,  1.0995889 , -0.48926035, -0.7099466 ,  0.49716166,\n",
      "        0.03396772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20558938,  1.0995889 , -0.48926035, -0.7099466 ,  0.49716166,\n",
      "        0.03396772,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.712977385063083, next_state=array([-0.21052256,  1.0829699 , -0.49645597, -0.73975885,  0.50069374,\n",
      "        0.07064205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21052256,  1.0829699 , -0.49645597, -0.73975885,  0.50069374,\n",
      "        0.07064205,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9865373469899623, next_state=array([-0.21545573,  1.0657512 , -0.4964552 , -0.76642644,  0.5042258 ,\n",
      "        0.07064155,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21545573,  1.0657512 , -0.4964552 , -0.76642644,  0.5042258 ,\n",
      "        0.07064155,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.20050903050625266, next_state=array([-0.22032805,  1.047974  , -0.4887816 , -0.7906745 ,  0.5059712 ,\n",
      "        0.03490857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22032805,  1.047974  , -0.4887816 , -0.7906745 ,  0.5059712 ,\n",
      "        0.03490857,  0.        ,  0.        ], dtype=float32), action=3, reward=0.23771099061230075, next_state=array([-0.22513008,  1.0296679 , -0.47970253, -0.81342036,  0.5054079 ,\n",
      "       -0.01126483,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22513008,  1.0296679 , -0.47970253, -0.81342036,  0.5054079 ,\n",
      "       -0.01126483,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4443210864708533, next_state=array([-0.23024464,  1.0112693 , -0.5105055 , -0.8173644 ,  0.50433743,\n",
      "       -0.0214103 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23024464,  1.0112693 , -0.5105055 , -0.8173644 ,  0.50433743,\n",
      "       -0.0214103 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.43006820158495884, next_state=array([-0.23535919,  0.9922707 , -0.5105053 , -0.84403116,  0.50326693,\n",
      "       -0.02141013,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23535919,  0.9922707 , -0.5105053 , -0.84403116,  0.50326693,\n",
      "       -0.02141013,  0.        ,  0.        ], dtype=float32), action=3, reward=0.3576354464285043, next_state=array([-0.24041876,  0.9727258 , -0.5034231 , -0.86773247,  0.5004134 ,\n",
      "       -0.05707036,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24041876,  0.9727258 , -0.5034231 , -0.86773247,  0.5004134 ,\n",
      "       -0.05707036,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3718321076934615, next_state=array([-0.24595389,  0.9534505 , -0.5504052 , -0.8555481 ,  0.4969161 ,\n",
      "       -0.06994636,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24595389,  0.9534505 , -0.5504052 , -0.8555481 ,  0.4969161 ,\n",
      "       -0.06994636,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.12223954050824659, next_state=array([-0.2514891 ,  0.9335754 , -0.5504045 , -0.8822157 ,  0.49341878,\n",
      "       -0.06994628,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2514891 ,  0.9335754 , -0.5504045 , -0.8822157 ,  0.49341878,\n",
      "       -0.06994628,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8926708464117905, next_state=array([-0.2569529 ,  0.9131679 , -0.5412053 , -0.90515864,  0.4876323 ,\n",
      "       -0.11572894,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2569529 ,  0.9131679 , -0.5412053 , -0.90515864,  0.4876323 ,\n",
      "       -0.11572894,  0.        ,  0.        ], dtype=float32), action=3, reward=0.85498081279252, next_state=array([-0.26235747,  0.89219874, -0.53372777, -0.9296027 ,  0.4801298 ,\n",
      "       -0.15005067,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26235747,  0.89219874, -0.53372777, -0.9296027 ,  0.4801298 ,\n",
      "       -0.15005067,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0956343472692833, next_state=array([-0.26770368,  0.8706805 , -0.5262277 , -0.9534842 ,  0.4708089 ,\n",
      "       -0.1864187 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26770368,  0.8706805 , -0.5262277 , -0.9534842 ,  0.4708089 ,\n",
      "       -0.1864187 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5389530845228876, next_state=array([-0.27305025,  0.8485634 , -0.5262227 , -0.9801572 ,  0.461488  ,\n",
      "       -0.1864176 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27305025,  0.8485634 , -0.5262227 , -0.9801572 ,  0.461488  ,\n",
      "       -0.1864176 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.565579116470019, next_state=array([-0.27839717,  0.82584715, -0.52621776, -1.0068303 ,  0.45216718,\n",
      "       -0.18641646,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27839717,  0.82584715, -0.52621776, -1.0068303 ,  0.45216718,\n",
      "       -0.18641646,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5037953198536342, next_state=array([-0.2841634 ,  0.8033448 , -0.5675149 , -0.99718803,  0.44219828,\n",
      "       -0.19937845,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2841634 ,  0.8033448 , -0.5675149 , -0.99718803,  0.44219828,\n",
      "       -0.19937845,  0.        ,  0.        ], dtype=float32), action=3, reward=1.6329688313444148, next_state=array([-0.28984684,  0.78029794, -0.5569882 , -1.0207686 ,  0.4298251 ,\n",
      "       -0.24746375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28984684,  0.78029794, -0.5569882 , -1.0207686 ,  0.4298251 ,\n",
      "       -0.24746375,  0.        ,  0.        ], dtype=float32), action=1, reward=0.1752661592004199, next_state=array([-0.2955822 ,  0.7566064 , -0.5635963 , -1.0499593 ,  0.4190524 ,\n",
      "       -0.21545434,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2955822 ,  0.7566064 , -0.5635963 , -1.0499593 ,  0.4190524 ,\n",
      "       -0.21545434,  0.        ,  0.        ], dtype=float32), action=3, reward=1.3961638278766497, next_state=array([-0.30126435,  0.73235506, -0.5567459 , -1.0744764 ,  0.40669575,\n",
      "       -0.24713299,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30126435,  0.73235506, -0.5567459 , -1.0744764 ,  0.40669575,\n",
      "       -0.24713299,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.0759168227487794, next_state=array([-0.30702406,  0.707444  , -0.5666086 , -1.1044993 ,  0.39665487,\n",
      "       -0.2008178 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30702406,  0.707444  , -0.5666086 , -1.1044993 ,  0.39665487,\n",
      "       -0.2008178 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2845493973585167, next_state=array([-0.3128663 ,  0.68188035, -0.57704866, -1.1341808 ,  0.38898242,\n",
      "       -0.15344921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3128663 ,  0.68188035, -0.57704866, -1.1341808 ,  0.38898242,\n",
      "       -0.15344921,  0.        ,  0.        ], dtype=float32), action=3, reward=1.1603722526506044, next_state=array([-0.31865367,  0.6557615 , -0.56998   , -1.1584772 ,  0.37966007,\n",
      "       -0.1864465 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31865367,  0.6557615 , -0.56998   , -1.1584772 ,  0.37966007,\n",
      "       -0.1864465 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.6637759424226601, next_state=array([-0.32444134,  0.6290437 , -0.569976  , -1.1851505 ,  0.37033784,\n",
      "       -0.18644533,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32444134,  0.6290437 , -0.569976  , -1.1851505 ,  0.37033784,\n",
      "       -0.18644533,  0.        ,  0.        ], dtype=float32), action=3, reward=1.520536603147293, next_state=array([-0.33014876,  0.6017724 , -0.5597965 , -1.2092631 ,  0.35876587,\n",
      "       -0.23143962,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33014876,  0.6017724 , -0.5597965 , -1.2092631 ,  0.35876587,\n",
      "       -0.23143962,  0.        ,  0.        ], dtype=float32), action=3, reward=1.467997673677503, next_state=array([-0.33580264,  0.57394034, -0.5529012 , -1.2339194 ,  0.34563386,\n",
      "       -0.26263997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33580264,  0.57394034, -0.5529012 , -1.2339194 ,  0.34563386,\n",
      "       -0.26263997,  0.        ,  0.        ], dtype=float32), action=3, reward=1.9480486790344866, next_state=array([-0.34137073,  0.54556686, -0.54190457, -1.2575463 ,  0.33004037,\n",
      "       -0.31187037,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34137073,  0.54556686, -0.54190457, -1.2575463 ,  0.33004037,\n",
      "       -0.31187037,  0.        ,  0.        ], dtype=float32), action=3, reward=1.8511589589233222, next_state=array([-0.34687155,  0.51662153, -0.53337544, -1.2827402 ,  0.3126507 ,\n",
      "       -0.34779328,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34687155,  0.51662153, -0.53337544, -1.2827402 ,  0.3126507 ,\n",
      "       -0.34779328,  0.        ,  0.        ], dtype=float32), action=1, reward=0.4765025384602677, next_state=array([-0.3524658 ,  0.48704612, -0.54498875, -1.3114219 ,  0.2977078 ,\n",
      "       -0.29885855,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3524658 ,  0.48704612, -0.54498875, -1.3114219 ,  0.2977078 ,\n",
      "       -0.29885855,  0.        ,  0.        ], dtype=float32), action=0, reward=1.1005807024508272, next_state=array([-0.3580607 ,  0.45687363, -0.5449802 , -1.3381064 ,  0.28276512,\n",
      "       -0.29885393,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3580607 ,  0.45687363, -0.5449802 , -1.3381064 ,  0.28276512,\n",
      "       -0.29885393,  0.        ,  0.        ], dtype=float32), action=3, reward=1.6323729501015987, next_state=array([-0.36358914,  0.42612743, -0.53656006, -1.363434  ,  0.26606196,\n",
      "       -0.33406308,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36358914,  0.42612743, -0.53656006, -1.363434  ,  0.26606196,\n",
      "       -0.33406308,  0.        ,  0.        ], dtype=float32), action=0, reward=1.1535456967974085, next_state=array([-0.3691182 ,  0.39478478, -0.5365506 , -1.390123  ,  0.24935913,\n",
      "       -0.3340567 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3691182 ,  0.39478478, -0.5365506 , -1.390123  ,  0.24935913,\n",
      "       -0.3340567 ,  0.        ,  0.        ], dtype=float32), action=0, reward=1.0688671027860153, next_state=array([-0.37464792,  0.36284566, -0.5365416 , -1.4168122 ,  0.23265661,\n",
      "       -0.3340503 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37464792,  0.36284566, -0.5365416 , -1.4168122 ,  0.23265661,\n",
      "       -0.3340503 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.9642880081837575, next_state=array([-0.38017815,  0.3303102 , -0.53653324, -1.4435016 ,  0.21595442,\n",
      "       -0.3340439 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38017815,  0.3303102 , -0.53653324, -1.4435016 ,  0.21595442,\n",
      "       -0.3340439 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2260039556340712, next_state=array([-0.38577685,  0.29715824, -0.5450634 , -1.4713224 ,  0.20101425,\n",
      "       -0.29880363,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38577685,  0.29715824, -0.5450634 , -1.4713224 ,  0.20101425,\n",
      "       -0.29880363,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.15083805205048748, next_state=array([-0.39145318,  0.26339272, -0.5547427 , -1.4989963 ,  0.18804932,\n",
      "       -0.25929868,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39145318,  0.26339272, -0.5547427 , -1.4989963 ,  0.18804932,\n",
      "       -0.25929868,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5751902206402792, next_state=array([-0.39721164,  0.22901009, -0.5650331 , -1.5267818 ,  0.17718782,\n",
      "       -0.21723023,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39721164,  0.22901009, -0.5650331 , -1.5267818 ,  0.17718782,\n",
      "       -0.21723023,  0.        ,  0.        ], dtype=float32), action=3, reward=0.16170727871627946, next_state=array([-0.40291148,  0.19404359, -0.55762845, -1.5526378 ,  0.16481264,\n",
      "       -0.24750355,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40291148,  0.19404359, -0.55762845, -1.5526378 ,  0.16481264,\n",
      "       -0.24750355,  0.        ,  0.        ], dtype=float32), action=3, reward=0.23841364208419805, next_state=array([-0.40853697,  0.15850769, -0.54821455, -1.5778484 ,  0.15048736,\n",
      "       -0.28650597,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40853697,  0.15850769, -0.54821455, -1.5778484 ,  0.15048736,\n",
      "       -0.28650597,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.45564269261882373, next_state=array([-0.4141627 ,  0.12237448, -0.54821056, -1.604532  ,  0.13616228,\n",
      "       -0.28650188,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4141627 ,  0.12237448, -0.54821056, -1.604532  ,  0.13616228,\n",
      "       -0.28650188,  0.        ,  0.        ], dtype=float32), action=3, reward=9.818332293676095, next_state=array([-0.4197038 ,  0.08565031, -0.5375856 , -1.6307576 ,  0.11970665,\n",
      "       -0.32911265,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.4197038 ,  0.08565031, -0.5375856 , -1.6307576 ,  0.11970665,\n",
      "       -0.32911265,  0.        ,  1.        ], dtype=float32), action=1, reward=-100, next_state=array([-0.42528686,  0.05687557, -0.2840348 , -0.91911715, -0.03886177,\n",
      "       -5.934299  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([-4.7979355e-04,  1.4163464e+00, -4.8614688e-02,  2.4116841e-01,\n",
      "        5.6276587e-04,  1.1011939e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-4.988641180182799, next_state=array([-7.9097750e-04,  1.4227210e+00, -3.2489847e-02,  2.8331500e-01,\n",
      "        1.9220457e-03,  2.7188700e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-7.9097750e-04,  1.4227210e+00, -3.2489847e-02,  2.8331500e-01,\n",
      "        1.9220457e-03,  2.7188700e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=1.5218929330620494, next_state=array([-1.1930466e-03,  1.4284928e+00, -4.3884285e-02,  2.5651163e-01,\n",
      "        5.5645336e-03,  7.2856694e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.1930466e-03,  1.4284928e+00, -4.3884285e-02,  2.5651163e-01,\n",
      "        5.5645336e-03,  7.2856694e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=2.0813575615733, next_state=array([-0.00151844,  1.4336613 , -0.0342783 ,  0.22969934,  0.00727757,\n",
      "        0.03426408,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00151844,  1.4336613 , -0.0342783 ,  0.22969934,  0.00727757,\n",
      "        0.03426408,  0.        ,  0.        ], dtype=float32), action=3, reward=2.3539634126241267, next_state=array([-0.00175066,  1.4382335 , -0.02258073,  0.20321296,  0.00664475,\n",
      "       -0.01265785,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00175066,  1.4382335 , -0.02258073,  0.20321296,  0.00664475,\n",
      "       -0.01265785,  0.        ,  0.        ], dtype=float32), action=0, reward=2.3140707346523754, next_state=array([-0.00198288,  1.4422058 , -0.02257859,  0.1765446 ,  0.00601262,\n",
      "       -0.01264361,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00198288,  1.4422058 , -0.02257859,  0.1765446 ,  0.00601262,\n",
      "       -0.01264361,  0.        ,  0.        ], dtype=float32), action=3, reward=2.6360564144036984, next_state=array([-0.00214453,  1.4455745 , -0.01372118,  0.14973341,  0.00360489,\n",
      "       -0.04815929,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00214453,  1.4455745 , -0.01372118,  0.14973341,  0.00360489,\n",
      "       -0.04815929,  0.        ,  0.        ], dtype=float32), action=0, reward=2.6171738520245924, next_state=array([-2.3060800e-03,  1.4483434e+00, -1.3713723e-02,  1.2306476e-01,\n",
      "        1.1983000e-03, -4.8136361e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.3060800e-03,  1.4483434e+00, -1.3713723e-02,  1.2306476e-01,\n",
      "        1.1983000e-03, -4.8136361e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.26136618261562, next_state=array([-2.4494170e-03,  1.4514902e+00, -1.1987453e-02,  1.3986009e-01,\n",
      "       -1.1185115e-03, -4.6340685e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.4494170e-03,  1.4514902e+00, -1.1987453e-02,  1.3986009e-01,\n",
      "       -1.1185115e-03, -4.6340685e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=2.165181640305066, next_state=array([-2.6794435e-03,  1.4540429e+00, -2.2866495e-02,  1.1345231e-01,\n",
      "       -1.2526616e-03, -2.6832768e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.6794435e-03,  1.4540429e+00, -2.2866495e-02,  1.1345231e-01,\n",
      "       -1.2526616e-03, -2.6832768e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=2.2862949285820675, next_state=array([-2.9703141e-03,  1.4559896e+00, -3.0500049e-02,  8.6515084e-02,\n",
      "        1.4234451e-04,  2.7902450e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.9703141e-03,  1.4559896e+00, -3.0500049e-02,  8.6515084e-02,\n",
      "        1.4234451e-04,  2.7902450e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=2.1819831452339713, next_state=array([-0.00326128,  1.4573362 , -0.03050425,  0.05984658,  0.00153694,\n",
      "        0.02789437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00326128,  1.4573362 , -0.03050425,  0.05984658,  0.00153694,\n",
      "        0.02789437,  0.        ,  0.        ], dtype=float32), action=3, reward=2.758158190539349, next_state=array([-3.4746169e-03,  1.4580815e+00, -2.0774450e-02,  3.3125915e-02,\n",
      "        9.8070549e-04, -1.1125390e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.4746169e-03,  1.4580815e+00, -2.0774450e-02,  3.3125915e-02,\n",
      "        9.8070549e-04, -1.1125390e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=2.365955814137864, next_state=array([-3.6277771e-03,  1.4582353e+00, -1.3218144e-02,  6.8320977e-03,\n",
      "       -1.0887865e-03, -4.1393474e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.6277771e-03,  1.4582353e+00, -1.3218144e-02,  6.8320977e-03,\n",
      "       -1.0887865e-03, -4.1393474e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.009648113024968541, next_state=array([-0.00373468,  1.4583423 , -0.00881045,  0.0047625 , -0.002942  ,\n",
      "       -0.03706765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00373468,  1.4583423 , -0.00881045,  0.0047625 , -0.002942  ,\n",
      "       -0.03706765,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8490269231237437, next_state=array([-3.9140703e-03,  1.4578384e+00, -1.7909594e-02, -2.2400076e-02,\n",
      "       -2.9714743e-03, -5.8963365e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.9140703e-03,  1.4578384e+00, -1.7909594e-02, -2.2400076e-02,\n",
      "       -2.9714743e-03, -5.8963365e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-2.531717177645332, next_state=array([-4.1788099e-03,  1.4567313e+00, -2.8615912e-02, -4.9201649e-02,\n",
      "       -8.5641368e-04,  4.2305037e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.1788099e-03,  1.4567313e+00, -2.8615912e-02, -4.9201649e-02,\n",
      "       -8.5641368e-04,  4.2305037e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=2.412539719815226, next_state=array([-0.00431356,  1.4561815 , -0.01622963, -0.02443529,  0.00186448,\n",
      "        0.05442275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00431356,  1.4561815 , -0.01622963, -0.02443529,  0.00186448,\n",
      "        0.05442275,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.327925977366873, next_state=array([-0.00453892,  1.4550217 , -0.02758933, -0.05155976,  0.00685973,\n",
      "        0.09991445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00453892,  1.4550217 , -0.02758933, -0.05155976,  0.00685973,\n",
      "        0.09991445,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4479783426098707, next_state=array([-0.00470276,  1.4532558 , -0.019854  , -0.07850905,  0.01030158,\n",
      "        0.06884269,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00470276,  1.4532558 , -0.019854  , -0.07850905,  0.01030158,\n",
      "        0.06884269,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3880836476151033, next_state=array([-0.00478487,  1.4508914 , -0.00962393, -0.10509494,  0.01169237,\n",
      "        0.02781838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00478487,  1.4508914 , -0.00962393, -0.10509494,  0.01169237,\n",
      "        0.02781838,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6192496814849278, next_state=array([-0.00479355,  1.4489459 , -0.00266422, -0.08647632,  0.01346265,\n",
      "        0.03540906,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00479355,  1.4489459 , -0.00266422, -0.08647632,  0.01346265,\n",
      "        0.03540906,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.397295425304519, next_state=array([-0.00471811,  1.4464079 ,  0.00790003, -0.1128019 ,  0.013113  ,\n",
      "       -0.00699349,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00471811,  1.4464079 ,  0.00790003, -0.1128019 ,  0.013113  ,\n",
      "       -0.00699349,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.281555829904305, next_state=array([-0.00457249,  1.4432607 ,  0.01669549, -0.13985652,  0.01100497,\n",
      "       -0.04216432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00457249,  1.4432607 ,  0.01669549, -0.13985652,  0.01100497,\n",
      "       -0.04216432,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4245033595978898, next_state=array([-0.00443363,  1.4406221 ,  0.01601174, -0.11725677,  0.0089035 ,\n",
      "       -0.04203314,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00443363,  1.4406221 ,  0.01601174, -0.11725677,  0.0089035 ,\n",
      "       -0.04203314,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.379557261885934, next_state=array([-0.00436687,  1.4373544 ,  0.00697146, -0.14522745,  0.0086171 ,\n",
      "       -0.00572805,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00436687,  1.4373544 ,  0.00697146, -0.14522745,  0.0086171 ,\n",
      "       -0.00572805,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2486351517567584, next_state=array([-0.00430002,  1.4334867 ,  0.00697146, -0.17189412,  0.0083307 ,\n",
      "       -0.00572803,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00430002,  1.4334867 ,  0.00697146, -0.17189412,  0.0083307 ,\n",
      "       -0.00572803,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.380190025366572, next_state=array([-0.00431271,  1.429026  , -0.00300133, -0.19826537,  0.0100405 ,\n",
      "        0.03419591,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00431271,  1.429026  , -0.00300133, -0.19826537,  0.0100405 ,\n",
      "        0.03419591,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6064430524907025, next_state=array([-0.00441465,  1.4239707 , -0.01419036, -0.22471026,  0.01399011,\n",
      "        0.07899216,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00441465,  1.4239707 , -0.01419036, -0.22471026,  0.01399011,\n",
      "        0.07899216,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3107348524928555, next_state=array([-0.00443916,  1.4183106 , -0.00448512, -0.251578  ,  0.01599734,\n",
      "        0.04014472,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00443916,  1.4183106 , -0.00448512, -0.251578  ,  0.01599734,\n",
      "        0.04014472,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0304468135236946, next_state=array([-0.00438776,  1.4120617 ,  0.00503629, -0.2777283 ,  0.01609487,\n",
      "        0.00195074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00438776,  1.4120617 ,  0.00503629, -0.2777283 ,  0.01609487,\n",
      "        0.00195074,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0118341153605115, next_state=array([-0.00426712,  1.4059863 ,  0.0116109 , -0.27002493,  0.01655176,\n",
      "        0.00913765,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00426712,  1.4059863 ,  0.0116109 , -0.27002493,  0.01655176,\n",
      "        0.00913765,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.24296473159947, next_state=array([-4.2379377e-03,  1.3993201e+00,  1.2051390e-04, -2.9631501e-01,\n",
      "        1.9307073e-02,  5.5106468e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.2379377e-03,  1.3993201e+00,  1.2051390e-04, -2.9631501e-01,\n",
      "        1.9307073e-02,  5.5106468e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-2.065126979358665, next_state=array([-0.00414944,  1.3920624 ,  0.00757286, -0.32257518,  0.02056724,\n",
      "        0.02520331,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00414944,  1.3920624 ,  0.00757286, -0.32257518,  0.02056724,\n",
      "        0.02520331,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0062516382678837, next_state=array([-0.00406094,  1.384205  ,  0.00757286, -0.34924206,  0.02182741,\n",
      "        0.02520333,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00406094,  1.384205  ,  0.00757286, -0.34924206,  0.02182741,\n",
      "        0.02520333,  0.        ,  0.        ], dtype=float32), action=2, reward=0.45986865879352196, next_state=array([-0.0038435 ,  1.3763967 ,  0.01982453, -0.34706813,  0.02372792,\n",
      "        0.03801037,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0038435 ,  1.3763967 ,  0.01982453, -0.34706813,  0.02372792,\n",
      "        0.03801037,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8653993626818124, next_state=array([-0.00355396,  1.368     ,  0.02886523, -0.37318507,  0.02381345,\n",
      "        0.00171077,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00355396,  1.368     ,  0.02886523, -0.37318507,  0.02381345,\n",
      "        0.00171077,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.701383173108353, next_state=array([-0.00320292,  1.3590039 ,  0.03658501, -0.3998005 ,  0.02235297,\n",
      "       -0.02920971,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00320292,  1.3590039 ,  0.03658501, -0.3998005 ,  0.02235297,\n",
      "       -0.02920971,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7173041049001643, next_state=array([-0.00294266,  1.3494108 ,  0.02519776, -0.42637518,  0.02317159,\n",
      "        0.01637252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00294266,  1.3494108 ,  0.02519776, -0.42637518,  0.02317159,\n",
      "        0.01637252,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5285819685002595, next_state=array([-0.00274563,  1.3402549 ,  0.01909337, -0.40694168,  0.02377175,\n",
      "        0.01200322,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00274563,  1.3402549 ,  0.01909337, -0.40694168,  0.02377175,\n",
      "        0.01200322,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7482939261232673, next_state=array([-0.0025486 ,  1.3304988 ,  0.01909337, -0.4336084 ,  0.02437192,\n",
      "        0.01200322,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0025486 ,  1.3304988 ,  0.01909337, -0.4336084 ,  0.02437192,\n",
      "        0.01200322,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6886327878695795, next_state=array([-0.00235167,  1.320143  ,  0.01909337, -0.46027514,  0.02497208,\n",
      "        0.01200323,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00235167,  1.320143  ,  0.01909337, -0.46027514,  0.02497208,\n",
      "        0.01200323,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8338810297981751, next_state=array([-0.00227518,  1.3100344 ,  0.00753869, -0.44926965,  0.02508006,\n",
      "        0.0021594 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00227518,  1.3100344 ,  0.00753869, -0.44926965,  0.02508006,\n",
      "        0.0021594 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.421285308498352, next_state=array([-0.00208073,  1.3008062 ,  0.01866828, -0.41015586,  0.02584814,\n",
      "        0.01536175,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00208073,  1.3008062 ,  0.01866828, -0.41015586,  0.02584814,\n",
      "        0.01536175,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.988137276836652, next_state=array([-0.00196123,  1.2909694 ,  0.00924797, -0.4372429 ,  0.02850627,\n",
      "        0.05316276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00196123,  1.2909694 ,  0.00924797, -0.4372429 ,  0.02850627,\n",
      "        0.05316276,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1670012292824878, next_state=array([-0.00199394,  1.2812885 , -0.00531129, -0.43029717,  0.03052779,\n",
      "        0.04043011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00199394,  1.2812885 , -0.00531129, -0.43029717,  0.03052779,\n",
      "        0.04043011,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.840604604561804, next_state=array([-0.00202656,  1.2710079 , -0.00531128, -0.4569642 ,  0.03254929,\n",
      "        0.0404301 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00202656,  1.2710079 , -0.00531128, -0.4569642 ,  0.03254929,\n",
      "        0.0404301 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4623627009735687, next_state=array([-0.00221252,  1.2613995 , -0.02005432, -0.42706853,  0.03398961,\n",
      "        0.02880631,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00221252,  1.2613995 , -0.02005432, -0.42706853,  0.03398961,\n",
      "        0.02880631,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3648480315774065, next_state=array([-0.00248432,  1.2519903 , -0.02832618, -0.41821417,  0.03511656,\n",
      "        0.02253892,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00248432,  1.2519903 , -0.02832618, -0.41821417,  0.03511656,\n",
      "        0.02253892,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.438299610616183, next_state=array([-0.00266285,  1.2419959 , -0.01660236, -0.44416815,  0.03388759,\n",
      "       -0.02457942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00266285,  1.2419959 , -0.01660236, -0.44416815,  0.03388759,\n",
      "       -0.02457942,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.482617522951557, next_state=array([-0.00284128,  1.2314014 , -0.01660236, -0.47083494,  0.03265861,\n",
      "       -0.02457942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00284128,  1.2314014 , -0.01660236, -0.47083494,  0.03265861,\n",
      "       -0.02457942,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4228292566461107, next_state=array([-0.00301981,  1.2202071 , -0.01660235, -0.49750176,  0.03142965,\n",
      "       -0.02457941,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00301981,  1.2202071 , -0.01660235, -0.49750176,  0.03142965,\n",
      "       -0.02457941,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5734494768804541, next_state=array([-0.00325956,  1.2084143 , -0.02428713, -0.5241341 ,  0.0317385 ,\n",
      "        0.00617692,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00325956,  1.2084143 , -0.02428713, -0.5241341 ,  0.0317385 ,\n",
      "        0.00617692,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1851418602007857, next_state=array([-0.00342197,  1.1960369 , -0.01457917, -0.5500747 ,  0.03009544,\n",
      "       -0.03286163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00342197,  1.1960369 , -0.01457917, -0.5500747 ,  0.03009544,\n",
      "       -0.03286163,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4281722323889585, next_state=array([-3.6520958e-03,  1.1830610e+00, -2.3072938e-02, -5.7670665e-01,\n",
      "        3.0152176e-02,  1.1349784e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.6520958e-03,  1.1830610e+00, -2.3072938e-02, -5.7670665e-01,\n",
      "        3.0152176e-02,  1.1349784e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.6304978488206519, next_state=array([-0.00397425,  1.1694859 , -0.0346113 , -0.60338855,  0.03251877,\n",
      "        0.0473319 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00397425,  1.1694859 , -0.0346113 , -0.60338855,  0.03251877,\n",
      "        0.0473319 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2297610744885776, next_state=array([-0.00420475,  1.1553096 , -0.02311601, -0.6300638 ,  0.03258459,\n",
      "        0.00131648,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00420475,  1.1553096 , -0.02311601, -0.6300638 ,  0.03258459,\n",
      "        0.00131648,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1939769373771298, next_state=array([-0.00443525,  1.1405331 , -0.02311601, -0.6567304 ,  0.03265041,\n",
      "        0.00131651,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00443525,  1.1405331 , -0.02311601, -0.6567304 ,  0.03265041,\n",
      "        0.00131651,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.826977664933678, next_state=array([-0.00457382,  1.1251731 , -0.01157276, -0.6826223 ,  0.03039616,\n",
      "       -0.04508501,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00457382,  1.1251731 , -0.01157276, -0.6826223 ,  0.03039616,\n",
      "       -0.04508501,  0.        ,  0.        ], dtype=float32), action=2, reward=4.014861001813711, next_state=array([-0.00465727,  1.110408  , -0.00643392, -0.6561925 ,  0.02850867,\n",
      "       -0.03774949,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00465727,  1.110408  , -0.00643392, -0.6561925 ,  0.02850867,\n",
      "       -0.03774949,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9413572076314836, next_state=array([-0.00474072,  1.0950428 , -0.00643391, -0.68285936,  0.02662121,\n",
      "       -0.0377495 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00474072,  1.0950428 , -0.00643391, -0.68285936,  0.02662121,\n",
      "       -0.0377495 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8813787510303541, next_state=array([-0.00482426,  1.0790777 , -0.0064339 , -0.7095263 ,  0.02473373,\n",
      "       -0.03774948,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00482426,  1.0790777 , -0.0064339 , -0.7095263 ,  0.02473373,\n",
      "       -0.03774948,  0.        ,  0.        ], dtype=float32), action=2, reward=4.047564553478549, next_state=array([-4.8428536e-03,  1.0637110e+00, -3.3911175e-04, -6.8294209e-01,\n",
      "        2.3237875e-02, -2.9917281e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.8428536e-03,  1.0637110e+00, -3.3911175e-04, -6.8294209e-01,\n",
      "        2.3237875e-02, -2.9917281e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.9204630295375296, next_state=array([-4.8614503e-03,  1.0477444e+00, -3.3910468e-04, -7.0960897e-01,\n",
      "        2.1742012e-02, -2.9917289e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.8614503e-03,  1.0477444e+00, -3.3910468e-04, -7.0960897e-01,\n",
      "        2.1742012e-02, -2.9917289e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.055353542651942, next_state=array([-0.004951  ,  1.0311826 , -0.00925156, -0.7360786 ,  0.02202895,\n",
      "        0.00573881,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.004951  ,  1.0311826 , -0.00925156, -0.7360786 ,  0.02202895,\n",
      "        0.00573881,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7135752282949681, next_state=array([-0.00498753,  1.0147157 , -0.00423763, -0.73187554,  0.0226087 ,\n",
      "        0.0115949 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00498753,  1.0147157 , -0.00423763, -0.73187554,  0.0226087 ,\n",
      "        0.0115949 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0179325127938057, next_state=array([-0.00502396,  0.9976487 , -0.00423763, -0.7585422 ,  0.02318843,\n",
      "        0.0115949 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00502396,  0.9976487 , -0.00423763, -0.7585422 ,  0.02318843,\n",
      "        0.0115949 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7712368102291964, next_state=array([-0.0049716 ,  0.97997993,  0.0069017 , -0.785255  ,  0.02153836,\n",
      "       -0.03300127,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0049716 ,  0.97997993,  0.0069017 , -0.785255  ,  0.02153836,\n",
      "       -0.03300127,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8299905807566279, next_state=array([-4.9808500e-03,  9.6171772e-01, -8.1239705e-04, -8.1165445e-01,\n",
      "        2.1430613e-02, -2.1549794e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.9808500e-03,  9.6171772e-01, -8.1239705e-04, -8.1165445e-01,\n",
      "        2.1430613e-02, -2.1549794e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=5.192277903644862, next_state=array([-0.00503025,  0.9442951 , -0.00473645, -0.77433807,  0.02123227,\n",
      "       -0.00396707,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00503025,  0.9442951 , -0.00473645, -0.77433807,  0.02123227,\n",
      "       -0.00396707,  0.        ,  0.        ], dtype=float32), action=2, reward=2.463097522508929, next_state=array([-0.00527277,  0.9270909 , -0.02320566, -0.76461047,  0.02019392,\n",
      "       -0.02076684,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00527277,  0.9270909 , -0.02320566, -0.76461047,  0.02019392,\n",
      "       -0.02076684,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0605602333135085, next_state=array([-0.00560637,  0.90929246, -0.03461393, -0.79106313,  0.02143815,\n",
      "        0.02488448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00560637,  0.90929246, -0.03461393, -0.79106313,  0.02143815,\n",
      "        0.02488448,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9490274402143655, next_state=array([-0.00593996,  0.89089394, -0.03461393, -0.81772983,  0.02268239,\n",
      "        0.02488448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00593996,  0.89089394, -0.03461393, -0.81772983,  0.02268239,\n",
      "        0.02488448,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2567618087588517, next_state=array([-0.0063612 ,  0.8718814 , -0.0456224 , -0.84505427,  0.02613632,\n",
      "        0.06907867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0063612 ,  0.8718814 , -0.0456224 , -0.84505427,  0.02613632,\n",
      "        0.06907867,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4564980577544704, next_state=array([-0.00694933,  0.8533847 , -0.06162146, -0.8221335 ,  0.02890828,\n",
      "        0.05543969,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00694933,  0.8533847 , -0.06162146, -0.8221335 ,  0.02890828,\n",
      "        0.05543969,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.434246399056916, next_state=array([-0.00762587,  0.83427376, -0.07271747, -0.8494791 ,  0.03390893,\n",
      "        0.1000128 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00762587,  0.83427376, -0.07271747, -0.8494791 ,  0.03390893,\n",
      "        0.1000128 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1871997305153457, next_state=array([-0.0083024 ,  0.81456316, -0.07271736, -0.87614787,  0.03890956,\n",
      "        0.10001266,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0083024 ,  0.81456316, -0.07271736, -0.87614787,  0.03890956,\n",
      "        0.10001266,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8404517020348112, next_state=array([-0.00888824,  0.79425275, -0.0613368 , -0.902764  ,  0.04163205,\n",
      "        0.05444969,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00888824,  0.79425275, -0.0613368 , -0.902764  ,  0.04163205,\n",
      "        0.05444969,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6045703438996657, next_state=array([-0.0093914 ,  0.7733405 , -0.05097436, -0.92944986,  0.0422814 ,\n",
      "        0.01298729,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0093914 ,  0.7733405 , -0.05097436, -0.92944986,  0.0422814 ,\n",
      "        0.01298729,  0.        ,  0.        ], dtype=float32), action=2, reward=4.156198029177813, next_state=array([-0.01003237,  0.7529966 , -0.06426694, -0.90417296,  0.04244602,\n",
      "        0.00329223,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01003237,  0.7529966 , -0.06426694, -0.90417296,  0.04244602,\n",
      "        0.00329223,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9333622039016223, next_state=array([-0.01075582,  0.73204625, -0.07461973, -0.93119913,  0.04468784,\n",
      "        0.04483641,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01075582,  0.73204625, -0.07461973, -0.93119913,  0.04468784,\n",
      "        0.04483641,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1135726361713114, next_state=array([-0.01156464,  0.7104857 , -0.08531979, -0.9583837 ,  0.04907912,\n",
      "        0.08782588,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01156464,  0.7104857 , -0.08531979, -0.9583837 ,  0.04907912,\n",
      "        0.08782588,  0.        ,  0.        ], dtype=float32), action=2, reward=3.15082119987012, next_state=array([-0.01239452,  0.6893324 , -0.08748836, -0.9402944 ,  0.05352509,\n",
      "        0.08891948,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01239452,  0.6893324 , -0.08748836, -0.9402944 ,  0.05352509,\n",
      "        0.08891948,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2060817331513636, next_state=array([-0.01328459,  0.6675748 , -0.09503552, -0.967235  ,  0.05948586,\n",
      "        0.11921543,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01328459,  0.6675748 , -0.09503552, -0.967235  ,  0.05948586,\n",
      "        0.11921543,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7607472703404585, next_state=array([-0.01410656,  0.6452242 , -0.08648413, -0.9935289 ,  0.06372872,\n",
      "        0.08485687,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01410656,  0.6452242 , -0.08648413, -0.9935289 ,  0.06372872,\n",
      "        0.08485687,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9160928106451365, next_state=array([-0.01498213,  0.6229766 , -0.0917316 , -0.988968  ,  0.06786215,\n",
      "        0.08266866,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01498213,  0.6229766 , -0.0917316 , -0.988968  ,  0.06786215,\n",
      "        0.08266866,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7872445354587114, next_state=array([-0.0158577 ,  0.6001292 , -0.09173146, -1.0156361 ,  0.07199558,\n",
      "        0.08266857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0158577 ,  0.6001292 , -0.09173146, -1.0156361 ,  0.07199558,\n",
      "        0.08266857,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.47065288197191424, next_state=array([-0.01665344,  0.5766807 , -0.08173543, -1.0422587 ,  0.07413118,\n",
      "        0.04271204,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01665344,  0.5766807 , -0.08173543, -1.0422587 ,  0.07413118,\n",
      "        0.04271204,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8204651494359723, next_state=array([-0.01762962,  0.5532486 , -0.09907609, -1.0414997 ,  0.07557533,\n",
      "        0.02888276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01762962,  0.5532486 , -0.09907609, -1.0414997 ,  0.07557533,\n",
      "        0.02888276,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.09817769537974527, next_state=array([-0.01852865,  0.5292263 , -0.08938965, -1.0676322 ,  0.0750698 ,\n",
      "       -0.01011064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01852865,  0.5292263 , -0.08938965, -1.0676322 ,  0.0750698 ,\n",
      "       -0.01011064,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6066991261262149, next_state=array([-0.01952353,  0.5045885 , -0.10141943, -1.0951132 ,  0.07698976,\n",
      "        0.03839897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01952353,  0.5045885 , -0.10141943, -1.0951132 ,  0.07698976,\n",
      "        0.03839897,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7459282893694581, next_state=array([-0.02060718,  0.47934067, -0.11256846, -1.1223476 ,  0.08115235,\n",
      "        0.08325192,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02060718,  0.47934067, -0.11256846, -1.1223476 ,  0.08115235,\n",
      "        0.08325192,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.22965081250646222, next_state=array([-0.02162781,  0.45350447, -0.10465617, -1.148415  ,  0.0837172 ,\n",
      "        0.0512969 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02162781,  0.45350447, -0.10465617, -1.148415  ,  0.0837172 ,\n",
      "        0.0512969 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5600826947992334, next_state=array([-0.02271004,  0.42706442, -0.11237325, -1.1753536 ,  0.08783067,\n",
      "        0.08226928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02271004,  0.42706442, -0.11237325, -1.1753536 ,  0.08783067,\n",
      "        0.08226928,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.37269352677569145, next_state=array([-0.02379227,  0.4000246 , -0.11237307, -1.2020218 ,  0.09194414,\n",
      "        0.08226921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02379227,  0.4000246 , -0.11237307, -1.2020218 ,  0.09194414,\n",
      "        0.08226921,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6567898322604993, next_state=array([-0.02493525,  0.37236795, -0.12002401, -1.2295473 ,  0.0976132 ,\n",
      "        0.11338133,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02493525,  0.37236795, -0.12002401, -1.2295473 ,  0.0976132 ,\n",
      "        0.11338133,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.1017267794174461, next_state=array([-0.02599058,  0.3441127 , -0.10903548, -1.2560221 ,  0.1010851 ,\n",
      "        0.06943832,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02599058,  0.3441127 , -0.10903548, -1.2560221 ,  0.1010851 ,\n",
      "        0.06943832,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3847201281379684, next_state=array([-0.02707005,  0.3159168 , -0.1115391 , -1.2533977 ,  0.10465134,\n",
      "        0.07132445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02707005,  0.3159168 , -0.1115391 , -1.2533977 ,  0.10465134,\n",
      "        0.07132445,  0.        ,  0.        ], dtype=float32), action=3, reward=0.13845827131760416, next_state=array([-0.02807932,  0.28713456, -0.10272189, -1.2793378 ,  0.10643271,\n",
      "        0.03562764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02807932,  0.28713456, -0.10272189, -1.2793378 ,  0.10643271,\n",
      "        0.03562764,  0.        ,  0.        ], dtype=float32), action=3, reward=0.3640879727673234, next_state=array([-0.02902346,  0.25777024, -0.09453072, -1.305087  ,  0.10654608,\n",
      "        0.00226729,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02902346,  0.25777024, -0.09453072, -1.305087  ,  0.10654608,\n",
      "        0.00226729,  0.        ,  0.        ], dtype=float32), action=2, reward=6.597917673106321, next_state=array([-0.02993641,  0.22934204, -0.09205543, -1.2635283 ,  0.10730715,\n",
      "        0.0152212 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02993641,  0.22934204, -0.09205543, -1.2635283 ,  0.10730715,\n",
      "        0.0152212 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.12533156204088414, next_state=array([-0.03084927,  0.20031396, -0.09205543, -1.2901951 ,  0.10806822,\n",
      "        0.01522123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03084927,  0.20031396, -0.09205543, -1.2901951 ,  0.10806822,\n",
      "        0.01522123,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1534507145548207, next_state=array([-0.03182096,  0.17066811, -0.0994471 , -1.3177592 ,  0.11033761,\n",
      "        0.04538762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03182096,  0.17066811, -0.0994471 , -1.3177592 ,  0.11033761,\n",
      "        0.04538762,  0.        ,  0.        ], dtype=float32), action=3, reward=0.35178036350376485, next_state=array([-0.03272867,  0.14044355, -0.09139893, -1.3433625 ,  0.11096066,\n",
      "        0.01246093,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03272867,  0.14044355, -0.09139893, -1.3433625 ,  0.11096066,\n",
      "        0.01246093,  0.        ,  0.        ], dtype=float32), action=3, reward=0.47084188810672, next_state=array([-0.03357458,  0.10963033, -0.0836396 , -1.3694056 ,  0.11001324,\n",
      "       -0.01894838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03357458,  0.10963033, -0.0836396 , -1.3694056 ,  0.11001324,\n",
      "       -0.01894838,  0.        ,  0.        ], dtype=float32), action=3, reward=0.7075377938144538, next_state=array([-0.03432417,  0.0782291 , -0.0715415 , -1.3953626 ,  0.10662824,\n",
      "       -0.06770018,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03432417,  0.0782291 , -0.0715415 , -1.3953626 ,  0.10662824,\n",
      "       -0.06770018,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6649170000274307, next_state=array([-0.03501482,  0.04624623, -0.06413749, -1.4211173 ,  0.10173212,\n",
      "       -0.09792224,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03501482,  0.04624623, -0.06413749, -1.4211173 ,  0.10173212,\n",
      "       -0.09792224,  0.        ,  0.        ], dtype=float32), action=3, reward=0.15433833921727683, next_state=array([-0.03561497,  0.01368221, -0.05275968, -1.4468129 ,  0.09453189,\n",
      "       -0.14400451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03561497,  0.01368221, -0.05275968, -1.4468129 ,  0.09453189,\n",
      "       -0.14400451,  0.        ,  0.        ], dtype=float32), action=1, reward=17.519060507951423, next_state=array([-0.03628311, -0.01947887, -0.06126794, -1.473486  ,  0.08902811,\n",
      "       -0.11007575,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.03628311, -0.01947887, -0.06126794, -1.473486  ,  0.08902811,\n",
      "       -0.11007575,  1.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([-3.7384700e-02, -4.2762447e-02, -1.0097587e-09, -2.8065741e-09,\n",
      "        8.7437395e-05,  5.0034372e-09,  1.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([ 1.1175156e-03,  1.4104086e+00,  1.1317883e-01, -2.2735469e-02,\n",
      "       -1.2881511e-03, -2.5636733e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.7560090491939604, next_state=array([ 0.00213079,  1.4103192 ,  0.10311923, -0.00397563, -0.00306026,\n",
      "       -0.03544493,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00213079,  1.4103192 ,  0.10311923, -0.00397563, -0.00306026,\n",
      "       -0.03544493,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5293522389290206, next_state=array([ 0.00320864,  1.409619  ,  0.11121728, -0.03113547, -0.00645453,\n",
      "       -0.06789169,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00320864,  1.409619  ,  0.11121728, -0.03113547, -0.00645453,\n",
      "       -0.06789169,  0.        ,  0.        ], dtype=float32), action=2, reward=0.27634884996099346, next_state=array([ 0.00422392,  1.4098469 ,  0.10528926,  0.01011185, -0.01018007,\n",
      "       -0.07451768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00422392,  1.4098469 ,  0.10528926,  0.01011185, -0.01018007,\n",
      "       -0.07451768,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5076881726610349, next_state=array([ 0.00517511,  1.4094771 ,  0.09726744, -0.01645519, -0.01229398,\n",
      "       -0.04228244,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00517511,  1.4094771 ,  0.09726744, -0.01645519, -0.01229398,\n",
      "       -0.04228244,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0371357210011807, next_state=array([ 0.00630999,  1.4094279 ,  0.11477113, -0.00219206, -0.01356739,\n",
      "       -0.02547039,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00630999,  1.4094279 ,  0.11477113, -0.00219206, -0.01356739,\n",
      "       -0.02547039,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8500095743600593, next_state=array([ 0.00735645,  1.4087821 ,  0.10368635, -0.02869219, -0.01261701,\n",
      "        0.01900913,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00735645,  1.4087821 ,  0.10368635, -0.02869219, -0.01261701,\n",
      "        0.01900913,  0.        ,  0.        ], dtype=float32), action=1, reward=0.20052075178446785, next_state=array([ 0.0083292 ,  1.4075431 ,  0.09444119, -0.05505168, -0.00981321,\n",
      "        0.05608113,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0083292 ,  1.4075431 ,  0.09444119, -0.05505168, -0.00981321,\n",
      "        0.05608113,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.321352614434544, next_state=array([ 0.00923166,  1.405695  ,  0.08562861, -0.08211363, -0.00524669,\n",
      "        0.09133872,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00923166,  1.405695  ,  0.08562861, -0.08211363, -0.00524669,\n",
      "        0.09133872,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1997169946931465, next_state=array([ 0.01021547,  1.4032375 ,  0.09583656, -0.10921421, -0.00273115,\n",
      "        0.05031532,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01021547,  1.4032375 ,  0.09583656, -0.10921421, -0.00273115,\n",
      "        0.05031532,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.07229297324632283, next_state=array([ 1.1383152e-02,  1.4011242e+00,  1.1335172e-01, -9.3926176e-02,\n",
      "        6.4950512e-04,  6.7619339e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.1383152e-02,  1.4011242e+00,  1.1335172e-01, -9.3926176e-02,\n",
      "        6.4950512e-04,  6.7619339e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.5105658246010865, next_state=array([ 0.01247902,  1.3984091 ,  0.10434937, -0.120682  ,  0.00583091,\n",
      "        0.10363743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01247902,  1.3984091 ,  0.10434937, -0.120682  ,  0.00583091,\n",
      "        0.10363743,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.708552534310995, next_state=array([ 0.01365356,  1.3950942 ,  0.11422485, -0.14734083,  0.00902867,\n",
      "        0.06396084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01365356,  1.3950942 ,  0.11422485, -0.14734083,  0.00902867,\n",
      "        0.06396084,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4951305118083256, next_state=array([ 0.01490574,  1.3911765 ,  0.12394538, -0.17413095,  0.01027774,\n",
      "        0.02498393,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01490574,  1.3911765 ,  0.12394538, -0.17413095,  0.01027774,\n",
      "        0.02498393,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9047516342773008, next_state=array([ 0.01627836,  1.3880849 ,  0.13537823, -0.13742031,  0.01214127,\n",
      "        0.03727381,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01627836,  1.3880849 ,  0.13537823, -0.13742031,  0.01214127,\n",
      "        0.03727381,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2145348629337875, next_state=array([ 1.7724991e-02,  1.3844032e+00,  1.4467391e-01, -1.6363047e-01,\n",
      "        1.2137578e-02, -7.3677758e-05,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.7724991e-02,  1.3844032e+00,  1.4467391e-01, -1.6363047e-01,\n",
      "        1.2137578e-02, -7.3677758e-05,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.34367351262125, next_state=array([ 0.01910877,  1.3801252 ,  0.1367787 , -0.19014923,  0.01371632,\n",
      "        0.03157768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01910877,  1.3801252 ,  0.1367787 , -0.19014923,  0.01371632,\n",
      "        0.03157768,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2088155967865064, next_state=array([ 2.0555878e-02,  1.3752408e+00,  1.4472288e-01, -2.1707860e-01,\n",
      "        1.3702456e-02, -2.7742621e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.0555878e-02,  1.3752408e+00,  1.4472288e-01, -2.1707860e-01,\n",
      "        1.3702456e-02, -2.7742621e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.7101947630040968, next_state=array([ 2.2002887e-02,  1.3697565e+00,  1.4472353e-01, -2.4374717e-01,\n",
      "        1.3689587e-02, -2.5758828e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.2002887e-02,  1.3697565e+00,  1.4472353e-01, -2.4374717e-01,\n",
      "        1.3689587e-02, -2.5758828e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.7161098867019575, next_state=array([ 2.3449993e-02,  1.3636721e+00,  1.4472364e-01, -2.7041599e-01,\n",
      "        1.3676392e-02, -2.6418280e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.3449993e-02,  1.3636721e+00,  1.4472364e-01, -2.7041599e-01,\n",
      "        1.3676392e-02, -2.6418280e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.542148378268364, next_state=array([ 0.02481031,  1.356976  ,  0.13382728, -0.29762414,  0.01584884,\n",
      "        0.043453  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02481031,  1.356976  ,  0.13382728, -0.29762414,  0.01584884,\n",
      "        0.043453  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1280598842959066, next_state=array([ 0.02623339,  1.3496776 ,  0.14171273, -0.3243839 ,  0.01643974,\n",
      "        0.01181937,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02623339,  1.3496776 ,  0.14171273, -0.3243839 ,  0.01643974,\n",
      "        0.01181937,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7312454172377727, next_state=array([ 0.02765656,  1.341779  ,  0.14171179, -0.3510531 ,  0.01703165,\n",
      "        0.01183953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02765656,  1.341779  ,  0.14171179, -0.3510531 ,  0.01703165,\n",
      "        0.01183953,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.49740771189506744, next_state=array([ 0.02924643,  1.3338245 ,  0.15757121, -0.3535518 ,  0.0184259 ,\n",
      "        0.02788789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02924643,  1.3338245 ,  0.15757121, -0.3535518 ,  0.0184259 ,\n",
      "        0.02788789,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.626163673944858, next_state=array([ 0.03076944,  1.3252695 ,  0.1492034 , -0.38026324,  0.02149449,\n",
      "        0.06137703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03076944,  1.3252695 ,  0.1492034 , -0.38026324,  0.02149449,\n",
      "        0.06137703,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1456138244978136, next_state=array([ 0.03237658,  1.316098  ,  0.15974405, -0.4076304 ,  0.02245466,\n",
      "        0.01920306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03237658,  1.316098  ,  0.15974405, -0.4076304 ,  0.02245466,\n",
      "        0.01920306,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5301484423077614, next_state=array([ 0.03389368,  1.306319  ,  0.14843822, -0.4346793 ,  0.02568166,\n",
      "        0.06453995,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03389368,  1.306319  ,  0.14843822, -0.4346793 ,  0.02568166,\n",
      "        0.06453995,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9619094885143784, next_state=array([ 0.03550281,  1.2959448 ,  0.16000138, -0.46109086,  0.02659124,\n",
      "        0.01819158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03550281,  1.2959448 ,  0.16000138, -0.46109086,  0.02659124,\n",
      "        0.01819158,  0.        ,  0.        ], dtype=float32), action=2, reward=4.406904050710733, next_state=array([ 0.0370388 ,  1.286428  ,  0.15289465, -0.42298847,  0.02728163,\n",
      "        0.01380797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0370388 ,  1.286428  ,  0.15289465, -0.42298847,  0.02728163,\n",
      "        0.01380797,  0.        ,  0.        ], dtype=float32), action=2, reward=2.379398732098889, next_state=array([ 0.03849106,  1.2772778 ,  0.14483336, -0.4066772 ,  0.02766649,\n",
      "        0.00769679,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03849106,  1.2772778 ,  0.14483336, -0.4066772 ,  0.02766649,\n",
      "        0.00769679,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5892881501049771, next_state=array([ 0.03994322,  1.2675277 ,  0.14483336, -0.43334392,  0.02805132,\n",
      "        0.00769677,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03994322,  1.2675277 ,  0.14483336, -0.43334392,  0.02805132,\n",
      "        0.00769677,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5452638848306322, next_state=array([ 0.04139547,  1.2571778 ,  0.14483336, -0.4600106 ,  0.02843616,\n",
      "        0.0076968 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04139547,  1.2571778 ,  0.14483336, -0.4600106 ,  0.02843616,\n",
      "        0.0076968 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6160940033276734, next_state=array([ 0.04294052,  1.2462325 ,  0.15647122, -0.48642045,  0.02648852,\n",
      "       -0.03895282,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04294052,  1.2462325 ,  0.15647122, -0.48642045,  0.02648852,\n",
      "       -0.03895282,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1485510797297696, next_state=array([ 0.04438934,  1.2346847 ,  0.14441502, -0.5132449 ,  0.02695605,\n",
      "        0.00935065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04438934,  1.2346847 ,  0.14441502, -0.5132449 ,  0.02695605,\n",
      "        0.00935065,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5092501876885638, next_state=array([ 0.04592714,  1.2225374 ,  0.15556327, -0.53984874,  0.02519118,\n",
      "       -0.03529702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04592714,  1.2225374 ,  0.15556327, -0.53984874,  0.02519118,\n",
      "       -0.03529702,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1193886620629587, next_state=array([ 4.7394942e-02,  1.2097867e+00,  1.4678915e-01, -5.6669849e-01,\n",
      "        2.5184669e-02, -1.3021876e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 4.7394942e-02,  1.2097867e+00,  1.4678915e-01, -5.6669849e-01,\n",
      "        2.5184669e-02, -1.3021876e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.2418094186797635, next_state=array([ 0.0487997 ,  1.1964409 ,  0.13888541, -0.59318185,  0.02675875,\n",
      "        0.0314814 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0487997 ,  1.1964409 ,  0.13888541, -0.59318185,  0.02675875,\n",
      "        0.0314814 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8949911384731422, next_state=array([ 0.05022135,  1.1833496 ,  0.14042184, -0.58186805,  0.02848151,\n",
      "        0.03445496,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05022135,  1.1833496 ,  0.14042184, -0.58186805,  0.02848151,\n",
      "        0.03445496,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.464578089411673, next_state=array([ 0.05171861,  1.1696578 ,  0.14991078, -0.60851544,  0.02830452,\n",
      "       -0.00353982,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05171861,  1.1696578 ,  0.14991078, -0.60851544,  0.02830452,\n",
      "       -0.00353982,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1322664119278147, next_state=array([ 0.05313826,  1.1553739 ,  0.14016885, -0.6348781 ,  0.03007444,\n",
      "        0.03539854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05313826,  1.1553739 ,  0.14016885, -0.6348781 ,  0.03007444,\n",
      "        0.03539854,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3071089431915925, next_state=array([ 0.05447388,  1.1404972 ,  0.12963022, -0.6612739 ,  0.03395082,\n",
      "        0.07752772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05447388,  1.1404972 ,  0.12963022, -0.6612739 ,  0.03395082,\n",
      "        0.07752772,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5418322482581732, next_state=array([ 0.0557436 ,  1.125015  ,  0.12137612, -0.68822724,  0.03948294,\n",
      "        0.11064243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0557436 ,  1.125015  ,  0.12137612, -0.68822724,  0.03948294,\n",
      "        0.11064243,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7016743922297737, next_state=array([ 0.05684366,  1.1099253 ,  0.1050773 , -0.6707982 ,  0.0443515 ,\n",
      "        0.09737105,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05684366,  1.1099253 ,  0.1050773 , -0.6707982 ,  0.0443515 ,\n",
      "        0.09737105,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6928658417529039, next_state=array([ 0.05787487,  1.0942253 ,  0.09643257, -0.6979952 ,  0.05095847,\n",
      "        0.13213962,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05787487,  1.0942253 ,  0.09643257, -0.6979952 ,  0.05095847,\n",
      "        0.13213962,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7764016338247746, next_state=array([ 0.05884008,  1.0779262 ,  0.0881649 , -0.7247084 ,  0.05921986,\n",
      "        0.1652279 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05884008,  1.0779262 ,  0.0881649 , -0.7247084 ,  0.05921986,\n",
      "        0.1652279 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.9078231852234184, next_state=array([ 0.05971022,  1.0621564 ,  0.07889569, -0.7012177 ,  0.06724845,\n",
      "        0.16057178,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05971022,  1.0621564 ,  0.07889569, -0.7012177 ,  0.06724845,\n",
      "        0.16057178,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8246760489933251, next_state=array([ 0.06058035,  1.0457877 ,  0.0788962 , -0.72788966,  0.075277  ,\n",
      "        0.16057105,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06058035,  1.0457877 ,  0.0788962 , -0.72788966,  0.075277  ,\n",
      "        0.16057105,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9441374642156848, next_state=array([ 0.06138229,  1.0288081 ,  0.07034499, -0.7551746 ,  0.08503074,\n",
      "        0.1950748 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06138229,  1.0288081 ,  0.07034499, -0.7551746 ,  0.08503074,\n",
      "        0.1950748 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8819594012807386, next_state=array([ 0.06218414,  1.0112299 ,  0.07034595, -0.7818491 ,  0.09478443,\n",
      "        0.19507354,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06218414,  1.0112299 ,  0.07034595, -0.7818491 ,  0.09478443,\n",
      "        0.19507354,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8232678810516347, next_state=array([ 0.0629859 ,  0.9930528 ,  0.070347  , -0.8085236 ,  0.10453805,\n",
      "        0.19507226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0629859 ,  0.9930528 ,  0.070347  , -0.8085236 ,  0.10453805,\n",
      "        0.19507226,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.960503126554811, next_state=array([ 0.0637269 ,  0.97426313,  0.06271939, -0.8359347 ,  0.11584011,\n",
      "        0.2260416 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0637269 ,  0.97426313,  0.06271939, -0.8359347 ,  0.11584011,\n",
      "        0.2260416 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8610753840192444, next_state=array([ 0.06446781,  0.9548752 ,  0.06272113, -0.862612  ,  0.12714209,\n",
      "        0.2260396 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06446781,  0.9548752 ,  0.06272113, -0.862612  ,  0.12714209,\n",
      "        0.2260396 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.581091970014653, next_state=array([ 0.06529035,  0.9349119 ,  0.07302737, -0.88806635,  0.13633835,\n",
      "        0.18392509,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06529035,  0.9349119 ,  0.07302737, -0.88806635,  0.13633835,\n",
      "        0.18392509,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.533089214620361, next_state=array([ 0.0661129 ,  0.91435003,  0.07302876, -0.9147399 ,  0.14553455,\n",
      "        0.183924  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0661129 ,  0.91435003,  0.07302876, -0.9147399 ,  0.14553455,\n",
      "        0.183924  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7802256205955007, next_state=array([ 0.06684027,  0.89316773,  0.06108397, -0.94261813,  0.15716386,\n",
      "        0.232586  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06684027,  0.89316773,  0.06108397, -0.94261813,  0.15716386,\n",
      "        0.232586  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.009089276819678, next_state=array([ 0.06748285,  0.8713557 ,  0.05044074, -0.9709445 ,  0.17099643,\n",
      "        0.27665108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06748285,  0.8713557 ,  0.05044074, -0.9709445 ,  0.17099643,\n",
      "        0.27665108,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6146832893250849, next_state=array([ 0.06819763,  0.8489638 ,  0.05952426, -0.9966155 ,  0.18297197,\n",
      "        0.23951074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06819763,  0.8489638 ,  0.05952426, -0.9966155 ,  0.18297197,\n",
      "        0.23951074,  0.        ,  0.        ], dtype=float32), action=2, reward=4.537130017970367, next_state=array([ 0.06883907,  0.82745475,  0.05173575, -0.9575339 ,  0.19544692,\n",
      "        0.24949872,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06883907,  0.82745475,  0.05173575, -0.9575339 ,  0.19544692,\n",
      "        0.24949872,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4876667574539215, next_state=array([ 0.06955309,  0.8053697 ,  0.06089047, -0.9829823 ,  0.20603362,\n",
      "        0.21173398,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06955309,  0.8053697 ,  0.06089047, -0.9829823 ,  0.20603362,\n",
      "        0.21173398,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7259885243097688, next_state=array([ 0.07019158,  0.78267187,  0.05147159, -1.0105671 ,  0.21853729,\n",
      "        0.25007302,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07019158,  0.78267187,  0.05147159, -1.0105671 ,  0.21853729,\n",
      "        0.25007302,  0.        ,  0.        ], dtype=float32), action=2, reward=3.8742227327686125, next_state=array([ 0.07045422,  0.76065534,  0.01474284, -0.980263  ,  0.23020004,\n",
      "        0.23325512,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07045422,  0.76065534,  0.01474284, -0.980263  ,  0.23020004,\n",
      "        0.23325512,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.236864991456797, next_state=array([ 0.0708003 ,  0.7380734 ,  0.02530324, -1.0051261 ,  0.23964782,\n",
      "        0.18895534,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0708003 ,  0.7380734 ,  0.02530324, -1.0051261 ,  0.23964782,\n",
      "        0.18895534,  0.        ,  0.        ], dtype=float32), action=2, reward=3.391941798636293, next_state=array([ 0.0710515 ,  0.71604997,  0.01541313, -0.9804297 ,  0.24951702,\n",
      "        0.19738394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0710515 ,  0.71604997,  0.01541313, -0.9804297 ,  0.24951702,\n",
      "        0.19738394,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8019921369206873, next_state=array([ 0.0712183 ,  0.69340026,  0.00485544, -1.0087093 ,  0.26158527,\n",
      "        0.24136475,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0712183 ,  0.69340026,  0.00485544, -1.0087093 ,  0.26158527,\n",
      "        0.24136475,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9925245319333544, next_state=array([ 0.0713131 ,  0.6701138 , -0.00421095, -1.0374621 ,  0.2756111 ,\n",
      "        0.280517  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0713131 ,  0.6701138 , -0.00421095, -1.0374621 ,  0.2756111 ,\n",
      "        0.280517  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6973372721203646, next_state=array([ 0.07140751,  0.64622986, -0.0042044 , -1.0641447 ,  0.28963676,\n",
      "        0.28051326,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07140751,  0.64622986, -0.0042044 , -1.0641447 ,  0.28963676,\n",
      "        0.28051326,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1528275397706964, next_state=array([ 0.07142   ,  0.6217014 , -0.01453317, -1.0933734 ,  0.3059209 ,\n",
      "        0.32568276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07142   ,  0.6217014 , -0.01453317, -1.0933734 ,  0.3059209 ,\n",
      "        0.32568276,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.801656016589817, next_state=array([ 0.07143173,  0.59657645, -0.01452342, -1.1200612 ,  0.32220474,\n",
      "        0.3256771 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07143173,  0.59657645, -0.01452342, -1.1200612 ,  0.32220474,\n",
      "        0.3256771 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7439071068796466, next_state=array([ 0.0714427 ,  0.5708546 , -0.01451315, -1.1467489 ,  0.33848828,\n",
      "        0.3256713 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0714427 ,  0.5708546 , -0.01451315, -1.1467489 ,  0.33848828,\n",
      "        0.3256713 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5332492127928503, next_state=array([ 0.07128191,  0.5453564 , -0.03169538, -1.1370021 ,  0.35486534,\n",
      "        0.32754198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07128191,  0.5453564 , -0.03169538, -1.1370021 ,  0.35486534,\n",
      "        0.32754198,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7168456469847513, next_state=array([ 0.07112026,  0.5192616 , -0.03168395, -1.16369   ,  0.37124214,\n",
      "        0.32753593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07112026,  0.5192616 , -0.03168395, -1.16369   ,  0.37124214,\n",
      "        0.32753593,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.270040829296305, next_state=array([ 0.07102032,  0.49261087, -0.0237298 , -1.188107  ,  0.38582507,\n",
      "        0.29165944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07102032,  0.49261087, -0.0237298 , -1.188107  ,  0.38582507,\n",
      "        0.29165944,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9374054356505599, next_state=array([ 0.070996  ,  0.46541536, -0.01400638, -1.211876  ,  0.39819103,\n",
      "        0.24731937,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.070996  ,  0.46541536, -0.01400638, -1.211876  ,  0.39819103,\n",
      "        0.24731937,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8084152786403933, next_state=array([ 0.07083235,  0.43814945, -0.02792399, -1.2151084 ,  0.4105959 ,\n",
      "        0.24809694,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07083235,  0.43814945, -0.02792399, -1.2151084 ,  0.4105959 ,\n",
      "        0.24809694,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1565047897651084, next_state=array([ 0.07066812,  0.41028544, -0.02791639, -1.2417868 ,  0.42300057,\n",
      "        0.2480944 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07066812,  0.41028544, -0.02791639, -1.2417868 ,  0.42300057,\n",
      "        0.2480944 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1027369575097907, next_state=array([ 0.07050333,  0.38182327, -0.02790857, -1.2684654 ,  0.43540516,\n",
      "        0.24809182,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07050333,  0.38182327, -0.02790857, -1.2684654 ,  0.43540516,\n",
      "        0.24809182,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.050540882775607, next_state=array([ 0.07033787,  0.35276294, -0.02790054, -1.2951437 ,  0.44780967,\n",
      "        0.2480892 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07033787,  0.35276294, -0.02790054, -1.2951437 ,  0.44780967,\n",
      "        0.2480892 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4755984588894069, next_state=array([ 0.07011823,  0.32305586, -0.03478277, -1.3244882 ,  0.46189427,\n",
      "        0.281692  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07011823,  0.32305586, -0.03478277, -1.3244882 ,  0.46189427,\n",
      "        0.281692  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6111873654737952, next_state=array([ 0.06996803,  0.29280597, -0.0258339 , -1.3480762 ,  0.47385538,\n",
      "        0.23922198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06996803,  0.29280597, -0.0258339 , -1.3480762 ,  0.47385538,\n",
      "        0.23922198,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8685937109577822, next_state=array([ 0.06981726,  0.26195776, -0.0258258 , -1.3747537 ,  0.48581636,\n",
      "        0.23921967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06981726,  0.26195776, -0.0258258 , -1.3747537 ,  0.48581636,\n",
      "        0.23921967,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.25586488977987076, next_state=array([ 0.06974058,  0.23057729, -0.01628103, -1.3977468 ,  0.4954383 ,\n",
      "        0.1924387 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06974058,  0.23057729, -0.01628103, -1.3977468 ,  0.4954383 ,\n",
      "        0.1924387 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.869142617277373, next_state=array([ 0.06931591,  0.1999562 , -0.05153685, -1.3642412 ,  0.5056377 ,\n",
      "        0.2039878 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06931591,  0.1999562 , -0.05153685, -1.3642412 ,  0.5056377 ,\n",
      "        0.2039878 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7482630413969673, next_state=array([ 0.06889085,  0.16873628, -0.05153058, -1.3909155 ,  0.515837  ,\n",
      "        0.2039861 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06889085,  0.16873628, -0.05153058, -1.3909155 ,  0.515837  ,\n",
      "        0.2039861 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7678955656313349, next_state=array([ 0.06846533,  0.13691762, -0.05152419, -1.4175897 ,  0.52603626,\n",
      "        0.20398459,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06846533,  0.13691762, -0.05152419, -1.4175897 ,  0.52603626,\n",
      "        0.20398459,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3753395865604421, next_state=array([ 0.06809769,  0.10455301, -0.04405778, -1.4412732 ,  0.5343761 ,\n",
      "        0.16679658,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06809769,  0.10455301, -0.04405778, -1.4412732 ,  0.5343761 ,\n",
      "        0.16679658,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.877579342970904, next_state=array([ 0.06772976,  0.0715891 , -0.04405337, -1.4679449 ,  0.54271585,\n",
      "        0.16679576,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06772976,  0.0715891 , -0.04405337, -1.4679449 ,  0.54271585,\n",
      "        0.16679576,  0.        ,  0.        ], dtype=float32), action=0, reward=8.619819422738232, next_state=array([ 0.06736145,  0.03802608, -0.04404888, -1.4946166 ,  0.55105555,\n",
      "        0.16679496,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.06736145,  0.03802608, -0.04404888, -1.4946166 ,  0.55105555,\n",
      "        0.16679496,  0.        ,  1.        ], dtype=float32), action=1, reward=-2.0807676441872602, next_state=array([ 0.06743746,  0.00591442,  0.00788402, -1.4273009 ,  0.54916316,\n",
      "       -0.04004695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06743746,  0.00591442,  0.00788402, -1.4273009 ,  0.54916316,\n",
      "       -0.04004695,  0.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([ 0.06689425, -0.01258509,  0.14242947, -0.38349   ,  0.40592822,\n",
      "       -4.2794642 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00510702,  1.4019433 , -0.5172996 , -0.39899388,  0.00592452,\n",
      "        0.11717594,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.372352767951638, next_state=array([-0.01030979,  1.3923885 , -0.52856547, -0.42470858,  0.0141143 ,\n",
      "        0.16381198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01030979,  1.3923885 , -0.52856547, -0.42470858,  0.0141143 ,\n",
      "        0.16381198,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4852941284780727, next_state=array([-0.01558828,  1.3822238 , -0.5380447 , -0.45189658,  0.0241976 ,\n",
      "        0.20168476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01558828,  1.3822238 , -0.5380447 , -0.45189658,  0.0241976 ,\n",
      "        0.20168476,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6410348937301635, next_state=array([-0.0209445 ,  1.3714608 , -0.54779303, -0.4785915 ,  0.03622752,\n",
      "        0.24062116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0209445 ,  1.3714608 , -0.54779303, -0.4785915 ,  0.03622752,\n",
      "        0.24062116,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8610732494421711, next_state=array([-0.02630129,  1.3600998 , -0.54782915, -0.5052694 ,  0.04825502,\n",
      "        0.24057242,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02630129,  1.3600998 , -0.54782915, -0.5052694 ,  0.04825502,\n",
      "        0.24057242,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7600530287793663, next_state=array([-0.03156042,  1.3481386 , -0.53556174, -0.53194517,  0.05781696,\n",
      "        0.19125655,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03156042,  1.3481386 , -0.53556174, -0.53194517,  0.05781696,\n",
      "        0.19125655,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8585600371857527, next_state=array([-0.0367487 ,  1.3355764 , -0.5266867 , -0.55864364,  0.0655973 ,\n",
      "        0.15562078,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0367487 ,  1.3355764 , -0.5266867 , -0.55864364,  0.0655973 ,\n",
      "        0.15562078,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5218712720962049, next_state=array([-0.04184999,  1.3224137 , -0.51578003, -0.5852717 ,  0.07118898,\n",
      "        0.11184382,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04184999,  1.3224137 , -0.51578003, -0.5852717 ,  0.07118898,\n",
      "        0.11184382,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.27853528974080066, next_state=array([-0.04686451,  1.3086646 , -0.5048626 , -0.611242  ,  0.07457517,\n",
      "        0.06773005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04686451,  1.3086646 , -0.5048626 , -0.611242  ,  0.07457517,\n",
      "        0.06773005,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.11785826400276164, next_state=array([-0.05179157,  1.2943166 , -0.4938949 , -0.6377389 ,  0.07576204,\n",
      "        0.02373947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05179157,  1.2943166 , -0.4938949 , -0.6377389 ,  0.07576204,\n",
      "        0.02373947,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6447054613008152, next_state=array([-0.05679531,  1.279351  , -0.50353825, -0.6653026 ,  0.07890189,\n",
      "        0.06280258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05679531,  1.279351  , -0.50353825, -0.6653026 ,  0.07890189,\n",
      "        0.06280258,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0166140298123991, next_state=array([-0.06190376,  1.2646048 , -0.5137177 , -0.65554196,  0.08174969,\n",
      "        0.05696081,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06190376,  1.2646048 , -0.5137177 , -0.65554196,  0.08174969,\n",
      "        0.05696081,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7670256134459226, next_state=array([-0.06708793,  1.2492394 , -0.523234  , -0.68317425,  0.08652689,\n",
      "        0.09555304,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06708793,  1.2492394 , -0.523234  , -0.68317425,  0.08652689,\n",
      "        0.09555304,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.727422272337576, next_state=array([-0.07233667,  1.2332741 , -0.53130907, -0.7099613 ,  0.09291561,\n",
      "        0.12778601,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07233667,  1.2332741 , -0.53130907, -0.7099613 ,  0.09291561,\n",
      "        0.12778601,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.168072957583263, next_state=array([-0.0775857 ,  1.2167091 , -0.53132784, -0.73663425,  0.09930307,\n",
      "        0.12776062,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0775857 ,  1.2167091 , -0.53132784, -0.73663425,  0.09930307,\n",
      "        0.12776062,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8772861881461551, next_state=array([-0.08291149,  1.200326  , -0.53889734, -0.7285677 ,  0.10557351,\n",
      "        0.12542011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08291149,  1.200326  , -0.53889734, -0.7285677 ,  0.10557351,\n",
      "        0.12542011,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5199909264434257, next_state=array([-0.08817492,  1.1833485 , -0.5310575 , -0.7548966 ,  0.11026361,\n",
      "        0.09381055,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08817492,  1.1833485 , -0.5310575 , -0.7548966 ,  0.11026361,\n",
      "        0.09381055,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9382006373573961, next_state=array([-0.09352942,  1.1657536 , -0.54249996, -0.7825273 ,  0.11727013,\n",
      "        0.14014313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09352942,  1.1657536 , -0.54249996, -0.7825273 ,  0.11727013,\n",
      "        0.14014313,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.123101451865351, next_state=array([-0.09897757,  1.1475462 , -0.5542159 , -0.8099835 ,  0.12663633,\n",
      "        0.18734108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09897757,  1.1475462 , -0.5542159 , -0.8099835 ,  0.12663633,\n",
      "        0.18734108,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3262518145452304, next_state=array([-0.104426  ,  1.12874   , -0.5542423 , -0.8366613 ,  0.1360006 ,\n",
      "        0.18730249,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.104426  ,  1.12874   , -0.5542423 , -0.8366613 ,  0.1360006 ,\n",
      "        0.18730249,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2941326965352844, next_state=array([-0.10996713,  1.1093113 , -0.5658514 , -0.86460716,  0.14772858,\n",
      "        0.23458068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10996713,  1.1093113 , -0.5658514 , -0.86460716,  0.14772858,\n",
      "        0.23458068,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4812977322186214, next_state=array([-0.11550875,  1.0892843 , -0.56588304, -0.8912904 ,  0.15945375,\n",
      "        0.23452444,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11550875,  1.0892843 , -0.56588304, -0.8912904 ,  0.15945375,\n",
      "        0.23452444,  0.        ,  0.        ], dtype=float32), action=2, reward=1.158137032703462, next_state=array([-0.12109099,  1.0695225 , -0.5701505 , -0.87963   ,  0.17141858,\n",
      "        0.2393178 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12109099,  1.0695225 , -0.5701505 , -0.87963   ,  0.17141858,\n",
      "        0.2393178 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2590365005552813, next_state=array([-0.1267477 ,  1.0491527 , -0.57946324, -0.90696704,  0.18525527,\n",
      "        0.27675834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1267477 ,  1.0491527 , -0.57946324, -0.90696704,  0.18525527,\n",
      "        0.27675834,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0726340070789435, next_state=array([-0.13239288,  1.029296  , -0.578944  , -0.88438714,  0.1997769 ,\n",
      "        0.2904589 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13239288,  1.029296  , -0.578944  , -0.88438714,  0.1997769 ,\n",
      "        0.2904589 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8223316344104432, next_state=array([-0.13811246,  1.009756  , -0.5865853 , -0.8704884 ,  0.21452165,\n",
      "        0.29489496,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13811246,  1.009756  , -0.5865853 , -0.8704884 ,  0.21452165,\n",
      "        0.29489496,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.128933428897368, next_state=array([-0.14377108,  0.9896407 , -0.57883865, -0.8959502 ,  0.22765306,\n",
      "        0.26262826,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14377108,  0.9896407 , -0.57883865, -0.8959502 ,  0.22765306,\n",
      "        0.26262826,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.54889093049769, next_state=array([-0.14951134,  0.9688937 , -0.5891066 , -0.92448694,  0.24294691,\n",
      "        0.3058769 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14951134,  0.9688937 , -0.5891066 , -0.92448694,  0.24294691,\n",
      "        0.3058769 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7709606292183082, next_state=array([-0.15525217,  0.94754976, -0.58909976, -0.9511727 ,  0.2582405 ,\n",
      "        0.3058719 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15525217,  0.94754976, -0.58909976, -0.9511727 ,  0.2582405 ,\n",
      "        0.3058719 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7102601645331377, next_state=array([-0.16108103,  0.92558026, -0.6000658 , -0.9795505 ,  0.27582172,\n",
      "        0.35162455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16108103,  0.92558026, -0.6000658 , -0.9795505 ,  0.27582172,\n",
      "        0.35162455,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.923748469926494, next_state=array([-0.16691065,  0.90301466, -0.6000556 , -1.0062422 ,  0.2934026 ,\n",
      "        0.3516177 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16691065,  0.90301466, -0.6000556 , -1.0062422 ,  0.2934026 ,\n",
      "        0.3516177 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7133941413183493, next_state=array([-0.17283973,  0.8803871 , -0.6099497 , -1.0092041 ,  0.31102228,\n",
      "        0.35239357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17283973,  0.8803871 , -0.6099497 , -1.0092041 ,  0.31102228,\n",
      "        0.35239357,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8950553392886604, next_state=array([-0.17876968,  0.8571636 , -0.609938  , -1.0358956 ,  0.32864162,\n",
      "        0.35238606,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17876968,  0.8571636 , -0.609938  , -1.0358956 ,  0.32864162,\n",
      "        0.35238606,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1008928900842239, next_state=array([-0.18463297,  0.83338225, -0.6013886 , -1.0604541 ,  0.34438217,\n",
      "        0.3148111 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18463297,  0.83338225, -0.6013886 , -1.0604541 ,  0.34438217,\n",
      "        0.3148111 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.655828698222649, next_state=array([-0.19049692,  0.809004  , -0.60137826, -1.0871404 ,  0.36012238,\n",
      "        0.3148044 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19049692,  0.809004  , -0.60137826, -1.0871404 ,  0.36012238,\n",
      "        0.3148044 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8835889102259376, next_state=array([-0.19629773,  0.7840714 , -0.59322095, -1.1114831 ,  0.37402338,\n",
      "        0.27801964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19629773,  0.7840714 , -0.59322095, -1.1114831 ,  0.37402338,\n",
      "        0.27801964,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4229243568863694, next_state=array([-0.20209913,  0.75854105, -0.5932122 , -1.1381649 ,  0.38792416,\n",
      "        0.278016  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20209913,  0.75854105, -0.5932122 , -1.1381649 ,  0.38792416,\n",
      "        0.278016  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5064984518888014, next_state=array([-0.20781751,  0.7324545 , -0.58269966, -1.162403  ,  0.39952865,\n",
      "        0.23208973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20781751,  0.7324545 , -0.58269966, -1.162403  ,  0.39952865,\n",
      "        0.23208973,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.1411219267118497, next_state=array([-0.21391268,  0.70652676, -0.6196804 , -1.1552377 ,  0.4104372 ,\n",
      "        0.21817069,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21391268,  0.70652676, -0.6196804 , -1.1552377 ,  0.4104372 ,\n",
      "        0.21817069,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0978921336429437, next_state=array([-0.22000828,  0.68000066, -0.6196745 , -1.1819135 ,  0.42134565,\n",
      "        0.21816893,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22000828,  0.68000066, -0.6196745 , -1.1819135 ,  0.42134565,\n",
      "        0.21816893,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1924124548344524, next_state=array([-0.22619328,  0.6528145 , -0.6309563 , -1.2120482 ,  0.43485138,\n",
      "        0.27011442,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22619328,  0.6528145 , -0.6309563 , -1.2120482 ,  0.43485138,\n",
      "        0.27011442,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3161643057555352, next_state=array([-0.232379  ,  0.6250307 , -0.63094676, -1.2387288 ,  0.44835693,\n",
      "        0.27011102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.232379  ,  0.6250307 , -0.63094676, -1.2387288 ,  0.44835693,\n",
      "        0.27011102,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3071916556971246, next_state=array([-0.23856544,  0.59664905, -0.630937  , -1.2654092 ,  0.4618623 ,\n",
      "        0.2701077 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23856544,  0.59664905, -0.630937  , -1.2654092 ,  0.4618623 ,\n",
      "        0.2701077 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1800559408067373, next_state=array([-0.24481788,  0.56761354, -0.6392709 , -1.2952008 ,  0.47738746,\n",
      "        0.31050298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24481788,  0.56761354, -0.6392709 , -1.2952008 ,  0.47738746,\n",
      "        0.31050298,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5457961654481938, next_state=array([-0.25099343,  0.53804415, -0.62935   , -1.3183198 ,  0.4905311 ,\n",
      "        0.26287252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25099343,  0.53804415, -0.62935   , -1.3183198 ,  0.4905311 ,\n",
      "        0.26287252,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7809726545798299, next_state=array([-0.25753245,  0.5084648 , -0.6650523 , -1.3186593 ,  0.50304866,\n",
      "        0.2503516 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25753245,  0.5084648 , -0.6650523 , -1.3186593 ,  0.50304866,\n",
      "        0.2503516 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5846510289074331, next_state=array([-0.2644158 ,  0.47893432, -0.6990312 , -1.3164382 ,  0.51513475,\n",
      "        0.2417219 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2644158 ,  0.47893432, -0.6990312 , -1.3164382 ,  0.51513475,\n",
      "        0.2417219 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.240474369016026, next_state=array([-0.2713713 ,  0.44875267, -0.70805705, -1.3461931 ,  0.52936774,\n",
      "        0.28465998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2713713 ,  0.44875267, -0.70805705, -1.3461931 ,  0.52936774,\n",
      "        0.28465998,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5629853979194195, next_state=array([-0.2783278 ,  0.41797343, -0.70804423, -1.3728745 ,  0.5436006 ,\n",
      "        0.284656  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2783278 ,  0.41797343, -0.70804423, -1.3728745 ,  0.5436006 ,\n",
      "        0.284656  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7524832796776468, next_state=array([-0.2852221 ,  0.3866627 , -0.6999017 , -1.3958557 ,  0.55571663,\n",
      "        0.24232073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2852221 ,  0.3866627 , -0.6999017 , -1.3958557 ,  0.55571663,\n",
      "        0.24232073,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9589499654322367, next_state=array([-0.29243764,  0.355874  , -0.7324288 , -1.3729444 ,  0.5683948 ,\n",
      "        0.253563  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29243764,  0.355874  , -0.7324288 , -1.3729444 ,  0.5683948 ,\n",
      "        0.253563  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.58913231635742, next_state=array([-0.29971734,  0.32443723, -0.74039716, -1.4025592 ,  0.5830163 ,\n",
      "        0.29242942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29971734,  0.32443723, -0.74039716, -1.4025592 ,  0.5830163 ,\n",
      "        0.29242942,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9602552708099936, next_state=array([-0.30706018,  0.2923427 , -0.7483101 , -1.4326932 ,  0.5996808 ,\n",
      "        0.33329022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30706018,  0.2923427 , -0.7483101 , -1.4326932 ,  0.5996808 ,\n",
      "        0.33329022,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9720850591372596, next_state=array([-0.3148218 ,  0.26062703, -0.79011667, -1.4160469 ,  0.61644894,\n",
      "        0.3353633 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3148218 ,  0.26062703, -0.79011667, -1.4160469 ,  0.61644894,\n",
      "        0.3353633 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6615879502019197, next_state=array([-0.32258493,  0.22831443, -0.7900964 , -1.4427329 ,  0.6332168 ,\n",
      "        0.3353568 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32258493,  0.22831443, -0.7900964 , -1.4427329 ,  0.6332168 ,\n",
      "        0.3353568 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4019620927212373, next_state=array([-0.33063293,  0.19625624, -0.8188194 , -1.4317788 ,  0.6504806 ,\n",
      "        0.34527633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33063293,  0.19625624, -0.8188194 , -1.4317788 ,  0.6504806 ,\n",
      "        0.34527633,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5066139186377243, next_state=array([-0.33863625,  0.16365625, -0.8128373 , -1.4553243 ,  0.66607577,\n",
      "        0.311903  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33863625,  0.16365625, -0.8128373 , -1.4553243 ,  0.66607577,\n",
      "        0.311903  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5142863157452937, next_state=array([-0.3465925 ,  0.13052775, -0.806479  , -1.4781401 ,  0.6797696 ,\n",
      "        0.27387664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3465925 ,  0.13052775, -0.806479  , -1.4781401 ,  0.6797696 ,\n",
      "        0.27387664,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.4324929995675575, next_state=array([-0.35454974,  0.09680115, -0.8064643 , -1.5048193 ,  0.69346315,\n",
      "        0.27387312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35454974,  0.09680115, -0.8064643 , -1.5048193 ,  0.69346315,\n",
      "        0.27387312,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.757270258472488, next_state=array([-0.36250806,  0.06247645, -0.8064494 , -1.531498  ,  0.7071566 ,\n",
      "        0.27386957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36250806,  0.06247645, -0.8064494 , -1.531498  ,  0.7071566 ,\n",
      "        0.27386957,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.532524629062652, next_state=array([-0.3707792 ,  0.02844466, -0.8381258 , -1.5188817 ,  0.7215385 ,\n",
      "        0.28763762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3707792 ,  0.02844466, -0.8381258 , -1.5188817 ,  0.7215385 ,\n",
      "        0.28763762,  0.        ,  0.        ], dtype=float32), action=1, reward=22.05822789360022, next_state=array([-0.37867922, -0.00294613, -0.78694546, -1.3935177 ,  0.7282457 ,\n",
      "        0.14746413,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.37867922, -0.00294613, -0.78694546, -1.3935177 ,  0.7282457 ,\n",
      "        0.14746413,  0.        ,  1.        ], dtype=float32), action=3, reward=-2.14035165236143, next_state=array([-0.38698655, -0.03471464, -0.81893426, -1.4050874 ,  0.71354425,\n",
      "       -0.29309577,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.38698655, -0.03471464, -0.81893426, -1.4050874 ,  0.71354425,\n",
      "       -0.29309577,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.39646763, -0.04781076, -0.81085044, -0.34072226,  0.55351365,\n",
      "       -3.665528  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00492458,  1.4040709 ,  0.4987896 , -0.304414  , -0.00569954,\n",
      "       -0.11298327,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.106807058036195, next_state=array([ 0.00992222,  1.3966501 ,  0.5072695 , -0.32986364, -0.01311797,\n",
      "       -0.1483821 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00992222,  1.3966501 ,  0.5072695 , -0.32986364, -0.01311797,\n",
      "       -0.1483821 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.2654100097529863, next_state=array([ 0.01491413,  1.3892303 ,  0.50675297, -0.32985404, -0.02058536,\n",
      "       -0.149362  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01491413,  1.3892303 ,  0.50675297, -0.32985404, -0.02058536,\n",
      "       -0.149362  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.46444036253407606, next_state=array([ 0.0198267 ,  1.3812097 ,  0.49677834, -0.35655552, -0.02604805,\n",
      "       -0.1092639 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0198267 ,  1.3812097 ,  0.49677834, -0.35655552, -0.02604805,\n",
      "       -0.1092639 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1019375479152247, next_state=array([ 0.02461319,  1.3736987 ,  0.48487264, -0.33394518, -0.03220683,\n",
      "       -0.12318669,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02461319,  1.3736987 ,  0.48487264, -0.33394518, -0.03220683,\n",
      "       -0.12318669,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.543837249750338, next_state=array([ 0.02948933,  1.3655835 ,  0.49612445, -0.36087406, -0.04061796,\n",
      "       -0.1682384 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02948933,  1.3655835 ,  0.49612445, -0.36087406, -0.04061796,\n",
      "       -0.1682384 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7449032195916618, next_state=array([ 0.03429375,  1.3568621 ,  0.48711166, -0.38782203, -0.04722074,\n",
      "       -0.13206783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03429375,  1.3568621 ,  0.48711166, -0.38782203, -0.04722074,\n",
      "       -0.13206783,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7401011738474483, next_state=array([ 0.03903637,  1.347534  ,  0.47936472, -0.4147553 , -0.05227352,\n",
      "       -0.10106499,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03903637,  1.347534  ,  0.47936472, -0.4147553 , -0.05227352,\n",
      "       -0.10106499,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.304845008162033, next_state=array([ 0.04377909,  1.3376061 ,  0.4793784 , -0.44142613, -0.05732581,\n",
      "       -0.10105499,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04377909,  1.3376061 ,  0.4793784 , -0.44142613, -0.05732581,\n",
      "       -0.10105499,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7632106972504973, next_state=array([ 0.04846706,  1.3284762 ,  0.47441608, -0.4060007 , -0.0628904 ,\n",
      "       -0.11130194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04846706,  1.3284762 ,  0.47441608, -0.4060007 , -0.0628904 ,\n",
      "       -0.11130194,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4155176202618507, next_state=array([ 0.05324059,  1.3187464 ,  0.48513222, -0.4327754 , -0.07059667,\n",
      "       -0.15413943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05324059,  1.3187464 ,  0.48513222, -0.4327754 , -0.07059667,\n",
      "       -0.15413943,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5653303395554872, next_state=array([ 0.05801439,  1.3084178 ,  0.48515588, -0.4594436 , -0.07830104,\n",
      "       -0.15410191,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05801439,  1.3084178 ,  0.48515588, -0.4594436 , -0.07830104,\n",
      "       -0.15410191,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1951401038858591, next_state=array([ 0.06284084,  1.2986588 ,  0.49045396, -0.43415642, -0.08604563,\n",
      "       -0.15490586,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06284084,  1.2986588 ,  0.49045396, -0.43415642, -0.08604563,\n",
      "       -0.15490586,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5639423195348456, next_state=array([ 0.06766758,  1.2883003 ,  0.49047464, -0.46083993, -0.09378892,\n",
      "       -0.1548802 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06766758,  1.2883003 ,  0.49047464, -0.46083993, -0.09378892,\n",
      "       -0.1548802 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5615513930425209, next_state=array([ 0.07249451,  1.2773426 ,  0.49049687, -0.48751032, -0.10153107,\n",
      "       -0.15485711,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07249451,  1.2773426 ,  0.49049687, -0.48751032, -0.10153107,\n",
      "       -0.15485711,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6588411656323945, next_state=array([ 0.0772398 ,  1.2657872 ,  0.48024186, -0.51397187, -0.10721496,\n",
      "       -0.11368813,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0772398 ,  1.2657872 ,  0.48024186, -0.51397187, -0.10721496,\n",
      "       -0.11368813,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.073633869029861, next_state=array([ 0.08204403,  1.2536215 ,  0.48765007, -0.54122984, -0.11439566,\n",
      "       -0.14362708,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08204403,  1.2536215 ,  0.48765007, -0.54122984, -0.11439566,\n",
      "       -0.14362708,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7958188213280539, next_state=array([ 0.08678837,  1.2408738 ,  0.4800753 , -0.567002  , -0.12002319,\n",
      "       -0.11256056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08678837,  1.2408738 ,  0.4800753 , -0.567002  , -0.12002319,\n",
      "       -0.11256056,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8782739870155012, next_state=array([ 0.09148703,  1.2282145 ,  0.47598702, -0.5631365 , -0.12612005,\n",
      "       -0.1219479 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09148703,  1.2282145 ,  0.47598702, -0.5631365 , -0.12612005,\n",
      "       -0.1219479 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4898778224016214, next_state=array([ 0.09616041,  1.2162035 ,  0.4740591 , -0.5344066 , -0.13282181,\n",
      "       -0.13404705,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09616041,  1.2162035 ,  0.4740591 , -0.5344066 , -0.13282181,\n",
      "       -0.13404705,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5366077441393304, next_state=array([ 0.10075216,  1.2036159 ,  0.46378508, -0.5598667 , -0.13741742,\n",
      "       -0.09192059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10075216,  1.2036159 ,  0.46378508, -0.5598667 , -0.13741742,\n",
      "       -0.09192059,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3038935410703505, next_state=array([ 0.10525284,  1.1904383 ,  0.45236248, -0.585889  , -0.13971101,\n",
      "       -0.04587547,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10525284,  1.1904383 ,  0.45236248, -0.585889  , -0.13971101,\n",
      "       -0.04587547,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.307685748887269, next_state=array([ 0.10991459,  1.1772199 ,  0.46798033, -0.58765393, -0.14150383,\n",
      "       -0.03585982,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10991459,  1.1772199 ,  0.46798033, -0.58765393, -0.14150383,\n",
      "       -0.03585982,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2807315017419387, next_state=array([ 0.11451082,  1.1634091 ,  0.45975262, -0.61382335, -0.14163715,\n",
      "       -0.00266629,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11451082,  1.1634091 ,  0.45975262, -0.61382335, -0.14163715,\n",
      "       -0.00266629,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7763191099979849, next_state=array([ 0.11910696,  1.1489984 ,  0.45975178, -0.64048994, -0.14177087,\n",
      "       -0.00267495,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11910696,  1.1489984 ,  0.45975178, -0.64048994, -0.14177087,\n",
      "       -0.00267495,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6608293898607929, next_state=array([ 0.12378101,  1.1339587 ,  0.46954638, -0.6686409 , -0.14391541,\n",
      "       -0.0428907 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12378101,  1.1339587 ,  0.46954638, -0.6686409 , -0.14391541,\n",
      "       -0.0428907 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6061147366917623, next_state=array([ 0.12865086,  1.1191292 ,  0.48859978, -0.65924436, -0.14552076,\n",
      "       -0.03210694,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12865086,  1.1191292 ,  0.48859978, -0.65924436, -0.14552076,\n",
      "       -0.03210694,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5359099669575176, next_state=array([ 0.13358316,  1.1036899 ,  0.49643025, -0.68650794, -0.14871034,\n",
      "       -0.06379195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13358316,  1.1036899 ,  0.49643025, -0.68650794, -0.14871034,\n",
      "       -0.06379195,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6401549097484451, next_state=array([ 0.13857861,  1.0876452 ,  0.50433487, -0.7135915 , -0.1534887 ,\n",
      "       -0.095567  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13857861,  1.0876452 ,  0.50433487, -0.7135915 , -0.1534887 ,\n",
      "       -0.095567  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0143044737093008, next_state=array([ 0.14365931,  1.0709844 ,  0.515023  , -0.7412149 , -0.16043754,\n",
      "       -0.13897684,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14365931,  1.0709844 ,  0.515023  , -0.7412149 , -0.16043754,\n",
      "       -0.13897684,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3395175896958438, next_state=array([ 0.14864913,  1.0537415 ,  0.50361884, -0.76685715, -0.16507003,\n",
      "       -0.09264962,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14864913,  1.0537415 ,  0.50361884, -0.76685715, -0.16507003,\n",
      "       -0.09264962,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.00930669740859, next_state=array([ 0.15363903,  1.0358989 ,  0.50361836, -0.7935255 , -0.1697025 ,\n",
      "       -0.09264974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15363903,  1.0358989 ,  0.50361836, -0.7935255 , -0.1697025 ,\n",
      "       -0.09264974,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9772506462983586, next_state=array([ 0.15862894,  1.0174565 ,  0.50361794, -0.82019395, -0.17433497,\n",
      "       -0.09264959,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15862894,  1.0174565 ,  0.50361794, -0.82019395, -0.17433497,\n",
      "       -0.09264959,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5932242204276406, next_state=array([ 0.16384669,  0.99949795,  0.5259293 , -0.7986599 , -0.17850897,\n",
      "       -0.08347966,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16384669,  0.99949795,  0.5259293 , -0.7986599 , -0.17850897,\n",
      "       -0.08347966,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.911966754443597, next_state=array([ 0.16906443,  0.9809393 ,  0.5259289 , -0.825328  , -0.18268296,\n",
      "       -0.08347957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16906443,  0.9809393 ,  0.5259289 , -0.825328  , -0.18268296,\n",
      "       -0.08347957,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8808727766325717, next_state=array([ 0.17428216,  0.9617812 ,  0.5259285 , -0.85199606, -0.18685694,\n",
      "       -0.08347943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17428216,  0.9617812 ,  0.5259285 , -0.85199606, -0.18685694,\n",
      "       -0.08347943,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.01424057207174087, next_state=array([ 0.17942142,  0.9420572 ,  0.5160121 , -0.87688565, -0.1889546 ,\n",
      "       -0.04195321,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17942142,  0.9420572 ,  0.5160121 , -0.87688565, -0.1889546 ,\n",
      "       -0.04195321,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4261485137599539, next_state=array([ 0.18463306,  0.921705  ,  0.5251533 , -0.90505594, -0.19295718,\n",
      "       -0.0800515 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18463306,  0.921705  ,  0.5251533 , -0.90505594, -0.19295718,\n",
      "       -0.0800515 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.13558384539757526, next_state=array([ 0.18977776,  0.90076846,  0.5167392 , -0.9308112 , -0.19524   ,\n",
      "       -0.04565651,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18977776,  0.90076846,  0.5167392 , -0.9308112 , -0.19524   ,\n",
      "       -0.04565651,  0.        ,  0.        ], dtype=float32), action=1, reward=0.17765282969495047, next_state=array([ 0.19484349,  0.87925315,  0.50681   , -0.9562655 , -0.19548331,\n",
      "       -0.00486599,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19484349,  0.87925315,  0.50681   , -0.9562655 , -0.19548331,\n",
      "       -0.00486599,  0.        ,  0.        ], dtype=float32), action=1, reward=0.36333084850196085, next_state=array([ 0.19983654,  0.8571652 ,  0.497649  , -0.98147213, -0.19381966,\n",
      "        0.03327283,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19983654,  0.8571652 ,  0.497649  , -0.98147213, -0.19381966,\n",
      "        0.03327283,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7517888366212435, next_state=array([ 0.20488644,  0.83445066,  0.50484383, -1.0095154 , -0.19367024,\n",
      "        0.00298824,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20488644,  0.83445066,  0.50484383, -1.0095154 , -0.19367024,\n",
      "        0.00298824,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0316556616347146, next_state=array([ 0.21001539,  0.81111234,  0.5147854 , -1.037511  , -0.19557121,\n",
      "       -0.038019  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21001539,  0.81111234,  0.5147854 , -1.037511  , -0.19557121,\n",
      "       -0.038019  ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.38170336867114085, next_state=array([ 0.21505804,  0.7871982 ,  0.5039429 , -1.0628062 , -0.1952415 ,\n",
      "        0.00659394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21505804,  0.7871982 ,  0.5039429 , -1.0628062 , -0.1952415 ,\n",
      "        0.00659394,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.1582240130838386, next_state=array([ 0.22010079,  0.76268405,  0.5039429 , -1.0894731 , -0.19491178,\n",
      "        0.00659431,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22010079,  0.76268405,  0.5039429 , -1.0894731 , -0.19491178,\n",
      "        0.00659431,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8823615291833267, next_state=array([ 0.22522259,  0.73754954,  0.5138882 , -1.117318  , -0.1966222 ,\n",
      "       -0.03420864,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22522259,  0.73754954,  0.5138882 , -1.117318  , -0.1966222 ,\n",
      "       -0.03420864,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0937623837789079, next_state=array([ 0.23042612,  0.7117892 ,  0.5241605 , -1.145411  , -0.20045547,\n",
      "       -0.07666589,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23042612,  0.7117892 ,  0.5241605 , -1.145411  , -0.20045547,\n",
      "       -0.07666589,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3737718517671853, next_state=array([ 0.2357502 ,  0.68661994,  0.5363973 , -1.1191826 , -0.20447277,\n",
      "       -0.08034579,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2357502 ,  0.68661994,  0.5363973 , -1.1191826 , -0.20447277,\n",
      "       -0.08034579,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2017829120322563, next_state=array([ 0.24113779,  0.6608298 ,  0.5443773 , -1.1470183 , -0.2101446 ,\n",
      "       -0.11343638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24113779,  0.6608298 ,  0.5443773 , -1.1470183 , -0.2101446 ,\n",
      "       -0.11343638,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.06690880721148915, next_state=array([ 0.24645033,  0.6344537 ,  0.5349847 , -1.1728063 , -0.21390764,\n",
      "       -0.07526114,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24645033,  0.6344537 ,  0.5349847 , -1.1728063 , -0.21390764,\n",
      "       -0.07526114,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5015218517260678, next_state=array([ 0.25176287,  0.6074778 ,  0.5349843 , -1.1994742 , -0.2176707 ,\n",
      "       -0.07526105,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25176287,  0.6074778 ,  0.5349843 , -1.1994742 , -0.2176707 ,\n",
      "       -0.07526105,  0.        ,  0.        ], dtype=float32), action=1, reward=0.05885769775059771, next_state=array([ 0.2570096 ,  0.5799164 ,  0.5267273 , -1.225252  , -0.21974678,\n",
      "       -0.04152142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2570096 ,  0.5799164 ,  0.5267273 , -1.225252  , -0.21974678,\n",
      "       -0.04152142,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.32108626418906283, next_state=array([ 0.26225632,  0.55175513,  0.5267272 , -1.2519192 , -0.22182286,\n",
      "       -0.04152145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26225632,  0.55175513,  0.5267272 , -1.2519192 , -0.22182286,\n",
      "       -0.04152145,  0.        ,  0.        ], dtype=float32), action=1, reward=0.36195438046766637, next_state=array([ 2.6742381e-01,  5.2301848e-01,  5.1675737e-01, -1.2771900e+00,\n",
      "       -2.2183526e-01, -2.4800171e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.6742381e-01,  5.2301848e-01,  5.1675737e-01, -1.2771900e+00,\n",
      "       -2.2183526e-01, -2.4800171e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.12859715917156223, next_state=array([ 2.7259120e-01,  4.9368167e-01,  5.1675737e-01, -1.3038566e+00,\n",
      "       -2.2184765e-01, -2.4800614e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.7259120e-01,  4.9368167e-01,  5.1675737e-01, -1.3038566e+00,\n",
      "       -2.2184765e-01, -2.4800614e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=5.015333271500208, next_state=array([ 0.2777852 ,  0.46515185,  0.52022976, -1.2681195 , -0.22269438,\n",
      "       -0.01693419,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2777852 ,  0.46515185,  0.52022976, -1.2681195 , -0.22269438,\n",
      "       -0.01693419,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.35702951451634135, next_state=array([ 0.2829791 ,  0.43602204,  0.5202297 , -1.2947862 , -0.2235411 ,\n",
      "       -0.01693418,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2829791 ,  0.43602204,  0.5202297 , -1.2947862 , -0.2235411 ,\n",
      "       -0.01693418,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1195897591847757, next_state=array([ 0.28825226,  0.40627   ,  0.5301761 , -1.3227509 , -0.22643879,\n",
      "       -0.05795399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28825226,  0.40627   ,  0.5301761 , -1.3227509 , -0.22643879,\n",
      "       -0.05795399,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3787447373927353, next_state=array([ 0.29359666,  0.3758822 ,  0.5391842 , -1.3513049 , -0.23125476,\n",
      "       -0.09631928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29359666,  0.3758822 ,  0.5391842 , -1.3513049 , -0.23125476,\n",
      "       -0.09631928,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8456227999411225, next_state=array([ 0.2991782 ,  0.34586048,  0.5625264 , -1.3349928 , -0.23568445,\n",
      "       -0.08859424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2991782 ,  0.34586048,  0.5625264 , -1.3349928 , -0.23568445,\n",
      "       -0.08859424,  0.        ,  0.        ], dtype=float32), action=2, reward=2.419744870764174, next_state=array([ 0.30500668,  0.316409  ,  0.5869512 , -1.3096168 , -0.2398454 ,\n",
      "       -0.08321905,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30500668,  0.316409  ,  0.5869512 , -1.3096168 , -0.2398454 ,\n",
      "       -0.08321905,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1689734596242545, next_state=array([ 0.31083527,  0.28635773,  0.5869507 , -1.3362849 , -0.24400634,\n",
      "       -0.08321902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31083527,  0.28635773,  0.5869507 , -1.3362849 , -0.24400634,\n",
      "       -0.08321902,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8953294548183794, next_state=array([ 0.3167224 ,  0.25568435,  0.5943207 , -1.3642037 , -0.24971381,\n",
      "       -0.11414931,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3167224 ,  0.25568435,  0.5943207 , -1.3642037 , -0.24971381,\n",
      "       -0.11414931,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.285612153723291, next_state=array([ 0.3226777 ,  0.22438847,  0.6028773 , -1.3921959 , -0.25720537,\n",
      "       -0.14983062,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3226777 ,  0.22438847,  0.6028773 , -1.3921959 , -0.25720537,\n",
      "       -0.14983062,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9832773489283682, next_state=array([ 0.32863313,  0.19249335,  0.6028756 , -1.418867  , -0.26469687,\n",
      "       -0.14983009,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32863313,  0.19249335,  0.6028756 , -1.418867  , -0.26469687,\n",
      "       -0.14983009,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2090329787575627, next_state=array([ 0.3345887 ,  0.15999892,  0.6028738 , -1.4455382 , -0.27218837,\n",
      "       -0.14982949,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3345887 ,  0.15999892,  0.6028738 , -1.4455382 , -0.27218837,\n",
      "       -0.14982949,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1700017715729247, next_state=array([ 0.34063703,  0.12823857,  0.612816  , -1.4130744 , -0.28037146,\n",
      "       -0.16366194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34063703,  0.12823857,  0.612816  , -1.4130744 , -0.28037146,\n",
      "       -0.16366194,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.720822582200752, next_state=array([ 0.34677523,  0.09584936,  0.62405854, -1.4415234 , -0.29090416,\n",
      "       -0.2106541 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34677523,  0.09584936,  0.62405854, -1.4415234 , -0.29090416,\n",
      "       -0.2106541 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.11855707949752, next_state=array([ 0.35298538,  0.06283065,  0.63307613, -1.4699543 , -0.3033578 ,\n",
      "       -0.24907255,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35298538,  0.06283065,  0.63307613, -1.4699543 , -0.3033578 ,\n",
      "       -0.24907255,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.182117582191664, next_state=array([ 0.35911894,  0.02924059,  0.62342244, -1.4950277 , -0.3137864 ,\n",
      "       -0.20857139,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35911894,  0.02924059,  0.62342244, -1.4950277 , -0.3137864 ,\n",
      "       -0.20857139,  0.        ,  0.        ], dtype=float32), action=0, reward=5.994169081793984, next_state=array([ 0.3652528 , -0.00494809,  0.6234183 , -1.521703  , -0.32421488,\n",
      "       -0.20856984,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3652528 , -0.00494809,  0.6234183 , -1.521703  , -0.32421488,\n",
      "       -0.20856984,  1.        ,  0.        ], dtype=float32), action=2, reward=7.933199022267854, next_state=array([ 0.37123194, -0.03751594,  0.5870255 , -1.4448149 , -0.31898513,\n",
      "        0.09677967,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37123194, -0.03751594,  0.5870255 , -1.4448149 , -0.31898513,\n",
      "        0.09677967,  1.        ,  0.        ], dtype=float32), action=3, reward=-100, next_state=array([ 0.3784979 , -0.06349382,  0.55216   , -0.76440495, -0.18436135,\n",
      "        5.2063255 ,  1.        ,  1.        ], dtype=float32), done=True), Experience(state=array([-0.00604143,  1.4118774 , -0.611944  ,  0.04252802,  0.00700727,\n",
      "        0.1386146 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5795245780226412, next_state=array([-0.01215153,  1.4122688 , -0.6196772 ,  0.01732823,  0.01557234,\n",
      "        0.17131777,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01215153,  1.4122688 , -0.6196772 ,  0.01732823,  0.01557234,\n",
      "        0.17131777,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5317009324185744, next_state=array([-0.01816969,  1.4120721 , -0.6081337 , -0.00881981,  0.0218092 ,\n",
      "        0.12474915,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01816969,  1.4120721 , -0.6081337 , -0.00881981,  0.0218092 ,\n",
      "        0.12474915,  0.        ,  0.        ], dtype=float32), action=3, reward=0.33405138222681896, next_state=array([-0.02412071,  1.4112803 , -0.5996853 , -0.03526441,  0.02634765,\n",
      "        0.09077744,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02412071,  1.4112803 , -0.5996853 , -0.03526441,  0.02634765,\n",
      "        0.09077744,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6014060805289876, next_state=array([-0.0301404 ,  1.4098876 , -0.60829604, -0.06202114,  0.03261   ,\n",
      "        0.12525858,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0301404 ,  1.4098876 , -0.60829604, -0.06202114,  0.03261   ,\n",
      "        0.12525858,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7707989627051859, next_state=array([-0.03616028,  1.4078953 , -0.60831577, -0.08869232,  0.03887023,\n",
      "        0.12521599,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03616028,  1.4078953 , -0.60831577, -0.08869232,  0.03887023,\n",
      "        0.12521599,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1040863403244985, next_state=array([-0.04226417,  1.4053011 , -0.6188489 , -0.11554083,  0.04723923,\n",
      "        0.16739546,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04226417,  1.4053011 , -0.6188489 , -0.11554083,  0.04723923,\n",
      "        0.16739546,  0.        ,  0.        ], dtype=float32), action=3, reward=0.26033238342978504, next_state=array([-0.04827661,  1.4021261 , -0.60735166, -0.1413165 ,  0.05328236,\n",
      "        0.12087379,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04827661,  1.4021261 , -0.60735166, -0.1413165 ,  0.05328236,\n",
      "        0.12087379,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9087536593335983, next_state=array([-0.05428924,  1.3983517 , -0.60736793, -0.16798791,  0.059326  ,\n",
      "        0.12088399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05428924,  1.3983517 , -0.60736793, -0.16798791,  0.059326  ,\n",
      "        0.12088399,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9826116774452658, next_state=array([-0.06039944,  1.3950348 , -0.61685526, -0.14766034,  0.06510456,\n",
      "        0.11558191,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06039944,  1.3950348 , -0.61685526, -0.14766034,  0.06510456,\n",
      "        0.11558191,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2969759272690156, next_state=array([-0.0666028 ,  1.391105  , -0.628551  , -0.17502275,  0.07323571,\n",
      "        0.16263834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0666028 ,  1.391105  , -0.628551  , -0.17502275,  0.07323571,\n",
      "        0.16263834,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.067080714595248, next_state=array([-0.0728672 ,  1.3865768 , -0.636168  , -0.20175828,  0.08288396,\n",
      "        0.19298275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0728672 ,  1.3865768 , -0.636168  , -0.20175828,  0.08288396,\n",
      "        0.19298275,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1007797543004643, next_state=array([-0.07924471,  1.3827462 , -0.6472689 , -0.17079782,  0.09233738,\n",
      "        0.18908545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07924471,  1.3827462 , -0.6472689 , -0.17079782,  0.09233738,\n",
      "        0.18908545,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3888911933919688, next_state=array([-0.08569622,  1.378308  , -0.6565386 , -0.19799344,  0.10365255,\n",
      "        0.2263237 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08569622,  1.378308  , -0.6565386 , -0.19799344,  0.10365255,\n",
      "        0.2263237 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.650210138480303, next_state=array([-0.09208775,  1.3732715 , -0.64900565, -0.22456639,  0.11345302,\n",
      "        0.19602716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09208775,  1.3732715 , -0.64900565, -0.22456639,  0.11345302,\n",
      "        0.19602716,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3825374834275124, next_state=array([-0.09847965,  1.367636  , -0.64903116, -0.25124392,  0.12325297,\n",
      "        0.19601688,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09847965,  1.367636  , -0.64903116, -0.25124392,  0.12325297,\n",
      "        0.19601688,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4149631973718613, next_state=array([-0.10487203,  1.3614016 , -0.6490575 , -0.277922  ,  0.13305111,\n",
      "        0.19598025,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10487203,  1.3614016 , -0.6490575 , -0.277922  ,  0.13305111,\n",
      "        0.19598025,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4437061007810996, next_state=array([-0.11126471,  1.3545685 , -0.64908427, -0.3046001 ,  0.14284767,\n",
      "        0.19594917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11126471,  1.3545685 , -0.64908427, -0.3046001 ,  0.14284767,\n",
      "        0.19594917,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7523563599469, next_state=array([-0.11774702,  1.347126  , -0.6602858 , -0.33197847,  0.1548968 ,\n",
      "        0.24100383,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11774702,  1.347126  , -0.6602858 , -0.33197847,  0.1548968 ,\n",
      "        0.24100383,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6596491740186241, next_state=array([-0.12415352,  1.3390975 , -0.6507319 , -0.3578965 ,  0.16500074,\n",
      "        0.20209745,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12415352,  1.3390975 , -0.6507319 , -0.3578965 ,  0.16500074,\n",
      "        0.20209745,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1774191493300803, next_state=array([-0.13083287,  1.3314048 , -0.6772414 , -0.3429613 ,  0.17432661,\n",
      "        0.18653463,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13083287,  1.3314048 , -0.6772414 , -0.3429613 ,  0.17432661,\n",
      "        0.18653463,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.418940257065259, next_state=array([-0.13751268,  1.3231127 , -0.6772631 , -0.3696476 ,  0.18365137,\n",
      "        0.18651229,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13751268,  1.3231127 , -0.6772631 , -0.3696476 ,  0.18365137,\n",
      "        0.18651229,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.06897057025206549, next_state=array([-0.14431639,  1.3156269 , -0.68987215, -0.33390522,  0.19320396,\n",
      "        0.19106922,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14431639,  1.3156269 , -0.68987215, -0.33390522,  0.19320396,\n",
      "        0.19106922,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5510706288040865, next_state=array([-0.15136023,  1.3088065 , -0.713529  , -0.30433422,  0.20241341,\n",
      "        0.18420538,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15136023,  1.3088065 , -0.713529  , -0.30433422,  0.20241341,\n",
      "        0.18420538,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4352619205778001, next_state=array([-0.15833941,  1.301404  , -0.70537835, -0.33003995,  0.20994419,\n",
      "        0.1506294 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15833941,  1.301404  , -0.70537835, -0.33003995,  0.20994419,\n",
      "        0.1506294 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.588007337501891, next_state=array([-0.16540556,  1.2933459 , -0.71640617, -0.3595635 ,  0.21984114,\n",
      "        0.19793871,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16540556,  1.2933459 , -0.71640617, -0.3595635 ,  0.21984114,\n",
      "        0.19793871,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.12438920521583327, next_state=array([-0.1723773 ,  1.284715  , -0.70452845, -0.38470966,  0.22729124,\n",
      "        0.14900205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1723773 ,  1.284715  , -0.70452845, -0.38470966,  0.22729124,\n",
      "        0.14900205,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.509899826835908, next_state=array([-0.17964907,  1.2762185 , -0.73369694, -0.3786433 ,  0.23389849,\n",
      "        0.13214488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17964907,  1.2762185 , -0.73369694, -0.3786433 ,  0.23389849,\n",
      "        0.13214488,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.347508783562857, next_state=array([-0.18700275,  1.2670927 , -0.7439953 , -0.40698847,  0.24265891,\n",
      "        0.1752083 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18700275,  1.2670927 , -0.7439953 , -0.40698847,  0.24265891,\n",
      "        0.1752083 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3359865732016658, next_state=array([-0.19435653,  1.2573678 , -0.743993  , -0.43366137,  0.25141928,\n",
      "        0.17520745,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19435653,  1.2573678 , -0.743993  , -0.43366137,  0.25141928,\n",
      "        0.17520745,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4360962618290205, next_state=array([-0.20164394,  1.2470621 , -0.7356471 , -0.4592294 ,  0.25845748,\n",
      "        0.14076446,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20164394,  1.2470621 , -0.7356471 , -0.4592294 ,  0.25845748,\n",
      "        0.14076446,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6335572200174113, next_state=array([-0.20921397,  1.2371219 , -0.76340073, -0.4429296 ,  0.26499218,\n",
      "        0.13069397,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20921397,  1.2371219 , -0.76340073, -0.4429296 ,  0.26499218,\n",
      "        0.13069397,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1119157522216199, next_state=array([-0.21678415,  1.2265822 , -0.7633994 , -0.46959972,  0.27152684,\n",
      "        0.13069318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21678415,  1.2265822 , -0.7633994 , -0.46959972,  0.27152684,\n",
      "        0.13069318,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.30173230326872047, next_state=array([-0.22429737,  1.2154727 , -0.756183  , -0.49466294,  0.27650654,\n",
      "        0.09959401,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22429737,  1.2154727 , -0.756183  , -0.49466294,  0.27650654,\n",
      "        0.09959401,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9735082235091852, next_state=array([-0.23181072,  1.2037635 , -0.75618213, -0.5213316 ,  0.28148624,\n",
      "        0.09959378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23181072,  1.2037635 , -0.75618213, -0.5213316 ,  0.28148624,\n",
      "        0.09959378,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9312718547273835, next_state=array([-0.23938636,  1.1914182 , -0.7640938 , -0.54995847,  0.28819394,\n",
      "        0.13415407,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23938636,  1.1914182 , -0.7640938 , -0.54995847,  0.28819394,\n",
      "        0.13415407,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8015866277243162, next_state=array([-0.2470632 ,  1.1797609 , -0.77485037, -0.51953673,  0.2955815 ,\n",
      "        0.14775091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2470632 ,  1.1797609 , -0.77485037, -0.51953673,  0.2955815 ,\n",
      "        0.14775091,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.028049986793262177, next_state=array([-0.25465614,  1.1675425 , -0.7642517 , -0.5440586 ,  0.30070233,\n",
      "        0.10241719,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25465614,  1.1675425 , -0.7642517 , -0.5440586 ,  0.30070233,\n",
      "        0.10241719,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.051421244733744514, next_state=array([-0.26218423,  1.1547663 , -0.75599027, -0.56848794,  0.30399227,\n",
      "        0.0657979 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26218423,  1.1547663 , -0.75599027, -0.56848794,  0.30399227,\n",
      "        0.0657979 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.837744678617496, next_state=array([-0.26977816,  1.1413472 , -0.76437193, -0.5974643 ,  0.30914524,\n",
      "        0.10305985,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26977816,  1.1413472 , -0.76437193, -0.5974643 ,  0.30914524,\n",
      "        0.10305985,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9951630121722417, next_state=array([-0.27737218,  1.127328  , -0.7643709 , -0.62413305,  0.3142982 ,\n",
      "        0.10305963,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27737218,  1.127328  , -0.7643709 , -0.62413305,  0.3142982 ,\n",
      "        0.10305963,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0800207450361357, next_state=array([-0.28504324,  1.1126784 , -0.774041  , -0.6526205 ,  0.32150537,\n",
      "        0.14414321,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28504324,  1.1126784 , -0.774041  , -0.6526205 ,  0.32150537,\n",
      "        0.14414321,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2640674286109277, next_state=array([-0.29264417,  1.0974542 , -0.7652384 , -0.6777818 ,  0.32686043,\n",
      "        0.1071011 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29264417,  1.0974542 , -0.7652384 , -0.6777818 ,  0.32686043,\n",
      "        0.1071011 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9955155793103359, next_state=array([-0.30024523,  1.0816303 , -0.7652373 , -0.7044507 ,  0.33221546,\n",
      "        0.10710087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30024523,  1.0816303 , -0.7652373 , -0.7044507 ,  0.33221546,\n",
      "        0.10710087,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1058091036979634, next_state=array([-0.30792636,  1.0651705 , -0.7753023 , -0.7332138 ,  0.3397341 ,\n",
      "        0.15037239,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30792636,  1.0651705 , -0.7753023 , -0.7332138 ,  0.3397341 ,\n",
      "        0.15037239,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1828168539277044, next_state=array([-0.31560764,  1.0481116 , -0.77529985, -0.75988495,  0.3472527 ,\n",
      "        0.15037182,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31560764,  1.0481116 , -0.77529985, -0.75988495,  0.3472527 ,\n",
      "        0.15037182,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3233072874377556, next_state=array([-0.3233663 ,  1.0303993 , -0.78513503, -0.789486  ,  0.35700086,\n",
      "        0.19496313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3233663 ,  1.0303993 , -0.78513503, -0.789486  ,  0.35700086,\n",
      "        0.19496313,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4760867322680429, next_state=array([-0.33105746,  1.0121247 , -0.77657205, -0.8140864 ,  0.36486924,\n",
      "        0.15736745,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33105746,  1.0121247 , -0.77657205, -0.8140864 ,  0.36486924,\n",
      "        0.15736745,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.112528063580014, next_state=array([-0.33881202,  0.9932083 , -0.7846068 , -0.8430938 ,  0.37455633,\n",
      "        0.19374213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33881202,  0.9932083 , -0.7846068 , -0.8430938 ,  0.37455633,\n",
      "        0.19374213,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.562563624064494, next_state=array([-0.34665447,  0.9736456 , -0.7956435 , -0.87248737,  0.38667703,\n",
      "        0.24241368,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34665447,  0.9736456 , -0.7956435 , -0.87248737,  0.38667703,\n",
      "        0.24241368,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.39279139037793587, next_state=array([-0.35440642,  0.9535307 , -0.7841958 , -0.8964747 ,  0.39629245,\n",
      "        0.19230844,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35440642,  0.9535307 , -0.7841958 , -0.8964747 ,  0.39629245,\n",
      "        0.19230844,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5515301577967464, next_state=array([-0.36225   ,  0.93277115, -0.7956702 , -0.9258435 ,  0.4084212 ,\n",
      "        0.24257407,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36225   ,  0.93277115, -0.7956702 , -0.9258435 ,  0.4084212 ,\n",
      "        0.24257407,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4688773532726486, next_state=array([-0.37044063,  0.91254133, -0.8302318 , -0.90237415,  0.4204591 ,\n",
      "        0.24075826,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37044063,  0.91254133, -0.8302318 , -0.90237415,  0.4204591 ,\n",
      "        0.24075826,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0287706203931635, next_state=array([-0.37899512,  0.89276004, -0.866362  , -0.8824589 ,  0.43227947,\n",
      "        0.23640807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37899512,  0.89276004, -0.866362  , -0.8824589 ,  0.43227947,\n",
      "        0.23640807,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6116005102493205, next_state=array([-0.38781995,  0.87306875, -0.8931042 , -0.87847996,  0.44385538,\n",
      "        0.23151812,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38781995,  0.87306875, -0.8931042 , -0.87847996,  0.44385538,\n",
      "        0.23151812,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.692682415609879, next_state=array([-0.39672422,  0.85273546, -0.90300703, -0.9077524 ,  0.45764422,\n",
      "        0.27577683,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39672422,  0.85273546, -0.90300703, -0.9077524 ,  0.45764422,\n",
      "        0.27577683,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9813744203014767, next_state=array([-0.4055739 ,  0.8318466 , -0.8959559 , -0.93204844,  0.46976987,\n",
      "        0.2425127 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4055739 ,  0.8318466 , -0.8959559 , -0.93204844,  0.46976987,\n",
      "        0.2425127 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8698634965660108, next_state=array([-0.41437393,  0.8104055 , -0.88950855, -0.9561867 ,  0.480311  ,\n",
      "        0.21082303,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41437393,  0.8104055 , -0.88950855, -0.9561867 ,  0.480311  ,\n",
      "        0.21082303,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5083317161147805, next_state=array([-0.4232436 ,  0.7883164 , -0.898246  , -0.98571384,  0.49290273,\n",
      "        0.25183433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4232436 ,  0.7883164 , -0.898246  , -0.98571384,  0.49290273,\n",
      "        0.25183433,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.43455785217403675, next_state=array([-0.4320323 ,  0.7657067 , -0.8877411 , -1.008076  ,  0.5028707 ,\n",
      "        0.19935918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4320323 ,  0.7657067 , -0.8877411 , -1.008076  ,  0.5028707 ,\n",
      "        0.19935918,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4412757074283036, next_state=array([-0.44082147,  0.7424984 , -0.8877352 , -1.0347499 ,  0.5128386 ,\n",
      "        0.19935796,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44082147,  0.7424984 , -0.8877352 , -1.0347499 ,  0.5128386 ,\n",
      "        0.19935796,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4562726073944532, next_state=array([-0.449611  ,  0.7186913 , -0.88772917, -1.0614238 ,  0.52280647,\n",
      "        0.19935663,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.449611  ,  0.7186913 , -0.88772917, -1.0614238 ,  0.52280647,\n",
      "        0.19935663,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.467505973977086, next_state=array([-0.45896688,  0.6954924 , -0.94395685, -1.0343015 ,  0.5323641 ,\n",
      "        0.19115198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45896688,  0.6954924 , -0.94395685, -1.0343015 ,  0.5323641 ,\n",
      "        0.19115198,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4927142914239084, next_state=array([-0.46832317,  0.6716945 , -0.943951  , -1.0609748 ,  0.5419216 ,\n",
      "        0.19115098,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46832317,  0.6716945 , -0.943951  , -1.0609748 ,  0.5419216 ,\n",
      "        0.19115098,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5220251309062292, next_state=array([-0.47767997,  0.64729786, -0.9439451 , -1.0876482 ,  0.5514791 ,\n",
      "        0.19114996,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47767997,  0.64729786, -0.9439451 , -1.0876482 ,  0.5514791 ,\n",
      "        0.19114996,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4803092075385096, next_state=array([-0.48709482,  0.6222489 , -0.95131046, -1.1173595 ,  0.56289524,\n",
      "        0.22832301,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48709482,  0.6222489 , -0.95131046, -1.1173595 ,  0.56289524,\n",
      "        0.22832301,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2284308879553008, next_state=array([-0.49678016,  0.59707445, -0.9780458 , -1.1229126 ,  0.57403374,\n",
      "        0.22276998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49678016,  0.59707445, -0.9780458 , -1.1229126 ,  0.57403374,\n",
      "        0.22276998,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.810761215532466, next_state=array([-0.50646603,  0.5713014 , -0.97803736, -1.1495879 ,  0.5851721 ,\n",
      "        0.22276807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.50646603,  0.5713014 , -0.97803736, -1.1495879 ,  0.5851721 ,\n",
      "        0.22276807,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0383401422803034, next_state=array([-0.5162221 ,  0.5448532 , -0.9869915 , -1.180571  ,  0.5987057 ,\n",
      "        0.27067235,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5162221 ,  0.5448532 , -0.9869915 , -1.180571  ,  0.5987057 ,\n",
      "        0.27067235,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9393486743701078, next_state=array([-0.5258962 ,  0.517879  , -0.97651035, -1.2030336 ,  0.6096102 ,\n",
      "        0.21808942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5258962 ,  0.517879  , -0.97651035, -1.2030336 ,  0.6096102 ,\n",
      "        0.21808942,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7630477126944288, next_state=array([-0.535498  ,  0.4903947 , -0.9670351 , -1.2247376 ,  0.6178848 ,\n",
      "        0.16549243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.535498  ,  0.4903947 , -0.9670351 , -1.2247376 ,  0.6178848 ,\n",
      "        0.16549243,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0559067915027345, next_state=array([-0.5450546 ,  0.46236572, -0.9611303 , -1.2483438 ,  0.6245254 ,\n",
      "        0.13281243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5450546 ,  0.46236572, -0.9611303 , -1.2483438 ,  0.6245254 ,\n",
      "        0.13281243,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6739615069602951, next_state=array([-0.55454475,  0.4338092 , -0.95257294, -1.2708948 ,  0.6288667 ,\n",
      "        0.0868253 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.55454475,  0.4338092 , -0.95257294, -1.2708948 ,  0.6288667 ,\n",
      "        0.0868253 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.404282200999478, next_state=array([-0.56463397,  0.405864  , -1.0124342 , -1.2437227 ,  0.633163  ,\n",
      "        0.0859257 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.56463397,  0.405864  , -1.0124342 , -1.2437227 ,  0.633163  ,\n",
      "        0.0859257 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0318171345037286, next_state=array([-0.5751805 ,  0.378522  , -1.0585556 , -1.2171216 ,  0.63794833,\n",
      "        0.09570669,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5751805 ,  0.378522  , -1.0585556 , -1.2171216 ,  0.63794833,\n",
      "        0.09570669,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9315029257835747, next_state=array([-0.58578265,  0.35050642, -1.0658023 , -1.2479118 ,  0.64482737,\n",
      "        0.13758056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.58578265,  0.35050642, -1.0658023 , -1.2479118 ,  0.64482737,\n",
      "        0.13758056,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.231685607142879, next_state=array([-0.59638506,  0.32189134, -1.065799  , -1.2745817 ,  0.6517064 ,\n",
      "        0.13758013,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.59638506,  0.32189134, -1.065799  , -1.2745817 ,  0.6517064 ,\n",
      "        0.13758013,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.357935130145279, next_state=array([-0.6069877 ,  0.29267687, -1.0657954 , -1.3012515 ,  0.65858537,\n",
      "        0.1375797 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6069877 ,  0.29267687, -1.0657954 , -1.3012515 ,  0.65858537,\n",
      "        0.1375797 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.493237259701573, next_state=array([-0.61759067,  0.2628628 , -1.0657918 , -1.3279213 ,  0.66546434,\n",
      "        0.13757916,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.61759067,  0.2628628 , -1.0657918 , -1.3279213 ,  0.66546434,\n",
      "        0.13757916,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4497799772404096, next_state=array([-0.6281165 ,  0.23252536, -1.0560057 , -1.3501292 ,  0.6697622 ,\n",
      "        0.08595679,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6281165 ,  0.23252536, -1.0560057 , -1.3501292 ,  0.6697622 ,\n",
      "        0.08595679,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.4940358639818667, next_state=array([-0.6390793 ,  0.20216647, -1.0993063 , -1.3508899 ,  0.67358273,\n",
      "        0.07641049,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6390793 ,  0.20216647, -1.0993063 , -1.3508899 ,  0.67358273,\n",
      "        0.07641049,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5318425016509125, next_state=array([-0.65009063,  0.17114583, -1.1055907 , -1.3810765 ,  0.6792162 ,\n",
      "        0.11266991,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.65009063,  0.17114583, -1.1055907 , -1.3810765 ,  0.6792162 ,\n",
      "        0.11266991,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9952619081327043, next_state=array([-0.6611022 ,  0.13952552, -1.1055882 , -1.4077452 ,  0.6848497 ,\n",
      "        0.11266921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6611022 ,  0.13952552, -1.1055882 , -1.4077452 ,  0.6848497 ,\n",
      "        0.11266921,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0566168729021954, next_state=array([-0.6720423 ,  0.10737799, -1.0965298 , -1.4301566 ,  0.6880619 ,\n",
      "        0.06424418,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6720423 ,  0.10737799, -1.0965298 , -1.4301566 ,  0.6880619 ,\n",
      "        0.06424418,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0928022035499794, next_state=array([-0.6829825 ,  0.07463051, -1.0965291 , -1.4568238 ,  0.6912741 ,\n",
      "        0.0642445 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6829825 ,  0.07463051, -1.0965291 , -1.4568238 ,  0.6912741 ,\n",
      "        0.0642445 ,  0.        ,  0.        ], dtype=float32), action=2, reward=6.8278321770057575, next_state=array([-0.6942705 ,  0.04200991, -1.1314466 , -1.4512724 ,  0.6946754 ,\n",
      "        0.0680254 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.6942705 ,  0.04200991, -1.1314466 , -1.4512724 ,  0.6946754 ,\n",
      "        0.0680254 ,  0.        ,  1.        ], dtype=float32), action=2, reward=100.84575359804991, next_state=array([-0.69996357,  0.03862382, -0.670282  , -0.26155064,  0.79843247,\n",
      "        1.9633732 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.69996357,  0.03862382, -0.670282  , -0.26155064,  0.79843247,\n",
      "        1.9633732 ,  0.        ,  1.        ], dtype=float32), action=3, reward=-1.995734807864095, next_state=array([-0.70481205,  0.04270478, -0.5841254 ,  0.07511757,  0.94358253,\n",
      "        2.8417773 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.70481205,  0.04270478, -0.5841254 ,  0.07511757,  0.94358253,\n",
      "        2.8417773 ,  0.        ,  1.        ], dtype=float32), action=1, reward=-15.026084070637237, next_state=array([-0.70990825,  0.04558698, -0.5877941 ,  0.0413071 ,  1.0879694 ,\n",
      "        2.878653  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.70990825,  0.04558698, -0.5877941 ,  0.0413071 ,  1.0879694 ,\n",
      "        2.878653  ,  0.        ,  1.        ], dtype=float32), action=0, reward=-14.584525377400155, next_state=array([-0.7151779 ,  0.04791027, -0.58601415,  0.01484603,  1.2314458 ,\n",
      "        2.8697145 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.7151779 ,  0.04791027, -0.58601415,  0.01484603,  1.2314458 ,\n",
      "        2.8697145 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-24.640118670859067, next_state=array([-0.72062016,  0.04971686, -0.5836611 , -0.01268802,  1.3746979 ,\n",
      "        2.8652253 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.72062016,  0.04971686, -0.5836611 , -0.01268802,  1.3746979 ,\n",
      "        2.8652253 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-18.812119758155962, next_state=array([-0.72661793,  0.05097242, -0.618879  , -0.03961056,  1.5174023 ,\n",
      "        2.854264  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.72661793,  0.05097242, -0.618879  , -0.03961056,  1.5174023 ,\n",
      "        2.854264  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-15.254665651827535, next_state=array([-0.7327978 ,  0.05152732, -0.6162762 , -0.07356978,  1.6629387 ,\n",
      "        2.9111447 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7327978 ,  0.05152732, -0.6162762 , -0.07356978,  1.6629387 ,\n",
      "        2.9111447 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-15.259274529123047, next_state=array([-0.7391611 ,  0.05145057, -0.61354995, -0.10022417,  1.8081591 ,\n",
      "        2.9069462 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7391611 ,  0.05145057, -0.61354995, -0.10022417,  1.8081591 ,\n",
      "        2.9069462 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-15.212965977209107, next_state=array([-0.745716  ,  0.0508195 , -0.61296856, -0.1198718 ,  1.950595  ,\n",
      "        2.8514268 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.745716  ,  0.0508195 , -0.61296856, -0.1198718 ,  1.950595  ,\n",
      "        2.8514268 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-15.301784657411444, next_state=array([-0.7524183 ,  0.04938663, -0.6076082 , -0.1517138 ,  2.0950382 ,\n",
      "        2.8916585 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7524183 ,  0.04938663, -0.6076082 , -0.1517138 ,  2.0950382 ,\n",
      "        2.8916585 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-15.42072108347716, next_state=array([-0.75923055,  0.04709252, -0.5985953 , -0.18448512,  2.2421763 ,\n",
      "        2.9456902 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.75923055,  0.04709252, -0.5985953 , -0.18448512,  2.2421763 ,\n",
      "        2.9456902 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-15.950932508766982, next_state=array([-0.7661907 ,  0.04401835, -0.5962716 , -0.21010332,  2.3890955 ,\n",
      "        2.9413238 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7661907 ,  0.04401835, -0.5962716 , -0.21010332,  2.3890955 ,\n",
      "        2.9413238 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-19.380520817008392, next_state=array([-0.7734958 ,  0.0395274 , -0.61632144, -0.26225024,  2.5352583 ,\n",
      "        2.9261644 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7734958 ,  0.0395274 , -0.61632144, -0.26225024,  2.5352583 ,\n",
      "        2.9261644 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-23.538689887051635, next_state=array([-0.7814605 ,  0.03316456, -0.6697508 , -0.3337172 ,  2.681496  ,\n",
      "        2.9276624 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7814605 ,  0.03316456, -0.6697508 , -0.3337172 ,  2.681496  ,\n",
      "        2.9276624 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-16.40608510132023, next_state=array([-0.789507  ,  0.02594713, -0.6683349 , -0.35879484,  2.8275197 ,\n",
      "        2.9233747 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.789507  ,  0.02594713, -0.6683349 , -0.35879484,  2.8275197 ,\n",
      "        2.9233747 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-16.489669491029417, next_state=array([-0.79760927,  0.0178613 , -0.66728437, -0.38375697,  2.9733303 ,\n",
      "        2.919106  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.79760927,  0.0178613 , -0.66728437, -0.38375697,  2.9733303 ,\n",
      "        2.919106  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([-0.80376434,  0.0140545 , -0.44502813,  0.03759492,  3.0380335 ,\n",
      "       -0.17023906,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00234833,  1.4049017 , -0.23788302, -0.26748213,  0.00272798,\n",
      "        0.05388393,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6314722063579541, next_state=array([-0.004603  ,  1.3982984 , -0.22576725, -0.29348305,  0.00302557,\n",
      "        0.0059533 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.004603  ,  1.3982984 , -0.22576725, -0.29348305,  0.00302557,\n",
      "        0.0059533 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2382632353485676, next_state=array([-0.00692987,  1.3910838 , -0.23483276, -0.32065058,  0.00514156,\n",
      "        0.04232392,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00692987,  1.3910838 , -0.23483276, -0.32065058,  0.00514156,\n",
      "        0.04232392,  0.        ,  0.        ], dtype=float32), action=2, reward=0.797920192611042, next_state=array([-0.00940971,  1.3842837 , -0.24940488, -0.3022369 ,  0.00653924,\n",
      "        0.0279564 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00940971,  1.3842837 , -0.24940488, -0.3022369 ,  0.00653924,\n",
      "        0.0279564 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4944666464655825, next_state=array([-0.01188965,  1.3768831 , -0.24940856, -0.32891366,  0.00793771,\n",
      "        0.02797188,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01188965,  1.3768831 , -0.24940856, -0.32891366,  0.00793771,\n",
      "        0.02797188,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2004427670617985, next_state=array([-0.01434193,  1.3697041 , -0.24679899, -0.31907222,  0.00948863,\n",
      "        0.0310214 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01434193,  1.3697041 , -0.24679899, -0.31907222,  0.00948863,\n",
      "        0.0310214 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3176142118073515, next_state=array([-0.01686945,  1.361919  , -0.2562281 , -0.3460344 ,  0.01292978,\n",
      "        0.0688296 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01686945,  1.361919  , -0.2562281 , -0.3460344 ,  0.01292978,\n",
      "        0.0688296 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.8715687551851206, next_state=array([-0.01932335,  1.3548217 , -0.24928054, -0.31547648,  0.01677321,\n",
      "        0.07687557,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01932335,  1.3548217 , -0.24928054, -0.31547648,  0.01677321,\n",
      "        0.07687557,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.569075567153361, next_state=array([-0.02185697,  1.347125  , -0.2592644 , -0.3421492 ,  0.02261516,\n",
      "        0.11684953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02185697,  1.347125  , -0.2592644 , -0.3421492 ,  0.02261516,\n",
      "        0.11684953,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.22398694646776, next_state=array([-0.02431526,  1.338826  , -0.2498137 , -0.36891016,  0.02655873,\n",
      "        0.07887857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02431526,  1.338826  , -0.2498137 , -0.36891016,  0.02655873,\n",
      "        0.07887857,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9806705018478101, next_state=array([-0.02668667,  1.329926  , -0.2389231 , -0.39558145,  0.02831839,\n",
      "        0.03519643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02668667,  1.329926  , -0.2389231 , -0.39558145,  0.02831839,\n",
      "        0.03519643,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0401470914304685, next_state=array([-0.02899895,  1.3204292 , -0.23150635, -0.42209232,  0.02858969,\n",
      "        0.00542681,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02899895,  1.3204292 , -0.23150635, -0.42209232,  0.02858969,\n",
      "        0.00542681,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9345627439704163, next_state=array([-0.03137264,  1.310329  , -0.23919702, -0.44893926,  0.03040382,\n",
      "        0.03628565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03137264,  1.310329  , -0.23919702, -0.44893926,  0.03040382,\n",
      "        0.03628565,  0.        ,  0.        ], dtype=float32), action=2, reward=1.744007707947543, next_state=array([-0.03369589,  1.3004987 , -0.23448507, -0.43693867,  0.03253753,\n",
      "        0.04267799,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03369589,  1.3004987 , -0.23448507, -0.43693867,  0.03253753,\n",
      "        0.04267799,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1730338522294916, next_state=array([-0.03622169,  1.2913632 , -0.25390926, -0.40605232,  0.03384963,\n",
      "        0.02624485,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03622169,  1.2913632 , -0.25390926, -0.40605232,  0.03384963,\n",
      "        0.02624485,  0.        ,  0.        ], dtype=float32), action=2, reward=2.504061525447111, next_state=array([-0.03868265,  1.2827061 , -0.24785468, -0.38479745,  0.03558132,\n",
      "        0.03463707,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03868265,  1.2827061 , -0.24785468, -0.38479745,  0.03558132,\n",
      "        0.03463707,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5198249287771262, next_state=array([-0.0411437 ,  1.2734491 , -0.24785984, -0.41146994,  0.03731205,\n",
      "        0.03461789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0411437 ,  1.2734491 , -0.24785984, -0.41146994,  0.03731205,\n",
      "        0.03461789,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2218356576678375, next_state=array([-0.04367733,  1.2635779 , -0.25694385, -0.43880442,  0.04087021,\n",
      "        0.07116955,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04367733,  1.2635779 , -0.25694385, -0.43880442,  0.04087021,\n",
      "        0.07116955,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3968198488491168, next_state=array([-0.04626513,  1.2540674 , -0.26223823, -0.4227914 ,  0.04429599,\n",
      "        0.06852138,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04626513,  1.2540674 , -0.26223823, -0.4227914 ,  0.04429599,\n",
      "        0.06852138,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.29189292145213, next_state=array([-0.0489253 ,  1.2439609 , -0.2712989 , -0.44934776,  0.04953148,\n",
      "        0.1047193 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0489253 ,  1.2439609 , -0.2712989 , -0.44934776,  0.04953148,\n",
      "        0.1047193 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3617358441286003, next_state=array([-0.05152626,  1.234658  , -0.26588255, -0.41366407,  0.05525738,\n",
      "        0.1145284 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05152626,  1.234658  , -0.26588255, -0.41366407,  0.05525738,\n",
      "        0.1145284 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0898069906487649, next_state=array([-0.0540061 ,  1.2254936 , -0.25446174, -0.4075654 ,  0.06167311,\n",
      "        0.1283262 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0540061 ,  1.2254936 , -0.25446174, -0.4075654 ,  0.06167311,\n",
      "        0.1283262 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.17706444937585958, next_state=array([-0.05656347,  1.2164938 , -0.26200157, -0.40025598,  0.06787427,\n",
      "        0.12403417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05656347,  1.2164938 , -0.26200157, -0.40025598,  0.06787427,\n",
      "        0.12403417,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9275294290539193, next_state=array([-0.05912113,  1.2068945 , -0.2620181 , -0.4269317 ,  0.07407501,\n",
      "        0.12402599,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05912113,  1.2068945 , -0.2620181 , -0.4269317 ,  0.07407501,\n",
      "        0.12402599,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9067933549661404, next_state=array([-0.06167898,  1.1966958 , -0.26203552, -0.45360237,  0.08027473,\n",
      "        0.12400564,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06167898,  1.1966958 , -0.26203552, -0.45360237,  0.08027473,\n",
      "        0.12400564,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6649873878501453, next_state=array([-0.06430664,  1.1858611 , -0.2708438 , -0.4819945 ,  0.08827549,\n",
      "        0.16001523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06430664,  1.1858611 , -0.2708438 , -0.4819945 ,  0.08827549,\n",
      "        0.16001523,  0.        ,  0.        ], dtype=float32), action=2, reward=0.38367336482882025, next_state=array([-0.0671401 ,  1.1753925 , -0.29072937, -0.46572742,  0.09559017,\n",
      "        0.14629364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0671401 ,  1.1753925 , -0.29072937, -0.46572742,  0.09559017,\n",
      "        0.14629364,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3786017509800945, next_state=array([-0.06991339,  1.1643327 , -0.28316078, -0.49192247,  0.10137898,\n",
      "        0.11577606,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06991339,  1.1643327 , -0.28316078, -0.49192247,  0.10137898,\n",
      "        0.11577606,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.612112720819623, next_state=array([-0.07277928,  1.1526706 , -0.29476294, -0.51889384,  0.10949088,\n",
      "        0.16223806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07277928,  1.1526706 , -0.29476294, -0.51889384,  0.10949088,\n",
      "        0.16223806,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1037286959484733, next_state=array([-0.07578621,  1.141755  , -0.30865553, -0.48574665,  0.11740801,\n",
      "        0.15834281,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07578621,  1.141755  , -0.30865553, -0.48574665,  0.11740801,\n",
      "        0.15834281,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.8590458101317027, next_state=array([-0.07888345,  1.1302245 , -0.31999955, -0.51331073,  0.12762097,\n",
      "        0.20425901,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07888345,  1.1302245 , -0.31999955, -0.51331073,  0.12762097,\n",
      "        0.20425901,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4294394703657918, next_state=array([-0.08190651,  1.1181058 , -0.3106677 , -0.53934896,  0.13594991,\n",
      "        0.16657878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08190651,  1.1181058 , -0.3106677 , -0.53934896,  0.13594991,\n",
      "        0.16657878,  0.        ,  0.        ], dtype=float32), action=2, reward=1.517091938959777, next_state=array([-0.08510399,  1.1066167 , -0.32781297, -0.51137716,  0.14399315,\n",
      "        0.16086476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08510399,  1.1066167 , -0.32781297, -0.51137716,  0.14399315,\n",
      "        0.16086476,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8861871006288595, next_state=array([-0.08830156,  1.0945287 , -0.32781184, -0.5380491 ,  0.15203635,\n",
      "        0.16086386,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08830156,  1.0945287 , -0.32781184, -0.5380491 ,  0.15203635,\n",
      "        0.16086386,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6837790968296076, next_state=array([-0.09157248,  1.0827167 , -0.33521482, -0.525833  ,  0.16015287,\n",
      "        0.16233023,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09157248,  1.0827167 , -0.33521482, -0.525833  ,  0.16015287,\n",
      "        0.16233023,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8682746801939345, next_state=array([-0.09484348,  1.0703053 , -0.33521357, -0.5525051 ,  0.16826935,\n",
      "        0.16232947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09484348,  1.0703053 , -0.33521357, -0.5525051 ,  0.16826935,\n",
      "        0.16232947,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8314785238238074, next_state=array([-0.09823332,  1.0578005 , -0.346806  , -0.55667764,  0.17610526,\n",
      "        0.15671805,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09823332,  1.0578005 , -0.346806  , -0.55667764,  0.17610526,\n",
      "        0.15671805,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9953543256989394, next_state=array([-0.10154428,  1.0447214 , -0.336855  , -0.58198994,  0.18188934,\n",
      "        0.11568116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10154428,  1.0447214 , -0.336855  , -0.58198994,  0.18188934,\n",
      "        0.11568116,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.438323528308841, next_state=array([-0.10494242,  1.0310282 , -0.3477832 , -0.60958725,  0.18988927,\n",
      "        0.15999824,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10494242,  1.0310282 , -0.3477832 , -0.60958725,  0.18988927,\n",
      "        0.15999824,  0.        ,  0.        ], dtype=float32), action=2, reward=0.17495290241747058, next_state=array([-0.10846777,  1.0174876 , -0.3603416 , -0.60282236,  0.19774982,\n",
      "        0.15721078,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10846777,  1.0174876 , -0.3603416 , -0.60282236,  0.19774982,\n",
      "        0.15721078,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6451618767966907, next_state=array([-0.11207724,  1.0033171 , -0.37093306, -0.6311649 ,  0.20781451,\n",
      "        0.20129386,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11207724,  1.0033171 , -0.37093306, -0.6311649 ,  0.20781451,\n",
      "        0.20129386,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.89185235775426, next_state=array([-0.11568689,  0.9885481 , -0.3709305 , -0.6578399 ,  0.21787915,\n",
      "        0.20129251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11568689,  0.9885481 , -0.3709305 , -0.6578399 ,  0.21787915,\n",
      "        0.20129251,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8579812550642885, next_state=array([-0.11929674,  0.97318023, -0.37092778, -0.6845148 ,  0.2279437 ,\n",
      "        0.20129108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11929674,  0.97318023, -0.37092778, -0.6845148 ,  0.2279437 ,\n",
      "        0.20129108,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0704485261496746, next_state=array([-0.12282391,  0.9572309 , -0.36055794, -0.7101023 ,  0.23589309,\n",
      "        0.15898833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12282391,  0.9572309 , -0.36055794, -0.7101023 ,  0.23589309,\n",
      "        0.15898833,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.494372412363758, next_state=array([-0.12644215,  0.9406567 , -0.37196082, -0.7382918 ,  0.24619707,\n",
      "        0.20607968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12644215,  0.9406567 , -0.37196082, -0.7382918 ,  0.24619707,\n",
      "        0.20607968,  0.        ,  0.        ], dtype=float32), action=2, reward=0.07958499777150224, next_state=array([-0.13011113,  0.9241061 , -0.37724543, -0.7373531 ,  0.25674188,\n",
      "        0.21089604,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13011113,  0.9241061 , -0.37724543, -0.7373531 ,  0.25674188,\n",
      "        0.21089604,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4345333012465447, next_state=array([-0.13383655,  0.9069268 , -0.38434893, -0.7656381 ,  0.2688178 ,\n",
      "        0.24151878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13383655,  0.9069268 , -0.38434893, -0.7656381 ,  0.2688178 ,\n",
      "        0.24151878,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8976790159909456, next_state=array([-0.13756219,  0.8891493 , -0.3843442 , -0.7923166 ,  0.28089365,\n",
      "        0.24151635,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13756219,  0.8891493 , -0.3843442 , -0.7923166 ,  0.28089365,\n",
      "        0.24151635,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.79084144054073, next_state=array([-0.14137192,  0.87072873, -0.3949371 , -0.8214422 ,  0.2952651 ,\n",
      "        0.28742853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14137192,  0.87072873, -0.3949371 , -0.8214422 ,  0.2952651 ,\n",
      "        0.28742853,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0352843760587973, next_state=array([-0.14518222,  0.8517107 , -0.3949297 , -0.84812534,  0.3096363 ,\n",
      "        0.28742445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14518222,  0.8517107 , -0.3949297 , -0.84812534,  0.3096363 ,\n",
      "        0.28742445,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6764321815224263, next_state=array([-0.14906463,  0.8332154 , -0.40279585, -0.8251865 ,  0.32474384,\n",
      "        0.30215067,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14906463,  0.8332154 , -0.40279585, -0.8251865 ,  0.32474384,\n",
      "        0.30215067,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1077677784505227, next_state=array([-0.15294771,  0.8141231 , -0.40278688, -0.8518713 ,  0.33985114,\n",
      "        0.3021459 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15294771,  0.8141231 , -0.40278688, -0.8518713 ,  0.33985114,\n",
      "        0.3021459 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3765594811911785, next_state=array([-0.1567626 ,  0.79446733, -0.39408475, -0.8766127 ,  0.3530722 ,\n",
      "        0.26442152,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1567626 ,  0.79446733, -0.39408475, -0.8766127 ,  0.3530722 ,\n",
      "        0.26442152,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2266626183806124, next_state=array([-0.16096744,  0.77548873, -0.43271154, -0.84655255,  0.36596173,\n",
      "        0.25779054,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16096744,  0.77548873, -0.43271154, -0.84655255,  0.36596173,\n",
      "        0.25779054,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.629184245694687, next_state=array([-0.16524068,  0.7558758 , -0.44125643, -0.8753135 ,  0.3807317 ,\n",
      "        0.29539973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16524068,  0.7558758 , -0.44125643, -0.8753135 ,  0.3807317 ,\n",
      "        0.29539973,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6864319311774352, next_state=array([-0.17000493,  0.7370276 , -0.48976532, -0.8413308 ,  0.3949561 ,\n",
      "        0.28448826,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17000493,  0.7370276 , -0.48976532, -0.8413308 ,  0.3949561 ,\n",
      "        0.28448826,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9547121147475366, next_state=array([-0.17476988,  0.7175816 , -0.48975572, -0.86801314,  0.4091803 ,\n",
      "        0.28448433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17476988,  0.7175816 , -0.48975572, -0.86801314,  0.4091803 ,\n",
      "        0.28448433,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9256597502170507, next_state=array([-0.17953558,  0.6975383 , -0.48974577, -0.89469534,  0.42340434,\n",
      "        0.28448033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17953558,  0.6975383 , -0.48974577, -0.89469534,  0.42340434,\n",
      "        0.28448033,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9856454622740203, next_state=array([-0.18439397,  0.67684793, -0.5012848 , -0.92431   ,  0.44019172,\n",
      "        0.3357467 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18439397,  0.67684793, -0.5012848 , -0.92431   ,  0.44019172,\n",
      "        0.3357467 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1481894482166013, next_state=array([-0.18963185,  0.65636057, -0.538632  , -0.915306  ,  0.45644528,\n",
      "        0.32507116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18963185,  0.65636057, -0.538632  , -0.915306  ,  0.45644528,\n",
      "        0.32507116,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3176848293786054, next_state=array([-0.19481306,  0.6353249 , -0.5312452 , -0.93928885,  0.47092286,\n",
      "        0.2895514 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19481306,  0.6353249 , -0.5312452 , -0.93928885,  0.47092286,\n",
      "        0.2895514 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5928708148208102, next_state=array([-0.20044966,  0.61505973, -0.57671815, -0.90517783,  0.48544067,\n",
      "        0.29035628,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20044966,  0.61505973, -0.57671815, -0.90517783,  0.48544067,\n",
      "        0.29035628,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9580591492652375, next_state=array([-0.20616159,  0.594137  , -0.58618134, -0.9352696 ,  0.5022377 ,\n",
      "        0.33593997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20616159,  0.594137  , -0.58618134, -0.9352696 ,  0.5022377 ,\n",
      "        0.33593997,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0686503876775817, next_state=array([-0.21234517,  0.57368267, -0.63292277, -0.9145089 ,  0.5187078 ,\n",
      "        0.32940245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21234517,  0.57368267, -0.63292277, -0.9145089 ,  0.5187078 ,\n",
      "        0.32940245,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.197674920146254, next_state=array([-0.2186048,  0.5525683, -0.6424221, -0.9448062,  0.5375088,\n",
      "        0.376021 ,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([-0.2186048,  0.5525683, -0.6424221, -0.9448062,  0.5375088,\n",
      "        0.376021 ,  0.       ,  0.       ], dtype=float32), action=2, reward=-0.4620928907699124, next_state=array([-0.22511654,  0.5318992 , -0.66801167, -0.92545354,  0.55695754,\n",
      "        0.3889756 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22511654,  0.5318992 , -0.66801167, -0.92545354,  0.55695754,\n",
      "        0.3889756 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4320761955638943, next_state=array([-0.23163009,  0.5106343 , -0.667987  , -0.9521473 ,  0.5764058 ,\n",
      "        0.38896546,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23163009,  0.5106343 , -0.667987  , -0.9521473 ,  0.5764058 ,\n",
      "        0.38896546,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.437373590012072, next_state=array([-0.2381455 ,  0.48877352, -0.6679615 , -0.97884065,  0.59585357,\n",
      "        0.3889553 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2381455 ,  0.48877352, -0.6679615 , -0.97884065,  0.59585357,\n",
      "        0.3889553 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.403668533659071, next_state=array([-0.24472328,  0.46625477, -0.6756705 , -1.0090911 ,  0.61733717,\n",
      "        0.4296716 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24472328,  0.46625477, -0.6756705 , -1.0090911 ,  0.61733717,\n",
      "        0.4296716 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6600218085102085, next_state=array([-0.25130337,  0.44314107, -0.6756375 , -1.0357896 ,  0.63882005,\n",
      "        0.429658  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25130337,  0.44314107, -0.6756375 , -1.0357896 ,  0.63882005,\n",
      "        0.429658  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.684172138990192, next_state=array([-0.257886  ,  0.4194322 , -0.67560345, -1.0624875 ,  0.6603023 ,\n",
      "        0.42964426,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.257886  ,  0.4194322 , -0.67560345, -1.0624875 ,  0.6603023 ,\n",
      "        0.42964426,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.944842203902964, next_state=array([-0.26442426,  0.39519176, -0.669468  , -1.0856038 ,  0.679989  ,\n",
      "        0.393734  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26442426,  0.39519176, -0.669468  , -1.0856038 ,  0.679989  ,\n",
      "        0.393734  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5864718160768234, next_state=array([-0.2709647 ,  0.37035528, -0.66943777, -1.112296  ,  0.69967514,\n",
      "        0.39372346,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2709647 ,  0.37035528, -0.66943777, -1.112296  ,  0.69967514,\n",
      "        0.39372346,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6413978051249387, next_state=array([-0.27750736,  0.34492272, -0.6694068 , -1.1389877 ,  0.71936077,\n",
      "        0.39371294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27750736,  0.34492272, -0.6694068 , -1.1389877 ,  0.71936077,\n",
      "        0.39371294,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7055460026451204, next_state=array([-0.2839901 ,  0.31897473, -0.66138804, -1.1610198 ,  0.73668337,\n",
      "        0.34645215,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2839901 ,  0.31897473, -0.66138804, -1.1610198 ,  0.73668337,\n",
      "        0.34645215,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6395447862795993, next_state=array([-0.29041475,  0.2925017 , -0.6537436 , -1.1834953 ,  0.7518076 ,\n",
      "        0.30248457,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29041475,  0.2925017 , -0.6537436 , -1.1834953 ,  0.7518076 ,\n",
      "        0.30248457,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8845055030132472, next_state=array([-0.29739276,  0.26670313, -0.7095164 , -1.1540109 ,  0.76774573,\n",
      "        0.31876332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29739276,  0.26670313, -0.7095164 , -1.1540109 ,  0.76774573,\n",
      "        0.31876332,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9158458085377095, next_state=array([-0.30432335,  0.24036957, -0.7032639 , -1.1770284 ,  0.781825  ,\n",
      "        0.28158522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30432335,  0.24036957, -0.7032639 , -1.1770284 ,  0.781825  ,\n",
      "        0.28158522,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9126838083806195, next_state=array([-0.3112072 ,  0.21349612, -0.6971796 , -1.2002605 ,  0.7941254 ,\n",
      "        0.2460074 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3112072 ,  0.21349612, -0.6971796 , -1.2002605 ,  0.7941254 ,\n",
      "        0.2460074 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.552657734756876, next_state=array([-0.31813866,  0.18595012, -0.70323366, -1.2311977 ,  0.80842525,\n",
      "        0.2859974 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31813866,  0.18595012, -0.70323366, -1.2311977 ,  0.80842525,\n",
      "        0.2859974 ,  0.        ,  0.        ], dtype=float32), action=3, reward=7.837975955306065, next_state=array([-0.32502785,  0.15788907, -0.69740623, -1.2531532 ,  0.8206312 ,\n",
      "        0.24411888,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.32502785,  0.15788907, -0.69740623, -1.2531532 ,  0.8206312 ,\n",
      "        0.24411888,  0.        ,  1.        ], dtype=float32), action=2, reward=-2.609152204578936, next_state=array([-0.33255392,  0.13062038, -0.7641302 , -1.2264131 ,  0.8369416 ,\n",
      "        0.31073713,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.33255392,  0.13062038, -0.7641302 , -1.2264131 ,  0.8369416 ,\n",
      "        0.31073713,  0.        ,  1.        ], dtype=float32), action=3, reward=26.030215633395585, next_state=array([-0.33680463,  0.1174691 , -0.5597105 , -0.7995203 ,  1.0459445 ,\n",
      "        3.636917  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.33680463,  0.1174691 , -0.5597105 , -0.7995203 ,  1.0459445 ,\n",
      "        3.636917  ,  0.        ,  1.        ], dtype=float32), action=1, reward=-4.485289436588544, next_state=array([-0.34021378,  0.1093875 , -0.45583624, -0.59541285,  1.3159293 ,\n",
      "        4.9414797 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.34021378,  0.1093875 , -0.45583624, -0.59541285,  1.3159293 ,\n",
      "        4.9414797 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.3426186 ,  0.10667003, -0.12079202,  0.09031583,  1.456271  ,\n",
      "        0.56832886,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([-0.00754938,  1.4104091 , -0.7646941 , -0.02274104,  0.00875472,\n",
      "        0.17321454,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6402903841583065, next_state=array([-0.01500368,  1.4093215 , -0.7516509 , -0.04838263,  0.01490532,\n",
      "        0.12302437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01500368,  1.4093215 , -0.7516509 , -0.04838263,  0.01490532,\n",
      "        0.12302437,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.17129626603706355, next_state=array([-0.02239256,  1.4089446 , -0.7454842 , -0.01682691,  0.02142956,\n",
      "        0.13049701,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02239256,  1.4089446 , -0.7454842 , -0.01682691,  0.02142956,\n",
      "        0.13049701,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6781158371770744, next_state=array([-0.02978163,  1.407968  , -0.74550337, -0.04351208,  0.02795226,\n",
      "        0.13046578,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02978163,  1.407968  , -0.74550337, -0.04351208,  0.02795226,\n",
      "        0.13046578,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0212286108240094, next_state=array([-0.03725605,  1.4064001 , -0.7561945 , -0.06987707,  0.03661003,\n",
      "        0.17317133,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03725605,  1.4064001 , -0.7561945 , -0.06987707,  0.03661003,\n",
      "        0.17317133,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3446016964801673, next_state=array([-0.04482079,  1.4042288 , -0.76750994, -0.09680169,  0.04753133,\n",
      "        0.21844614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04482079,  1.4042288 , -0.76750994, -0.09680169,  0.04753133,\n",
      "        0.21844614,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3080734137150205, next_state=array([-0.05232267,  1.4014628 , -0.75961435, -0.12325282,  0.05685854,\n",
      "        0.18656139,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05232267,  1.4014628 , -0.75961435, -0.12325282,  0.05685854,\n",
      "        0.18656139,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.101040066293109, next_state=array([-0.05982494,  1.398098  , -0.75964   , -0.14992782,  0.06618544,\n",
      "        0.18655525,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05982494,  1.398098  , -0.75964   , -0.14992782,  0.06618544,\n",
      "        0.18655525,  0.        ,  0.        ], dtype=float32), action=3, reward=0.09551541186888926, next_state=array([-0.06724243,  1.394138  , -0.74899536, -0.17634061,  0.07336907,\n",
      "        0.14368577,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06724243,  1.394138  , -0.74899536, -0.17634061,  0.07336907,\n",
      "        0.14368577,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6202695773478013, next_state=array([-0.07469025,  1.3905878 , -0.75211775, -0.15816681,  0.08064348,\n",
      "        0.1455019 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07469025,  1.3905878 , -0.75211775, -0.15816681,  0.08064348,\n",
      "        0.1455019 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1940659879830833, next_state=array([-0.08223887,  1.3876985 , -0.7620393 , -0.12881906,  0.08776101,\n",
      "        0.14236394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08223887,  1.3876985 , -0.7620393 , -0.12881906,  0.08776101,\n",
      "        0.14236394,  0.        ,  0.        ], dtype=float32), action=3, reward=0.24669292078070384, next_state=array([-0.08970852,  1.3842131 , -0.7521265 , -0.15521744,  0.09288533,\n",
      "        0.10249592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08970852,  1.3842131 , -0.7521265 , -0.15521744,  0.09288533,\n",
      "        0.10249592,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.01145498411867, next_state=array([-0.0972621 ,  1.3801217 , -0.76263964, -0.18231182,  0.1001199 ,\n",
      "        0.14470458,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0972621 ,  1.3801217 , -0.76263964, -0.18231182,  0.1001199 ,\n",
      "        0.14470458,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9419340790616093, next_state=array([-0.10487966,  1.3754287 , -0.77064764, -0.2092003 ,  0.10895272,\n",
      "        0.17667261,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10487966,  1.3754287 , -0.77064764, -0.2092003 ,  0.10895272,\n",
      "        0.17667261,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3043667684159914, next_state=array([-0.11263151,  1.3715048 , -0.78390324, -0.17505251,  0.11762303,\n",
      "        0.17342244,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11263151,  1.3715048 , -0.78390324, -0.17505251,  0.11762303,\n",
      "        0.17342244,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1075782815116781, next_state=array([-0.12038364,  1.3669815 , -0.7839246 , -0.2017395 ,  0.12629253,\n",
      "        0.17340557,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12038364,  1.3669815 , -0.7839246 , -0.2017395 ,  0.12629253,\n",
      "        0.17340557,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.19360777453922992, next_state=array([-0.1280715 ,  1.3618758 , -0.77580935, -0.22751907,  0.13329978,\n",
      "        0.14015774,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1280715 ,  1.3618758 , -0.77580935, -0.22751907,  0.13329978,\n",
      "        0.14015774,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.223626213226139, next_state=array([-0.13583937,  1.3561497 , -0.7858702 , -0.25533345,  0.14235857,\n",
      "        0.18119258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13583937,  1.3561497 , -0.7858702 , -0.25533345,  0.14235857,\n",
      "        0.18119258,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2215650627110506, next_state=array([-0.14360762,  1.3498244 , -0.78589576, -0.28201082,  0.15141478,\n",
      "        0.18114059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14360762,  1.3498244 , -0.78589576, -0.28201082,  0.15141478,\n",
      "        0.18114059,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4658342230426897, next_state=array([-0.15145893,  1.3428917 , -0.7962583 , -0.30929548,  0.16255242,\n",
      "        0.22277267,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15145893,  1.3428917 , -0.7962583 , -0.30929548,  0.16255242,\n",
      "        0.22277267,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.10687239157871772, next_state=array([-0.15921517,  1.3353765 , -0.78431123, -0.33498415,  0.17125884,\n",
      "        0.17414407,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15921517,  1.3353765 , -0.78431123, -0.33498415,  0.17125884,\n",
      "        0.17414407,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3460739808738524, next_state=array([-0.16704473,  1.3272399 , -0.7935063 , -0.3628739 ,  0.1818545 ,\n",
      "        0.21193194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16704473,  1.3272399 , -0.7935063 , -0.3628739 ,  0.1818545 ,\n",
      "        0.21193194,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6019545302269751, next_state=array([-0.17481431,  1.3185167 , -0.7859484 , -0.3888244 ,  0.1909027 ,\n",
      "        0.18098022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17481431,  1.3185167 , -0.7859484 , -0.3888244 ,  0.1909027 ,\n",
      "        0.18098022,  0.        ,  0.        ], dtype=float32), action=3, reward=0.05007123212817646, next_state=array([-0.18249044,  1.3092319 , -0.77414125, -0.41350496,  0.19748037,\n",
      "        0.13156506,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18249044,  1.3092319 , -0.77414125, -0.41350496,  0.19748037,\n",
      "        0.13156506,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1206320157942558, next_state=array([-0.19023867,  1.2993324 , -0.7831698 , -0.4411088 ,  0.20589678,\n",
      "        0.16834305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19023867,  1.2993324 , -0.7831698 , -0.4411088 ,  0.20589678,\n",
      "        0.16834305,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2586171738025189, next_state=array([-0.1979061 ,  1.2888525 , -0.77356905, -0.46674725,  0.21278785,\n",
      "        0.13782491,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1979061 ,  1.2888525 , -0.77356905, -0.46674725,  0.21278785,\n",
      "        0.13782491,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1939972604619116, next_state=array([-0.20565191,  1.2777337 , -0.7829069 , -0.49539226,  0.22120532,\n",
      "        0.16834931,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20565191,  1.2777337 , -0.7829069 , -0.49539226,  0.22120532,\n",
      "        0.16834931,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.264479556109336, next_state=array([-0.21339783,  1.2660158 , -0.7829049 , -0.52206475,  0.22962274,\n",
      "        0.16834834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21339783,  1.2660158 , -0.7829049 , -0.52206475,  0.22962274,\n",
      "        0.16834834,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.302669320723878, next_state=array([-0.22121778,  1.2536824 , -0.7921617 , -0.5497717 ,  0.23993441,\n",
      "        0.20623353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22121778,  1.2536824 , -0.7921617 , -0.5497717 ,  0.23993441,\n",
      "        0.20623353,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.33225915314503, next_state=array([-0.22909956,  1.2407285 , -0.799898  , -0.577681  ,  0.2518623 ,\n",
      "        0.2385576 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22909956,  1.2407285 , -0.799898  , -0.577681  ,  0.2518623 ,\n",
      "        0.2385576 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4916678916675594, next_state=array([-0.23704548,  1.2271587 , -0.80789393, -0.6054446 ,  0.26544368,\n",
      "        0.27162802,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23704548,  1.2271587 , -0.80789393, -0.6054446 ,  0.26544368,\n",
      "        0.27162802,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2914080590395143, next_state=array([-0.2452488 ,  1.2136496 , -0.83298814, -0.6027501 ,  0.2784111 ,\n",
      "        0.25934845,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2452488 ,  1.2136496 , -0.83298814, -0.6027501 ,  0.2784111 ,\n",
      "        0.25934845,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.667251398405, next_state=array([-0.25345254,  1.1995426 , -0.83298254, -0.6294304 ,  0.2913784 ,\n",
      "        0.25934628,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25345254,  1.1995426 , -0.83298254, -0.6294304 ,  0.2913784 ,\n",
      "        0.25934628,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6620345604417253, next_state=array([-0.2616567 ,  1.184838  , -0.8329765 , -0.6561106 ,  0.30434555,\n",
      "        0.25934368,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2616567 ,  1.184838  , -0.8329765 , -0.6561106 ,  0.30434555,\n",
      "        0.25934368,  0.        ,  0.        ], dtype=float32), action=2, reward=0.04473559445297043, next_state=array([-0.2700847 ,  1.1710069 , -0.85567075, -0.61746097,  0.3176867 ,\n",
      "        0.26682314,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2700847 ,  1.1710069 , -0.85567075, -0.61746097,  0.3176867 ,\n",
      "        0.26682314,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.705667083636115, next_state=array([-0.2785132 ,  1.1565783 , -0.85566396, -0.6441419 ,  0.3310277 ,\n",
      "        0.26681983,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2785132 ,  1.1565783 , -0.85566396, -0.6441419 ,  0.3310277 ,\n",
      "        0.26681983,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4908669639925438, next_state=array([-0.28685588,  1.1415946 , -0.84477156, -0.66837853,  0.3420069 ,\n",
      "        0.2195841 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28685588,  1.1415946 , -0.84477156, -0.66837853,  0.3420069 ,\n",
      "        0.2195841 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.2865271350373632, next_state=array([-0.29541   ,  1.1272326 , -0.86620414, -0.64091223,  0.35332766,\n",
      "        0.22641563,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29541   ,  1.1272326 , -0.86620414, -0.64091223,  0.35332766,\n",
      "        0.22641563,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.24992551790424386, next_state=array([-0.30387306,  1.1123112 , -0.8547084 , -0.66526705,  0.3621862 ,\n",
      "        0.1771709 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30387306,  1.1123112 , -0.8547084 , -0.66526705,  0.3621862 ,\n",
      "        0.1771709 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6644703070686433, next_state=array([-0.3126474 ,  1.0981054 , -0.8858968 , -0.6335402 ,  0.37113565,\n",
      "        0.17898901,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3126474 ,  1.0981054 , -0.8858968 , -0.6335402 ,  0.37113565,\n",
      "        0.17898901,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5762575843781677, next_state=array([-0.32150665,  1.0832528 , -0.896593  , -0.662925  ,  0.3824534 ,\n",
      "        0.22635534,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32150665,  1.0832528 , -0.896593  , -0.662925  ,  0.3824534 ,\n",
      "        0.22635534,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5158918027664186, next_state=array([-0.3303663 ,  1.0678016 , -0.8965871 , -0.68960184,  0.39377108,\n",
      "        0.22635332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3303663 ,  1.0678016 , -0.8965871 , -0.68960184,  0.39377108,\n",
      "        0.22635332,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5136822661523297, next_state=array([-0.33922648,  1.0517521 , -0.89658105, -0.71627843,  0.40508866,\n",
      "        0.22635135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33922648,  1.0517521 , -0.89658105, -0.71627843,  0.40508866,\n",
      "        0.22635135,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5109463369993819, next_state=array([-0.348087  ,  1.035104  , -0.8965748 , -0.742955  ,  0.41640612,\n",
      "        0.22634935,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.348087  ,  1.035104  , -0.8965748 , -0.742955  ,  0.41640612,\n",
      "        0.22634935,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4705433971750381, next_state=array([-0.35713023,  1.018492  , -0.9148015 , -0.7414466 ,  0.42774427,\n",
      "        0.22676262,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35713023,  1.018492  , -0.9148015 , -0.7414466 ,  0.42774427,\n",
      "        0.22676262,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.32686628394324546, next_state=array([-0.36609477,  1.0013415 , -0.9047144 , -0.7647893 ,  0.43672284,\n",
      "        0.17957163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36609477,  1.0013415 , -0.9047144 , -0.7647893 ,  0.43672284,\n",
      "        0.17957163,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2820257955751118, next_state=array([-0.3754353 ,  0.984759  , -0.9422318 , -0.739572  ,  0.44564936,\n",
      "        0.17853019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3754353 ,  0.984759  , -0.9422318 , -0.739572  ,  0.44564936,\n",
      "        0.17853019,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.29519878382132, next_state=array([-0.38477612,  0.9675774 , -0.9422275 , -0.76624477,  0.4545758 ,\n",
      "        0.17852922,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38477612,  0.9675774 , -0.9422275 , -0.76624477,  0.4545758 ,\n",
      "        0.17852922,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3928401431033692, next_state=array([-0.39418554,  0.9497426 , -0.9509258 , -0.79594916,  0.46557102,\n",
      "        0.21990445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39418554,  0.9497426 , -0.9509258 , -0.79594916,  0.46557102,\n",
      "        0.21990445,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6491630597967515, next_state=array([-0.4039076 ,  0.9326613 , -0.9826546 , -0.762718  ,  0.47714752,\n",
      "        0.23153028,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4039076 ,  0.9326613 , -0.9826546 , -0.762718  ,  0.47714752,\n",
      "        0.23153028,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6351741565245266, next_state=array([-0.4135677 ,  0.91503054, -0.9746975 , -0.78660756,  0.48682624,\n",
      "        0.19357437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4135677 ,  0.91503054, -0.9746975 , -0.78660756,  0.48682624,\n",
      "        0.19357437,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5544978143256276, next_state=array([-0.42317542,  0.8968559 , -0.9678761 , -0.81029505,  0.49477047,\n",
      "        0.15888424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42317542,  0.8968559 , -0.9678761 , -0.81029505,  0.49477047,\n",
      "        0.15888424,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3675062966881613, next_state=array([-0.43285498,  0.87803066, -0.9769069 , -0.83992857,  0.504838  ,\n",
      "        0.20135096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43285498,  0.87803066, -0.9769069 , -0.83992857,  0.504838  ,\n",
      "        0.20135096,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.29672409283304435, next_state=array([-0.44245583,  0.85866255, -0.96691483, -0.8633473 ,  0.5125608 ,\n",
      "        0.15445533,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44245583,  0.85866255, -0.96691483, -0.8633473 ,  0.5125608 ,\n",
      "        0.15445533,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4898665164980387, next_state=array([-0.4521379 ,  0.83863825, -0.9771136 , -0.89334524,  0.52268004,\n",
      "        0.20238476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4521379 ,  0.83863825, -0.9771136 , -0.89334524,  0.52268004,\n",
      "        0.20238476,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.338239740700742, next_state=array([-0.46186882,  0.81796175, -0.9833849 , -0.92295396,  0.5344423 ,\n",
      "        0.2352448 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46186882,  0.81796175, -0.9833849 , -0.92295396,  0.5344423 ,\n",
      "        0.2352448 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.660327521694171, next_state=array([-0.47160035,  0.7966869 , -0.983376  , -0.9496307 ,  0.54620445,\n",
      "        0.23524264,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47160035,  0.7966869 , -0.983376  , -0.9496307 ,  0.54620445,\n",
      "        0.23524264,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0804339674169114, next_state=array([-0.4815336 ,  0.77562994, -1.0039117 , -0.9402059 ,  0.55847937,\n",
      "        0.24549821,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4815336 ,  0.77562994, -1.0039117 , -0.9402059 ,  0.55847937,\n",
      "        0.24549821,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.29636435671664, next_state=array([-0.4920574 ,  0.755021  , -1.0623789 , -0.92016107,  0.57015043,\n",
      "        0.23342165,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4920574 ,  0.755021  , -1.0623789 , -0.92016107,  0.57015043,\n",
      "        0.23342165,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0253375477856523, next_state=array([-0.50265473,  0.73373365, -1.0717661 , -0.95131385,  0.58431846,\n",
      "        0.28335997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.50265473,  0.73373365, -1.0717661 , -0.95131385,  0.58431846,\n",
      "        0.28335997,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.019549936972794, next_state=array([-0.5132531 ,  0.7118487 , -1.0717523 , -0.9779947 ,  0.59848624,\n",
      "        0.28335607,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5132531 ,  0.7118487 , -1.0717523 , -0.9779947 ,  0.59848624,\n",
      "        0.28335607,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0509254404738613, next_state=array([-0.52385247,  0.6893659 , -1.0717382 , -1.0046754 ,  0.61265385,\n",
      "        0.28335217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.52385247,  0.6893659 , -1.0717382 , -1.0046754 ,  0.61265385,\n",
      "        0.28335217,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0862351409670623, next_state=array([-0.5344528 ,  0.66628534, -1.0717238 , -1.031356  ,  0.6268213 ,\n",
      "        0.28334826,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5344528 ,  0.66628534, -1.0717238 , -1.031356  ,  0.6268213 ,\n",
      "        0.28334826,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7137245151000002, next_state=array([-0.5452202 ,  0.64328045, -1.0887911 , -1.0283424 ,  0.6415847 ,\n",
      "        0.29526797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5452202 ,  0.64328045, -1.0887911 , -1.0283424 ,  0.6415847 ,\n",
      "        0.29526797,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3516257459308736, next_state=array([-0.55593884,  0.6197468 , -1.0822489 , -1.0511698 ,  0.6544293 ,\n",
      "        0.25689235,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.55593884,  0.6197468 , -1.0822489 , -1.0511698 ,  0.6544293 ,\n",
      "        0.25689235,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.109039450139221, next_state=array([-0.56665844,  0.5956149 , -1.0822363 , -1.0778476 ,  0.6672738 ,\n",
      "        0.25688964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.56665844,  0.5956149 , -1.0822363 , -1.0778476 ,  0.6672738 ,\n",
      "        0.25688964,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1271164026643123, next_state=array([-0.5773206 ,  0.5709625 , -1.0746329 , -1.1001315 ,  0.6778969 ,\n",
      "        0.21246271,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5773206 ,  0.5709625 , -1.0746329 , -1.1001315 ,  0.6778969 ,\n",
      "        0.21246271,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.003856629485483, next_state=array([-0.58798325,  0.5457112 , -1.0746241 , -1.1268054 ,  0.68851995,\n",
      "        0.21246156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.58798325,  0.5457112 , -1.0746241 , -1.1268054 ,  0.68851995,\n",
      "        0.21246156,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1513141931615383, next_state=array([-0.59859043,  0.51992285, -1.0674608 , -1.1498815 ,  0.6971736 ,\n",
      "        0.17307255,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.59859043,  0.51992285, -1.0674608 , -1.1498815 ,  0.6971736 ,\n",
      "        0.17307255,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9465766070520658, next_state=array([-0.609198  ,  0.4935352 , -1.0674546 , -1.1765531 ,  0.7058272 ,\n",
      "        0.17307137,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.609198  ,  0.4935352 , -1.0674546 , -1.1765531 ,  0.7058272 ,\n",
      "        0.17307137,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7851412572501022, next_state=array([-0.6197345 ,  0.46663928, -1.0582488 , -1.1979958 ,  0.7117977 ,\n",
      "        0.11941101,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6197345 ,  0.46663928, -1.0582488 , -1.1979958 ,  0.7117977 ,\n",
      "        0.11941101,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0512562353529504, next_state=array([-0.63033295,  0.4390513 , -1.0663316 , -1.2298943 ,  0.7202847 ,\n",
      "        0.16973998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.63033295,  0.4390513 , -1.0663316 , -1.2298943 ,  0.7202847 ,\n",
      "        0.16973998,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.077299517500751, next_state=array([-0.64150137,  0.41150373, -1.1227715 , -1.2278284 ,  0.7280933 ,\n",
      "        0.15617299,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.64150137,  0.41150373, -1.1227715 , -1.2278284 ,  0.7280933 ,\n",
      "        0.15617299,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.5401480537357655, next_state=array([-0.6531991 ,  0.38453552, -1.1761056 , -1.2023774 ,  0.73649436,\n",
      "        0.16802038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6531991 ,  0.38453552, -1.1761056 , -1.2023774 ,  0.73649436,\n",
      "        0.16802038,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4245537779314645, next_state=array([-0.66489726,  0.35696805, -1.1760997 , -1.2290485 ,  0.74489534,\n",
      "        0.16801992,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.66489726,  0.35696805, -1.1760997 , -1.2290485 ,  0.74489534,\n",
      "        0.16801992,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3869710587375426, next_state=array([-0.67653614,  0.32889533, -1.1682557 , -1.2503756 ,  0.750774  ,\n",
      "        0.117574  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.67653614,  0.32889533, -1.1682557 , -1.2503756 ,  0.750774  ,\n",
      "        0.117574  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2744769865494436, next_state=array([-0.68811107,  0.30030608, -1.1600304 , -1.2722182 ,  0.75420576,\n",
      "        0.06863438,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.68811107,  0.30030608, -1.1600304 , -1.2722182 ,  0.75420576,\n",
      "        0.06863438,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.281908034937203, next_state=array([-0.69968605,  0.2711169 , -1.1600293 , -1.2988855 ,  0.7576375 ,\n",
      "        0.06863425,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.69968605,  0.2711169 , -1.1600293 , -1.2988855 ,  0.7576375 ,\n",
      "        0.06863425,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4120883629971672, next_state=array([-0.71126115,  0.24132787, -1.1600283 , -1.3255528 ,  0.76106924,\n",
      "        0.06863419,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.71126115,  0.24132787, -1.1600283 , -1.3255528 ,  0.76106924,\n",
      "        0.06863419,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.666123871901475, next_state=array([-0.722785  ,  0.21100424, -1.1534778 , -1.3484141 ,  0.76256025,\n",
      "        0.02982039,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.722785  ,  0.21100424, -1.1534778 , -1.3484141 ,  0.76256025,\n",
      "        0.02982039,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.597000515090342, next_state=array([-0.7343707 ,  0.1800062 , -1.1613296 , -1.3794533 ,  0.7663282 ,\n",
      "        0.07535984,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7343707 ,  0.1800062 , -1.1613296 , -1.3794533 ,  0.7663282 ,\n",
      "        0.07535984,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.241724254125461, next_state=array([-0.7463856 ,  0.14890653, -1.2039605 , -1.3838074 ,  0.76973253,\n",
      "        0.06808639,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7463856 ,  0.14890653, -1.2039605 , -1.3838074 ,  0.76973253,\n",
      "        0.06808639,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9994150785890088, next_state=array([-0.7583463 ,  0.11728528, -1.1969535 , -1.405956  ,  0.77094185,\n",
      "        0.02418643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7583463 ,  0.11728528, -1.1969535 , -1.405956  ,  0.77094185,\n",
      "        0.02418643,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9221452810272126, next_state=array([-0.77030706,  0.08506408, -1.1969534 , -1.4326228 ,  0.7721512 ,\n",
      "        0.02418671,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.77030706,  0.08506408, -1.1969534 , -1.4326228 ,  0.7721512 ,\n",
      "        0.02418671,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.077157145692297, next_state=array([-0.7822678 ,  0.05224286, -1.1969532 , -1.4592896 ,  0.77336043,\n",
      "        0.02418567,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7822678 ,  0.05224286, -1.1969532 , -1.4592896 ,  0.77336043,\n",
      "        0.02418567,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.2958165019438637, next_state=array([-0.7947406 ,  0.01990529, -1.2486193 , -1.4380991 ,  0.77520883,\n",
      "        0.03696775,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7947406 ,  0.01990529, -1.2486193 , -1.4380991 ,  0.77520883,\n",
      "        0.03696775,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.439257427536859, next_state=array([-0.8072135 , -0.01303231, -1.248619  , -1.464766  ,  0.77705723,\n",
      "        0.03696779,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8072135 , -0.01303231, -1.248619  , -1.464766  ,  0.77705723,\n",
      "        0.03696779,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.5908625953663886, next_state=array([-0.8196863 , -0.04656979, -1.2486186 , -1.4914328 ,  0.77890563,\n",
      "        0.03696777,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8196863 , -0.04656979, -1.2486186 , -1.4914328 ,  0.77890563,\n",
      "        0.03696777,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.69521987688812, next_state=array([-0.83248615, -0.07994705, -1.2817249 , -1.4845825 ,  0.7813243 ,\n",
      "        0.0483735 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.83248615, -0.07994705, -1.2817249 , -1.4845825 ,  0.7813243 ,\n",
      "        0.0483735 ,  0.        ,  0.        ], dtype=float32), action=0, reward=6.070745173608941, next_state=array([-0.845286  , -0.11392428, -1.2817245 , -1.5112497 ,  0.783743  ,\n",
      "        0.04837406,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.845286  , -0.11392428, -1.2817245 , -1.5112497 ,  0.783743  ,\n",
      "        0.04837406,  0.        ,  1.        ], dtype=float32), action=1, reward=71.14689031424044, next_state=array([-0.85549587, -0.1175449 , -1.1230824 , -0.2814436 ,  0.8851475 ,\n",
      "        1.8932524 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.85549587, -0.1175449 , -1.1230824 , -0.2814436 ,  0.8851475 ,\n",
      "        1.8932524 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-5.56516560893823, next_state=array([-0.86596197, -0.12191669, -1.0962045 , -0.2380372 ,  0.96588945,\n",
      "        1.6142706 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.86596197, -0.12191669, -1.0962045 , -0.2380372 ,  0.96588945,\n",
      "        1.6142706 ,  0.        ,  1.        ], dtype=float32), action=3, reward=-5.634948306434381, next_state=array([-0.87645686, -0.12591068, -1.0841967 , -0.21305622,  1.0278053 ,\n",
      "        1.2371982 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.87645686, -0.12591068, -1.0841967 , -0.21305622,  1.0278053 ,\n",
      "        1.2371982 ,  0.        ,  1.        ], dtype=float32), action=3, reward=4.469440932561754, next_state=array([-0.8871054 , -0.12721483, -1.0585955 , -0.0569911 ,  1.0168889 ,\n",
      "       -0.16083454,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.8871054 , -0.12721483, -1.0585955 , -0.0569911 ,  1.0168889 ,\n",
      "       -0.16083454,  0.        ,  1.        ], dtype=float32), action=2, reward=-5.289952925897626, next_state=array([-0.89843297, -0.12820347, -1.1207545 , -0.03284388,  0.99432796,\n",
      "       -0.4348771 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.89843297, -0.12820347, -1.1207545 , -0.03284388,  0.99432796,\n",
      "       -0.4348771 ,  0.        ,  1.        ], dtype=float32), action=3, reward=2.4645138649866865, next_state=array([-0.90974134, -0.12945795, -1.1140244 , -0.03904054,  0.9645378 ,\n",
      "       -0.5957901 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.90974134, -0.12945795, -1.1140244 , -0.03904054,  0.9645378 ,\n",
      "       -0.5957901 ,  0.        ,  1.        ], dtype=float32), action=3, reward=2.490211381631782, next_state=array([-0.9210202 , -0.13119037, -1.1088223 , -0.05925712,  0.9322289 ,\n",
      "       -0.646172  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.9210202 , -0.13119037, -1.1088223 , -0.05925712,  0.9322289 ,\n",
      "       -0.646172  ,  0.        ,  1.        ], dtype=float32), action=0, reward=1.946840935949922, next_state=array([-0.93228745, -0.13352208, -1.1074159 , -0.0868252 ,  0.900867  ,\n",
      "       -0.62726545,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.93228745, -0.13352208, -1.1074159 , -0.0868252 ,  0.900867  ,\n",
      "       -0.62726545,  0.        ,  1.        ], dtype=float32), action=2, reward=-13.608317000953935, next_state=array([-0.94408894, -0.13586196, -1.160017  , -0.08756629,  0.869433  ,\n",
      "       -0.6287052 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.94408894, -0.13586196, -1.160017  , -0.08756629,  0.869433  ,\n",
      "       -0.6287052 ,  0.        ,  0.        ], dtype=float32), action=3, reward=2.4089234348079187, next_state=array([-0.95586145, -0.13871308, -1.1550429 , -0.10973939,  0.8360576 ,\n",
      "       -0.6675352 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.95586145, -0.13871308, -1.1550429 , -0.10973939,  0.8360576 ,\n",
      "       -0.6675352 ,  0.        ,  0.        ], dtype=float32), action=0, reward=1.847457407837851, next_state=array([-0.9676415 , -0.14215317, -1.1549587 , -0.1364222 ,  0.802686  ,\n",
      "       -0.6674597 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9676415 , -0.14215317, -1.1549587 , -0.1364222 ,  0.802686  ,\n",
      "       -0.6674597 ,  0.        ,  0.        ], dtype=float32), action=3, reward=2.7556659816683875, next_state=array([-0.9793774 , -0.14608668, -1.1479638 , -0.15773323,  0.7668821 ,\n",
      "       -0.7161071 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9793774 , -0.14608668, -1.1479638 , -0.15773323,  0.7668821 ,\n",
      "       -0.7161071 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8315743642438929, next_state=array([-0.99117917, -0.15070191, -1.1555603 , -0.18979761,  0.73361504,\n",
      "       -0.66536754,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.99117917, -0.15070191, -1.1555603 , -0.18979761,  0.73361504,\n",
      "       -0.66536754,  0.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([-1.0029876 , -0.15590507, -1.1554825 , -0.21648546,  0.700351  ,\n",
      "       -0.66530764,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([ 0.0074235 ,  1.4133093 ,  0.75189406,  0.10615603, -0.00859508,\n",
      "       -0.1703153 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.696326866192339, next_state=array([ 0.01493683,  1.4164425 ,  0.7594517 ,  0.13919178, -0.01661492,\n",
      "       -0.160411  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01493683,  1.4164425 ,  0.7594517 ,  0.13919178, -0.01661492,\n",
      "       -0.160411  ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5222138967587011, next_state=array([ 0.02237148,  1.4189713 ,  0.7495592 ,  0.11230221, -0.02264296,\n",
      "       -0.12057199,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02237148,  1.4189713 ,  0.7495592 ,  0.11230221, -0.02264296,\n",
      "       -0.12057199,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8850425580023102, next_state=array([ 0.02989941,  1.4208944 ,  0.7612723 ,  0.0853215 , -0.0310186 ,\n",
      "       -0.16752848,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02989941,  1.4208944 ,  0.7612723 ,  0.0853215 , -0.0310186 ,\n",
      "       -0.16752848,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9264306419804587, next_state=array([ 0.03750477,  1.4222269 ,  0.77093685,  0.05898404, -0.04131923,\n",
      "       -0.20603177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03750477,  1.4222269 ,  0.77093685,  0.05898404, -0.04131923,\n",
      "       -0.20603177,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9363225015607552, next_state=array([ 0.04532928,  1.4243838 ,  0.79198533,  0.09556396, -0.05075897,\n",
      "       -0.18881209,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04532928,  1.4243838 ,  0.79198533,  0.09556396, -0.05075897,\n",
      "       -0.18881209,  0.        ,  0.        ], dtype=float32), action=1, reward=0.4417329989830716, next_state=array([ 0.05306568,  1.4259418 ,  0.7809292 ,  0.06898938, -0.05797698,\n",
      "       -0.14437358,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05306568,  1.4259418 ,  0.7809292 ,  0.06898938, -0.05797698,\n",
      "       -0.14437358,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6609217749645495, next_state=array([ 0.06080217,  1.4269009 ,  0.78094953,  0.04232268, -0.0651945 ,\n",
      "       -0.14436394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06080217,  1.4269009 ,  0.78094953,  0.04232268, -0.0651945 ,\n",
      "       -0.14436394,  0.        ,  0.        ], dtype=float32), action=1, reward=0.15857009730240293, next_state=array([ 0.06848039,  1.4272759 ,  0.77359265,  0.01640332, -0.07091563,\n",
      "       -0.11443331,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06848039,  1.4272759 ,  0.77359265,  0.01640332, -0.07091563,\n",
      "       -0.11443331,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7834911419839738, next_state=array([ 0.07606649,  1.4270668 ,  0.76201695, -0.00946185, -0.07429677,\n",
      "       -0.06762873,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07606649,  1.4270668 ,  0.76201695, -0.00946185, -0.07429677,\n",
      "       -0.06762873,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3875996192477646, next_state=array([ 0.08371744,  1.4262515 ,  0.7701567 , -0.03649623, -0.07931373,\n",
      "       -0.10034819,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08371744,  1.4262515 ,  0.7701567 , -0.03649623, -0.07931373,\n",
      "       -0.10034819,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8680562314677058, next_state=array([ 0.09127054,  1.4248487 ,  0.75786984, -0.06248718, -0.08185009,\n",
      "       -0.05073189,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09127054,  1.4248487 ,  0.75786984, -0.06248718, -0.08185009,\n",
      "       -0.05073189,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.37022780994846016, next_state=array([ 0.09882364,  1.422846  ,  0.7578755 , -0.08915653, -0.08438746,\n",
      "       -0.0507522 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09882364,  1.422846  ,  0.7578755 , -0.08915653, -0.08438746,\n",
      "       -0.0507522 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9037355916776459, next_state=array([ 0.10628815,  1.4202595 ,  0.7467276 , -0.11496646, -0.08466852,\n",
      "       -0.00562204,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10628815,  1.4202595 ,  0.7467276 , -0.11496646, -0.08466852,\n",
      "       -0.00562204,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2197185738662597, next_state=array([ 0.11375256,  1.4170731 ,  0.7467271 , -0.14163518, -0.08495051,\n",
      "       -0.00564022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11375256,  1.4170731 ,  0.7467271 , -0.14163518, -0.08495051,\n",
      "       -0.00564022,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.25438746237600185, next_state=array([ 0.12121697,  1.4132866 ,  0.7467272 , -0.16830382, -0.08523198,\n",
      "       -0.00562974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12121697,  1.4132866 ,  0.7467272 , -0.16830382, -0.08523198,\n",
      "       -0.00562974,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6200445340319913, next_state=array([ 0.12861729,  1.4088979 ,  0.7387006 , -0.19497636, -0.08391074,\n",
      "        0.02642716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12861729,  1.4088979 ,  0.7387006 , -0.19497636, -0.08391074,\n",
      "        0.02642716,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3884115609352932, next_state=array([ 0.13600178,  1.4045925 ,  0.7373689 , -0.19129197, -0.08284274,\n",
      "        0.02136231,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13600178,  1.4045925 ,  0.7373689 , -0.19129197, -0.08284274,\n",
      "        0.02136231,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4823715384901675, next_state=array([ 0.14337607,  1.4005679 ,  0.7366264 , -0.1788281 , -0.08204843,\n",
      "        0.01588762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14337607,  1.4005679 ,  0.7366264 , -0.1788281 , -0.08204843,\n",
      "        0.01588762,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2970095301166384, next_state=array([ 0.15082054,  1.3959225 ,  0.7454557 , -0.2065146 , -0.08304936,\n",
      "       -0.02002024,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15082054,  1.3959225 ,  0.7454557 , -0.2065146 , -0.08304936,\n",
      "       -0.02002024,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8998069026082487, next_state=array([ 0.15817328,  1.390686  ,  0.73394924, -0.23265988, -0.0817351 ,\n",
      "        0.02628748,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15817328,  1.390686  ,  0.73394924, -0.23265988, -0.0817351 ,\n",
      "        0.02628748,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1807036982185763, next_state=array([ 0.16547832,  1.3859152 ,  0.7296792 , -0.21199623, -0.08091261,\n",
      "        0.01645138,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16547832,  1.3859152 ,  0.7296792 , -0.21199623, -0.08091261,\n",
      "        0.01645138,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3436027294028008, next_state=array([ 0.17270938,  1.3816872 ,  0.72290826, -0.18790379, -0.08071785,\n",
      "        0.00389536,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17270938,  1.3816872 ,  0.72290826, -0.18790379, -0.08071785,\n",
      "        0.00389536,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3083210062672208, next_state=array([ 0.17994031,  1.3768588 ,  0.7229066 , -0.2145774 , -0.08052274,\n",
      "        0.00390233,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17994031,  1.3768588 ,  0.7229066 , -0.2145774 , -0.08052274,\n",
      "        0.00390233,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8831049626921879, next_state=array([ 0.18708506,  1.3714345 ,  0.71208197, -0.24095601, -0.07815806,\n",
      "        0.04729798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18708506,  1.3714345 ,  0.71208197, -0.24095601, -0.07815806,\n",
      "        0.04729798,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4075688867784197, next_state=array([ 0.1943039 ,  1.3653855 ,  0.72198594, -0.26884434, -0.07825725,\n",
      "       -0.00198077,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1943039 ,  1.3653855 ,  0.72198594, -0.26884434, -0.07825725,\n",
      "       -0.00198077,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6866856196828734, next_state=array([ 0.20145902,  1.3592784 ,  0.7156684 , -0.27143583, -0.07840767,\n",
      "       -0.00300851,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20145902,  1.3592784 ,  0.7156684 , -0.27143583, -0.07840767,\n",
      "       -0.00300851,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5294127728921125, next_state=array([ 0.20868063,  1.3538723 ,  0.7223092 , -0.24028309, -0.07856666,\n",
      "       -0.00317998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20868063,  1.3538723 ,  0.7223092 , -0.24028309, -0.07856666,\n",
      "       -0.00317998,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5482106231015973, next_state=array([ 0.21583375,  1.3478761 ,  0.713727  , -0.26641333, -0.07699637,\n",
      "        0.03140565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21583375,  1.3478761 ,  0.713727  , -0.26641333, -0.07699637,\n",
      "        0.03140565,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.13695007531582631, next_state=array([ 0.22312298,  1.342419  ,  0.7269752 , -0.24244547, -0.07506897,\n",
      "        0.03854828,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22312298,  1.342419  ,  0.7269752 , -0.24244547, -0.07506897,\n",
      "        0.03854828,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.21666479434753683, next_state=array([ 0.2304122 ,  1.3363618 ,  0.72697514, -0.26911247, -0.07314157,\n",
      "        0.03854825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2304122 ,  1.3363618 ,  0.72697514, -0.26911247, -0.07314157,\n",
      "        0.03854825,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.24324797749025606, next_state=array([ 0.23770142,  1.3297046 ,  0.7269751 , -0.29577944, -0.07121415,\n",
      "        0.03854831,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23770142,  1.3297046 ,  0.7269751 , -0.29577944, -0.07121415,\n",
      "        0.03854831,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3892681258660662, next_state=array([ 2.4506578e-01,  1.3224283e+00,  7.3641407e-01, -3.2338777e-01,\n",
      "       -7.1197599e-02,  3.3117691e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 2.4506578e-01,  1.3224283e+00,  7.3641407e-01, -3.2338777e-01,\n",
      "       -7.1197599e-02,  3.3117691e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.08932479292228662, next_state=array([ 0.25261346,  1.3159206 ,  0.75419426, -0.28920397, -0.07063603,\n",
      "        0.01123131,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25261346,  1.3159206 ,  0.75419426, -0.28920397, -0.07063603,\n",
      "        0.01123131,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.38365965834290705, next_state=array([ 0.260161  ,  1.3088129 ,  0.7541942 , -0.31587067, -0.07007447,\n",
      "        0.01123126,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.260161  ,  1.3088129 ,  0.7541942 , -0.31587067, -0.07007447,\n",
      "        0.01123126,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.40468871317031585, next_state=array([ 0.2677087 ,  1.3011053 ,  0.7541942 , -0.34253734, -0.06951293,\n",
      "        0.01123094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2677087 ,  1.3011053 ,  0.7541942 , -0.34253734, -0.06951293,\n",
      "        0.01123094,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.369601990244205, next_state=array([ 0.2753211 ,  1.2927884 ,  0.7623255 , -0.36968946, -0.07058859,\n",
      "       -0.02151321,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2753211 ,  1.2927884 ,  0.7623255 , -0.36968946, -0.07058859,\n",
      "       -0.02151321,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1268329748374242, next_state=array([ 0.28285798,  1.2846357 ,  0.75530136, -0.36241952, -0.07217822,\n",
      "       -0.03179288,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28285798,  1.2846357 ,  0.75530136, -0.36241952, -0.07217822,\n",
      "       -0.03179288,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.556170436179541, next_state=array([ 0.29045802,  1.2758816 ,  0.76320344, -0.3892248 , -0.07534996,\n",
      "       -0.06343471,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29045802,  1.2758816 ,  0.76320344, -0.3892248 , -0.07534996,\n",
      "       -0.06343471,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0268336371823465, next_state=array([ 0.29794836,  1.2671851 ,  0.752902  , -0.3867144 , -0.07917969,\n",
      "       -0.07659467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29794836,  1.2671851 ,  0.752902  , -0.3867144 , -0.07917969,\n",
      "       -0.07659467,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9001151388531923, next_state=array([ 0.3053299 ,  1.2585235 ,  0.74268126, -0.3851987 , -0.08366571,\n",
      "       -0.08972059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3053299 ,  1.2585235 ,  0.74268126, -0.3851987 , -0.08366571,\n",
      "       -0.08972059,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.161366948386869, next_state=array([ 0.312792  ,  1.2492414 ,  0.7528197 , -0.41292536, -0.0902085 ,\n",
      "       -0.1308558 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.312792  ,  1.2492414 ,  0.7528197 , -0.41292536, -0.0902085 ,\n",
      "       -0.1308558 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4902694749996101, next_state=array([ 0.3203391 ,  1.240192  ,  0.7611464 , -0.40258992, -0.0965917 ,\n",
      "       -0.12766403,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3203391 ,  1.240192  ,  0.7611464 , -0.40258992, -0.0965917 ,\n",
      "       -0.12766403,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.39793397615829806, next_state=array([ 0.3278266 ,  1.2305441 ,  0.7536785 , -0.42912075, -0.10148141,\n",
      "       -0.09779415,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3278266 ,  1.2305441 ,  0.7536785 , -0.42912075, -0.10148141,\n",
      "       -0.09779415,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.045366843948301, next_state=array([ 0.33531418,  1.2202966 ,  0.7536782 , -0.45578945, -0.10637111,\n",
      "       -0.09779392,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33531418,  1.2202966 ,  0.7536782 , -0.45578945, -0.10637111,\n",
      "       -0.09779392,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2801207938983452, next_state=array([ 0.3427535 ,  1.2104983 ,  0.7494238 , -0.43587896, -0.11182578,\n",
      "       -0.10909315,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3427535 ,  1.2104983 ,  0.7494238 , -0.43587896, -0.11182578,\n",
      "       -0.10909315,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.440446760944552, next_state=array([ 0.35028848,  1.2000953 ,  0.761417  , -0.46297738, -0.11968525,\n",
      "       -0.15718946,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35028848,  1.2000953 ,  0.761417  , -0.46297738, -0.11968525,\n",
      "       -0.15718946,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.270627926816671, next_state=array([ 0.35788888,  1.189085  ,  0.7695955 , -0.49013558, -0.12919289,\n",
      "       -0.19015285,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35788888,  1.189085  ,  0.7695955 , -0.49013558, -0.12919289,\n",
      "       -0.19015285,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6665278054477131, next_state=array([ 0.36542493,  1.1774925 ,  0.7614918 , -0.5159323 , -0.13704866,\n",
      "       -0.15711555,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36542493,  1.1774925 ,  0.7614918 , -0.5159323 , -0.13704866,\n",
      "       -0.15711555,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7355639327395351, next_state=array([ 0.37297145,  1.1668215 ,  0.76312983, -0.4750681 , -0.14549702,\n",
      "       -0.1689674 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37297145,  1.1668215 ,  0.76312983, -0.4750681 , -0.14549702,\n",
      "       -0.1689674 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8703265343581166, next_state=array([ 0.3806652 ,  1.15647   ,  0.7775788 , -0.46089458, -0.15368287,\n",
      "       -0.16371728,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3806652 ,  1.15647   ,  0.7775788 , -0.46089458, -0.15368287,\n",
      "       -0.16371728,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.412287309251269, next_state=array([ 0.38835907,  1.1455191 ,  0.7775775 , -0.48756686, -0.16186869,\n",
      "       -0.16371652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38835907,  1.1455191 ,  0.7775775 , -0.48756686, -0.16186869,\n",
      "       -0.16371652,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6880048065388267, next_state=array([ 0.39614516,  1.1339593 ,  0.78910613, -0.51495016, -0.17237641,\n",
      "       -0.21015427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39614516,  1.1339593 ,  0.78910613, -0.51495016, -0.17237641,\n",
      "       -0.21015427,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9153881869833627, next_state=array([ 0.4040187 ,  1.1217675 ,  0.8001071 , -0.5433895 , -0.18516934,\n",
      "       -0.25585878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4040187 ,  1.1217675 ,  0.8001071 , -0.5433895 , -0.18516934,\n",
      "       -0.25585878,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7551309042228411, next_state=array([ 0.41194135,  1.1097442 ,  0.8051942 , -0.5360328 , -0.1981754 ,\n",
      "       -0.26012132,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41194135,  1.1097442 ,  0.8051942 , -0.5360328 , -0.1981754 ,\n",
      "       -0.26012132,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9023431369195691, next_state=array([ 0.41986418,  1.0971231 ,  0.8051902 , -0.56271344, -0.21118131,\n",
      "       -0.2601183 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41986418,  1.0971231 ,  0.8051902 , -0.56271344, -0.21118131,\n",
      "       -0.2601183 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9074647588115283, next_state=array([ 0.4277874 ,  1.0839043 ,  0.8051858 , -0.589394  , -0.22418708,\n",
      "       -0.26011524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4277874 ,  1.0839043 ,  0.8051858 , -0.589394  , -0.22418708,\n",
      "       -0.26011524,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9113799308704813, next_state=array([ 0.4357109 ,  1.0700877 ,  0.8051813 , -0.6160745 , -0.23719268,\n",
      "       -0.2601122 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4357109 ,  1.0700877 ,  0.8051813 , -0.6160745 , -0.23719268,\n",
      "       -0.2601122 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1015792272287956, next_state=array([ 0.44357252,  1.0556922 ,  0.79735476, -0.64164394, -0.24857707,\n",
      "       -0.22768767,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44357252,  1.0556922 ,  0.79735476, -0.64164394, -0.24857707,\n",
      "       -0.22768767,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7611073792415084, next_state=array([ 0.45143443,  1.0406983 ,  0.7973508 , -0.66832125, -0.25996137,\n",
      "       -0.22768565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45143443,  1.0406983 ,  0.7973508 , -0.66832125, -0.25996137,\n",
      "       -0.22768565,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.767011026409277, next_state=array([ 0.4593706 ,  1.0250857 ,  0.80661315, -0.6962549 , -0.27326074,\n",
      "       -0.26598686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4593706 ,  1.0250857 ,  0.80661315, -0.6962549 , -0.27326074,\n",
      "       -0.26598686,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1627892572271594, next_state=array([ 0.46724653,  1.0088975 ,  0.798991  , -0.7216481 , -0.28496003,\n",
      "       -0.23398602,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46724653,  1.0088975 ,  0.798991  , -0.7216481 , -0.28496003,\n",
      "       -0.23398602,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9746838069918329, next_state=array([ 0.4750618 ,  0.9921427 ,  0.79126465, -0.74659306, -0.29499114,\n",
      "       -0.20062137,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4750618 ,  0.9921427 ,  0.79126465, -0.74659306, -0.29499114,\n",
      "       -0.20062137,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5172840733886972, next_state=array([ 0.48323146,  0.9757773 ,  0.82602674, -0.72921103, -0.3043409 ,\n",
      "       -0.1869953 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48323146,  0.9757773 ,  0.82602674, -0.72921103, -0.3043409 ,\n",
      "       -0.1869953 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4179314595808819, next_state=array([ 0.49147978,  0.9598636 ,  0.83445185, -0.7093288 , -0.3143156 ,\n",
      "       -0.19949374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49147978,  0.9598636 ,  0.83445185, -0.7093288 , -0.3143156 ,\n",
      "       -0.19949374,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4704612106181003, next_state=array([ 0.50000113,  0.9442602 ,  0.8614265 , -0.69552785, -0.32395637,\n",
      "       -0.19281569,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.50000113,  0.9442602 ,  0.8614265 , -0.69552785, -0.32395637,\n",
      "       -0.19281569,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9199072413550937, next_state=array([ 0.50877845,  0.92918473,  0.8869506 , -0.67212504, -0.3335832 ,\n",
      "       -0.19253702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.50877845,  0.92918473,  0.8869506 , -0.67212504, -0.3335832 ,\n",
      "       -0.19253702,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6601171986031489, next_state=array([ 0.5177086 ,  0.9145051 ,  0.9025389 , -0.6546584 , -0.343547  ,\n",
      "       -0.19927539,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5177086 ,  0.9145051 ,  0.9025389 , -0.6546584 , -0.343547  ,\n",
      "       -0.19927539,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5845564339977316, next_state=array([ 0.5266938 ,  0.8991855 ,  0.9095243 , -0.6835382 , -0.35510957,\n",
      "       -0.23125167,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5266938 ,  0.8991855 ,  0.9095243 , -0.6835382 , -0.35510957,\n",
      "       -0.23125167,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.848160699003215, next_state=array([ 0.5357459 ,  0.883238  ,  0.917865  , -0.7119715 , -0.3684697 ,\n",
      "       -0.26720247,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5357459 ,  0.883238  ,  0.917865  , -0.7119715 , -0.3684697 ,\n",
      "       -0.26720247,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4682583617479736, next_state=array([ 0.5449764 ,  0.8675813 ,  0.9358543 , -0.6991997 , -0.38204926,\n",
      "       -0.27159083,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5449764 ,  0.8675813 ,  0.9358543 , -0.6991997 , -0.38204926,\n",
      "       -0.27159083,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9066301711959841, next_state=array([ 0.554124  ,  0.8513722 ,  0.92530745, -0.7232759 , -0.39330363,\n",
      "       -0.22508736,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.554124  ,  0.8513722 ,  0.92530745, -0.7232759 , -0.39330363,\n",
      "       -0.22508736,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.870956555383627, next_state=array([ 0.5633322 ,  0.83451504,  0.9330214 , -0.7526382 , -0.4063751 ,\n",
      "       -0.26142925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5633322 ,  0.83451504,  0.9330214 , -0.7526382 , -0.4063751 ,\n",
      "       -0.26142925,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0830055858430683, next_state=array([ 0.57254106,  0.81705993,  0.9330131 , -0.77931815, -0.41944644,\n",
      "       -0.26142615,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.57254106,  0.81705993,  0.9330131 , -0.77931815, -0.41944644,\n",
      "       -0.26142615,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1000767150042066, next_state=array([ 0.5817506 ,  0.7990069 ,  0.9330045 , -0.805998  , -0.4325176 ,\n",
      "       -0.26142308,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5817506 ,  0.7990069 ,  0.9330045 , -0.805998  , -0.4325176 ,\n",
      "       -0.26142308,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.664888856373625, next_state=array([ 0.59115446,  0.7815591 ,  0.9530536 , -0.7794178 , -0.44632947,\n",
      "       -0.27623764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.59115446,  0.7815591 ,  0.9530536 , -0.7794178 , -0.44632947,\n",
      "       -0.27623764,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2249225095457519, next_state=array([ 0.6007309 ,  0.7645296 ,  0.9708253 , -0.76113325, -0.46077532,\n",
      "       -0.28891686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6007309 ,  0.7645296 ,  0.9708253 , -0.76113325, -0.46077532,\n",
      "       -0.28891686,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.355780979288254, next_state=array([ 0.6103752 ,  0.74686235,  0.97921145, -0.7902043 , -0.47712815,\n",
      "       -0.32705748,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6103752 ,  0.74686235,  0.97921145, -0.7902043 , -0.47712815,\n",
      "       -0.32705748,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.541992523390377, next_state=array([ 0.6200207 ,  0.7285978 ,  0.97919625, -0.8168911 , -0.49348068,\n",
      "       -0.3270515 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6200207 ,  0.7285978 ,  0.97919625, -0.8168911 , -0.49348068,\n",
      "       -0.3270515 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.3401265731006218, next_state=array([ 0.63007146,  0.7106931 ,  1.0193837 , -0.8009844 , -0.5095838 ,\n",
      "       -0.32206166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.63007146,  0.7106931 ,  1.0193837 , -0.8009844 , -0.5095838 ,\n",
      "       -0.32206166,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0430270336988654, next_state=array([ 0.64036214,  0.6932665 ,  1.0438073 , -0.7801149 , -0.52633953,\n",
      "       -0.33511513,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.64036214,  0.6932665 ,  1.0438073 , -0.7801149 , -0.52633953,\n",
      "       -0.33511513,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.624674506105491, next_state=array([ 0.65070647,  0.67518526,  1.0505935 , -0.8099789 , -0.54487634,\n",
      "       -0.3707357 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.65070647,  0.67518526,  1.0505935 , -0.8099789 , -0.54487634,\n",
      "       -0.3707357 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.8937536355489897, next_state=array([ 0.6610525 ,  0.6565082 ,  1.0505714 , -0.83667046, -0.56341267,\n",
      "       -0.37072697,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6610525 ,  0.6565082 ,  1.0505714 , -0.83667046, -0.56341267,\n",
      "       -0.37072697,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9305024535418056, next_state=array([ 0.67140025,  0.6372349 ,  1.0505487 , -0.86336166, -0.5819486 ,\n",
      "       -0.37071824,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.67140025,  0.6372349 ,  1.0505487 , -0.86336166, -0.5819486 ,\n",
      "       -0.37071824,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9698997417078203, next_state=array([ 0.6817495 ,  0.61736554,  1.0505251 , -0.8900527 , -0.6004841 ,\n",
      "       -0.37070945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6817495 ,  0.61736554,  1.0505251 , -0.8900527 , -0.6004841 ,\n",
      "       -0.37070945,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0122160197582843, next_state=array([ 0.6921007 ,  0.5968999 ,  1.0505009 , -0.91674334, -0.6190191 ,\n",
      "       -0.37070066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6921007 ,  0.5968999 ,  1.0505009 , -0.91674334, -0.6190191 ,\n",
      "       -0.37070066,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.423455923686759, next_state=array([ 0.70253164,  0.575754  ,  1.0604815 , -0.9482474 , -0.6402405 ,\n",
      "       -0.42442816,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.70253164,  0.575754  ,  1.0604815 , -0.9482474 , -0.6402405 ,\n",
      "       -0.42442816,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.372144392292455, next_state=array([ 0.712965  ,  0.5540128 ,  1.060448  , -0.97494465, -0.66146123,\n",
      "       -0.42441502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.712965  ,  0.5540128 ,  1.060448  , -0.97494465, -0.66146123,\n",
      "       -0.42441502,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.31112771030419, next_state=array([ 0.72333795,  0.5317573 ,  1.0522583 , -0.9970443 , -0.68032587,\n",
      "       -0.3772924 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.72333795,  0.5317573 ,  1.0522583 , -0.9970443 , -0.68032587,\n",
      "       -0.3772924 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.24909290621207, next_state=array([ 0.7337128 ,  0.5089055 ,  1.0522302 , -1.0237345 , -0.69919   ,\n",
      "       -0.37728313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7337128 ,  0.5089055 ,  1.0522302 , -1.0237345 , -0.69919   ,\n",
      "       -0.37728313,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.727259742521016, next_state=array([ 0.7446264 ,  0.4859999 ,  1.1052581 , -1.0259478 , -0.71723056,\n",
      "       -0.36081117,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7446264 ,  0.4859999 ,  1.1052581 , -1.0259478 , -0.71723056,\n",
      "       -0.36081117,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.2969182253317513, next_state=array([ 0.75554216,  0.46249753,  1.1052314 , -1.0526353 , -0.73527074,\n",
      "       -0.36080307,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.75554216,  0.46249753,  1.1052314 , -1.0526353 , -0.73527074,\n",
      "       -0.36080307,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.408045656904835, next_state=array([ 0.7671528 ,  0.43954697,  1.1745325 , -1.0282695 , -0.75330836,\n",
      "       -0.36075187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7671528 ,  0.43954697,  1.1745325 , -1.0282695 , -0.75330836,\n",
      "       -0.36075187,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.856076632328995, next_state=array([ 0.77913874,  0.41660523,  1.2118614 , -1.0280473 , -0.77136314,\n",
      "       -0.36109653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.77913874,  0.41660523,  1.2118614 , -1.0280473 , -0.77136314,\n",
      "       -0.36109653,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.362704438822436, next_state=array([ 0.7917202 ,  0.39420348,  1.271504  , -1.0044283 , -0.789894  ,\n",
      "       -0.3706165 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7917202 ,  0.39420348,  1.271504  , -1.0044283 , -0.789894  ,\n",
      "       -0.3706165 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.848687693032814, next_state=array([ 0.8043583,  0.371107 ,  1.2786427, -1.036699 , -0.810933 ,\n",
      "       -0.4207801,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.8043583,  0.371107 ,  1.2786427, -1.036699 , -0.810933 ,\n",
      "       -0.4207801,  0.       ,  0.       ], dtype=float32), action=1, reward=-2.885714770820725, next_state=array([ 0.81693935,  0.34749734,  1.2710154 , -1.058523  , -0.8295924 ,\n",
      "       -0.37318882,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.81693935,  0.34749734,  1.2710154 , -1.058523  , -0.8295924 ,\n",
      "       -0.37318882,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.701007418802901, next_state=array([ 0.8295614 ,  0.32321978,  1.276067  , -1.0892918 , -0.85007596,\n",
      "       -0.40967068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8295614 ,  0.32321978,  1.276067  , -1.0892918 , -0.85007596,\n",
      "       -0.40967068,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.274361261141705, next_state=array([ 0.8421421 ,  0.29841173,  1.2704233 , -1.1121114 , -0.8687206 ,\n",
      "       -0.3728928 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8421421 ,  0.29841173,  1.2704233 , -1.1121114 , -0.8687206 ,\n",
      "       -0.3728928 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-5.2765946642136035, next_state=array([ 0.8547863 ,  0.27290884,  1.2781949 , -1.1445361 , -0.8900282 ,\n",
      "       -0.4261517 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8547863 ,  0.27290884,  1.2781949 , -1.1445361 , -0.8900282 ,\n",
      "       -0.4261517 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5523220934127537, next_state=array([ 0.867396  ,  0.24688576,  1.2732127 , -1.166832  , -0.909423  ,\n",
      "       -0.38789684,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.867396  ,  0.24688576,  1.2732127 , -1.166832  , -0.909423  ,\n",
      "       -0.38789684,  0.        ,  0.        ], dtype=float32), action=2, reward=-8.838276354799053, next_state=array([ 0.8808931 ,  0.2210568 ,  1.3612939 , -1.1580431 , -0.92822933,\n",
      "       -0.3761285 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8808931 ,  0.2210568 ,  1.3612939 , -1.1580431 , -0.92822933,\n",
      "       -0.3761285 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.126084454378797, next_state=array([ 0.89433974,  0.19474247,  1.3543032 , -1.1782271 , -0.94423574,\n",
      "       -0.32012847,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.89433974,  0.19474247,  1.3543032 , -1.1782271 , -0.94423574,\n",
      "       -0.32012847,  0.        ,  0.        ], dtype=float32), action=2, reward=-7.003401242310065, next_state=array([ 0.9082953 ,  0.16827221,  1.404824  , -1.1851077 , -0.9599714 ,\n",
      "       -0.31471312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9082953 ,  0.16827221,  1.404824  , -1.1851077 , -0.9599714 ,\n",
      "       -0.31471312,  0.        ,  0.        ], dtype=float32), action=2, reward=-7.706397237717499, next_state=array([ 0.92276037,  0.14141645,  1.4551075 , -1.2018865 , -0.9748977 ,\n",
      "       -0.29852563,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.92276037,  0.14141645,  1.4551075 , -1.2018865 , -0.9748977 ,\n",
      "       -0.29852563,  0.        ,  0.        ], dtype=float32), action=3, reward=-5.117784924283597, next_state=array([ 0.93726045,  0.1138836 ,  1.4594871 , -1.2331486 , -0.99175113,\n",
      "       -0.3370685 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.93726045,  0.1138836 ,  1.4594871 , -1.2331486 , -0.99175113,\n",
      "       -0.3370685 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.562132340119206, next_state=array([ 0.9517628 ,  0.08575287,  1.4594572 , -1.2598286 , -1.0086042 ,\n",
      "       -0.33706185,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9517628 ,  0.08575287,  1.4594572 , -1.2598286 , -1.0086042 ,\n",
      "       -0.33706185,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.9983228867030105, next_state=array([ 0.9665693 ,  0.05749734,  1.4898989 , -1.2657616 , -1.0259461 ,\n",
      "       -0.3468389 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9665693 ,  0.05749734,  1.4898989 , -1.2657616 , -1.0259461 ,\n",
      "       -0.3468389 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.040281883667688, next_state=array([ 0.98135126,  0.02873047,  1.4861679 , -1.2874224 , -1.0412831 ,\n",
      "       -0.30674064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.98135126,  0.02873047,  1.4861679 , -1.2874224 , -1.0412831 ,\n",
      "       -0.30674064,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.7250555405541945, next_state=array([ 9.9613512e-01, -6.3481572e-04,  1.4861424e+00, -1.3140992e+00,\n",
      "       -1.0566199e+00, -3.0673561e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 9.9613512e-01, -6.3481572e-04,  1.4861424e+00, -1.3140992e+00,\n",
      "       -1.0566199e+00, -3.0673561e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-100, next_state=array([ 1.011767  , -0.02996996,  1.5706508 , -1.312696  , -1.0717189 ,\n",
      "       -0.301981  ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00316381,  1.4191802 , -0.3204754 ,  0.36710727,  0.00367287,\n",
      "        0.07259254,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.480026880930597, next_state=array([-0.00635195,  1.4282615 , -0.32234615,  0.4036063 ,  0.00716052,\n",
      "        0.06976014,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00635195,  1.4282615 , -0.32234615,  0.4036063 ,  0.00716052,\n",
      "        0.06976014,  0.        ,  0.        ], dtype=float32), action=3, reward=1.5962034454973388, next_state=array([-0.00946751,  1.4367435 , -0.31322688,  0.37696514,  0.00881518,\n",
      "        0.03309619,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00946751,  1.4367435 , -0.31322688,  0.37696514,  0.00881518,\n",
      "        0.03309619,  0.        ,  0.        ], dtype=float32), action=3, reward=1.84545827348805, next_state=array([-0.01250486,  1.4446349 , -0.3034199 ,  0.35072845,  0.00850156,\n",
      "       -0.00627297,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01250486,  1.4446349 , -0.3034199 ,  0.35072845,  0.00850156,\n",
      "       -0.00627297,  0.        ,  0.        ], dtype=float32), action=3, reward=1.93847754552644, next_state=array([-0.01547604,  1.4519389 , -0.2951177 ,  0.3246282 ,  0.00652224,\n",
      "       -0.03959004,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01547604,  1.4519389 , -0.2951177 ,  0.3246282 ,  0.00652224,\n",
      "       -0.03959004,  0.        ,  0.        ], dtype=float32), action=1, reward=0.41073798708146225, next_state=array([-0.01853723,  1.4586397 , -0.30640215,  0.29782185,  0.00680773,\n",
      "        0.00571006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01853723,  1.4586397 , -0.30640215,  0.29782185,  0.00680773,\n",
      "        0.00571006,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.320104734000057, next_state=array([-0.02158899,  1.4660633 , -0.30553478,  0.3299307 ,  0.00716511,\n",
      "        0.00714817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02158899,  1.4660633 , -0.30553478,  0.3299307 ,  0.00716511,\n",
      "        0.00714817,  0.        ,  0.        ], dtype=float32), action=3, reward=2.255609496800845, next_state=array([-0.02454329,  1.4728911 , -0.29329887,  0.30346853,  0.00506909,\n",
      "       -0.04192417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02454329,  1.4728911 , -0.29329887,  0.30346853,  0.00506909,\n",
      "       -0.04192417,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8403391690347803, next_state=array([-0.02752943,  1.4796772 , -0.2963571 ,  0.30161124,  0.00283056,\n",
      "       -0.04477468,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02752943,  1.4796772 , -0.2963571 ,  0.30161124,  0.00283056,\n",
      "       -0.04477468,  0.        ,  0.        ], dtype=float32), action=3, reward=2.099265528827375, next_state=array([-0.03043156,  1.4858644 , -0.28580952,  0.27498826, -0.00152118,\n",
      "       -0.08704257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03043156,  1.4858644 , -0.28580952,  0.27498826, -0.00152118,\n",
      "       -0.08704257,  0.        ,  0.        ], dtype=float32), action=1, reward=0.27878412696335997, next_state=array([-0.03340378,  1.4914515 , -0.29461306,  0.24830881, -0.00410405,\n",
      "       -0.05166195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03340378,  1.4914515 , -0.29461306,  0.24830881, -0.00410405,\n",
      "       -0.05166195,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.904677356206878, next_state=array([-0.03625374,  1.4975923 , -0.28294465,  0.27291903, -0.00612389,\n",
      "       -0.04040081,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03625374,  1.4975923 , -0.28294465,  0.27291903, -0.00612389,\n",
      "       -0.04040081,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9598790670765593, next_state=array([-0.03925858,  1.5042652 , -0.29768527,  0.29656124, -0.00889874,\n",
      "       -0.05550224,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03925858,  1.5042652 , -0.29768527,  0.29656124, -0.00889874,\n",
      "       -0.05550224,  0.        ,  0.        ], dtype=float32), action=3, reward=1.3689850026718215, next_state=array([-0.04220152,  1.5103266 , -0.28991893,  0.26936123, -0.01322886,\n",
      "       -0.08661011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04220152,  1.5103266 , -0.28991893,  0.26936123, -0.01322886,\n",
      "       -0.08661011,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7781640050822887, next_state=array([-0.04514437,  1.5157883 , -0.28990582,  0.24269572, -0.01755799,\n",
      "       -0.08659051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04514437,  1.5157883 , -0.28990582,  0.24269572, -0.01755799,\n",
      "       -0.08659051,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1908674988967958, next_state=array([-0.04822254,  1.5211953 , -0.30276045,  0.2402409 , -0.0225538 ,\n",
      "       -0.09992535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04822254,  1.5211953 , -0.30276045,  0.2402409 , -0.0225538 ,\n",
      "       -0.09992535,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.157829961343128, next_state=array([-0.05115614,  1.527242  , -0.28891665,  0.26866645, -0.02695892,\n",
      "       -0.08811042,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05115614,  1.527242  , -0.28891665,  0.26866645, -0.02695892,\n",
      "       -0.08811042,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2546016115513521, next_state=array([-0.05415916,  1.5326848 , -0.29759026,  0.24185346, -0.02962579,\n",
      "       -0.0533421 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05415916,  1.5326848 , -0.29759026,  0.24185346, -0.02962579,\n",
      "       -0.0533421 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.840743401436572, next_state=array([-0.05715141,  1.5383992 , -0.29649684,  0.253918  , -0.03232425,\n",
      "       -0.05397435,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05715141,  1.5383992 , -0.29649684,  0.253918  , -0.03232425,\n",
      "       -0.05397435,  0.        ,  0.        ], dtype=float32), action=0, reward=0.888602627125465, next_state=array([-0.06014366,  1.5435135 , -0.29648918,  0.22724168, -0.0350219 ,\n",
      "       -0.05395796,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06014366,  1.5435135 , -0.29648918,  0.22724168, -0.0350219 ,\n",
      "       -0.05395796,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.620347711001915, next_state=array([-0.06326075,  1.5495028 , -0.30823284,  0.26610625, -0.03846329,\n",
      "       -0.06883404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06326075,  1.5495028 , -0.30823284,  0.26610625, -0.03846329,\n",
      "       -0.06883404,  0.        ,  0.        ], dtype=float32), action=3, reward=1.524433819326391, next_state=array([-0.06628017,  1.5548782 , -0.2959834 ,  0.23874265, -0.04436371,\n",
      "       -0.11801876,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06628017,  1.5548782 , -0.2959834 ,  0.23874265, -0.04436371,\n",
      "       -0.11801876,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.060513856488444, next_state=array([-0.06927824,  1.5605214 , -0.29382637,  0.25061026, -0.05028364,\n",
      "       -0.11840945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06927824,  1.5605214 , -0.29382637,  0.25061026, -0.05028364,\n",
      "       -0.11840945,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7015861019061902, next_state=array([-0.07228346,  1.5662234 , -0.2944011 ,  0.2532101 , -0.05633967,\n",
      "       -0.12113126,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07228346,  1.5662234 , -0.2944011 ,  0.2532101 , -0.05633967,\n",
      "       -0.12113126,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5562862022834736, next_state=array([-0.07528839,  1.5713259 , -0.29438454,  0.22653581, -0.06239468,\n",
      "       -0.12111088,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07528839,  1.5713259 , -0.29438454,  0.22653581, -0.06239468,\n",
      "       -0.12111088,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.239001010938739, next_state=array([-0.07821798,  1.5765709 , -0.28704733,  0.23285155, -0.0682448 ,\n",
      "       -0.11700195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07821798,  1.5765709 , -0.28704733,  0.23285155, -0.0682448 ,\n",
      "       -0.11700195,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0953876533242406, next_state=array([-0.08107948,  1.582216  , -0.28034472,  0.25062695, -0.07399128,\n",
      "       -0.11492966,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08107948,  1.582216  , -0.28034472,  0.25062695, -0.07399128,\n",
      "       -0.11492966,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.207565627870099, next_state=array([-0.08383312,  1.5880394 , -0.26988426,  0.25853056, -0.07941774,\n",
      "       -0.10852921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08383312,  1.5880394 , -0.26988426,  0.25853056, -0.07941774,\n",
      "       -0.10852921,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8346893319303093, next_state=array([-0.08639622,  1.594389  , -0.25144172,  0.28194502, -0.08424152,\n",
      "       -0.0964756 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08639622,  1.594389  , -0.25144172,  0.28194502, -0.08424152,\n",
      "       -0.0964756 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.925405546927766, next_state=array([-0.08900747,  1.6007867 , -0.25586462,  0.28403556, -0.08945558,\n",
      "       -0.10428111,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08900747,  1.6007867 , -0.25586462,  0.28403556, -0.08945558,\n",
      "       -0.10428111,  0.        ,  0.        ], dtype=float32), action=0, reward=0.8225679051348607, next_state=array([-0.09161873,  1.6065847 , -0.25586492,  0.2573666 , -0.09466963,\n",
      "       -0.10428096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09161873,  1.6065847 , -0.25586492,  0.2573666 , -0.09466963,\n",
      "       -0.10428096,  0.        ,  0.        ], dtype=float32), action=1, reward=0.09789292076681136, next_state=array([-0.09431744,  1.6117979 , -0.26685894,  0.23149918, -0.09766324,\n",
      "       -0.05987169,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09431744,  1.6117979 , -0.26685894,  0.23149918, -0.09766324,\n",
      "       -0.05987169,  0.        ,  0.        ], dtype=float32), action=0, reward=0.9112795996041143, next_state=array([-0.09701624,  1.616411  , -0.26685908,  0.20483176, -0.10065682,\n",
      "       -0.05987163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09701624,  1.616411  , -0.26685908,  0.20483176, -0.10065682,\n",
      "       -0.05987163,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.732904514288481, next_state=array([-0.0995821 ,  1.6215948 , -0.25382087,  0.23019964, -0.10340186,\n",
      "       -0.05490087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0995821 ,  1.6215948 , -0.25382087,  0.23019964, -0.10340186,\n",
      "       -0.05490087,  0.        ,  0.        ], dtype=float32), action=3, reward=1.4456411355008651, next_state=array([-0.10208006,  1.6261803 , -0.245329  ,  0.2034842 , -0.10784025,\n",
      "       -0.0887676 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10208006,  1.6261803 , -0.245329  ,  0.2034842 , -0.10784025,\n",
      "       -0.0887676 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7753261370808104, next_state=array([-0.10457812,  1.630166  , -0.24532929,  0.17681591, -0.11227861,\n",
      "       -0.08876748,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10457812,  1.630166  , -0.24532929,  0.17681591, -0.11227861,\n",
      "       -0.08876748,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2589802493140099, next_state=array([-0.10708217,  1.63417   , -0.24569249,  0.17759791, -0.1169586 ,\n",
      "       -0.09360001,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10708217,  1.63417   , -0.24569249,  0.17759791, -0.1169586 ,\n",
      "       -0.09360001,  0.        ,  0.        ], dtype=float32), action=0, reward=0.6569089178314869, next_state=array([-0.10958624,  1.6375746 , -0.24569282,  0.1509294 , -0.1216386 ,\n",
      "       -0.09359981,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10958624,  1.6375746 , -0.24569282,  0.1509294 , -0.1216386 ,\n",
      "       -0.09359981,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5518360007349259, next_state=array([-0.11193065,  1.6412779 , -0.23013668,  0.16423512, -0.12592252,\n",
      "       -0.08567878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11193065,  1.6412779 , -0.23013668,  0.16423512, -0.12592252,\n",
      "       -0.08567878,  0.        ,  0.        ], dtype=float32), action=3, reward=1.38298412423086, next_state=array([-0.11419239,  1.6443732 , -0.21977237,  0.13702045, -0.13229157,\n",
      "       -0.12738067,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11419239,  1.6443732 , -0.21977237,  0.13702045, -0.13229157,\n",
      "       -0.12738067,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5723675342766683, next_state=array([-0.1162837 ,  1.6477495 , -0.20316318,  0.1495164 , -0.13823786,\n",
      "       -0.11892587,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1162837 ,  1.6477495 , -0.20316318,  0.1495164 , -0.13823786,\n",
      "       -0.11892587,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5969255613672999, next_state=array([-0.11837492,  1.6505263 , -0.20316374,  0.1228468 , -0.14418414,\n",
      "       -0.11892556,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11837492,  1.6505263 , -0.20316374,  0.1228468 , -0.14418414,\n",
      "       -0.11892556,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6563589518798265, next_state=array([-0.12042656,  1.6539893 , -0.19881716,  0.15327951, -0.15051934,\n",
      "       -0.12670393,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12042656,  1.6539893 , -0.19881716,  0.15327951, -0.15051934,\n",
      "       -0.12670393,  0.        ,  0.        ], dtype=float32), action=3, reward=1.377609223606471, next_state=array([-0.12238435,  1.6568344 , -0.18703076,  0.12553991, -0.15924896,\n",
      "       -0.17459254,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12238435,  1.6568344 , -0.18703076,  0.12553991, -0.15924896,\n",
      "       -0.17459254,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0140688354983933, next_state=array([-0.12425423,  1.6590676 , -0.17604047,  0.09803695, -0.17020157,\n",
      "       -0.21905258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12425423,  1.6590676 , -0.17604047,  0.09803695, -0.17020157,\n",
      "       -0.21905258,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.11813946096927452, next_state=array([-0.1261239 ,  1.6607022 , -0.17604293,  0.07136037, -0.1811541 ,\n",
      "       -0.21905074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1261239 ,  1.6607022 , -0.17604293,  0.07136037, -0.1811541 ,\n",
      "       -0.21905074,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1928536381797403, next_state=array([-0.12807122,  1.6617622 , -0.18583652,  0.04600164, -0.19008806,\n",
      "       -0.17867959,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12807122,  1.6617622 , -0.18583652,  0.04600164, -0.19008806,\n",
      "       -0.17867959,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4939814570045371, next_state=array([-0.13001843,  1.6622235 , -0.18583837,  0.01932841, -0.19902198,\n",
      "       -0.1786786 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13001843,  1.6622235 , -0.18583837,  0.01932841, -0.19902198,\n",
      "       -0.1786786 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.10111637213916083, next_state=array([-0.13187084,  1.662062  , -0.17395711, -0.00872108, -0.21039142,\n",
      "       -0.22738874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13187084,  1.662062  , -0.17395711, -0.00872108, -0.21039142,\n",
      "       -0.22738874,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4109471408401646, next_state=array([-0.13372298,  1.6613024 , -0.17396039, -0.03539834, -0.22176073,\n",
      "       -0.22738671,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13372298,  1.6613024 , -0.17396039, -0.03539834, -0.22176073,\n",
      "       -0.22738671,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8261686192707713, next_state=array([-0.13537511,  1.6609145 , -0.1542336 , -0.01892769, -0.23288704,\n",
      "       -0.22252627,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13537511,  1.6609145 , -0.1542336 , -0.01892769, -0.23288704,\n",
      "       -0.22252627,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3948475509317277, next_state=array([-0.13711557,  1.6599629 , -0.16538534, -0.04368851, -0.2416738 ,\n",
      "       -0.17573473,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13711557,  1.6599629 , -0.16538534, -0.04368851, -0.2416738 ,\n",
      "       -0.17573473,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5324732344289032, next_state=array([-0.13862868,  1.6595097 , -0.14286645, -0.02156092, -0.2502498 ,\n",
      "       -0.17152074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13862868,  1.6595097 , -0.14286645, -0.02156092, -0.2502498 ,\n",
      "       -0.17152074,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3960743612204851, next_state=array([-0.14014158,  1.6584572 , -0.14286868, -0.04823356, -0.2588258 ,\n",
      "       -0.17151989,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14014158,  1.6584572 , -0.14286868, -0.04823356, -0.2588258 ,\n",
      "       -0.17151989,  0.        ,  0.        ], dtype=float32), action=2, reward=1.493288953307524, next_state=array([-0.14142227,  1.6576804 , -0.12002152, -0.03596402, -0.26705563,\n",
      "       -0.16459644,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14142227,  1.6576804 , -0.12002152, -0.03596402, -0.26705563,\n",
      "       -0.16459644,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.200873275270253, next_state=array([-0.14276429,  1.6563319 , -0.12778726, -0.06112173, -0.2736347 ,\n",
      "       -0.1315814 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14276429,  1.6563319 , -0.12778726, -0.06112173, -0.2736347 ,\n",
      "       -0.1315814 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4405100553944112, next_state=array([-0.14403763,  1.654346  , -0.11907537, -0.08982991, -0.28210208,\n",
      "       -0.16934833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14403763,  1.654346  , -0.11907537, -0.08982991, -0.28210208,\n",
      "       -0.16934833,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9830121264013474, next_state=array([-0.14521971,  1.6517199 , -0.10760102, -0.11880001, -0.2930187 ,\n",
      "       -0.2183332 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14521971,  1.6517199 , -0.10760102, -0.11880001, -0.2930187 ,\n",
      "       -0.2183332 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7004700189934965, next_state=array([-0.14620027,  1.6492561 , -0.08769087, -0.11161888, -0.30372214,\n",
      "       -0.21406889,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14620027,  1.6492561 , -0.08769087, -0.11161888, -0.30372214,\n",
      "       -0.21406889,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.188532792955384, next_state=array([-0.14726734,  1.6462321 , -0.09861623, -0.13610771, -0.31209138,\n",
      "       -0.16738497,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14726734,  1.6462321 , -0.09861623, -0.13610771, -0.31209138,\n",
      "       -0.16738497,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4633854318729904, next_state=array([-0.14815398,  1.6441604 , -0.07994775, -0.09397837, -0.32113665,\n",
      "       -0.18090586,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14815398,  1.6441604 , -0.07994775, -0.09397837, -0.32113665,\n",
      "       -0.18090586,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.12714633575994866, next_state=array([-0.14902373,  1.6423411 , -0.07756707, -0.08297851, -0.3309381 ,\n",
      "       -0.19602902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14902373,  1.6423411 , -0.07756707, -0.08297851, -0.3309381 ,\n",
      "       -0.19602902,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6588938855793445, next_state=array([-0.14980488,  1.6398864 , -0.06649326, -0.11180819, -0.34310198,\n",
      "       -0.24327767,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14980488,  1.6398864 , -0.06649326, -0.11180819, -0.34310198,\n",
      "       -0.24327767,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.348670678455703, next_state=array([-0.15049544,  1.6367842 , -0.05507975, -0.14127013, -0.3577732 ,\n",
      "       -0.2934254 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15049544,  1.6367842 , -0.05507975, -0.14127013, -0.3577732 ,\n",
      "       -0.2934254 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.56357807267605, next_state=array([-0.15124169,  1.633116  , -0.06222815, -0.16618161, -0.37087062,\n",
      "       -0.26194802,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15124169,  1.633116  , -0.06222815, -0.16618161, -0.37087062,\n",
      "       -0.26194802,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.6011544209248414, next_state=array([-0.15192719,  1.6288102 , -0.05457531, -0.19506623, -0.38569966,\n",
      "       -0.29658163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15192719,  1.6288102 , -0.05457531, -0.19506623, -0.38569966,\n",
      "       -0.29658163,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.4329690978115637, next_state=array([-0.1527011 ,  1.6239476 , -0.06578622, -0.21929838, -0.39810207,\n",
      "       -0.2480485 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1527011 ,  1.6239476 , -0.06578622, -0.21929838, -0.39810207,\n",
      "       -0.2480485 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.49883090828616333, next_state=array([-0.15317221,  1.6192842 , -0.03586604, -0.21046354, -0.41016796,\n",
      "       -0.24131855,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15317221,  1.6192842 , -0.03586604, -0.21046354, -0.41016796,\n",
      "       -0.24131855,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7600574279928878, next_state=array([-0.15311737,  1.6151904 ,  0.01592667, -0.18501987, -0.4214418 ,\n",
      "       -0.22547643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15311737,  1.6151904 ,  0.01592667, -0.18501987, -0.4214418 ,\n",
      "       -0.22547643,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.018610647336344, next_state=array([-0.15297899,  1.6104393 ,  0.02648012, -0.21499506, -0.43515518,\n",
      "       -0.27426773,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15297899,  1.6104393 ,  0.02648012, -0.21499506, -0.43515518,\n",
      "       -0.27426773,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.4877062616129706, next_state=array([-0.15283975,  1.6050906 ,  0.02647033, -0.24167603, -0.4488684 ,\n",
      "       -0.27426422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15283975,  1.6050906 ,  0.02647033, -0.24167603, -0.4488684 ,\n",
      "       -0.27426422,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0069169375934153, next_state=array([-0.15275402,  1.5991867 ,  0.01956899, -0.2659776 , -0.46094787,\n",
      "       -0.24158947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15275402,  1.5991867 ,  0.01956899, -0.2659776 , -0.46094787,\n",
      "       -0.24158947,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3103287840761313, next_state=array([-0.15235634,  1.5941651 ,  0.05136307, -0.22707194, -0.4737691 ,\n",
      "       -0.25642458,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15235634,  1.5941651 ,  0.05136307, -0.22707194, -0.4737691 ,\n",
      "       -0.25642458,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5821572748045, next_state=array([-0.15204783,  1.5886014 ,  0.04007031, -0.2504682 , -0.48401397,\n",
      "       -0.20489764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15204783,  1.5886014 ,  0.04007031, -0.2504682 , -0.48401397,\n",
      "       -0.20489764,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.672932985814184, next_state=array([-0.15168066,  1.5823833 ,  0.04753307, -0.2801979 , -0.49612013,\n",
      "       -0.24212286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15168066,  1.5823833 ,  0.04753307, -0.2801979 , -0.49612013,\n",
      "       -0.24212286,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.784044390839624, next_state=array([-0.15125379,  1.575515  ,  0.0550857 , -0.30979666, -0.5100833 ,\n",
      "       -0.2792637 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15125379,  1.575515  ,  0.0550857 , -0.30979666, -0.5100833 ,\n",
      "       -0.2792637 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.716149187322418, next_state=array([-0.15039377,  1.5686984 ,  0.09762982, -0.30735585, -0.52327925,\n",
      "       -0.26391807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15039377,  1.5686984 ,  0.09762982, -0.30735585, -0.52327925,\n",
      "       -0.26391807,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.864057636354714, next_state=array([-0.14946651,  1.5612352 ,  0.1059978 , -0.33687913, -0.538465  ,\n",
      "       -0.30371535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14946651,  1.5612352 ,  0.1059978 , -0.33687913, -0.538465  ,\n",
      "       -0.30371535,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.557295762789464, next_state=array([-0.14860049,  1.5532339 ,  0.09801193, -0.3602187 , -0.5516322 ,\n",
      "       -0.26334366,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14860049,  1.5532339 ,  0.09801193, -0.3602187 , -0.5516322 ,\n",
      "       -0.26334366,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2985581791004506, next_state=array([-0.14735003,  1.5458192 ,  0.1367133 , -0.33439076, -0.5652029 ,\n",
      "       -0.27141312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14735003,  1.5458192 ,  0.1367133 , -0.33439076, -0.5652029 ,\n",
      "       -0.27141312,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.4405886040815856, next_state=array([-0.14565782,  1.5384701 ,  0.18024212, -0.3313442 , -0.5781482 ,\n",
      "       -0.2589056 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14565782,  1.5384701 ,  0.18024212, -0.3313442 , -0.5781482 ,\n",
      "       -0.2589056 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.156934959267079, next_state=array([-0.14340277,  1.5315834 ,  0.23611161, -0.31075376, -0.59070295,\n",
      "       -0.25109535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14340277,  1.5315834 ,  0.23611161, -0.31075376, -0.59070295,\n",
      "       -0.25109535,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9807709186589932, next_state=array([-0.14093609,  1.5247707 ,  0.2574735 , -0.3076797 , -0.60360265,\n",
      "       -0.2579934 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14093609,  1.5247707 ,  0.2574735 , -0.3076797 , -0.60360265,\n",
      "       -0.2579934 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.777992390686022, next_state=array([-0.13839741,  1.517284  ,  0.26660842, -0.3386836 , -0.6189378 ,\n",
      "       -0.30670246,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13839741,  1.517284  ,  0.26660842, -0.3386836 , -0.6189378 ,\n",
      "       -0.30670246,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9888071300315344, next_state=array([-0.13561459,  1.5096798 ,  0.29082116, -0.34400484, -0.6342174 ,\n",
      "       -0.30559063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13561459,  1.5096798 ,  0.29082116, -0.34400484, -0.6342174 ,\n",
      "       -0.30559063,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7543983915966237, next_state=array([-0.13283062,  1.5014783 ,  0.29080403, -0.3706874 , -0.6494966 ,\n",
      "       -0.3055857 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13283062,  1.5014783 ,  0.29080403, -0.3706874 , -0.6494966 ,\n",
      "       -0.3055857 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.898365275446024, next_state=array([-0.13009605,  1.4927473 ,  0.284173  , -0.39353943, -0.66284555,\n",
      "       -0.2669792 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13009605,  1.4927473 ,  0.284173  , -0.39353943, -0.66284555,\n",
      "       -0.2669792 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6482138760481166, next_state=array([-0.1274168 ,  1.4834905 ,  0.27686778, -0.41611397, -0.6740893 ,\n",
      "       -0.22487423,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1274168 ,  1.4834905 ,  0.27686778, -0.41611397, -0.6740893 ,\n",
      "       -0.22487423,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3608243732193728, next_state=array([-0.12473688,  1.473635  ,  0.27685794, -0.442789  , -0.68533295,\n",
      "       -0.22487226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12473688,  1.473635  ,  0.27685794, -0.442789  , -0.68533295,\n",
      "       -0.22487226,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0485459709334917, next_state=array([-0.12165127,  1.463963  ,  0.31740856, -0.43473855, -0.69665277,\n",
      "       -0.22639665,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12165127,  1.463963  ,  0.31740856, -0.43473855, -0.69665277,\n",
      "       -0.22639665,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2589197240705516, next_state=array([-0.11856489,  1.4536921 ,  0.3173983 , -0.4614135 , -0.7079725 ,\n",
      "       -0.2263947 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11856489,  1.4536921 ,  0.3173983 , -0.4614135 , -0.7079725 ,\n",
      "       -0.2263947 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.859116790382518, next_state=array([-0.11493673,  1.4436328 ,  0.3712871 , -0.45195124, -0.7190161 ,\n",
      "       -0.2208705 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11493673,  1.4436328 ,  0.3712871 , -0.45195124, -0.7190161 ,\n",
      "       -0.2208705 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0710950517242552, next_state=array([-0.11125898,  1.4328963 ,  0.37770936, -0.48305428, -0.7321309 ,\n",
      "       -0.26229614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11125898,  1.4328963 ,  0.37770936, -0.48305428, -0.7321309 ,\n",
      "       -0.26229614,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6243458742322217, next_state=array([-0.10699196,  1.4227111 ,  0.43678156, -0.45879003, -0.7455922 ,\n",
      "       -0.2692263 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10699196,  1.4227111 ,  0.43678156, -0.45879003, -0.7455922 ,\n",
      "       -0.2692263 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3232357536816994, next_state=array([-0.10277128,  1.411999  ,  0.43059716, -0.48139256, -0.75710136,\n",
      "       -0.23018353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10277128,  1.411999  ,  0.43059716, -0.48139256, -0.75710136,\n",
      "       -0.23018353,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.16751015633655, next_state=array([-0.09808598,  1.4017861 ,  0.47753185, -0.45962927, -0.7693767 ,\n",
      "       -0.24550728,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09808598,  1.4017861 ,  0.47753185, -0.45962927, -0.7693767 ,\n",
      "       -0.24550728,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.432492248550136, next_state=array([-0.09311561,  1.3916472 ,  0.5062754 , -0.4566563 , -0.7821512 ,\n",
      "       -0.25549075,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09311561,  1.3916472 ,  0.5062754 , -0.4566563 , -0.7821512 ,\n",
      "       -0.25549075,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0570619739742413, next_state=array([-0.08808756,  1.3808343 ,  0.5134906 , -0.487742  , -0.797126  ,\n",
      "       -0.29949552,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08808756,  1.3808343 ,  0.5134906 , -0.487742  , -0.797126  ,\n",
      "       -0.29949552,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.3367127999455577, next_state=array([-0.08300066,  1.3693359 ,  0.52090216, -0.5195096 , -0.8145148 ,\n",
      "       -0.34777695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08300066,  1.3693359 ,  0.52090216, -0.5195096 , -0.8145148 ,\n",
      "       -0.34777695,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4074808615673646, next_state=array([-0.07791166,  1.3572401 ,  0.52087474, -0.5461939 , -0.8319033 ,\n",
      "       -0.3477697 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07791166,  1.3572401 ,  0.52087474, -0.5461939 , -0.8319033 ,\n",
      "       -0.3477697 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.5018078710473604, next_state=array([-0.07277231,  1.3444502 ,  0.5273284 , -0.5784121 , -0.8517109 ,\n",
      "       -0.39615265,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07277231,  1.3444502 ,  0.5273284 , -0.5784121 , -0.8517109 ,\n",
      "       -0.39615265,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4015786900253306, next_state=array([-0.06769562,  1.3311598 ,  0.5189756 , -0.5994196 , -0.8688075 ,\n",
      "       -0.34193   ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06769562,  1.3311598 ,  0.5189756 , -0.5994196 , -0.8688075 ,\n",
      "       -0.34193   ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.0018210132983425, next_state=array([-0.06186008,  1.3181192 ,  0.59446484, -0.5883194 , -0.8856377 ,\n",
      "       -0.33660373,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06186008,  1.3181192 ,  0.59446484, -0.5883194 , -0.8856377 ,\n",
      "       -0.33660373,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3759656286196946, next_state=array([-0.05606403,  1.3045508 ,  0.58911383, -0.6109066 , -0.9005959 ,\n",
      "       -0.29916456,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05606403,  1.3045508 ,  0.58911383, -0.6109066 , -0.9005959 ,\n",
      "       -0.29916456,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.842651039456, next_state=array([-0.05022869,  1.2903125 ,  0.59400564, -0.6417591 , -0.9174003 ,\n",
      "       -0.33608752,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05022869,  1.2903125 ,  0.59400564, -0.6417591 , -0.9174003 ,\n",
      "       -0.33608752,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.856934464822973, next_state=array([-0.04360018,  1.2761141 ,  0.6727007 , -0.6397415 , -0.9335412 ,\n",
      "       -0.3228178 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04360018,  1.2761141 ,  0.6727007 , -0.6397415 , -0.9335412 ,\n",
      "       -0.3228178 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7633709755455402, next_state=array([-0.03702278,  1.2614322 ,  0.66569036, -0.6597751 , -0.9468326 ,\n",
      "       -0.26582783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03702278,  1.2614322 ,  0.66569036, -0.6597751 , -0.9468326 ,\n",
      "       -0.26582783,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.333658943205353, next_state=array([-0.03001461,  1.2463387 ,  0.70821726, -0.6777566 , -0.95943123,\n",
      "       -0.2519743 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03001461,  1.2463387 ,  0.70821726, -0.6777566 , -0.95943123,\n",
      "       -0.2519743 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5376960772211987, next_state=array([-0.0230053 ,  1.2306466 ,  0.70820093, -0.70443094, -0.97202975,\n",
      "       -0.25197154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0230053 ,  1.2306466 ,  0.70820093, -0.70443094, -0.97202975,\n",
      "       -0.25197154,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.933282395658625, next_state=array([-0.01516933,  1.2149328 ,  0.79034775, -0.7050651 , -0.98394704,\n",
      "       -0.23834643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01516933,  1.2149328 ,  0.79034775, -0.7050651 , -0.98394704,\n",
      "       -0.23834643,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3461731466331912, next_state=array([-0.00733242,  1.1986201 ,  0.79033303, -0.7317384 , -0.9958642 ,\n",
      "       -0.2383441 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00733242,  1.1986201 ,  0.79033303, -0.7317384 , -0.9958642 ,\n",
      "       -0.2383441 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.14211424343719045, next_state=array([ 4.5242309e-04,  1.1818186e+00,  7.8346086e-01, -7.5190818e-01,\n",
      "       -1.0049744e+00, -1.8220267e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 4.5242309e-04,  1.1818186e+00,  7.8346086e-01, -7.5190818e-01,\n",
      "       -1.0049744e+00, -1.8220267e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-2.118325039289202, next_state=array([ 0.00828066,  1.1643171 ,  0.789066  , -0.7844712 , -1.0165652 ,\n",
      "       -0.23181371,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00828066,  1.1643171 ,  0.789066  , -0.7844712 , -1.0165652 ,\n",
      "       -0.23181371,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.161467722447628, next_state=array([ 0.01668482,  1.1467092 ,  0.84648865, -0.78919417, -1.0280478 ,\n",
      "       -0.22965106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01668482,  1.1467092 ,  0.84648865, -0.78919417, -1.0280478 ,\n",
      "       -0.22965106,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.17729222032591, next_state=array([ 0.02508993,  1.128502  ,  0.84647447, -0.81586653, -1.0395303 ,\n",
      "       -0.22964898,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02508993,  1.128502  ,  0.84647447, -0.81586653, -1.0395303 ,\n",
      "       -0.22964898,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.188353477934099, next_state=array([ 0.03353243,  1.1095932 ,  0.8513231 , -0.8485411 , -1.0534598 ,\n",
      "       -0.2785894 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03353243,  1.1095932 ,  0.8513231 , -0.8485411 , -1.0534598 ,\n",
      "       -0.2785894 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3685414897244073, next_state=array([ 0.04197645,  1.0900854 ,  0.85130215, -0.8752158 , -1.067389  ,\n",
      "       -0.2785856 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04197645,  1.0900854 ,  0.85130215, -0.8752158 , -1.067389  ,\n",
      "       -0.2785856 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3684837352441537, next_state=array([ 0.05038948,  1.0700874 ,  0.8468305 , -0.8955707 , -1.078798  ,\n",
      "       -0.22818117,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05038948,  1.0700874 ,  0.8468305 , -0.8955707 , -1.078798  ,\n",
      "       -0.22818117,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.16717127435154452, next_state=array([ 0.0587719 ,  1.0495893 ,  0.84254706, -0.9164344 , -1.0878705 ,\n",
      "       -0.18144917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0587719 ,  1.0495893 ,  0.84254706, -0.9164344 , -1.0878705 ,\n",
      "       -0.18144917,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7525958508263375, next_state=array([ 0.06718998,  1.028404  ,  0.8470396 , -0.94830483, -1.0990999 ,\n",
      "       -0.22458827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06718998,  1.028404  ,  0.8470396 , -0.94830483, -1.0990999 ,\n",
      "       -0.22458827,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.407159781531607, next_state=array([ 0.0764431 ,  1.0070852 ,  0.9302219 , -0.9539945 , -1.1098555 ,\n",
      "       -0.21511357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0764431 ,  1.0070852 ,  0.9302219 , -0.9539945 , -1.1098555 ,\n",
      "       -0.21511357,  0.        ,  0.        ], dtype=float32), action=1, reward=0.004657716696187891, next_state=array([ 0.08567019,  0.9852701 ,  0.9264528 , -0.974645  , -1.1182408 ,\n",
      "       -0.16770549,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08567019,  0.9852701 ,  0.9264528 , -0.974645  , -1.1182408 ,\n",
      "       -0.16770549,  0.        ,  0.        ], dtype=float32), action=1, reward=0.44612120352488316, next_state=array([ 0.09485473,  0.96296555,  0.9209526 , -0.99477255, -1.1239247 ,\n",
      "       -0.1136777 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09485473,  0.96296555,  0.9209526 , -0.99477255, -1.1239247 ,\n",
      "       -0.1136777 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.037263966599244, next_state=array([ 0.10461493,  0.9401914 ,  0.9781562 , -1.0151684 , -1.1288209 ,\n",
      "       -0.09792306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10461493,  0.9401914 ,  0.9781562 , -1.0151684 , -1.1288209 ,\n",
      "       -0.09792306,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3782003173513135, next_state=array([ 0.1144104 ,  0.9166934 ,  0.9828966 , -1.0491229 , -1.1366098 ,\n",
      "       -0.15577783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1144104 ,  0.9166934 ,  0.9828966 , -1.0491229 , -1.1366098 ,\n",
      "       -0.15577783,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5930624470571797, next_state=array([ 0.12417383,  0.8927174 ,  0.97844493, -1.0686431 , -1.1415759 ,\n",
      "       -0.09932391,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12417383,  0.8927174 ,  0.97844493, -1.0686431 , -1.1415759 ,\n",
      "       -0.09932391,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6057960058647904, next_state=array([ 0.13391638,  0.8682368 ,  0.97544146, -1.0897604 , -1.1443868 ,\n",
      "       -0.05621631,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13391638,  0.8682368 ,  0.97544146, -1.0897604 , -1.1443868 ,\n",
      "       -0.05621631,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8440351128268457, next_state=array([ 0.14363089,  0.8432439 ,  0.97175944, -1.1112434 , -1.1451112 ,\n",
      "       -0.01448819,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14363089,  0.8432439 ,  0.97175944, -1.1112434 , -1.1451112 ,\n",
      "       -0.01448819,  0.        ,  0.        ], dtype=float32), action=0, reward=0.2581580360375142, next_state=array([ 0.15334539,  0.8176509 ,  0.9717592 , -1.13791   , -1.1458356 ,\n",
      "       -0.01448779,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15334539,  0.8176509 ,  0.9717592 , -1.13791   , -1.1458356 ,\n",
      "       -0.01448779,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8520782248605474, next_state=array([ 0.16310024,  0.7913468 ,  0.9769017 , -1.1711669 , -1.1492506 ,\n",
      "       -0.06829877,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16310024,  0.7913468 ,  0.9769017 , -1.1711669 , -1.1492506 ,\n",
      "       -0.06829877,  0.        ,  0.        ], dtype=float32), action=0, reward=0.025088250639555554, next_state=array([ 0.1728551 ,  0.76444304,  0.97690046, -1.1978339 , -1.1526655 ,\n",
      "       -0.06829827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1728551 ,  0.76444304,  0.97690046, -1.1978339 , -1.1526655 ,\n",
      "       -0.06829827,  0.        ,  0.        ], dtype=float32), action=1, reward=1.0785517799850777, next_state=array([ 0.18257952,  0.73705846,  0.9727106 , -1.2174919 , -1.153322  ,\n",
      "       -0.01312879,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18257952,  0.73705846,  0.9727106 , -1.2174919 , -1.153322  ,\n",
      "       -0.01312879,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.48051485084013623, next_state=array([ 0.1923255 ,  0.70899   ,  0.97566354, -1.249094  , -1.1559212 ,\n",
      "       -0.05198532,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1923255 ,  0.70899   ,  0.97566354, -1.249094  , -1.1559212 ,\n",
      "       -0.05198532,  0.        ,  0.        ], dtype=float32), action=0, reward=0.12169062777763884, next_state=array([ 0.20207158,  0.6803215 ,  0.9756628 , -1.2757609 , -1.1585206 ,\n",
      "       -0.0519865 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20207158,  0.6803215 ,  0.9756628 , -1.2757609 , -1.1585206 ,\n",
      "       -0.0519865 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.150472382858754, next_state=array([ 0.21220474,  0.6511445 ,  1.0141732 , -1.2980798 , -1.1606612 ,\n",
      "       -0.04281276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21220474,  0.6511445 ,  1.0141732 , -1.2980798 , -1.1606612 ,\n",
      "       -0.04281276,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9624325221700201, next_state=array([ 0.22231083,  0.62145525,  1.0106412 , -1.3195702 , -1.1607282 ,\n",
      "       -0.0013391 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22231083,  0.62145525,  1.0106412 , -1.3195702 , -1.1607282 ,\n",
      "       -0.0013391 ,  0.        ,  0.        ], dtype=float32), action=1, reward=1.3632223012652684, next_state=array([ 0.23238239,  0.5912759 ,  1.006125  , -1.3397295 , -1.1581821 ,\n",
      "        0.05092033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23238239,  0.5912759 ,  1.006125  , -1.3397295 , -1.1581821 ,\n",
      "        0.05092033,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5761205909216187, next_state=array([ 0.24245405,  0.5604965 ,  1.0061243 , -1.3663965 , -1.1556361 ,\n",
      "        0.05092032,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24245405,  0.5604965 ,  1.0061243 , -1.3663965 , -1.1556361 ,\n",
      "        0.05092032,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.29407404960121997, next_state=array([ 0.25254497,  0.52902454,  1.0089076 , -1.3984789 , -1.1551857 ,\n",
      "        0.00900772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25254497,  0.52902454,  1.0089076 , -1.3984789 , -1.1551857 ,\n",
      "        0.00900772,  0.        ,  0.        ], dtype=float32), action=1, reward=1.016254684540827, next_state=array([ 0.26261473,  0.49703652,  1.0059941 , -1.4202164 , -1.1527975 ,\n",
      "        0.04776416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26261473,  0.49703652,  1.0059941 , -1.4202164 , -1.1527975 ,\n",
      "        0.04776416,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7955105759769754, next_state=array([ 0.27272606,  0.46432737,  1.0113508 , -1.454065  , -1.153322  ,\n",
      "       -0.01048948,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27272606,  0.46432737,  1.0113508 , -1.454065  , -1.153322  ,\n",
      "       -0.01048948,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9664955124037806, next_state=array([ 0.2828743 ,  0.4309192 ,  1.0160286 , -1.4866194 , -1.1562574 ,\n",
      "       -0.05870812,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2828743 ,  0.4309192 ,  1.0160286 , -1.4866194 , -1.1562574 ,\n",
      "       -0.05870812,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5898577018722062, next_state=array([ 0.2929966 ,  0.39701107,  1.0124918 , -1.5074115 , -1.1568778 ,\n",
      "       -0.01240736,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2929966 ,  0.39701107,  1.0124918 , -1.5074115 , -1.1568778 ,\n",
      "       -0.01240736,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0457266897466002, next_state=array([ 0.30314606,  0.3624163 ,  1.0160244 , -1.5392003 , -1.1595527 ,\n",
      "       -0.05349962,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30314606,  0.3624163 ,  1.0160244 , -1.5392003 , -1.1595527 ,\n",
      "       -0.05349962,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.585378366523957, next_state=array([ 0.3141411 ,  0.32747835,  1.1002464 , -1.5539354 , -1.1613904 ,\n",
      "       -0.0367539 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3141411 ,  0.32747835,  1.1002464 , -1.5539354 , -1.1613904 ,\n",
      "       -0.0367539 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.68413664932649, next_state=array([ 0.3251361 ,  0.29194045,  1.1002461 , -1.5806022 , -1.1632282 ,\n",
      "       -0.03675395,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3251361 ,  0.29194045,  1.1002461 , -1.5806022 , -1.1632282 ,\n",
      "       -0.03675395,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.05320397388211859, next_state=array([ 0.3360978 ,  0.2558927 ,  1.0960325 , -1.6018986 , -1.1628708 ,\n",
      "        0.00714894,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3360978 ,  0.2558927 ,  1.0960325 , -1.6018986 , -1.1628708 ,\n",
      "        0.00714894,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.015819833286446, next_state=array([ 0.3479746 ,  0.22000359,  1.1877154 , -1.5951396 , -1.1629823 ,\n",
      "       -0.00223145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3479746 ,  0.22000359,  1.1877154 , -1.5951396 , -1.1629823 ,\n",
      "       -0.00223145,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.7329466022504674, next_state=array([ 0.36031303,  0.18371673,  1.2337923 , -1.6126488 , -1.1628193 ,\n",
      "        0.00326137,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36031303,  0.18371673,  1.2337923 , -1.6126488 , -1.1628193 ,\n",
      "        0.00326137,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9310384693056606, next_state=array([ 0.37269145,  0.14670697,  1.2389462 , -1.6465981 , -1.1655886 ,\n",
      "       -0.05538788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37269145,  0.14670697,  1.2389462 , -1.6465981 , -1.1655886 ,\n",
      "       -0.05538788,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.375673776357803, next_state=array([ 0.38540047,  0.10950194,  1.2722173 , -1.6556132 , -1.1689026 ,\n",
      "       -0.06628099,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38540047,  0.10950194,  1.2722173 , -1.6556132 , -1.1689026 ,\n",
      "       -0.06628099,  0.        ,  0.        ], dtype=float32), action=3, reward=6.238424573223342, next_state=array([ 0.39814216,  0.07160741,  1.276332  , -1.6876204 , -1.1743938 ,\n",
      "       -0.10982374,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39814216,  0.07160741,  1.276332  , -1.6876204 , -1.1743938 ,\n",
      "       -0.10982374,  1.        ,  0.        ], dtype=float32), action=1, reward=-1.9836994366729914, next_state=array([ 0.41087836,  0.03370593,  1.274309  , -1.6946456 , -1.1818115 ,\n",
      "       -0.13350718,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41087836,  0.03370593,  1.274309  , -1.6946456 , -1.1818115 ,\n",
      "       -0.13350718,  1.        ,  0.        ], dtype=float32), action=3, reward=-100, next_state=array([ 0.41554278,  0.02456683,  0.11990205, -0.11997496, -1.2578675 ,\n",
      "        1.1733556 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00295172,  1.4082562 , -0.2989977 , -0.11840951,  0.00342714,\n",
      "        0.06772731,  0.        ,  0.        ], dtype=float32), action=3, reward=0.15208891076082523, next_state=array([-0.00581627,  1.4050055 , -0.28761482, -0.14448325,  0.00457251,\n",
      "        0.02291033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00581627,  1.4050055 , -0.28761482, -0.14448325,  0.00457251,\n",
      "        0.02291033,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7047568988645765, next_state=array([-0.00884743,  1.402184  , -0.3034739 , -0.12539262,  0.00493243,\n",
      "        0.0071991 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00884743,  1.402184  , -0.3034739 , -0.12539262,  0.00493243,\n",
      "        0.0071991 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6432434206187725, next_state=array([-0.01193848,  1.398771  , -0.31099012, -0.15169576,  0.00679891,\n",
      "        0.0373329 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01193848,  1.398771  , -0.31099012, -0.15169576,  0.00679891,\n",
      "        0.0373329 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.10383324669800117, next_state=array([-1.4956474e-02,  1.3947525e+00, -3.0183214e-01, -1.7859989e-01,\n",
      "        6.8271863e-03,  5.6560070e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.4956474e-02,  1.3947525e+00, -3.0183214e-01, -1.7859989e-01,\n",
      "        6.8271863e-03,  5.6560070e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.9749187740757179, next_state=array([-1.7974472e-02,  1.3901340e+00, -3.0183145e-01, -2.0526804e-01,\n",
      "        6.8565793e-03,  5.8816362e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.7974472e-02,  1.3901340e+00, -3.0183145e-01, -2.0526804e-01,\n",
      "        6.8565793e-03,  5.8816362e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.8606229053657273, next_state=array([-0.02094498,  1.3856649 , -0.2973251 , -0.19862232,  0.00712858,\n",
      "        0.00544038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02094498,  1.3856649 , -0.2973251 , -0.19862232,  0.00712858,\n",
      "        0.00544038,  0.        ,  0.        ], dtype=float32), action=2, reward=1.405600443687274, next_state=array([-0.02375383,  1.3812375 , -0.28195745, -0.19677982,  0.0081848 ,\n",
      "        0.02112647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02375383,  1.3812375 , -0.28195745, -0.19677982,  0.0081848 ,\n",
      "        0.02112647,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2011981413310195, next_state=array([-0.02656269,  1.37621   , -0.2819608 , -0.22345051,  0.00924033,\n",
      "        0.02111259,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02656269,  1.37621   , -0.2819608 , -0.22345051,  0.00924033,\n",
      "        0.02111259,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8982840093607478, next_state=array([-0.02933674,  1.3713973 , -0.27865934, -0.21390696,  0.01048571,\n",
      "        0.02490981,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02933674,  1.3713973 , -0.27865934, -0.21390696,  0.01048571,\n",
      "        0.02490981,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.20024701605961923, next_state=array([-0.03202143,  1.3659973 , -0.26745012, -0.23999013,  0.0094809 ,\n",
      "       -0.02009803,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03202143,  1.3659973 , -0.26745012, -0.23999013,  0.0094809 ,\n",
      "       -0.02009803,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9529433812831758, next_state=array([-0.03477135,  1.3599861 , -0.27563912, -0.26716977,  0.01012118,\n",
      "        0.0128071 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03477135,  1.3599861 , -0.27563912, -0.26716977,  0.01012118,\n",
      "        0.0128071 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3121412158864985, next_state=array([-0.03752127,  1.3533748 , -0.27564183, -0.29383808,  0.01076021,\n",
      "        0.01278157,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03752127,  1.3533748 , -0.27564183, -0.29383808,  0.01076021,\n",
      "        0.01278157,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6372893813430085, next_state=array([-0.04019985,  1.3461542 , -0.26668438, -0.320909  ,  0.0096056 ,\n",
      "       -0.02309455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04019985,  1.3461542 , -0.26668438, -0.320909  ,  0.0096056 ,\n",
      "       -0.02309455,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1951994484208228, next_state=array([-0.04287825,  1.3383335 , -0.26668027, -0.34757763,  0.0084519 ,\n",
      "       -0.02307585,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04287825,  1.3383335 , -0.26668027, -0.34757763,  0.0084519 ,\n",
      "       -0.02307585,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8877946927327958, next_state=array([-0.04562102,  1.3299053 , -0.27474442, -0.37458757,  0.00891581,\n",
      "        0.00927903,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04562102,  1.3299053 , -0.27474442, -0.37458757,  0.00891581,\n",
      "        0.00927903,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5935521377018336, next_state=array([-0.04828148,  1.3208725 , -0.264426  , -0.40145552,  0.00731169,\n",
      "       -0.0320852 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04828148,  1.3208725 , -0.264426  , -0.40145552,  0.00731169,\n",
      "       -0.0320852 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8772293728804914, next_state=array([-0.05101652,  1.3112327 , -0.27378523, -0.42843458,  0.0075863 ,\n",
      "        0.00549274,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05101652,  1.3112327 , -0.27378523, -0.42843458,  0.0075863 ,\n",
      "        0.00549274,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2387422996332702, next_state=array([-0.05370636,  1.301704  , -0.269489  , -0.42349344,  0.00808827,\n",
      "        0.01004033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05370636,  1.301704  , -0.269489  , -0.42349344,  0.00808827,\n",
      "        0.01004033,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6544360339825745, next_state=array([-0.05646401,  1.2931261 , -0.27599052, -0.38123834,  0.00831214,\n",
      "        0.00447753,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05646401,  1.2931261 , -0.27599052, -0.38123834,  0.00831214,\n",
      "        0.00447753,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3037568691884474, next_state=array([-0.05922165,  1.2839482 , -0.2759909 , -0.40791628,  0.00853635,\n",
      "        0.0044846 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05922165,  1.2839482 , -0.2759909 , -0.40791628,  0.00853635,\n",
      "        0.0044846 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0239226716301857, next_state=array([-0.06194916,  1.2748533 , -0.27313584, -0.40421417,  0.00891877,\n",
      "        0.00764918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06194916,  1.2748533 , -0.27313584, -0.40421417,  0.00891877,\n",
      "        0.00764918,  0.        ,  0.        ], dtype=float32), action=2, reward=2.8147185028418393, next_state=array([-0.06480274,  1.2665906 , -0.28519744, -0.36723596,  0.00875355,\n",
      "       -0.00330445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06480274,  1.2665906 , -0.28519744, -0.36723596,  0.00875355,\n",
      "       -0.00330445,  0.        ,  0.        ], dtype=float32), action=2, reward=3.0967755507229926, next_state=array([-0.06769753,  1.2591708 , -0.28914988, -0.32976434,  0.00843692,\n",
      "       -0.00633309,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06769753,  1.2591708 , -0.28914988, -0.32976434,  0.00843692,\n",
      "       -0.00633309,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2227606121119834, next_state=array([-0.07059212,  1.251151  , -0.289149  , -0.35643882,  0.00812025,\n",
      "       -0.00633387,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07059212,  1.251151  , -0.289149  , -0.35643882,  0.00812025,\n",
      "       -0.00633387,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4738565053423247, next_state=array([-0.0734046 ,  1.2425189 , -0.2788216 , -0.38362944,  0.00573685,\n",
      "       -0.04766798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0734046 ,  1.2425189 , -0.2788216 , -0.38362944,  0.00573685,\n",
      "       -0.04766798,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6204228724116934, next_state=array([-0.07627773,  1.2332968 , -0.28644103, -0.4098734 ,  0.00487842,\n",
      "       -0.01716873,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07627773,  1.2332968 , -0.28644103, -0.4098734 ,  0.00487842,\n",
      "       -0.01716873,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5961486775155425, next_state=array([-0.07908459,  1.223468  , -0.2781337 , -0.43682984,  0.00235688,\n",
      "       -0.05043079,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07908459,  1.223468  , -0.2781337 , -0.43682984,  0.00235688,\n",
      "       -0.05043079,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0271137823480672, next_state=array([-8.1891343e-02,  1.2130393e+00, -2.7813369e-01, -4.6349701e-01,\n",
      "       -1.6466863e-04, -5.0430782e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-8.1891343e-02,  1.2130393e+00, -2.7813369e-01, -4.6349701e-01,\n",
      "       -1.6466863e-04, -5.0430782e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.474539621658522, next_state=array([-0.0846982 ,  1.2020106 , -0.2781337 , -0.4901642 , -0.00268621,\n",
      "       -0.05043083,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0846982 ,  1.2020106 , -0.2781337 , -0.4901642 , -0.00268621,\n",
      "       -0.05043083,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4913111344271328, next_state=array([-0.08737278,  1.1910582 , -0.26551145, -0.4867786 , -0.00460123,\n",
      "       -0.0383003 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08737278,  1.1910582 , -0.26551145, -0.4867786 , -0.00460123,\n",
      "       -0.0383003 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9585174764745374, next_state=array([-0.090174  ,  1.1806482 , -0.2775784 , -0.46267107, -0.00711927,\n",
      "       -0.05036091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.090174  ,  1.1806482 , -0.2775784 , -0.46267107, -0.00711927,\n",
      "       -0.05036091,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2450374730183842, next_state=array([-0.09289169,  1.1696292 , -0.2670885 , -0.4897613 , -0.01173916,\n",
      "       -0.0923977 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09289169,  1.1696292 , -0.2670885 , -0.4897613 , -0.01173916,\n",
      "       -0.0923977 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4646145576759284, next_state=array([-0.0955164 ,  1.157999  , -0.25542414, -0.5169656 , -0.01869725,\n",
      "       -0.13916159,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0955164 ,  1.157999  , -0.25542414, -0.5169656 , -0.01869725,\n",
      "       -0.13916159,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9019032225359922, next_state=array([-0.0981411 ,  1.1457696 , -0.2554242 , -0.5436363 , -0.02565531,\n",
      "       -0.13916114,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0981411 ,  1.1457696 , -0.2554242 , -0.5436363 , -0.02565531,\n",
      "       -0.13916114,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6866521186192063, next_state=array([-0.10069551,  1.1329488 , -0.24660894, -0.5699869 , -0.03437505,\n",
      "       -0.17439494,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10069551,  1.1329488 , -0.24660894, -0.5699869 , -0.03437505,\n",
      "       -0.17439494,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.129039117846388, next_state=array([-0.10331068,  1.1195427 , -0.25423664, -0.59601027, -0.04155969,\n",
      "       -0.14369261,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10331068,  1.1195427 , -0.25423664, -0.59601027, -0.04155969,\n",
      "       -0.14369261,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6603260292282005, next_state=array([-0.10584011,  1.1055379 , -0.24349947, -0.62273186, -0.05089353,\n",
      "       -0.18667704,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10584011,  1.1055379 , -0.24349947, -0.62273186, -0.05089353,\n",
      "       -0.18667704,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8859368018559735, next_state=array([-0.10822754,  1.0918319 , -0.22982533, -0.6094854 , -0.05971261,\n",
      "       -0.17638159,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10822754,  1.0918319 , -0.22982533, -0.6094854 , -0.05971261,\n",
      "       -0.17638159,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9345951066646296, next_state=array([-0.11052847,  1.0775139 , -0.21896625, -0.63684   , -0.07071797,\n",
      "       -0.22010717,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11052847,  1.0775139 , -0.21896625, -0.63684   , -0.07071797,\n",
      "       -0.22010717,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.338493958495944, next_state=array([-0.11292849,  1.0625974 , -0.23137972, -0.66338867, -0.07924028,\n",
      "       -0.17044654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11292849,  1.0625974 , -0.23137972, -0.66338867, -0.07924028,\n",
      "       -0.17044654,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.983667133347409, next_state=array([-0.11539821,  1.0470829 , -0.24014577, -0.68990844, -0.08600815,\n",
      "       -0.13535722,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11539821,  1.0470829 , -0.24014577, -0.68990844, -0.08600815,\n",
      "       -0.13535722,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6269400892554984, next_state=array([-0.11786795,  1.0309691 , -0.24014625, -0.7165789 , -0.09277599,\n",
      "       -0.13535681,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11786795,  1.0309691 , -0.24014625, -0.7165789 , -0.09277599,\n",
      "       -0.13535681,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4025853914821312, next_state=array([-0.12046032,  1.0149201 , -0.2516436 , -0.7137818 , -0.10029832,\n",
      "       -0.1504469 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12046032,  1.0149201 , -0.2516436 , -0.7137818 , -0.10029832,\n",
      "       -0.1504469 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.651023234245514, next_state=array([-0.1230525 ,  0.9982719 , -0.25164428, -0.7404531 , -0.10782064,\n",
      "       -0.1504463 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1230525 ,  0.9982719 , -0.25164428, -0.7404531 , -0.10782064,\n",
      "       -0.1504463 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6306905778483258, next_state=array([-0.12571773,  0.9810469 , -0.26083177, -0.7659727 , -0.11346689,\n",
      "       -0.1129248 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12571773,  0.9810469 , -0.26083177, -0.7659727 , -0.11346689,\n",
      "       -0.1129248 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0148569893733113, next_state=array([-0.12848625,  0.96421593, -0.27034757, -0.74855405, -0.1199357 ,\n",
      "       -0.12937613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12848625,  0.96421593, -0.27034757, -0.74855405, -0.1199357 ,\n",
      "       -0.12937613,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4704464444556606, next_state=array([-0.13125476,  0.94678545, -0.27034816, -0.7752241 , -0.1264045 ,\n",
      "       -0.12937576,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13125476,  0.94678545, -0.27034816, -0.7752241 , -0.1264045 ,\n",
      "       -0.12937576,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4555331292979304, next_state=array([-0.1340272 ,  0.9292936 , -0.2705148 , -0.77800375, -0.13310067,\n",
      "       -0.13392362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1340272 ,  0.9292936 , -0.2705148 , -0.77800375, -0.13310067,\n",
      "       -0.13392362,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1934044935787937, next_state=array([-0.13672209,  0.9118544 , -0.26285493, -0.7756847 , -0.13970858,\n",
      "       -0.13215819,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13672209,  0.9118544 , -0.26285493, -0.7756847 , -0.13970858,\n",
      "       -0.13215819,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4827069073709527, next_state=array([-0.13947706,  0.8938319 , -0.27042794, -0.8014837 , -0.1447689 ,\n",
      "       -0.10120622,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13947706,  0.8938319 , -0.27042794, -0.8014837 , -0.1447689 ,\n",
      "       -0.10120622,  0.        ,  0.        ], dtype=float32), action=2, reward=1.414227315796819, next_state=array([-0.14213657,  0.875851  , -0.26103303, -0.79963773, -0.14967766,\n",
      "       -0.09817526,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14213657,  0.875851  , -0.26103303, -0.79963773, -0.14967766,\n",
      "       -0.09817526,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2453223340456805, next_state=array([-0.14486437,  0.85729355, -0.26964515, -0.82510245, -0.15281317,\n",
      "       -0.06270976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14486437,  0.85729355, -0.26964515, -0.82510245, -0.15281317,\n",
      "       -0.06270976,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0540877052712563, next_state=array([-0.14766207,  0.8381507 , -0.27841935, -0.85093313, -0.15416387,\n",
      "       -0.02701432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14766207,  0.8381507 , -0.27841935, -0.85093313, -0.15416387,\n",
      "       -0.02701432,  0.        ,  0.        ], dtype=float32), action=2, reward=3.175042855859755, next_state=array([-0.15043573,  0.8194273 , -0.27564418, -0.83233047, -0.15588786,\n",
      "       -0.03447976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15043573,  0.8194273 , -0.27564418, -0.83233047, -0.15588786,\n",
      "       -0.03447976,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8596545158831077, next_state=array([-0.1532094 ,  0.80010384, -0.27564427, -0.8589974 , -0.15761185,\n",
      "       -0.0344796 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1532094 ,  0.80010384, -0.27564427, -0.8589974 , -0.15761185,\n",
      "       -0.0344796 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8439692561244942, next_state=array([-1.5605173e-01,  7.8019667e-01, -2.8426984e-01, -8.8475972e-01,\n",
      "       -1.5757620e-01,  7.1291986e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.5605173e-01,  7.8019667e-01, -2.8426984e-01, -8.8475972e-01,\n",
      "       -1.5757620e-01,  7.1291986e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-0.6615140354396931, next_state=array([-0.15896587,  0.7596964 , -0.2932552 , -0.9109228 , -0.15573366,\n",
      "        0.03685076,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15896587,  0.7596964 , -0.2932552 , -0.9109228 , -0.15573366,\n",
      "        0.03685076,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.355352505800937, next_state=array([-0.16187993,  0.7385964 , -0.29325527, -0.9375897 , -0.15389113,\n",
      "        0.03685071,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16187993,  0.7385964 , -0.29325527, -0.9375897 , -0.15389113,\n",
      "        0.03685071,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3232136493014923, next_state=array([-0.16486922,  0.716917  , -0.30270284, -0.9631404 , -0.15011424,\n",
      "        0.07553761,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16486922,  0.716917  , -0.30270284, -0.9631404 , -0.15011424,\n",
      "        0.07553761,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.051691777264607025, next_state=array([-0.167797  ,  0.69463605, -0.2950282 , -0.9900405 , -0.14787006,\n",
      "        0.04488342,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.167797  ,  0.69463605, -0.2950282 , -0.9900405 , -0.14787006,\n",
      "        0.04488342,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.20374699716071973, next_state=array([-0.17078857,  0.6717693 , -0.30303594, -1.0159185 , -0.1439958 ,\n",
      "        0.0774851 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17078857,  0.6717693 , -0.30303594, -1.0159185 , -0.1439958 ,\n",
      "        0.0774851 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.03722698782516545, next_state=array([-0.17384633,  0.6483254 , -0.31138217, -1.0414268 , -0.1384045 ,\n",
      "        0.11182649,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17384633,  0.6483254 , -0.31138217, -1.0414268 , -0.1384045 ,\n",
      "        0.11182649,  0.        ,  0.        ], dtype=float32), action=3, reward=0.15547099392975497, next_state=array([-0.17682305,  0.6242558 , -0.30117866, -1.069437  , -0.13490717,\n",
      "        0.06994632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17682305,  0.6242558 , -0.30117866, -1.069437  , -0.13490717,\n",
      "        0.06994632,  0.        ,  0.        ], dtype=float32), action=1, reward=0.03229221379246042, next_state=array([-0.1798707 ,  0.59959656, -0.3100906 , -1.0954906 , -0.12961021,\n",
      "        0.10593953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1798707 ,  0.59959656, -0.3100906 , -1.0954906 , -0.12961021,\n",
      "        0.10593953,  0.        ,  0.        ], dtype=float32), action=1, reward=0.31912535318099455, next_state=array([-0.18299532,  0.574365  , -0.31979087, -1.1207842 , -0.12231969,\n",
      "        0.14581032,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18299532,  0.574365  , -0.31979087, -1.1207842 , -0.12231969,\n",
      "        0.14581032,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5182619163274182, next_state=array([-0.18611994,  0.54853415, -0.3197917 , -1.1474552 , -0.11502919,\n",
      "        0.1458098 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18611994,  0.54853415, -0.3197917 , -1.1474552 , -0.11502919,\n",
      "        0.1458098 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4775132813239804, next_state=array([-0.18914776,  0.5220818 , -0.30763108, -1.1752961 , -0.11020894,\n",
      "        0.09640525,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18914776,  0.5220818 , -0.30763108, -1.1752961 , -0.11020894,\n",
      "        0.09640525,  0.        ,  0.        ], dtype=float32), action=1, reward=0.26686635039320206, next_state=array([-0.19225797,  0.49503267, -0.31796712, -1.2016882 , -0.10331997,\n",
      "        0.13777943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19225797,  0.49503267, -0.31796712, -1.2016882 , -0.10331997,\n",
      "        0.13777943,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4789347376641626, next_state=array([-0.1952753 ,  0.46736357, -0.30628803, -1.2294337 , -0.09879951,\n",
      "        0.09040873,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1952753 ,  0.46736357, -0.30628803, -1.2294337 , -0.09879951,\n",
      "        0.09040873,  0.        ,  0.        ], dtype=float32), action=2, reward=3.900286696368778, next_state=array([-0.1983078 ,  0.44002563, -0.30744368, -1.2147458 , -0.09463214,\n",
      "        0.08334751,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1983078 ,  0.44002563, -0.30744368, -1.2147458 , -0.09463214,\n",
      "        0.08334751,  0.        ,  0.        ], dtype=float32), action=2, reward=5.67973237624359, next_state=array([-0.2013524 ,  0.41346732, -0.3082028 , -1.1801363 , -0.09092338,\n",
      "        0.0741751 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2013524 ,  0.41346732, -0.3082028 , -1.1801363 , -0.09092338,\n",
      "        0.0741751 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.060877051280415345, next_state=array([-0.20447955,  0.38632387, -0.3185766 , -1.2060332 , -0.08511928,\n",
      "        0.11608249,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20447955,  0.38632387, -0.3185766 , -1.2060332 , -0.08511928,\n",
      "        0.11608249,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7368872784564475, next_state=array([-0.20745249,  0.35913214, -0.3037241 , -1.2081676 , -0.07874894,\n",
      "        0.12740663,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20745249,  0.35913214, -0.3037241 , -1.2081676 , -0.07874894,\n",
      "        0.12740663,  0.        ,  0.        ], dtype=float32), action=3, reward=0.24255484177209155, next_state=array([-0.21033087,  0.33133322, -0.2918632 , -1.2353007 , -0.07476043,\n",
      "        0.07977042,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21033087,  0.33133322, -0.2918632 , -1.2353007 , -0.07476043,\n",
      "        0.07977042,  0.        ,  0.        ], dtype=float32), action=0, reward=0.003319415428109096, next_state=array([-0.21320915,  0.3029345 , -0.29186335, -1.2619686 , -0.07077191,\n",
      "        0.0797703 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21320915,  0.3029345 , -0.29186335, -1.2619686 , -0.07077191,\n",
      "        0.0797703 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.0652247410303903, next_state=array([-0.21615224,  0.27394247, -0.29998842, -1.2882783 , -0.06515076,\n",
      "        0.11242305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21615224,  0.27394247, -0.29998842, -1.2882783 , -0.06515076,\n",
      "        0.11242305,  0.        ,  0.        ], dtype=float32), action=3, reward=0.033912071327280274, next_state=array([-0.2189981 ,  0.24435218, -0.28780776, -1.3149863 , -0.06196475,\n",
      "        0.06372018,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2189981 ,  0.24435218, -0.28780776, -1.3149863 , -0.06196475,\n",
      "        0.06372018,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.30991242737562175, next_state=array([-0.221844  ,  0.21416202, -0.28780785, -1.3416538 , -0.05877873,\n",
      "        0.06372017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.221844  ,  0.21416202, -0.28780785, -1.3416538 , -0.05877873,\n",
      "        0.06372017,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4381773209764335, next_state=array([-0.22457199,  0.18428479, -0.27640283, -1.3277396 , -0.05521398,\n",
      "        0.0712949 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22457199,  0.18428479, -0.27640283, -1.3277396 , -0.05521398,\n",
      "        0.0712949 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6424431480040471, next_state=array([-0.22738056,  0.15381697, -0.28652093, -1.3539269 , -0.04961601,\n",
      "        0.11195928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22738056,  0.15381697, -0.28652093, -1.3539269 , -0.04961601,\n",
      "        0.11195928,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6842939001550394, next_state=array([-0.23027782,  0.12275885, -0.2976577 , -1.3801209 , -0.04178161,\n",
      "        0.15668795,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23027782,  0.12275885, -0.2976577 , -1.3801209 , -0.04178161,\n",
      "        0.15668795,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8336482750806329, next_state=array([-0.23308054,  0.09109083, -0.28578794, -1.4073246 , -0.03633076,\n",
      "        0.10901705,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23308054,  0.09109083, -0.28578794, -1.4073246 , -0.03633076,\n",
      "        0.10901705,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4103766771878827, next_state=array([-0.23580337,  0.05881849, -0.27577013, -1.4342437 , -0.03288828,\n",
      "        0.06884964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23580337,  0.05881849, -0.27577013, -1.4342437 , -0.03288828,\n",
      "        0.06884964,  0.        ,  0.        ], dtype=float32), action=1, reward=8.064495267296936, next_state=array([-0.23862453,  0.02595828, -0.28810966, -1.4603364 , -0.02696881,\n",
      "        0.11838937,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.23862453,  0.02595828, -0.28810966, -1.4603364 , -0.02696881,\n",
      "        0.11838937,  0.        ,  1.        ], dtype=float32), action=3, reward=10.880730647243356, next_state=array([-0.24119043, -0.00655552, -0.23864886, -1.4452443 , -0.04028446,\n",
      "       -0.26077357,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.24119043, -0.00655552, -0.23864886, -1.4452443 , -0.04028446,\n",
      "       -0.26077357,  1.        ,  1.        ], dtype=float32), action=3, reward=-100, next_state=array([-2.4364257e-01, -2.8016344e-02,  1.5689264e-05, -2.0299262e-06,\n",
      "       -1.8466672e-01, -8.2928452e-08,  1.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([-0.00162525,  1.401429  , -0.16464135, -0.42182672,  0.00189009,\n",
      "        0.03729365,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2642974518044796, next_state=array([-0.00334454,  1.3913581 , -0.1761695 , -0.44760922,  0.00608956,\n",
      "        0.08399785,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00334454,  1.3913581 , -0.1761695 , -0.44760922,  0.00608956,\n",
      "        0.08399785,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1765313796856265, next_state=array([-0.00496769,  1.3806987 , -0.16410685, -0.47375777,  0.00786364,\n",
      "        0.03548512,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00496769,  1.3806987 , -0.16410685, -0.47375777,  0.00786364,\n",
      "        0.03548512,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2078842576765385, next_state=array([-0.00652628,  1.3694372 , -0.15601465, -0.50050473,  0.00801575,\n",
      "        0.00304245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00652628,  1.3694372 , -0.15601465, -0.50050473,  0.00801575,\n",
      "        0.00304245,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3816610854304372, next_state=array([-0.00808477,  1.3575759 , -0.15601489, -0.5271728 ,  0.00816802,\n",
      "        0.00304583,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00808477,  1.3575759 , -0.15601489, -0.5271728 ,  0.00816802,\n",
      "        0.00304583,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3322448867536423, next_state=array([-0.00964336,  1.3451144 , -0.15601525, -0.5538408 ,  0.00831988,\n",
      "        0.00303756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00964336,  1.3451144 , -0.15601525, -0.5538408 ,  0.00831988,\n",
      "        0.00303756,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2815949972293765, next_state=array([-0.01120195,  1.3320531 , -0.15601584, -0.58050907,  0.00847173,\n",
      "        0.00303752,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01120195,  1.3320531 , -0.15601584, -0.58050907,  0.00847173,\n",
      "        0.00303752,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6709376494237747, next_state=array([-0.01287127,  1.3196918 , -0.16658461, -0.54938495,  0.00813118,\n",
      "       -0.00681178,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01287127,  1.3196918 , -0.16658461, -0.54938495,  0.00813118,\n",
      "       -0.00681178,  0.        ,  0.        ], dtype=float32), action=2, reward=4.879260255240621, next_state=array([-0.01450768,  1.3082572 , -0.16349235, -0.5082033 ,  0.00798675,\n",
      "       -0.00288871,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01450768,  1.3082572 , -0.16349235, -0.5082033 ,  0.00798675,\n",
      "       -0.00288871,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6972758048644028, next_state=array([-0.01620417,  1.296232  , -0.17104125, -0.5344624 ,  0.00935408,\n",
      "        0.02734917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01620417,  1.296232  , -0.17104125, -0.5344624 ,  0.00935408,\n",
      "        0.02734917,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3032837128191206, next_state=array([-0.01776934,  1.2845044 , -0.15855846, -0.5212381 ,  0.01137022,\n",
      "        0.04032644,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01776934,  1.2845044 , -0.15855846, -0.5212381 ,  0.01137022,\n",
      "        0.04032644,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1133828503965606, next_state=array([-0.01926441,  1.2721837 , -0.14975561, -0.5475958 ,  0.01161892,\n",
      "        0.00497467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01926441,  1.2721837 , -0.14975561, -0.5475958 ,  0.01161892,\n",
      "        0.00497467,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6978069247219583, next_state=array([-0.020823  ,  1.2592654 , -0.1577304 , -0.57415503,  0.01346632,\n",
      "        0.03695169,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.020823  ,  1.2592654 , -0.1577304 , -0.57415503,  0.01346632,\n",
      "        0.03695169,  0.        ,  0.        ], dtype=float32), action=2, reward=4.825601035653489, next_state=array([-0.02226696,  1.2472539 , -0.14688458, -0.5338671 ,  0.01591682,\n",
      "        0.0490146 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02226696,  1.2472539 , -0.14688458, -0.5338671 ,  0.01591682,\n",
      "        0.0490146 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2711203214448233, next_state=array([-0.02388268,  1.2352417 , -0.16325834, -0.5338987 ,  0.01758876,\n",
      "        0.03344152,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02388268,  1.2352417 , -0.16325834, -0.5338987 ,  0.01758876,\n",
      "        0.03344152,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3381263502734668, next_state=array([-0.02550755,  1.2233825 , -0.16418739, -0.52709466,  0.01925919,\n",
      "        0.03341214,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02550755,  1.2233825 , -0.16418739, -0.52709466,  0.01925919,\n",
      "        0.03341214,  0.        ,  0.        ], dtype=float32), action=2, reward=2.88626828814098, next_state=array([-0.02718163,  1.2120808 , -0.16893657, -0.50231844,  0.02076836,\n",
      "        0.03018602,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02718163,  1.2120808 , -0.16893657, -0.50231844,  0.02076836,\n",
      "        0.03018602,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6078626760036456, next_state=array([-0.02881231,  1.2009807 , -0.16485386, -0.49336806,  0.02253299,\n",
      "        0.03529622,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02881231,  1.2009807 , -0.16485386, -0.49336806,  0.02253299,\n",
      "        0.03529622,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0660986267401413, next_state=array([-0.0305233 ,  1.1892872 , -0.1749275 , -0.51976466,  0.02631161,\n",
      "        0.07557932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0305233 ,  1.1892872 , -0.1749275 , -0.51976466,  0.02631161,\n",
      "        0.07557932,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2785579223935586, next_state=array([-0.0323164 ,  1.1769872 , -0.18521498, -0.5467883 ,  0.03215066,\n",
      "        0.11679162,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0323164 ,  1.1769872 , -0.18521498, -0.5467883 ,  0.03215066,\n",
      "        0.11679162,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.368116435835559, next_state=array([-0.03419008,  1.1640918 , -0.19531654, -0.5733114 ,  0.04000597,\n",
      "        0.15712032,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03419008,  1.1640918 , -0.19531654, -0.5733114 ,  0.04000597,\n",
      "        0.15712032,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9737102893647034, next_state=array([-0.03606415,  1.1505971 , -0.195339  , -0.5999859 ,  0.04785968,\n",
      "        0.15708837,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03606415,  1.1505971 , -0.195339  , -0.5999859 ,  0.04785968,\n",
      "        0.15708837,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5453871452326653, next_state=array([-0.03803377,  1.136509  , -0.20730369, -0.6265083 ,  0.05809958,\n",
      "        0.20481643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03803377,  1.136509  , -0.20730369, -0.6265083 ,  0.05809958,\n",
      "        0.20481643,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7042067342423468, next_state=array([-0.0399374 ,  1.1218234 , -0.19902171, -0.65304184,  0.0666718 ,\n",
      "        0.17145976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0399374 ,  1.1218234 , -0.19902171, -0.65304184,  0.0666718 ,\n",
      "        0.17145976,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8934214236550702, next_state=array([-0.04184132,  1.1065388 , -0.19904467, -0.679718  ,  0.07524388,\n",
      "        0.17145702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04184132,  1.1065388 , -0.19904467, -0.679718  ,  0.07524388,\n",
      "        0.17145702,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5041146648827337, next_state=array([-0.04382658,  1.0906243 , -0.20928702, -0.7078896 ,  0.08589287,\n",
      "        0.21297967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04382658,  1.0906243 , -0.20928702, -0.7078896 ,  0.08589287,\n",
      "        0.21297967,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9850909081046098, next_state=array([-0.04581194,  1.0741115 , -0.20928586, -0.7345658 ,  0.09654175,\n",
      "        0.21297792,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04581194,  1.0741115 , -0.20928586, -0.7345658 ,  0.09654175,\n",
      "        0.21297792,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5817947087428184, next_state=array([-0.04773359,  1.0570002 , -0.20127861, -0.76111346,  0.10559012,\n",
      "        0.18096718,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04773359,  1.0570002 , -0.20127861, -0.76111346,  0.10559012,\n",
      "        0.18096718,  0.        ,  0.        ], dtype=float32), action=2, reward=3.006609007012867, next_state=array([-0.04956894,  1.0404606 , -0.19342543, -0.7358248 ,  0.11541591,\n",
      "        0.19651565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04956894,  1.0404606 , -0.19342543, -0.7358248 ,  0.11541591,\n",
      "        0.19651565,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6294313438065844, next_state=array([-0.05144281,  1.0247377 , -0.19760022, -0.69962025,  0.12556721,\n",
      "        0.20302653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05144281,  1.0247377 , -0.19760022, -0.69962025,  0.12556721,\n",
      "        0.20302653,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.378944055522281, next_state=array([-0.05337982,  1.0084157 , -0.20548253, -0.72645295,  0.13729222,\n",
      "        0.23450041,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05337982,  1.0084157 , -0.20548253, -0.72645295,  0.13729222,\n",
      "        0.23450041,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3823387473123308, next_state=array([-0.05522108,  0.99152654, -0.1933957 , -0.75151354,  0.14653601,\n",
      "        0.18487568,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05522108,  0.99152654, -0.1933957 , -0.75151354,  0.14653601,\n",
      "        0.18487568,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4306063734689176, next_state=array([-0.05715303,  0.97401756, -0.2047588 , -0.77936614,  0.15809637,\n",
      "        0.23120698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05715303,  0.97401756, -0.2047588 , -0.77936614,  0.15809637,\n",
      "        0.23120698,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2600055042173723, next_state=array([-0.05913801,  0.95726866, -0.21047762, -0.74570173,  0.1700738 ,\n",
      "        0.23954856,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05913801,  0.95726866, -0.21047762, -0.74570173,  0.1700738 ,\n",
      "        0.23954856,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.049820860311229, next_state=array([-0.06112337,  0.93992186, -0.21047464, -0.7723802 ,  0.18205112,\n",
      "        0.23954618,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06112337,  0.93992186, -0.21047464, -0.7723802 ,  0.18205112,\n",
      "        0.23954618,  0.        ,  0.        ], dtype=float32), action=2, reward=2.205669071191733, next_state=array([-0.06333981,  0.92319745, -0.23319793, -0.7447633 ,  0.193659  ,\n",
      "        0.23215707,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06333981,  0.92319745, -0.23319793, -0.7447633 ,  0.193659  ,\n",
      "        0.23215707,  0.        ,  0.        ], dtype=float32), action=2, reward=3.083056503520777, next_state=array([-0.06561146,  0.9072363 , -0.23924264, -0.71101296,  0.20582512,\n",
      "        0.24332292,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06561146,  0.9072363 , -0.23924264, -0.71101296,  0.20582512,\n",
      "        0.24332292,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5377966382341117, next_state=array([-0.06781054,  0.89070386, -0.23006216, -0.7362241 ,  0.21607874,\n",
      "        0.20507213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06781054,  0.89070386, -0.23006216, -0.7362241 ,  0.21607874,\n",
      "        0.20507213,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8845727154013048, next_state=array([-0.07000971,  0.87357277, -0.23005936, -0.76289934,  0.22633226,\n",
      "        0.20507064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07000971,  0.87357277, -0.23005936, -0.76289934,  0.22633226,\n",
      "        0.20507064,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.319436227460129, next_state=array([-0.0722682 ,  0.8558264 , -0.23746105, -0.7905538 ,  0.23811375,\n",
      "        0.2356296 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0722682 ,  0.8558264 , -0.23746105, -0.7905538 ,  0.23811375,\n",
      "        0.2356296 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.928421495109319, next_state=array([-0.07452688,  0.8374818 , -0.23745704, -0.81723183,  0.24989511,\n",
      "        0.23562734,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07452688,  0.8374818 , -0.23745704, -0.81723183,  0.24989511,\n",
      "        0.23562734,  0.        ,  0.        ], dtype=float32), action=2, reward=3.040467316617776, next_state=array([-0.07695045,  0.81992114, -0.25420678, -0.78254145,  0.26199317,\n",
      "        0.24196048,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07695045,  0.81992114, -0.25420678, -0.78254145,  0.26199317,\n",
      "        0.24196048,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.524026271751238, next_state=array([-0.07943439,  0.80173606, -0.2617788 , -0.81067413,  0.275699  ,\n",
      "        0.27411664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07943439,  0.80173606, -0.2617788 , -0.81067413,  0.275699  ,\n",
      "        0.27411664,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.069865446209093, next_state=array([-0.08191872,  0.78295344, -0.26177254, -0.837356  ,  0.28940463,\n",
      "        0.27411312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08191872,  0.78295344, -0.26177254, -0.837356  ,  0.28940463,\n",
      "        0.27411312,  0.        ,  0.        ], dtype=float32), action=2, reward=2.054416129107591, next_state=array([-0.08464833,  0.7648201 , -0.28624114, -0.808627  ,  0.30312264,\n",
      "        0.27436045,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08464833,  0.7648201 , -0.28624114, -0.808627  ,  0.30312264,\n",
      "        0.27436045,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2694182148827737, next_state=array([-0.08766136,  0.7474743 , -0.3145729 , -0.77374923,  0.31686535,\n",
      "        0.27485424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08766136,  0.7474743 , -0.3145729 , -0.77374923,  0.31686535,\n",
      "        0.27485424,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5730113514518667, next_state=array([-0.09061813,  0.7295593 , -0.3073774 , -0.7988298 ,  0.3290515 ,\n",
      "        0.24372232,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09061813,  0.7295593 , -0.3073774 , -0.7988298 ,  0.3290515 ,\n",
      "        0.24372232,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.914631655378571, next_state=array([-0.09357519,  0.71104616, -0.30737144, -0.8255082 ,  0.3412375 ,\n",
      "        0.24371985,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09357519,  0.71104616, -0.30737144, -0.8255082 ,  0.3412375 ,\n",
      "        0.24371985,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.690779204100265, next_state=array([-0.09661303,  0.6918925 , -0.31748986, -0.8545847 ,  0.35563725,\n",
      "        0.2879954 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09661303,  0.6918925 , -0.31748986, -0.8545847 ,  0.35563725,\n",
      "        0.2879954 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7338008740425837, next_state=array([-0.09986105,  0.6736077 , -0.33907777, -0.81626254,  0.37070173,\n",
      "        0.3012892 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09986105,  0.6736077 , -0.33907777, -0.81626254,  0.37070173,\n",
      "        0.3012892 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.158659036150368, next_state=array([-0.10310984,  0.6547258 , -0.33906764, -0.842947  ,  0.38576594,\n",
      "        0.3012845 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10310984,  0.6547258 , -0.33906764, -0.842947  ,  0.38576594,\n",
      "        0.3012845 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1163798232202566, next_state=array([-0.10635938,  0.6352468 , -0.3390571 , -0.86963135,  0.40082994,\n",
      "        0.30127975,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10635938,  0.6352468 , -0.3390571 , -0.86963135,  0.40082994,\n",
      "        0.30127975,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0591102425757526, next_state=array([-0.10976772,  0.6161894 , -0.35536414, -0.8511789 ,  0.41644642,\n",
      "        0.31232974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10976772,  0.6161894 , -0.35536414, -0.8511789 ,  0.41644642,\n",
      "        0.31232974,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.115064523119712, next_state=array([-0.1132637 ,  0.59648424, -0.36625496, -0.88080484,  0.43450868,\n",
      "        0.36124542,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1132637 ,  0.59648424, -0.36625496, -0.88080484,  0.43450868,\n",
      "        0.36124542,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6334409129365326, next_state=array([-0.11707716,  0.5776022 , -0.39834726, -0.8445739 ,  0.45308504,\n",
      "        0.37152717,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11707716,  0.5776022 , -0.39834726, -0.8445739 ,  0.45308504,\n",
      "        0.37152717,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4497007789551333, next_state=array([-0.12089205,  0.55812436, -0.39832863, -0.8712667 ,  0.47166097,\n",
      "        0.37151834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12089205,  0.55812436, -0.39832863, -0.8712667 ,  0.47166097,\n",
      "        0.37151834,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7807032341666786, next_state=array([-0.12464742,  0.5380847 , -0.3906908 , -0.89589924,  0.4885241 ,\n",
      "        0.33726257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12464742,  0.5380847 , -0.3906908 , -0.89589924,  0.4885241 ,\n",
      "        0.33726257,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9913348668310094, next_state=array([-0.12846527,  0.51740015, -0.3984647 , -0.9253434 ,  0.5072532 ,\n",
      "        0.37458283,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12846527,  0.51740015, -0.3984647 , -0.9253434 ,  0.5072532 ,\n",
      "        0.37458283,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.027005329446399162, next_state=array([-0.13258295,  0.4971037 , -0.42851415, -0.908394  ,  0.52624947,\n",
      "        0.3799247 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13258295,  0.4971037 , -0.42851415, -0.908394  ,  0.52624947,\n",
      "        0.3799247 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.481945072647959, next_state=array([-0.13677931,  0.4761374 , -0.4383545 , -0.93924826,  0.547743  ,\n",
      "        0.4298706 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13677931,  0.4761374 , -0.4383545 , -0.93924826,  0.547743  ,\n",
      "        0.4298706 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.484505636840821, next_state=array([-0.14104328,  0.45452285, -0.44660464, -0.9690594 ,  0.57126325,\n",
      "        0.47040516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14104328,  0.45452285, -0.44660464, -0.9690594 ,  0.57126325,\n",
      "        0.47040516,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8665074904477013, next_state=array([-0.14524356,  0.43239042, -0.4379844 , -0.99152225,  0.5924696 ,\n",
      "        0.42412663,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14524356,  0.43239042, -0.4379844 , -0.99152225,  0.5924696 ,\n",
      "        0.42412663,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.41458642908866067, next_state=array([-0.14997283,  0.41086   , -0.49066418, -0.9650317 ,  0.61371505,\n",
      "        0.42491   ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14997283,  0.41086   , -0.49066418, -0.9650317 ,  0.61371505,\n",
      "        0.42491   ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.749834931581829, next_state=array([-0.15478364,  0.3886571 , -0.50070053, -0.996218  ,  0.6375845 ,\n",
      "        0.4773887 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15478364,  0.3886571 , -0.50070053, -0.996218  ,  0.6375845 ,\n",
      "        0.4773887 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.8585118040969917, next_state=array([-0.15959749,  0.36586034, -0.5006586 , -1.0229234 ,  0.661453  ,\n",
      "        0.47737008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15959749,  0.36586034, -0.5006586 , -1.0229234 ,  0.661453  ,\n",
      "        0.47737008,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5702226699460753, next_state=array([-0.16446476,  0.34242427, -0.506921  , -1.0523356 ,  0.6869448 ,\n",
      "        0.50983566,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16446476,  0.34242427, -0.506921  , -1.0523356 ,  0.6869448 ,\n",
      "        0.50983566,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3077780693919565, next_state=array([-0.16929169,  0.3184609 , -0.5010976 , -1.0753256 ,  0.7106504 ,\n",
      "        0.4741121 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16929169,  0.3184609 , -0.5010976 , -1.0753256 ,  0.7106504 ,\n",
      "        0.4741121 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2129149048254417, next_state=array([-0.17448378,  0.29455578, -0.53727025, -1.073045  ,  0.7343991 ,\n",
      "        0.4749735 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17448378,  0.29455578, -0.53727025, -1.073045  ,  0.7343991 ,\n",
      "        0.4749735 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.95211814591559, next_state=array([-0.17973766,  0.26997873, -0.5447249 , -1.1042295 ,  0.76039624,\n",
      "        0.5199436 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17973766,  0.26997873, -0.5447249 , -1.1042295 ,  0.76039624,\n",
      "        0.5199436 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.2488387845810394, next_state=array([-0.18499565,  0.24480823, -0.5446671 , -1.1309377 ,  0.7863922 ,\n",
      "        0.5199194 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18499565,  0.24480823, -0.5446671 , -1.1309377 ,  0.7863922 ,\n",
      "        0.5199194 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.425610660978605, next_state=array([-0.1903141 ,  0.2189483 , -0.55197835, -1.163131  ,  0.81489635,\n",
      "        0.57008326,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1903141 ,  0.2189483 , -0.55197835, -1.163131  ,  0.81489635,\n",
      "        0.57008326,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.7017038846417734, next_state=array([-0.1956377 ,  0.19249572, -0.55190504, -1.1898448 ,  0.8433989 ,\n",
      "        0.57005125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1956377 ,  0.19249572, -0.55190504, -1.1898448 ,  0.8433989 ,\n",
      "        0.57005125,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0853185409980015, next_state=array([-0.20091991,  0.16551863, -0.5458781 , -1.2125264 ,  0.8699708 ,\n",
      "        0.5314372 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20091991,  0.16551863, -0.5458781 , -1.2125264 ,  0.8699708 ,\n",
      "        0.5314372 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.700392894159978, next_state=array([-0.20705357,  0.13873094, -0.63003886, -1.204057  ,  0.89586246,\n",
      "        0.5178338 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20705357,  0.13873094, -0.63003886, -1.204057  ,  0.89586246,\n",
      "        0.5178338 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.3532110436497917, next_state=array([-0.21314959,  0.11141332, -0.62465304, -1.2269326 ,  0.91995955,\n",
      "        0.48194146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21314959,  0.11141332, -0.62465304, -1.2269326 ,  0.91995955,\n",
      "        0.48194146,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.6601205800288765, next_state=array([-0.21961479,  0.08389386, -0.6610642 , -1.2361066 ,  0.94399816,\n",
      "        0.48077187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21961479,  0.08389386, -0.6610642 , -1.2361066 ,  0.94399816,\n",
      "        0.48077187,  0.        ,  0.        ], dtype=float32), action=0, reward=5.462318362924805, next_state=array([-0.22608419,  0.05577894, -0.66100574, -1.2628021 ,  0.9680358 ,\n",
      "        0.48075265,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.22608419,  0.05577894, -0.66100574, -1.2628021 ,  0.9680358 ,\n",
      "        0.48075265,  0.        ,  1.        ], dtype=float32), action=1, reward=50.882440764790346, next_state=array([-0.23272166,  0.04774576, -0.7162392 , -0.42902625,  1.0446446 ,\n",
      "        1.4771646 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.23272166,  0.04774576, -0.7162392 , -0.42902625,  1.0446446 ,\n",
      "        1.4771646 ,  0.        ,  1.        ], dtype=float32), action=3, reward=-4.708351435387981, next_state=array([-0.23962727,  0.03957961, -0.71789974, -0.3963566 ,  1.1009777 ,\n",
      "        1.1266301 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.23962727,  0.03957961, -0.71789974, -0.3963566 ,  1.1009777 ,\n",
      "        1.1266301 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-4.25117020360176, next_state=array([-0.24667983,  0.03160988, -0.7232262 , -0.37891358,  1.1412393 ,\n",
      "        0.8047371 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.24667983,  0.03160988, -0.7232262 , -0.37891358,  1.1412393 ,\n",
      "        0.8047371 ,  0.        ,  1.        ], dtype=float32), action=0, reward=6.591511410906406, next_state=array([-0.25428122,  0.02608689, -0.7439104 , -0.22764285,  1.1069189 ,\n",
      "       -0.6468637 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.25428122,  0.02608689, -0.7439104 , -0.22764285,  1.1069189 ,\n",
      "       -0.6468637 ,  0.        ,  1.        ], dtype=float32), action=0, reward=3.667107273635537, next_state=array([-0.26195812,  0.02059422, -0.7465273 , -0.21888205,  1.0631047 ,\n",
      "       -0.864439  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.26195812,  0.02059422, -0.7465273 , -0.21888205,  1.0631047 ,\n",
      "       -0.864439  ,  0.        ,  1.        ], dtype=float32), action=3, reward=4.884226069785087, next_state=array([-0.26968798,  0.01504699, -0.7451447 , -0.21511628,  1.009001  ,\n",
      "       -1.0821517 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.26968798,  0.01504699, -0.7451447 , -0.21511628,  1.009001  ,\n",
      "       -1.0821517 ,  0.        ,  1.        ], dtype=float32), action=2, reward=0.16683522950823432, next_state=array([-0.27793425,  0.00946013, -0.79202163, -0.21579275,  0.9510266 ,\n",
      "       -1.1595666 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.27793425,  0.00946013, -0.79202163, -0.21579275,  0.9510266 ,\n",
      "       -1.1595666 ,  0.        ,  1.        ], dtype=float32), action=3, reward=5.381557462079884, next_state=array([-0.2861331 ,  0.00340388, -0.78337777, -0.23704055,  0.89129037,\n",
      "       -1.1947954 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.2861331 ,  0.00340388, -0.78337777, -0.23704055,  0.89129037,\n",
      "       -1.1947954 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-5.6401148239880285, next_state=array([-0.29435426, -0.00322118, -0.78290826, -0.2639155 ,  0.83173406,\n",
      "       -1.1911747 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29435426, -0.00322118, -0.78290826, -0.2639155 ,  0.83173406,\n",
      "       -1.1911747 ,  0.        ,  0.        ], dtype=float32), action=1, reward=3.1339096151842525, next_state=array([-0.30265445, -0.0104954 , -0.7898461 , -0.29548055,  0.7745182 ,\n",
      "       -1.1443647 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30265445, -0.0104954 , -0.7898461 , -0.29548055,  0.7745182 ,\n",
      "       -1.1443647 ,  0.        ,  0.        ], dtype=float32), action=3, reward=4.753179427914433, next_state=array([-0.31093258, -0.01826269, -0.78387153, -0.3181242 ,  0.7153952 ,\n",
      "       -1.1825092 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31093258, -0.01826269, -0.78387153, -0.3181242 ,  0.7153952 ,\n",
      "       -1.1825092 ,  0.        ,  0.        ], dtype=float32), action=1, reward=2.697126703162611, next_state=array([-0.31929797, -0.02668364, -0.7923766 , -0.35003936,  0.6588974 ,\n",
      "       -1.1300015 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31929797, -0.02668364, -0.7923766 , -0.35003936,  0.6588974 ,\n",
      "       -1.1300015 ,  0.        ,  0.        ], dtype=float32), action=0, reward=3.628795494373378, next_state=array([-0.32768136, -0.03566818, -0.79219633, -0.37679586,  0.602413  ,\n",
      "       -1.1297334 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32768136, -0.03566818, -0.79219633, -0.37679586,  0.602413  ,\n",
      "       -1.1297334 ,  0.        ,  0.        ], dtype=float32), action=3, reward=14.58662027453727, next_state=array([-0.33602032, -0.0451494 , -0.78412354, -0.39990997,  0.5438492 ,\n",
      "       -1.1713247 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.33602032, -0.0451494 , -0.78412354, -0.39990997,  0.5438492 ,\n",
      "       -1.1713247 ,  0.        ,  1.        ], dtype=float32), action=0, reward=11.449065365061387, next_state=array([-0.34405756, -0.0540935 , -0.7408425 , -0.37400064,  0.47043508,\n",
      "       -1.4711112 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.34405756, -0.0540935 , -0.7408425 , -0.37400064,  0.47043508,\n",
      "       -1.4711112 ,  0.        ,  1.        ], dtype=float32), action=3, reward=14.512084476499838, next_state=array([-0.35203868, -0.06240977, -0.7014259 , -0.34182248,  0.36538178,\n",
      "       -2.0851862 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.35203868, -0.06240977, -0.7014259 , -0.34182248,  0.36538178,\n",
      "       -2.0851862 ,  0.        ,  1.        ], dtype=float32), action=0, reward=21.55932285868198, next_state=array([-0.36004204, -0.07077587, -0.688523  , -0.34796783,  0.24920969,\n",
      "       -2.3237395 ,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.36004204, -0.07077587, -0.688523  , -0.34796783,  0.24920969,\n",
      "       -2.3237395 ,  1.        ,  1.        ], dtype=float32), action=0, reward=9.733055328855528, next_state=array([-0.36802292, -0.07912945, -0.68982184, -0.3555657 ,  0.13776699,\n",
      "       -2.2315857 ,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.36802292, -0.07912945, -0.68982184, -0.3555657 ,  0.13776699,\n",
      "       -2.2315857 ,  1.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.37549013, -0.08157988, -0.6554714 ,  0.03393789,  0.06502227,\n",
      "       -0.66624224,  1.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00411596,  1.4015578 ,  0.41688997, -0.4161111 , -0.00476261,\n",
      "       -0.09443176,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2741226634412044, next_state=array([ 0.00823202,  1.3916188 ,  0.41632682, -0.44174755, -0.00942901,\n",
      "       -0.09333658,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00823202,  1.3916188 ,  0.41632682, -0.44174755, -0.00942901,\n",
      "       -0.09333658,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8443519926055785, next_state=array([ 0.01244221,  1.3820702 ,  0.42530313, -0.42442337, -0.01367119,\n",
      "       -0.08485161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01244221,  1.3820702 ,  0.42530313, -0.42442337, -0.01367119,\n",
      "       -0.08485161,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5467510073440269, next_state=array([ 0.01658201,  1.3719311 ,  0.4164924 , -0.45065257, -0.01614169,\n",
      "       -0.04941462,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01658201,  1.3719311 ,  0.4164924 , -0.45065257, -0.01614169,\n",
      "       -0.04941462,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4103784458993516, next_state=array([ 0.02075596,  1.3621639 ,  0.41978312, -0.434122  , -0.01849956,\n",
      "       -0.04716191,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02075596,  1.3621639 ,  0.41978312, -0.434122  , -0.01849956,\n",
      "       -0.04716191,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6006497497214809, next_state=array([ 0.02496805,  1.3525301 ,  0.4234611 , -0.42819935, -0.02071754,\n",
      "       -0.04436376,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02496805,  1.3525301 ,  0.4234611 , -0.42819935, -0.02071754,\n",
      "       -0.04436376,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.23330245305467542, next_state=array([ 0.0290967 ,  1.3422983 ,  0.41298026, -0.45475167, -0.02083209,\n",
      "       -0.00229137,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0290967 ,  1.3422983 ,  0.41298026, -0.45475167, -0.02083209,\n",
      "       -0.00229137,  0.        ,  0.        ], dtype=float32), action=2, reward=4.67561829685742, next_state=array([ 0.03306894,  1.3330362 ,  0.3981977 , -0.411663  , -0.02179579,\n",
      "       -0.01927581,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03306894,  1.3330362 ,  0.3981977 , -0.411663  , -0.02179579,\n",
      "       -0.01927581,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.16920809413014012, next_state=array([ 0.03695755,  1.3231783 ,  0.38770533, -0.43810728, -0.02065261,\n",
      "        0.02286546,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03695755,  1.3231783 ,  0.38770533, -0.43810728, -0.02065261,\n",
      "        0.02286546,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6271057627782965, next_state=array([ 0.0410409 ,  1.31364   ,  0.4062999 , -0.42390183, -0.0186461 ,\n",
      "        0.04013415,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0410409 ,  1.31364   ,  0.4062999 , -0.42390183, -0.0186461 ,\n",
      "        0.04013415,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.004831957383912594, next_state=array([ 0.04505577,  1.303512  ,  0.39771962, -0.45009696, -0.01491832,\n",
      "        0.07456257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04505577,  1.303512  ,  0.39771962, -0.45009696, -0.01491832,\n",
      "        0.07456257,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5943263142155617, next_state=array([ 0.0490449 ,  1.2938148 ,  0.395314  , -0.43095013, -0.01136109,\n",
      "        0.07115128,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0490449 ,  1.2938148 ,  0.395314  , -0.43095013, -0.01136109,\n",
      "        0.07115128,  0.        ,  0.        ], dtype=float32), action=1, reward=0.08949174606172619, next_state=array([ 0.05296183,  1.2835094 ,  0.38625383, -0.45798385, -0.00599167,\n",
      "        0.10739791,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05296183,  1.2835094 ,  0.38625383, -0.45798385, -0.00599167,\n",
      "        0.10739791,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9401263042784764, next_state=array([ 0.05672846,  1.273764  ,  0.3719839 , -0.43311527, -0.00135262,\n",
      "        0.09278943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05672846,  1.273764  ,  0.3719839 , -0.43311527, -0.00135262,\n",
      "        0.09278943,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.737722581567083, next_state=array([ 6.0581110e-02,  1.2634146e+00,  3.8274869e-01, -4.5997629e-01,\n",
      "        1.1266352e-03,  4.9589776e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 6.0581110e-02,  1.2634146e+00,  3.8274869e-01, -4.5997629e-01,\n",
      "        1.1266352e-03,  4.9589776e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=2.7758104386173104, next_state=array([ 0.0645401 ,  1.2540036 ,  0.3928816 , -0.41826984,  0.0041132 ,\n",
      "        0.05973672,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0645401 ,  1.2540036 ,  0.3928816 , -0.41826984,  0.0041132 ,\n",
      "        0.05973672,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2921493029591886, next_state=array([ 0.06849899,  1.2439923 ,  0.39287257, -0.44495133,  0.00709846,\n",
      "        0.05971069,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06849899,  1.2439923 ,  0.39287257, -0.44495133,  0.00709846,\n",
      "        0.05971069,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2852047929739285, next_state=array([ 0.07245779,  1.2333814 ,  0.39286396, -0.47161534,  0.01008346,\n",
      "        0.05970564,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07245779,  1.2333814 ,  0.39286396, -0.47161534,  0.01008346,\n",
      "        0.05970564,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8840631250037905, next_state=array([ 0.0763423 ,  1.2221812 ,  0.38354987, -0.49783215,  0.01493077,\n",
      "        0.09695476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0763423 ,  1.2221812 ,  0.38354987, -0.49783215,  0.01493077,\n",
      "        0.09695476,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7850783343839225, next_state=array([ 0.08035507,  1.2116687 ,  0.3957041 , -0.46728972,  0.02043677,\n",
      "        0.11013005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08035507,  1.2116687 ,  0.3957041 , -0.46728972,  0.02043677,\n",
      "        0.11013005,  0.        ,  0.        ], dtype=float32), action=2, reward=1.412907176133683, next_state=array([ 0.0844572 ,  1.2017282 ,  0.40414444, -0.44189534,  0.02643444,\n",
      "        0.11996429,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0844572 ,  1.2017282 ,  0.40414444, -0.44189534,  0.02643444,\n",
      "        0.11996429,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2424714301857864, next_state=array([ 0.08849593,  1.1911896 ,  0.39620474, -0.46853358,  0.03401734,\n",
      "        0.15167163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08849593,  1.1911896 ,  0.39620474, -0.46853358,  0.03401734,\n",
      "        0.15167163,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4330126642392418, next_state=array([ 0.09246597,  1.1800449 ,  0.38760352, -0.49555382,  0.04332085,\n",
      "        0.18608694,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09246597,  1.1800449 ,  0.38760352, -0.49555382,  0.04332085,\n",
      "        0.18608694,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.601825227840634, next_state=array([ 0.09635334,  1.1682851 ,  0.37722707, -0.523035  ,  0.05470723,\n",
      "        0.22774784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09635334,  1.1682851 ,  0.37722707, -0.523035  ,  0.05470723,\n",
      "        0.22774784,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1201244653481126, next_state=array([ 0.10024023,  1.1559268 ,  0.37719494, -0.5497153 ,  0.06609132,\n",
      "        0.22770247,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10024023,  1.1559268 ,  0.37719494, -0.5497153 ,  0.06609132,\n",
      "        0.22770247,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1796403681660763, next_state=array([ 0.10412779,  1.1429487 ,  0.37725633, -0.57734793,  0.07747503,\n",
      "        0.22767344,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10412779,  1.1429487 ,  0.37725633, -0.57734793,  0.07747503,\n",
      "        0.22767344,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0710289224218172, next_state=array([ 0.10801525,  1.1293726 ,  0.3772575 , -0.6040255 ,  0.0888586 ,\n",
      "        0.22767147,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10801525,  1.1293726 ,  0.3772575 , -0.6040255 ,  0.0888586 ,\n",
      "        0.22767147,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7159953869091396, next_state=array([ 0.11193457,  1.1163576 ,  0.37998343, -0.5792023 ,  0.10070714,\n",
      "        0.23697051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11193457,  1.1163576 ,  0.37998343, -0.5792023 ,  0.10070714,\n",
      "        0.23697051,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3704322615438387, next_state=array([ 0.11592865,  1.1027657 ,  0.38940892, -0.6047863 ,  0.11063619,\n",
      "        0.19858092,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11592865,  1.1027657 ,  0.38940892, -0.6047863 ,  0.11063619,\n",
      "        0.19858092,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6794357626707768, next_state=array([ 0.11985932,  1.088572  ,  0.3814762 , -0.6317312 ,  0.12215555,\n",
      "        0.23038752,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11985932,  1.088572  ,  0.3814762 , -0.6317312 ,  0.12215555,\n",
      "        0.23038752,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2038739111795964, next_state=array([ 0.12364702,  1.0747948 ,  0.36747175, -0.61329496,  0.1334009 ,\n",
      "        0.22490683,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12364702,  1.0747948 ,  0.36747175, -0.61329496,  0.1334009 ,\n",
      "        0.22490683,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.800142341856456, next_state=array([ 0.12734699,  1.060411  ,  0.35650027, -0.640537  ,  0.14685252,\n",
      "        0.2690323 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12734699,  1.060411  ,  0.35650027, -0.640537  ,  0.14685252,\n",
      "        0.2690323 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5192325146907977, next_state=array([ 0.13114138,  1.0454459 ,  0.3683764 , -0.666241  ,  0.15789782,\n",
      "        0.22090581,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13114138,  1.0454459 ,  0.3683764 , -0.666241  ,  0.15789782,\n",
      "        0.22090581,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.152643858500453, next_state=array([ 0.1350297 ,  1.0299162 ,  0.3802268 , -0.6911542 ,  0.16649485,\n",
      "        0.17194049,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1350297 ,  1.0299162 ,  0.3802268 , -0.6911542 ,  0.16649485,\n",
      "        0.17194049,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8640878576705109, next_state=array([ 0.13900633,  1.0138141 ,  0.39137244, -0.71636766,  0.17279945,\n",
      "        0.12609217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13900633,  1.0138141 ,  0.39137244, -0.71636766,  0.17279945,\n",
      "        0.12609217,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5252715604634364, next_state=array([ 0.1430583 ,  0.9971429 ,  0.4008735 , -0.7414473 ,  0.1771263 ,\n",
      "        0.08653743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1430583 ,  0.9971429 ,  0.4008735 , -0.7414473 ,  0.1771263 ,\n",
      "        0.08653743,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1379456026269565, next_state=array([ 0.14711018,  0.97987205,  0.40087384, -0.7681154 ,  0.18145317,\n",
      "        0.0865373 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14711018,  0.97987205,  0.40087384, -0.7681154 ,  0.18145317,\n",
      "        0.0865373 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.001168072864117, next_state=array([ 0.15107775,  0.9619755 ,  0.39027426, -0.7962111 ,  0.1879654 ,\n",
      "        0.13024406,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15107775,  0.9619755 ,  0.39027426, -0.7962111 ,  0.1879654 ,\n",
      "        0.13024406,  0.        ,  0.        ], dtype=float32), action=2, reward=4.153005099883427, next_state=array([ 0.15480538,  0.94467515,  0.36668307, -0.7696833 ,  0.1940771 ,\n",
      "        0.12223425,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15480538,  0.94467515,  0.36668307, -0.7696833 ,  0.1940771 ,\n",
      "        0.12223425,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3901449910665622, next_state=array([ 0.15860157,  0.92680734,  0.37535515, -0.7946901 ,  0.19836348,\n",
      "        0.0857275 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15860157,  0.92680734,  0.37535515, -0.7946901 ,  0.19836348,\n",
      "        0.0857275 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0934769809815919, next_state=array([ 0.16239767,  0.90833974,  0.3753556 , -0.82135814,  0.20264986,\n",
      "        0.08572743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16239767,  0.90833974,  0.3753556 , -0.82135814,  0.20264986,\n",
      "        0.08572743,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0217136466749526, next_state=array([ 0.16613293,  0.8892553 ,  0.36771232, -0.84901136,  0.20851056,\n",
      "        0.11721413,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16613293,  0.8892553 ,  0.36771232, -0.84901136,  0.20851056,\n",
      "        0.11721413,  0.        ,  0.        ], dtype=float32), action=2, reward=2.287435124875498, next_state=array([ 0.16985321,  0.8705103 ,  0.365697  , -0.83401465,  0.2149039 ,\n",
      "        0.12786691,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16985321,  0.8705103 ,  0.365697  , -0.83401465,  0.2149039 ,\n",
      "        0.12786691,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.263747951264861, next_state=array([ 0.1735734 ,  0.85116595,  0.36569807, -0.86068463,  0.22129723,\n",
      "        0.12786655,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1735734 ,  0.85116595,  0.36569807, -0.86068463,  0.22129723,\n",
      "        0.12786655,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2016194557968152, next_state=array([ 0.17722674,  0.831205  ,  0.35731894, -0.8883826 ,  0.22941303,\n",
      "        0.16231625,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17722674,  0.831205  ,  0.35731894, -0.8883826 ,  0.22941303,\n",
      "        0.16231625,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4302543722518795, next_state=array([ 0.18081474,  0.8106112 ,  0.34906384, -0.9168276 ,  0.23929165,\n",
      "        0.1975718 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18081474,  0.8106112 ,  0.34906384, -0.9168276 ,  0.23929165,\n",
      "        0.1975718 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.173817507418687, next_state=array([ 0.18419352,  0.7904576 ,  0.3283468 , -0.89730126,  0.24899103,\n",
      "        0.19398764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18419352,  0.7904576 ,  0.3283468 , -0.89730126,  0.24899103,\n",
      "        0.19398764,  0.        ,  0.        ], dtype=float32), action=2, reward=4.572389644319071, next_state=array([ 0.18740006,  0.77113724,  0.31083012, -0.8603765 ,  0.25900796,\n",
      "        0.20033917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18740006,  0.77113724,  0.31083012, -0.8603765 ,  0.25900796,\n",
      "        0.20033917,  0.        ,  0.        ], dtype=float32), action=2, reward=2.150314785253056, next_state=array([ 0.19053784,  0.7521754 ,  0.30353728, -0.8445923 ,  0.26947474,\n",
      "        0.20933516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19053784,  0.7521754 ,  0.30353728, -0.8445923 ,  0.26947474,\n",
      "        0.20933516,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9179650854505723, next_state=array([ 0.1933897 ,  0.73334026,  0.2756374 , -0.8389118 ,  0.27926365,\n",
      "        0.1957778 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1933897 ,  0.73334026,  0.2756374 , -0.8389118 ,  0.27926365,\n",
      "        0.1957778 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7145358764974787, next_state=array([ 0.19624129,  0.71390635,  0.2756406 , -0.86558616,  0.2890525 ,\n",
      "        0.19577652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19624129,  0.71390635,  0.2756406 , -0.86558616,  0.2890525 ,\n",
      "        0.19577652,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.67260349135978, next_state=array([ 0.19909258,  0.6938736 ,  0.27564397, -0.8922605 ,  0.29884124,\n",
      "        0.19577521,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19909258,  0.6938736 ,  0.27564397, -0.8922605 ,  0.29884124,\n",
      "        0.19577521,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8675017883786154, next_state=array([ 0.20167045,  0.6737117 ,  0.24906978, -0.8979037 ,  0.3078483 ,\n",
      "        0.18014172,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20167045,  0.6737117 ,  0.24906978, -0.8979037 ,  0.3078483 ,\n",
      "        0.18014172,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.563909747389971, next_state=array([ 0.20424815,  0.6529508 ,  0.24907283, -0.9245768 ,  0.3168553 ,\n",
      "        0.18014073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20424815,  0.6529508 ,  0.24907283, -0.9245768 ,  0.3168553 ,\n",
      "        0.18014073,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.708167814583162, next_state=array([ 0.2067379 ,  0.6315557 ,  0.23807207, -0.95331687,  0.32819945,\n",
      "        0.22688241,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2067379 ,  0.6315557 ,  0.23807207, -0.95331687,  0.32819945,\n",
      "        0.22688241,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4905743050726972, next_state=array([ 0.20931597,  0.6096166 ,  0.24932821, -0.97702116,  0.3370483 ,\n",
      "        0.17697687,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20931597,  0.6096166 ,  0.24932821, -0.97702116,  0.3370483 ,\n",
      "        0.17697687,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.431194659101493, next_state=array([ 0.21189384,  0.5870784 ,  0.24933143, -1.0036939 ,  0.34589705,\n",
      "        0.17697592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21189384,  0.5870784 ,  0.24933143, -1.0036939 ,  0.34589705,\n",
      "        0.17697592,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6571221384479873, next_state=array([ 0.21437779,  0.563896  ,  0.23755178, -1.0329802 ,  0.3573004 ,\n",
      "        0.22806695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21437779,  0.563896  ,  0.23755178, -1.0329802 ,  0.3573004 ,\n",
      "        0.22806695,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0748124572562974, next_state=array([ 0.21681671,  0.5410524 ,  0.23232225, -1.0181985 ,  0.36952165,\n",
      "        0.24442485,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21681671,  0.5410524 ,  0.23232225, -1.0181985 ,  0.36952165,\n",
      "        0.24442485,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0820768358630617, next_state=array([ 0.21917458,  0.5175561 ,  0.22206649, -1.0478935 ,  0.3840711 ,\n",
      "        0.29098907,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21917458,  0.5175561 ,  0.22206649, -1.0478935 ,  0.3840711 ,\n",
      "        0.29098907,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.952502289237458, next_state=array([ 0.22153158,  0.49346223,  0.22207622, -1.0745767 ,  0.39862037,\n",
      "        0.2909848 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22153158,  0.49346223,  0.22207622, -1.0745767 ,  0.39862037,\n",
      "        0.2909848 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.231301811965578, next_state=array([ 0.22381039,  0.46872663,  0.21230742, -1.1038246 ,  0.41535026,\n",
      "        0.33459753,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22381039,  0.46872663,  0.21230742, -1.1038246 ,  0.41535026,\n",
      "        0.33459753,  0.        ,  0.        ], dtype=float32), action=2, reward=3.7472314476287467, next_state=array([ 0.22588053,  0.44476748,  0.19080596, -1.0697197 ,  0.43291092,\n",
      "        0.35121325,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22588053,  0.44476748,  0.19080596, -1.0697197 ,  0.43291092,\n",
      "        0.35121325,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5268399224630516, next_state=array([ 0.2275279 ,  0.4212357 ,  0.1490473 , -1.0507846 ,  0.45002487,\n",
      "        0.34227914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2275279 ,  0.4212357 ,  0.1490473 , -1.0507846 ,  0.45002487,\n",
      "        0.34227914,  0.        ,  0.        ], dtype=float32), action=2, reward=0.45875455168849727, next_state=array([ 0.22881451,  0.39769587,  0.1137438 , -1.051108  ,  0.4664304 ,\n",
      "        0.3281104 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22881451,  0.39769587,  0.1137438 , -1.051108  ,  0.4664304 ,\n",
      "        0.3281104 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.743274521875121, next_state=array([ 0.23002443,  0.3735052 ,  0.10420549, -1.0808938 ,  0.4850708 ,\n",
      "        0.37280813,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23002443,  0.3735052 ,  0.10420549, -1.0808938 ,  0.4850708 ,\n",
      "        0.37280813,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3155906404176507, next_state=array([ 0.23085508,  0.35006306,  0.06609072, -1.0479634 ,  0.5040981 ,\n",
      "        0.3805459 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23085508,  0.35006306,  0.06609072, -1.0479634 ,  0.5040981 ,\n",
      "        0.3805459 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.224674921291664, next_state=array([ 0.23174095,  0.32608038,  0.07340752, -1.0715843 ,  0.52128476,\n",
      "        0.34373325,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23174095,  0.32608038,  0.07340752, -1.0715843 ,  0.52128476,\n",
      "        0.34373325,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9748873905084678, next_state=array([ 0.23230295,  0.30255282,  0.04088716, -1.0516361 ,  0.53879297,\n",
      "        0.35016432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23230295,  0.30255282,  0.04088716, -1.0516361 ,  0.53879297,\n",
      "        0.35016432,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.2373305396248484, next_state=array([ 0.23278847,  0.27835178,  0.03126202, -1.0826356 ,  0.5587945 ,\n",
      "        0.40003094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23278847,  0.27835178,  0.03126202, -1.0826356 ,  0.5587945 ,\n",
      "        0.40003094,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4135987173404474, next_state=array([ 0.23331852,  0.2536121 ,  0.03732611, -1.1061984 ,  0.5771425 ,\n",
      "        0.3669591 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23331852,  0.2536121 ,  0.03732611, -1.1061984 ,  0.5771425 ,\n",
      "        0.3669591 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.092472999756052, next_state=array([ 0.23348942,  0.22944339,  0.0010997 , -1.0812323 ,  0.5960682 ,\n",
      "        0.3785141 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23348942,  0.22944339,  0.0010997 , -1.0812323 ,  0.5960682 ,\n",
      "        0.3785141 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4184231439933783, next_state=array([ 0.23372145,  0.2047318 ,  0.0090816 , -1.104784  ,  0.6130092 ,\n",
      "        0.33882046,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23372145,  0.2047318 ,  0.0090816 , -1.104784  ,  0.6130092 ,\n",
      "        0.33882046,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.232157135339945, next_state=array([ 0.2340084 ,  0.17949222,  0.01638912, -1.1276075 ,  0.62791646,\n",
      "        0.2981449 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2340084 ,  0.17949222,  0.01638912, -1.1276075 ,  0.62791646,\n",
      "        0.2981449 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0359059606825256, next_state=array([ 0.2343584 ,  0.153738  ,  0.02478197, -1.149637  ,  0.64043313,\n",
      "        0.25033456,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2343584 ,  0.153738  ,  0.02478197, -1.149637  ,  0.64043313,\n",
      "        0.25033456,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.595215960879358, next_state=array([ 0.23470755,  0.12738548,  0.02479362, -1.1763145 ,  0.65294975,\n",
      "        0.25033188,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23470755,  0.12738548,  0.02479362, -1.1763145 ,  0.65294975,\n",
      "        0.25033188,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.3128833027442384, next_state=array([ 0.23500767,  0.10037328,  0.01856831, -1.2064598 ,  0.6672544 ,\n",
      "        0.28609306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23500767,  0.10037328,  0.01856831, -1.2064598 ,  0.6672544 ,\n",
      "        0.28609306,  0.        ,  0.        ], dtype=float32), action=2, reward=0.44880298009830427, next_state=array([ 0.23501405,  0.07366463, -0.0112028 , -1.1933572 ,  0.6822159 ,\n",
      "        0.29923108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23501405,  0.07366463, -0.0112028 , -1.1933572 ,  0.6822159 ,\n",
      "        0.29923108,  0.        ,  0.        ], dtype=float32), action=2, reward=10.581040455647422, next_state=array([ 0.23464823,  0.04738091, -0.04879719, -1.1748729 ,  0.6978341 ,\n",
      "        0.3123633 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.23464823,  0.04738091, -0.04879719, -1.1748729 ,  0.6978341 ,\n",
      "        0.3123633 ,  0.        ,  1.        ], dtype=float32), action=3, reward=18.53101893214722, next_state=array([ 0.23518696,  0.02531162,  0.04869466, -0.98425496,  0.7054899 ,\n",
      "        0.15374711,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.23518696,  0.02531162,  0.04869466, -0.98425496,  0.7054899 ,\n",
      "        0.15374711,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.23478317,  0.00403251, -0.14241295, -0.42124   ,  0.6730592 ,\n",
      "       -3.2948735 ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00549345,  1.4086589 ,  0.55640113, -0.10051729, -0.00635863,\n",
      "       -0.12603311,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4024649283361328, next_state=array([ 0.01111736,  1.4070914 ,  0.56808144, -0.06969623, -0.0119844 ,\n",
      "       -0.1125255 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01111736,  1.4070914 ,  0.56808144, -0.06969623, -0.0119844 ,\n",
      "       -0.1125255 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.4033674410808896, next_state=array([ 0.01666279,  1.4049253 ,  0.55822843, -0.09630872, -0.0156274 ,\n",
      "       -0.07286656,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01666279,  1.4049253 ,  0.55822843, -0.09630872, -0.0156274 ,\n",
      "       -0.07286656,  0.        ,  0.        ], dtype=float32), action=1, reward=0.398557252041287, next_state=array([ 0.0221386 ,  1.402169  ,  0.5494898 , -0.12252184, -0.0175139 ,\n",
      "       -0.03773315,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0221386 ,  1.402169  ,  0.5494898 , -0.12252184, -0.0175139 ,\n",
      "       -0.03773315,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6294210107377125, next_state=array([ 0.02752075,  1.3994527 ,  0.54061663, -0.12075881, -0.01988437,\n",
      "       -0.04741402,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02752075,  1.3994527 ,  0.54061663, -0.12075881, -0.01988437,\n",
      "       -0.04741402,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3729657388374392, next_state=array([ 0.03302002,  1.3966707 ,  0.5518006 , -0.12366426, -0.02172777,\n",
      "       -0.03687173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03302002,  1.3966707 ,  0.5518006 , -0.12366426, -0.02172777,\n",
      "       -0.03687173,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.19148174793831457, next_state=array([ 0.03857336,  1.3945891 ,  0.5570308 , -0.09254294, -0.02340338,\n",
      "       -0.03351521,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03857336,  1.3945891 ,  0.5570308 , -0.09254294, -0.02340338,\n",
      "       -0.03351521,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6695491170298464, next_state=array([ 0.04405193,  1.3919156 ,  0.547649  , -0.11881676, -0.02319372,\n",
      "        0.00419369,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04405193,  1.3919156 ,  0.547649  , -0.11881676, -0.02319372,\n",
      "        0.00419369,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.505440870334296, next_state=array([ 0.04961042,  1.3886338 ,  0.5576683 , -0.14588417, -0.0249968 ,\n",
      "       -0.03606471,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04961042,  1.3886338 ,  0.5576683 , -0.14588417, -0.0249968 ,\n",
      "       -0.03606471,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.080993616363901, next_state=array([ 0.05530806,  1.3856947 ,  0.5709953 , -0.1306453 , -0.02621183,\n",
      "       -0.02430299,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05530806,  1.3856947 ,  0.5709953 , -0.1306453 , -0.02621183,\n",
      "       -0.02430299,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9445369886096568, next_state=array([ 0.06090975,  1.3821689 ,  0.5589518 , -0.15668501, -0.0250073 ,\n",
      "        0.02409268,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06090975,  1.3821689 ,  0.5589518 , -0.15668501, -0.0250073 ,\n",
      "        0.02409268,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2687054060256173, next_state=array([ 0.06651144,  1.3780432 ,  0.5589474 , -0.1833498 , -0.02380378,\n",
      "        0.02407273,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06651144,  1.3780432 ,  0.5589474 , -0.1833498 , -0.02380378,\n",
      "        0.02407273,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4178532117159637, next_state=array([ 0.07218704,  1.373311  ,  0.5682346 , -0.21032223, -0.02446447,\n",
      "       -0.01321506,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07218704,  1.373311  ,  0.5682346 , -0.21032223, -0.02446447,\n",
      "       -0.01321506,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6703336370085242, next_state=array([ 0.07793989,  1.3679738 ,  0.57791716, -0.23726222, -0.02706653,\n",
      "       -0.05204569,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07793989,  1.3679738 ,  0.57791716, -0.23726222, -0.02706653,\n",
      "       -0.05204569,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6626092862546387, next_state=array([ 0.0838809 ,  1.3626245 ,  0.5958851 , -0.23777871, -0.02883181,\n",
      "       -0.03530914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0838809 ,  1.3626245 ,  0.5958851 , -0.23777871, -0.02883181,\n",
      "       -0.03530914,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2415724348593085, next_state=array([ 0.08975468,  1.356669  ,  0.587468  , -0.2646945 , -0.02891366,\n",
      "       -0.0016374 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08975468,  1.356669  ,  0.587468  , -0.2646945 , -0.02891366,\n",
      "       -0.0016374 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4274739330229638, next_state=array([ 0.09553309,  1.3515843 ,  0.5785116 , -0.22599483, -0.0295761 ,\n",
      "       -0.01324999,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09553309,  1.3515843 ,  0.5785116 , -0.22599483, -0.0295761 ,\n",
      "       -0.01324999,  0.        ,  0.        ], dtype=float32), action=1, reward=0.722129047099686, next_state=array([ 0.10121965,  1.3459138 ,  0.5669855 , -0.25199544, -0.02792093,\n",
      "        0.03310649,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10121965,  1.3459138 ,  0.5669855 , -0.25199544, -0.02792093,\n",
      "        0.03310649,  0.        ,  0.        ], dtype=float32), action=2, reward=0.030095914965340864, next_state=array([ 0.1071044 ,  1.3410889 ,  0.5859848 , -0.21439292, -0.02546526,\n",
      "        0.04911802,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1071044 ,  1.3410889 ,  0.5859848 , -0.21439292, -0.02546526,\n",
      "        0.04911802,  0.        ,  0.        ], dtype=float32), action=2, reward=0.15548154521188168, next_state=array([ 0.1130353 ,  1.3363929 ,  0.5904382 , -0.20866738, -0.02285165,\n",
      "        0.05227692,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1130353 ,  1.3363929 ,  0.5904382 , -0.20866738, -0.02285165,\n",
      "        0.05227692,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3810315174883658, next_state=array([ 0.1190464 ,  1.331091  ,  0.6005162 , -0.23562463, -0.02226089,\n",
      "        0.01181641,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1190464 ,  1.331091  ,  0.6005162 , -0.23562463, -0.02226089,\n",
      "        0.01181641,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.429136907846555, next_state=array([ 0.12505761,  1.3251894 ,  0.6005156 , -0.26229054, -0.02166932,\n",
      "        0.01183251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12505761,  1.3251894 ,  0.6005156 , -0.26229054, -0.02166932,\n",
      "        0.01183251,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.09079997071960405, next_state=array([ 0.13121338,  1.3198159 ,  0.61437154, -0.23879893, -0.02048099,\n",
      "        0.02376871,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13121338,  1.3198159 ,  0.61437154, -0.23879893, -0.02048099,\n",
      "        0.02376871,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6456864050383786, next_state=array([ 0.13754788,  1.3148545 ,  0.6314675 , -0.22048262, -0.01852714,\n",
      "        0.03908051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13754788,  1.3148545 ,  0.6314675 , -0.22048262, -0.01852714,\n",
      "        0.03908051,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.24471916262805848, next_state=array([ 0.14388227,  1.3092929 ,  0.6314616 , -0.2471553 , -0.01657399,\n",
      "        0.03906651,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14388227,  1.3092929 ,  0.6314616 , -0.2471553 , -0.01657399,\n",
      "        0.03906651,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3129053941523807, next_state=array([ 0.15021639,  1.3031101 ,  0.6314298 , -0.27477407, -0.01462077,\n",
      "        0.03906449,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15021639,  1.3031101 ,  0.6314298 , -0.27477407, -0.01462077,\n",
      "        0.03906449,  0.        ,  0.        ], dtype=float32), action=1, reward=0.49203134086238376, next_state=array([ 0.15649004,  1.2963259 ,  0.62384826, -0.30148536, -0.01114964,\n",
      "        0.06942235,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15649004,  1.2963259 ,  0.62384826, -0.30148536, -0.01114964,\n",
      "        0.06942235,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4652211131789388, next_state=array([ 0.16260652,  1.2904229 ,  0.6089198 , -0.26234582, -0.00845536,\n",
      "        0.05388572,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16260652,  1.2904229 ,  0.6089198 , -0.26234582, -0.00845536,\n",
      "        0.05388572,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9938461061089197, next_state=array([ 0.16863136,  1.2839297 ,  0.59742105, -0.2885634 , -0.00345689,\n",
      "        0.09996964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16863136,  1.2839297 ,  0.59742105, -0.2885634 , -0.00345689,\n",
      "        0.09996964,  0.        ,  0.        ], dtype=float32), action=1, reward=0.44802664702942363, next_state=array([ 0.1745574 ,  1.2768468 ,  0.5850249 , -0.31480408,  0.00402466,\n",
      "        0.14963089,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1745574 ,  1.2768468 ,  0.5850249 , -0.31480408,  0.00402466,\n",
      "        0.14963089,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0264219109400188, next_state=array([ 0.18056431,  1.2698255 ,  0.5927238 , -0.31209773,  0.01188892,\n",
      "        0.15728523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18056431,  1.2698255 ,  0.5927238 , -0.31209773,  0.01188892,\n",
      "        0.15728523,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9593694200754885, next_state=array([ 0.18663149,  1.2621946 ,  0.6002793 , -0.33921084,  0.01824213,\n",
      "        0.12706448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18663149,  1.2621946 ,  0.6002793 , -0.33921084,  0.01824213,\n",
      "        0.12706448,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0286814474669357, next_state=array([ 0.19279155,  1.2539772 ,  0.61194146, -0.36527917,  0.02225605,\n",
      "        0.08027854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19279155,  1.2539772 ,  0.61194146, -0.36527917,  0.02225605,\n",
      "        0.08027854,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1589079087115521, next_state=array([ 0.19894838,  1.2462853 ,  0.61155444, -0.34192744,  0.026333  ,\n",
      "        0.08153908,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19894838,  1.2462853 ,  0.61155444, -0.34192744,  0.026333  ,\n",
      "        0.08153908,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2835127683306655, next_state=array([ 0.20501223,  1.2379994 ,  0.5999031 , -0.3683898 ,  0.03274044,\n",
      "        0.12814875,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20501223,  1.2379994 ,  0.5999031 , -0.3683898 ,  0.03274044,\n",
      "        0.12814875,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.084644336033078, next_state=array([ 0.21117249,  1.2291183 ,  0.61197996, -0.39480105,  0.03672741,\n",
      "        0.07973947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21117249,  1.2291183 ,  0.61197996, -0.39480105,  0.03672741,\n",
      "        0.07973947,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.710265936930141, next_state=array([ 0.21741286,  1.219637  ,  0.62204796, -0.42144415,  0.03869917,\n",
      "        0.03943498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21741286,  1.219637  ,  0.62204796, -0.42144415,  0.03869917,\n",
      "        0.03943498,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3164604439177754, next_state=array([ 0.22357626,  1.2095447 ,  0.61238515, -0.44865972,  0.04261264,\n",
      "        0.07826932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22357626,  1.2095447 ,  0.61238515, -0.44865972,  0.04261264,\n",
      "        0.07826932,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5892278410209542, next_state=array([ 0.22969818,  1.199878  ,  0.6082788 , -0.42974508,  0.04646906,\n",
      "        0.07712854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22969818,  1.199878  ,  0.6082788 , -0.42974508,  0.04646906,\n",
      "        0.07712854,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0649901570533018, next_state=array([ 0.23582001,  1.1896114 ,  0.6082789 , -0.45641297,  0.05032548,\n",
      "        0.07712846,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23582001,  1.1896114 ,  0.6082789 , -0.45641297,  0.05032548,\n",
      "        0.07712846,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5011719808078101, next_state=array([ 0.24185868,  1.1787448 ,  0.5978575 , -0.48318043,  0.05626818,\n",
      "        0.11885397,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24185868,  1.1787448 ,  0.5978575 , -0.48318043,  0.05626818,\n",
      "        0.11885397,  0.        ,  0.        ], dtype=float32), action=2, reward=0.25172600095528425, next_state=array([ 0.24800014,  1.1682671 ,  0.60748434, -0.46593508,  0.06285783,\n",
      "        0.13179286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24800014,  1.1682671 ,  0.60748434, -0.46593508,  0.06285783,\n",
      "        0.13179286,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0176922429156705, next_state=array([ 0.25422984,  1.1571927 ,  0.6185495 , -0.49239734,  0.06723098,\n",
      "        0.08746305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25422984,  1.1571927 ,  0.6185495 , -0.49239734,  0.06723098,\n",
      "        0.08746305,  0.        ,  0.        ], dtype=float32), action=2, reward=2.070263337889128, next_state=array([ 0.26029196,  1.146318  ,  0.6023989 , -0.48349106,  0.07099659,\n",
      "        0.07531222,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26029196,  1.146318  ,  0.6023989 , -0.48349106,  0.07099659,\n",
      "        0.07531222,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0915442718831514, next_state=array([ 0.2663539 ,  1.1348435 ,  0.602399  , -0.5101589 ,  0.0747622 ,\n",
      "        0.07531217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2663539 ,  1.1348435 ,  0.602399  , -0.5101589 ,  0.0747622 ,\n",
      "        0.07531217,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0919676814417016, next_state=array([ 0.27241594,  1.1227692 ,  0.6023992 , -0.5368268 ,  0.0785278 ,\n",
      "        0.07531194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27241594,  1.1227692 ,  0.6023992 , -0.5368268 ,  0.0785278 ,\n",
      "        0.07531194,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0895341527636901, next_state=array([ 0.27847797,  1.1100953 ,  0.60239923, -0.5634946 ,  0.0822934 ,\n",
      "        0.07531188,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27847797,  1.1100953 ,  0.60239923, -0.5634946 ,  0.0822934 ,\n",
      "        0.07531188,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3744187608946676, next_state=array([ 0.28450108,  1.0980026 ,  0.5983956 , -0.5376737 ,  0.08618028,\n",
      "        0.07773741,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28450108,  1.0980026 ,  0.5983956 , -0.5376737 ,  0.08618028,\n",
      "        0.07773741,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2986631059346054, next_state=array([ 0.29038963,  1.0865959 ,  0.58521444, -0.50717735,  0.08978889,\n",
      "        0.07217215,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29038963,  1.0865959 ,  0.58521444, -0.50717735,  0.08978889,\n",
      "        0.07217215,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6881978558401147, next_state=array([ 0.2963584 ,  1.0745924 ,  0.5952685 , -0.5335894 ,  0.09138355,\n",
      "        0.03189313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2963584 ,  1.0745924 ,  0.5952685 , -0.5335894 ,  0.09138355,\n",
      "        0.03189313,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.302818221768631, next_state=array([ 3.0239049e-01,  1.0620070e+00,  6.0323828e-01, -5.5934870e-01,\n",
      "        9.1357410e-02, -5.2265904e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 3.0239049e-01,  1.0620070e+00,  6.0323828e-01, -5.5934870e-01,\n",
      "        9.1357410e-02, -5.2265904e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.2600167488427576, next_state=array([ 0.30851087,  1.0488458 ,  0.6143417 , -0.5848052 ,  0.08907514,\n",
      "       -0.04564565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30851087,  1.0488458 ,  0.6143417 , -0.5848052 ,  0.08907514,\n",
      "       -0.04564565,  0.        ,  0.        ], dtype=float32), action=2, reward=4.477940901615296, next_state=array([ 0.314454  ,  1.036415  ,  0.5970634 , -0.5523097 ,  0.08634171,\n",
      "       -0.05466881,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.314454  ,  1.036415  ,  0.5970634 , -0.5523097 ,  0.08634171,\n",
      "       -0.05466881,  0.        ,  0.        ], dtype=float32), action=2, reward=4.363041815963141, next_state=array([ 0.32021227,  1.0246712 ,  0.5791073 , -0.5217589 ,  0.08310018,\n",
      "       -0.06483065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32021227,  1.0246712 ,  0.5791073 , -0.5217589 ,  0.08310018,\n",
      "       -0.06483065,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.48304507326042767, next_state=array([ 0.32597065,  1.0123277 ,  0.5791074 , -0.5484265 ,  0.07985864,\n",
      "       -0.0648307 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32597065,  1.0123277 ,  0.5791074 , -0.5484265 ,  0.07985864,\n",
      "       -0.0648307 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.06603071393138407, next_state=array([ 0.33163738,  0.9993848 ,  0.56762695, -0.5751882 ,  0.07891171,\n",
      "       -0.0189386 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33163738,  0.9993848 ,  0.56762695, -0.5751882 ,  0.07891171,\n",
      "       -0.0189386 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7221416150762252, next_state=array([ 0.33730412,  0.9858419 ,  0.56762695, -0.601855  ,  0.07796478,\n",
      "       -0.01893887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33730412,  0.9858419 ,  0.56762695, -0.601855  ,  0.07796478,\n",
      "       -0.01893887,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.23392640161574604, next_state=array([ 0.34287605,  0.9716881 ,  0.5557376 , -0.6291355 ,  0.07940969,\n",
      "        0.02889819,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34287605,  0.9716881 ,  0.5557376 , -0.6291355 ,  0.07940969,\n",
      "        0.02889819,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6264002184375375, next_state=array([ 0.3483696 ,  0.9569149 ,  0.5458817 , -0.65677387,  0.08285135,\n",
      "        0.06883342,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3483696 ,  0.9569149 ,  0.5458817 , -0.65677387,  0.08285135,\n",
      "        0.06883342,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.160427385618533, next_state=array([ 0.35386315,  0.9415419 ,  0.5458818 , -0.6834416 ,  0.08629302,\n",
      "        0.06883337,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35386315,  0.9415419 ,  0.5458818 , -0.6834416 ,  0.08629302,\n",
      "        0.06883337,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8222463787138554, next_state=array([ 0.3592721 ,  0.9255499 ,  0.5352541 , -0.71108985,  0.09188712,\n",
      "        0.11188214,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3592721 ,  0.9255499 ,  0.5352541 , -0.71108985,  0.09188712,\n",
      "        0.11188214,  0.        ,  0.        ], dtype=float32), action=2, reward=4.154487395654297, next_state=array([ 0.3645772 ,  0.9104572 ,  0.5249171 , -0.67113787,  0.0974277 ,\n",
      "        0.11081133,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3645772 ,  0.9104572 ,  0.5249171 , -0.67113787,  0.0974277 ,\n",
      "        0.11081133,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.416641991571396, next_state=array([ 0.3698823 ,  0.8947649 ,  0.5249175 , -0.697807  ,  0.10296825,\n",
      "        0.1108111 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3698823 ,  0.8947649 ,  0.5249175 , -0.697807  ,  0.10296825,\n",
      "        0.1108111 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1615504129480019, next_state=array([ 0.37512475,  0.8784671 ,  0.5170723 , -0.7248643 ,  0.11008671,\n",
      "        0.14236924,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37512475,  0.8784671 ,  0.5170723 , -0.7248643 ,  0.11008671,\n",
      "        0.14236924,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.306171751295692, next_state=array([ 0.3803052 ,  0.8615709 ,  0.50931746, -0.75160867,  0.11875185,\n",
      "        0.17330289,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3803052 ,  0.8615709 ,  0.50931746, -0.75160867,  0.11875185,\n",
      "        0.17330289,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0100577931130474, next_state=array([ 0.38557416,  0.8441028 ,  0.52047896, -0.7768796 ,  0.12513475,\n",
      "        0.12765796,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38557416,  0.8441028 ,  0.52047896, -0.7768796 ,  0.12513475,\n",
      "        0.12765796,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.21311191302584, next_state=array([ 0.39076185,  0.82601756,  0.5102694 , -0.80452794,  0.13359252,\n",
      "        0.16915561,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39076185,  0.82601756,  0.5102694 , -0.80452794,  0.13359252,\n",
      "        0.16915561,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3824315344239142, next_state=array([ 0.3958575 ,  0.80731934,  0.49874678, -0.83204204,  0.14437984,\n",
      "        0.2157462 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3958575 ,  0.80731934,  0.49874678, -0.83204204,  0.14437984,\n",
      "        0.2157462 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0462189485738507, next_state=array([ 0.40101546,  0.78804517,  0.5066086 , -0.85754234,  0.15354533,\n",
      "        0.18331006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40101546,  0.78804517,  0.5066086 , -0.85754234,  0.15354533,\n",
      "        0.18331006,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0206386510880465, next_state=array([ 0.4060522 ,  0.7690763 ,  0.49463415, -0.8440253 ,  0.16258451,\n",
      "        0.18078372,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4060522 ,  0.7690763 ,  0.49463415, -0.8440253 ,  0.16258451,\n",
      "        0.18078372,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9740563175600119, next_state=array([ 0.4111722 ,  0.74952865,  0.50510246, -0.86955523,  0.1694852 ,\n",
      "        0.1380141 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4111722 ,  0.74952865,  0.50510246, -0.86955523,  0.1694852 ,\n",
      "        0.1380141 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4968884177121708, next_state=array([ 0.4162921 ,  0.7293816 ,  0.5051034 , -0.8962258 ,  0.17638588,\n",
      "        0.13801363,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4162921 ,  0.7293816 ,  0.5051034 , -0.8962258 ,  0.17638588,\n",
      "        0.13801363,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4868380345576213, next_state=array([ 0.4214119 ,  0.7086352 ,  0.5051044 , -0.9228963 ,  0.18328652,\n",
      "        0.1380132 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4214119 ,  0.7086352 ,  0.5051044 , -0.9228963 ,  0.18328652,\n",
      "        0.1380132 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.292255111903967, next_state=array([ 0.4265005 ,  0.68832296,  0.50154746, -0.9036876 ,  0.19062684,\n",
      "        0.14680625,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4265005 ,  0.68832296,  0.50154746, -0.9036876 ,  0.19062684,\n",
      "        0.14680625,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4341882905825958, next_state=array([ 0.43150824,  0.66739213,  0.49142545, -0.93149334,  0.20003892,\n",
      "        0.18824151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43150824,  0.66739213,  0.49142545, -0.93149334,  0.20003892,\n",
      "        0.18824151,  0.        ,  0.        ], dtype=float32), action=2, reward=3.7690918691915387, next_state=array([ 0.43646652,  0.64733577,  0.4858141 , -0.8927763 ,  0.2101309 ,\n",
      "        0.20183952,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43646652,  0.64733577,  0.4858141 , -0.8927763 ,  0.2101309 ,\n",
      "        0.20183952,  0.        ,  0.        ], dtype=float32), action=2, reward=3.657815279143546, next_state=array([ 0.4413209 ,  0.62809956,  0.47501302, -0.8564703 ,  0.22066738,\n",
      "        0.21072991,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4413209 ,  0.62809956,  0.47501302, -0.8564703 ,  0.22066738,\n",
      "        0.21072991,  0.        ,  0.        ], dtype=float32), action=2, reward=2.9612620224811623, next_state=array([ 0.44609672,  0.60957086,  0.46664786, -0.82516295,  0.23173235,\n",
      "        0.22129945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44609672,  0.60957086,  0.46664786, -0.82516295,  0.23173235,\n",
      "        0.22129945,  0.        ,  0.        ], dtype=float32), action=2, reward=0.22484931035806427, next_state=array([ 0.45089617,  0.59120166,  0.4684193 , -0.81826985,  0.24344255,\n",
      "        0.23420353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45089617,  0.59120166,  0.4684193 , -0.81826985,  0.24344255,\n",
      "        0.23420353,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4413793659488306, next_state=array([ 0.45570993,  0.573067  ,  0.4692096 , -0.8080503 ,  0.2558377 ,\n",
      "        0.24790294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45570993,  0.573067  ,  0.4692096 , -0.8080503 ,  0.2558377 ,\n",
      "        0.24790294,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.350834162412552, next_state=array([ 0.46044606,  0.5542944 ,  0.45943236, -0.836876  ,  0.2703334 ,\n",
      "        0.28991398,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46044606,  0.5542944 ,  0.45943236, -0.836876  ,  0.2703334 ,\n",
      "        0.28991398,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.819115939491182, next_state=array([ 0.4652686 ,  0.5349501 ,  0.47032946, -0.8620001 ,  0.28257   ,\n",
      "        0.24473199,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4652686 ,  0.5349501 ,  0.47032946, -0.8620001 ,  0.28257   ,\n",
      "        0.24473199,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4057338179805186, next_state=array([ 0.47009078,  0.5150077 ,  0.47033462, -0.8886787 ,  0.29480648,\n",
      "        0.24472947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47009078,  0.5150077 ,  0.47033462, -0.8886787 ,  0.29480648,\n",
      "        0.24472947,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3874680587048815, next_state=array([ 0.47483176,  0.49442947,  0.46014485, -0.9174784 ,  0.3092293 ,\n",
      "        0.28845733,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47483176,  0.49442947,  0.46014485, -0.9174784 ,  0.3092293 ,\n",
      "        0.28845733,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7603027638874083, next_state=array([ 0.47965488,  0.47328767,  0.47055387, -0.94218814,  0.32144096,\n",
      "        0.24423292,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47965488,  0.47328767,  0.47055387, -0.94218814,  0.32144096,\n",
      "        0.24423292,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.485810127374292, next_state=array([ 0.4844164 ,  0.4515135 ,  0.46280676, -0.970763  ,  0.33535206,\n",
      "        0.27822182,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4844164 ,  0.4515135 ,  0.46280676, -0.970763  ,  0.33535206,\n",
      "        0.27822182,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.711730372259551, next_state=array([ 0.48926315,  0.4291825 ,  0.4736247 , -0.9951023 ,  0.34692746,\n",
      "        0.23150794,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48926315,  0.4291825 ,  0.4736247 , -0.9951023 ,  0.34692746,\n",
      "        0.23150794,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5382849676049077, next_state=array([ 0.49403563,  0.4062049 ,  0.46424785, -1.02442   ,  0.3606092 ,\n",
      "        0.27363497,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49403563,  0.4062049 ,  0.46424785, -1.02442   ,  0.3606092 ,\n",
      "        0.27363497,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0028341742037528, next_state=array([ 0.49862176,  0.38369817,  0.44533262, -1.0037012 ,  0.3746498 ,\n",
      "        0.28081173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49862176,  0.38369817,  0.44533262, -1.0037012 ,  0.3746498 ,\n",
      "        0.28081173,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.810414649357709, next_state=array([ 0.50327605,  0.36063674,  0.4540608 , -1.0279825 ,  0.38673314,\n",
      "        0.24166688,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.50327605,  0.36063674,  0.4540608 , -1.0279825 ,  0.38673314,\n",
      "        0.24166688,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6936772370265203, next_state=array([ 0.5079297 ,  0.33697715,  0.45406762, -1.0546606 ,  0.3988164 ,\n",
      "        0.24166445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5079297 ,  0.33697715,  0.45406762, -1.0546606 ,  0.3988164 ,\n",
      "        0.24166445,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2491102613383704, next_state=array([ 0.5121757 ,  0.31387433,  0.41366205, -1.0299085 ,  0.4105469 ,\n",
      "        0.2346104 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5121757 ,  0.31387433,  0.41366205, -1.0299085 ,  0.4105469 ,\n",
      "        0.2346104 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.96065926208385, next_state=array([ 0.51633674,  0.2901239 ,  0.403045  , -1.0594345 ,  0.42465752,\n",
      "        0.28221166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51633674,  0.2901239 ,  0.403045  , -1.0594345 ,  0.42465752,\n",
      "        0.28221166,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.3718830157222315, next_state=array([ 0.52041036,  0.26570937,  0.3919925 , -1.0898151 ,  0.44136256,\n",
      "        0.33410093,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.52041036,  0.26570937,  0.3919925 , -1.0898151 ,  0.44136256,\n",
      "        0.33410093,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.634536513264719, next_state=array([ 0.5244297 ,  0.2406581 ,  0.38526   , -1.118754  ,  0.45965242,\n",
      "        0.3657968 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5244297 ,  0.2406581 ,  0.38526   , -1.118754  ,  0.45965242,\n",
      "        0.3657968 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.035967832442622, next_state=array([ 0.5283632 ,  0.21493743,  0.37445205, -1.149527  ,  0.48056927,\n",
      "        0.41833654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5283632 ,  0.21493743,  0.37445205, -1.149527  ,  0.48056927,\n",
      "        0.41833654,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2292198237038976, next_state=array([ 0.5319704 ,  0.18996628,  0.34150177, -1.1166674 ,  0.5020718 ,\n",
      "        0.43005037,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5319704 ,  0.18996628,  0.34150177, -1.1166674 ,  0.5020718 ,\n",
      "        0.43005037,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.2437086439808525, next_state=array([ 0.53557557,  0.1644006 ,  0.34152907, -1.1433681 ,  0.52357364,\n",
      "        0.43003663,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.53557557,  0.1644006 ,  0.34152907, -1.1433681 ,  0.52357364,\n",
      "        0.43003663,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.349495676036099, next_state=array([ 0.53917867,  0.13824013,  0.34155744, -1.1700686 ,  0.54507476,\n",
      "        0.43002295,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.53917867,  0.13824013,  0.34155744, -1.1700686 ,  0.54507476,\n",
      "        0.43002295,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.237506387788442, next_state=array([ 0.54285   ,  0.11153784,  0.3504416 , -1.1936516 ,  0.5644488 ,\n",
      "        0.38747975,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.54285   ,  0.11153784,  0.3504416 , -1.1936516 ,  0.5644488 ,\n",
      "        0.38747975,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.207405762302357, next_state=array([ 0.54657763,  0.08428117,  0.35774353, -1.2178612 ,  0.5820895 ,\n",
      "        0.35281494,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.54657763,  0.08428117,  0.35774353, -1.2178612 ,  0.5820895 ,\n",
      "        0.35281494,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.0531107073606725, next_state=array([ 0.55037946,  0.05649162,  0.36731422, -1.2408204 ,  0.5973582 ,\n",
      "        0.30537498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.55037946,  0.05649162,  0.36731422, -1.2408204 ,  0.5973582 ,\n",
      "        0.30537498,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8609061261278328, next_state=array([ 0.553882  ,  0.02852763,  0.3378571 , -1.2485425 ,  0.6122209 ,\n",
      "        0.29725277,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.553882  ,  0.02852763,  0.3378571 , -1.2485425 ,  0.6122209 ,\n",
      "        0.29725277,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.340763939404098, next_state=array([ 5.5738342e-01, -3.3893586e-05,  3.3787289e-01, -1.2752244e+00,\n",
      "        6.2708324e-01,  2.9724818e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 5.5738342e-01, -3.3893586e-05,  3.3787289e-01, -1.2752244e+00,\n",
      "        6.2708324e-01,  2.9724818e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-4.923996247241035, next_state=array([ 0.56080943, -0.02926314,  0.3284839 , -1.3060046 ,  0.6443786 ,\n",
      "        0.34590682,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.56080943, -0.02926314,  0.3284839 , -1.3060046 ,  0.6443786 ,\n",
      "        0.34590682,  0.        ,  0.        ], dtype=float32), action=2, reward=9.580927590574372, next_state=array([ 0.56366575, -0.05831229,  0.27224657, -1.2978892 ,  0.6610135 ,\n",
      "        0.33269733,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.56366575, -0.05831229,  0.27224657, -1.2978892 ,  0.6610135 ,\n",
      "        0.33269733,  0.        ,  1.        ], dtype=float32), action=3, reward=-3.9822232619557654, next_state=array([ 0.5666806 , -0.08747116,  0.28538734, -1.3110998 ,  0.6781527 ,\n",
      "        0.324694  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.5666806 , -0.08747116,  0.28538734, -1.3110998 ,  0.6781527 ,\n",
      "        0.324694  ,  0.        ,  1.        ], dtype=float32), action=0, reward=-5.940123245120958, next_state=array([ 0.56977654, -0.11683255,  0.2878646 , -1.3333068 ,  0.7070865 ,\n",
      "        0.39137176,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.56977654, -0.11683255,  0.2878646 , -1.3333068 ,  0.7070865 ,\n",
      "        0.39137176,  0.        ,  1.        ], dtype=float32), action=3, reward=-100, next_state=array([ 0.57641804, -0.13269624,  0.63585484, -0.71427655,  0.9029096 ,\n",
      "        4.3732877 ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00296202,  1.3990834 ,  0.3000049 , -0.5260817 , -0.00342545,\n",
      "       -0.06795559,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5566741416954517, next_state=array([ 0.00583181,  1.3866733 ,  0.28802514, -0.5515677 , -0.00446215,\n",
      "       -0.02073513,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00583181,  1.3866733 ,  0.28802514, -0.5515677 , -0.00446215,\n",
      "       -0.02073513,  0.        ,  0.        ], dtype=float32), action=2, reward=1.854988530878171, next_state=array([ 0.00870275,  1.3745308 ,  0.28815573, -0.5396643 , -0.00550446,\n",
      "       -0.02084801,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00870275,  1.3745308 ,  0.28815573, -0.5396643 , -0.00550446,\n",
      "       -0.02084801,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0204963875667645, next_state=array([ 0.01166668,  1.3617828 ,  0.299807  , -0.5665994 , -0.00888245,\n",
      "       -0.0675661 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01166668,  1.3617828 ,  0.299807  , -0.5665994 , -0.00888245,\n",
      "       -0.0675661 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7927085966976903, next_state=array([ 0.01467638,  1.3493885 ,  0.3041842 , -0.5508794 , -0.01206739,\n",
      "       -0.06370488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01467638,  1.3493885 ,  0.3041842 , -0.5508794 , -0.01206739,\n",
      "       -0.06370488,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1820659416456167, next_state=array([ 0.01777477,  1.3363864 ,  0.31531376, -0.57792926, -0.01748378,\n",
      "       -0.10833763,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01777477,  1.3363864 ,  0.31531376, -0.57792926, -0.01748378,\n",
      "       -0.10833763,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.539588557676808, next_state=array([ 0.02087336,  1.3227847 ,  0.31533048, -0.604596  , -0.02289829,\n",
      "       -0.10830002,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02087336,  1.3227847 ,  0.31533048, -0.604596  , -0.02289829,\n",
      "       -0.10830002,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5028158744797508, next_state=array([ 0.02397203,  1.3085833 ,  0.31534606, -0.6312647 , -0.02831242,\n",
      "       -0.10829258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02397203,  1.3085833 ,  0.31534606, -0.6312647 , -0.02831242,\n",
      "       -0.10829258,  0.        ,  0.        ], dtype=float32), action=2, reward=3.018477364763794, next_state=array([ 0.02720699,  1.2951648 ,  0.32843235, -0.5964817 , -0.0332028 ,\n",
      "       -0.09781654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02720699,  1.2951648 ,  0.32843235, -0.5964817 , -0.0332028 ,\n",
      "       -0.09781654,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1222755596213845, next_state=array([ 0.03051834,  1.2811466 ,  0.33803385, -0.6232017 , -0.04001429,\n",
      "       -0.1362426 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03051834,  1.2811466 ,  0.33803385, -0.6232017 , -0.04001429,\n",
      "       -0.1362426 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8450386841422233, next_state=array([ 0.03374042,  1.266535  ,  0.32679537, -0.64952576, -0.04456344,\n",
      "       -0.09099127,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03374042,  1.266535  ,  0.32679537, -0.64952576, -0.04456344,\n",
      "       -0.09099127,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3360917560395364, next_state=array([ 0.03696251,  1.251324  ,  0.3268076 , -0.67619604, -0.04911326,\n",
      "       -0.09100486,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03696251,  1.251324  ,  0.3268076 , -0.67619604, -0.04911326,\n",
      "       -0.09100486,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5757122823389398, next_state=array([ 0.04009523,  1.2355255 ,  0.31559375, -0.7022337 , -0.05140252,\n",
      "       -0.04578922,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04009523,  1.2355255 ,  0.31559375, -0.7022337 , -0.05140252,\n",
      "       -0.04578922,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.38677615574891777, next_state=array([ 0.04314012,  1.2191328 ,  0.3045693 , -0.72856385, -0.05147792,\n",
      "       -0.00150841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04314012,  1.2191328 ,  0.3045693 , -0.72856385, -0.05147792,\n",
      "       -0.00150841,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.42158006256244, next_state=array([ 0.04626398,  1.2021346 ,  0.3144784 , -0.75555074, -0.05354331,\n",
      "       -0.04131151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04626398,  1.2021346 ,  0.3144784 , -0.75555074, -0.05354331,\n",
      "       -0.04131151,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9290767078404372, next_state=array([ 0.04938793,  1.1845363 ,  0.3144851 , -0.78221965, -0.05560707,\n",
      "       -0.04127911,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04938793,  1.1845363 ,  0.3144851 , -0.78221965, -0.05560707,\n",
      "       -0.04127911,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.33702792068015586, next_state=array([ 0.05243759,  1.1663495 ,  0.30515793, -0.80831015, -0.05579139,\n",
      "       -0.003687  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05243759,  1.1663495 ,  0.30515793, -0.80831015, -0.05579139,\n",
      "       -0.003687  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.316462091408822, next_state=array([ 0.05557547,  1.147559  ,  0.31621426, -0.8352254 , -0.05819367,\n",
      "       -0.04805008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05557547,  1.147559  ,  0.31621426, -0.8352254 , -0.05819367,\n",
      "       -0.04805008,  0.        ,  0.        ], dtype=float32), action=2, reward=4.709928722542327, next_state=array([ 0.05861054,  1.1295393 ,  0.30666673, -0.8009988 , -0.0613234 ,\n",
      "       -0.06260064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05861054,  1.1295393 ,  0.30666673, -0.8009988 , -0.0613234 ,\n",
      "       -0.06260064,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2368783182902066, next_state=array([ 0.061514  ,  1.1116943 ,  0.2942775 , -0.7932766 , -0.06521416,\n",
      "       -0.07782196,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.061514  ,  1.1116943 ,  0.2942775 , -0.7932766 , -0.06521416,\n",
      "       -0.07782196,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6366938772166566, next_state=array([ 0.06434746,  1.0932463 ,  0.2855052 , -0.82000774, -0.06734958,\n",
      "       -0.04271238,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06434746,  1.0932463 ,  0.2855052 , -0.82000774, -0.06734958,\n",
      "       -0.04271238,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4698170047683152, next_state=array([ 0.0671217 ,  1.0742035 ,  0.27807397, -0.84637517, -0.06799179,\n",
      "       -0.01284532,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0671217 ,  1.0742035 ,  0.27807397, -0.84637517, -0.06799179,\n",
      "       -0.01284532,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.659332977944274, next_state=array([ 0.06989594,  1.0545608 ,  0.27807528, -0.8730443 , -0.06863414,\n",
      "       -0.01284857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06989594,  1.0545608 ,  0.27807528, -0.8730443 , -0.06863414,\n",
      "       -0.01284857,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1507354231010811, next_state=array([ 0.07259379,  1.0343199 ,  0.26850015, -0.8995371 , -0.06735761,\n",
      "        0.02553253,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07259379,  1.0343199 ,  0.26850015, -0.8995371 , -0.06735761,\n",
      "        0.02553253,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8805737367381983, next_state=array([ 0.07536831,  1.0134774 ,  0.27809882, -0.92635745, -0.06800504,\n",
      "       -0.01294951,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07536831,  1.0134774 ,  0.27809882, -0.92635745, -0.06800504,\n",
      "       -0.01294951,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1393912527602754, next_state=array([ 0.07806425,  0.9920164 ,  0.26828808, -0.95377153, -0.0667056 ,\n",
      "        0.02598888,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07806425,  0.9920164 ,  0.26828808, -0.95377153, -0.0667056 ,\n",
      "        0.02598888,  0.        ,  0.        ], dtype=float32), action=2, reward=4.957698333896457, next_state=array([ 0.08090601,  0.9713651 ,  0.2824697 , -0.91776097, -0.06502301,\n",
      "        0.03365197,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08090601,  0.9713651 ,  0.2824697 , -0.91776097, -0.06502301,\n",
      "        0.03365197,  0.        ,  0.        ], dtype=float32), action=2, reward=5.50409586538363, next_state=array([ 0.08375378,  0.9515974 ,  0.28335127, -0.87850744, -0.06360893,\n",
      "        0.02828175,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08375378,  0.9515974 ,  0.28335127, -0.87850744, -0.06360893,\n",
      "        0.02828175,  0.        ,  0.        ], dtype=float32), action=2, reward=3.489464652517836, next_state=array([ 0.08663969,  0.9322729 ,  0.28719288, -0.858802  , -0.06222297,\n",
      "        0.02771931,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08663969,  0.9322729 ,  0.28719288, -0.858802  , -0.06222297,\n",
      "        0.02771931,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.012165026083805514, next_state=array([ 0.08945207,  0.91234475,  0.27796447, -0.8855709 , -0.05899493,\n",
      "        0.06456091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08945207,  0.91234475,  0.27796447, -0.8855709 , -0.05899493,\n",
      "        0.06456091,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2106023721127599, next_state=array([ 0.09226437,  0.8918165 ,  0.2779644 , -0.9122385 , -0.0557669 ,\n",
      "        0.06456093,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09226437,  0.8918165 ,  0.2779644 , -0.9122385 , -0.0557669 ,\n",
      "        0.06456093,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3281899060593798, next_state=array([ 0.09500132,  0.87070185,  0.26849824, -0.9382452 , -0.05063211,\n",
      "        0.10269576,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09500132,  0.87070185,  0.26849824, -0.9382452 , -0.05063211,\n",
      "        0.10269576,  0.        ,  0.        ], dtype=float32), action=2, reward=4.217700603873635, next_state=array([ 0.09766827,  0.85002035,  0.2619957 , -0.919022  , -0.04598112,\n",
      "        0.09301953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09766827,  0.85002035,  0.2619957 , -0.919022  , -0.04598112,\n",
      "        0.09301953,  0.        ,  0.        ], dtype=float32), action=2, reward=4.825189308008885, next_state=array([ 0.10045948,  0.8300461 ,  0.27402028, -0.88760024, -0.04094104,\n",
      "        0.10080162,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10045948,  0.8300461 ,  0.27402028, -0.88760024, -0.04094104,\n",
      "        0.10080162,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.04016994926197981, next_state=array([ 0.1032507 ,  0.8094721 ,  0.27402017, -0.91426915, -0.03590097,\n",
      "        0.10080147,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1032507 ,  0.8094721 ,  0.27402017, -0.91426915, -0.03590097,\n",
      "        0.10080147,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.44423489361793034, next_state=array([ 0.10610132,  0.78828436,  0.281478  , -0.94159675, -0.03236249,\n",
      "        0.0707697 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10610132,  0.78828436,  0.281478  , -0.94159675, -0.03236249,\n",
      "        0.0707697 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.39601940854544293, next_state=array([ 0.1088746 ,  0.7665077 ,  0.27178162, -0.9677463 , -0.02687683,\n",
      "        0.109713  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1088746 ,  0.7665077 ,  0.27178162, -0.9677463 , -0.02687683,\n",
      "        0.109713  ,  0.        ,  0.        ], dtype=float32), action=2, reward=5.1976330247778835, next_state=array([ 0.11183481,  0.7455165 ,  0.28970748, -0.9328367 , -0.02064146,\n",
      "        0.12470726,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11183481,  0.7455165 ,  0.28970748, -0.9328367 , -0.02064146,\n",
      "        0.12470726,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.28734988382365034, next_state=array([ 0.11486302,  0.7239268 ,  0.29823303, -0.95948446, -0.01611298,\n",
      "        0.09057001,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11486302,  0.7239268 ,  0.29823303, -0.95948446, -0.01611298,\n",
      "        0.09057001,  0.        ,  0.        ], dtype=float32), action=2, reward=2.172915145897787, next_state=array([ 0.11795597,  0.7023613 ,  0.3044339 , -0.9584304 , -0.01131588,\n",
      "        0.0959423 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11795597,  0.7023613 ,  0.3044339 , -0.9584304 , -0.01131588,\n",
      "        0.0959423 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.4058271071076842, next_state=array([ 0.12098207,  0.6801853 ,  0.29605857, -0.985562  , -0.00484359,\n",
      "        0.12944567,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12098207,  0.6801853 ,  0.29605857, -0.985562  , -0.00484359,\n",
      "        0.12944567,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.257676872849429, next_state=array([ 1.24090195e-01,  6.57409310e-01,  3.06340188e-01, -1.01226330e+00,\n",
      "       -4.30417014e-04,  8.82633775e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.24090195e-01,  6.57409310e-01,  3.06340188e-01, -1.01226330e+00,\n",
      "       -4.30417014e-04,  8.82633775e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=1, reward=-0.600447717952959, next_state=array([ 0.12710047,  0.6340356 ,  0.29406703, -1.0388455 ,  0.00644065,\n",
      "        0.13742134,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12710047,  0.6340356 ,  0.29406703, -1.0388455 ,  0.00644065,\n",
      "        0.13742134,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9690534619997493, next_state=array([ 0.13011074,  0.61006254,  0.29406705, -1.0655162 ,  0.0133117 ,\n",
      "        0.13742085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13011074,  0.61006254,  0.29406705, -1.0655162 ,  0.0133117 ,\n",
      "        0.13742085,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9253112849985428, next_state=array([ 0.13312101,  0.5854901 ,  0.29406708, -1.092187  ,  0.02018273,\n",
      "        0.13742042,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13312101,  0.5854901 ,  0.29406708, -1.092187  ,  0.02018273,\n",
      "        0.13742042,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9003514832932911, next_state=array([ 0.13604784,  0.56030947,  0.28360802, -1.1192893 ,  0.02915123,\n",
      "        0.17936966,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13604784,  0.56030947,  0.28360802, -1.1192893 ,  0.02915123,\n",
      "        0.17936966,  0.        ,  0.        ], dtype=float32), action=2, reward=3.856036056097037, next_state=array([ 0.13879594,  0.5356495 ,  0.26646373, -1.0961864 ,  0.03739404,\n",
      "        0.16485633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13879594,  0.5356495 ,  0.26646373, -1.0961864 ,  0.03739404,\n",
      "        0.16485633,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3419396508680963, next_state=array([ 0.14134721,  0.5113769 ,  0.24758394, -1.0789886 ,  0.04484086,\n",
      "        0.14893667,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14134721,  0.5113769 ,  0.24758394, -1.0789886 ,  0.04484086,\n",
      "        0.14893667,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.024645476883478, next_state=array([ 0.1438984 ,  0.4865051 ,  0.24758418, -1.1056598 ,  0.05228767,\n",
      "        0.14893612,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1438984 ,  0.4865051 ,  0.24758418, -1.1056598 ,  0.05228767,\n",
      "        0.14893612,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.088452110836214, next_state=array([ 0.1463769 ,  0.4610169 ,  0.23845382, -1.1331618 ,  0.06157696,\n",
      "        0.18578586,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1463769 ,  0.4610169 ,  0.23845382, -1.1331618 ,  0.06157696,\n",
      "        0.18578586,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1404996826906881, next_state=array([ 0.1488554 ,  0.43492985,  0.23845442, -1.1598357 ,  0.07086621,\n",
      "        0.18578479,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1488554 ,  0.43492985,  0.23845442, -1.1598357 ,  0.07086621,\n",
      "        0.18578479,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.067877336900209, next_state=array([ 0.15139619,  0.40825963,  0.24630454, -1.1857319 ,  0.07856651,\n",
      "        0.15400614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15139619,  0.40825963,  0.24630454, -1.1857319 ,  0.07856651,\n",
      "        0.15400614,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8989334085070471, next_state=array([ 0.15403318,  0.38100314,  0.258375  , -1.2116874 ,  0.0838358 ,\n",
      "        0.10538594,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15403318,  0.38100314,  0.258375  , -1.2116874 ,  0.0838358 ,\n",
      "        0.10538594,  0.        ,  0.        ], dtype=float32), action=2, reward=5.546939673733857, next_state=array([ 0.15672532,  0.35472187,  0.26322284, -1.1684053 ,  0.08976656,\n",
      "        0.11861523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15672532,  0.35472187,  0.26322284, -1.1684053 ,  0.08976656,\n",
      "        0.11861523,  0.        ,  0.        ], dtype=float32), action=2, reward=4.5991083229825565, next_state=array([ 0.15918636,  0.3290658 ,  0.24084869, -1.1405953 ,  0.09497188,\n",
      "        0.1041064 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15918636,  0.3290658 ,  0.24084869, -1.1405953 ,  0.09497188,\n",
      "        0.1041064 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.264139371378957, next_state=array([ 0.16149846,  0.304013  ,  0.22630064, -1.113776  ,  0.0998441 ,\n",
      "        0.09744423,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16149846,  0.304013  ,  0.22630064, -1.113776  ,  0.0998441 ,\n",
      "        0.09744423,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9784732079937146, next_state=array([ 0.16390276,  0.27836403,  0.23785956, -1.140127  ,  0.10240116,\n",
      "        0.05114106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16390276,  0.27836403,  0.23785956, -1.140127  ,  0.10240116,\n",
      "        0.05114106,  0.        ,  0.        ], dtype=float32), action=2, reward=4.9237193801417165, next_state=array([ 0.16623631,  0.25348616,  0.23067307, -1.1058717 ,  0.10506519,\n",
      "        0.0532806 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16623631,  0.25348616,  0.23067307, -1.1058717 ,  0.10506519,\n",
      "        0.0532806 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7558890578276134, next_state=array([ 0.16857357,  0.22871175,  0.23079185, -1.1012928 ,  0.10797376,\n",
      "        0.05817164,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16857357,  0.22871175,  0.23079185, -1.1012928 ,  0.10797376,\n",
      "        0.05817164,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0523391141883849, next_state=array([ 0.17091075,  0.20333742,  0.23079197, -1.1279601 ,  0.11088235,\n",
      "        0.05817166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17091075,  0.20333742,  0.23079197, -1.1279601 ,  0.11088235,\n",
      "        0.05817166,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1019758372264892, next_state=array([ 0.1733367 ,  0.1773755 ,  0.2419266 , -1.1539156 ,  0.11154503,\n",
      "        0.01325349,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1733367 ,  0.1773755 ,  0.2419266 , -1.1539156 ,  0.11154503,\n",
      "        0.01325349,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.036401533114514, next_state=array([ 0.17576265,  0.15081353,  0.24192658, -1.1805823 ,  0.1122077 ,\n",
      "        0.01325348,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17576265,  0.15081353,  0.24192658, -1.1805823 ,  0.1122077 ,\n",
      "        0.01325348,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7983958396926996, next_state=array([ 0.17822981,  0.12468547,  0.24550852, -1.1613376 ,  0.1134178 ,\n",
      "        0.02420177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17822981,  0.12468547,  0.24550852, -1.1613376 ,  0.1134178 ,\n",
      "        0.02420177,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.470603825554149, next_state=array([ 0.18076964,  0.09797788,  0.25463396, -1.1869549 ,  0.11276717,\n",
      "       -0.01301255,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18076964,  0.09797788,  0.25463396, -1.1869549 ,  0.11276717,\n",
      "       -0.01301255,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7611259399551489, next_state=array([ 0.18324414,  0.07064846,  0.24642113, -1.2147216 ,  0.11379772,\n",
      "        0.0206109 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18324414,  0.07064846,  0.24642113, -1.2147216 ,  0.11379772,\n",
      "        0.0206109 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0896007018143608, next_state=array([ 0.185783  ,  0.04273404,  0.2544998 , -1.2405928 ,  0.11318669,\n",
      "       -0.01222056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.185783  ,  0.04273404,  0.2544998 , -1.2405928 ,  0.11318669,\n",
      "       -0.01222056,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3155361618915706, next_state=array([ 0.18838501,  0.01423811,  0.26245314, -1.2663181 ,  0.11095282,\n",
      "       -0.0446772 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18838501,  0.01423811,  0.26245314, -1.2663181 ,  0.11095282,\n",
      "       -0.0446772 ,  0.        ,  0.        ], dtype=float32), action=3, reward=7.392504170093361, next_state=array([ 0.19108096, -0.01484187,  0.27424696, -1.292105  ,  0.10633478,\n",
      "       -0.0923609 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.19108096, -0.01484187,  0.27424696, -1.292105  ,  0.10633478,\n",
      "       -0.0923609 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.19335976, -0.04076377,  0.36417586, -0.8155845 ,  0.02339243,\n",
      "       -4.607233  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00379171,  1.4140053 ,  0.38405564,  0.13711356, -0.00438696,\n",
      "       -0.08699429,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.4159896926245663, next_state=array([ 0.00770359,  1.4179041 ,  0.39496663,  0.17327073, -0.00812776,\n",
      "       -0.07482239,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00770359,  1.4179041 ,  0.39496663,  0.17327073, -0.00812776,\n",
      "       -0.07482239,  0.        ,  0.        ], dtype=float32), action=0, reward=0.2926321053253673, next_state=array([ 0.01161547,  1.4212034 ,  0.39497823,  0.14661221, -0.01186655,\n",
      "       -0.07478257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01161547,  1.4212034 ,  0.39497823,  0.14661221, -0.01186655,\n",
      "       -0.07478257,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.30467216148499, next_state=array([ 0.015516  ,  1.4252702 ,  0.39393777,  0.1807101 , -0.01571177,\n",
      "       -0.0769116 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.015516  ,  1.4252702 ,  0.39393777,  0.1807101 , -0.01571177,\n",
      "       -0.0769116 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0577565562873292, next_state=array([ 0.01951094,  1.4287331 ,  0.4057774 ,  0.15383016, -0.02192903,\n",
      "       -0.12435677,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01951094,  1.4287331 ,  0.4057774 ,  0.15383016, -0.02192903,\n",
      "       -0.12435677,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8452514370780488, next_state=array([ 0.02344322,  1.4315889 ,  0.39792037,  0.12685384, -0.02656814,\n",
      "       -0.0927905 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02344322,  1.4315889 ,  0.39792037,  0.12685384, -0.02656814,\n",
      "       -0.0927905 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9988454978200718, next_state=array([ 0.02730732,  1.4338509 ,  0.38935965,  0.10047485, -0.02948631,\n",
      "       -0.05836902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02730732,  1.4338509 ,  0.38935965,  0.10047485, -0.02948631,\n",
      "       -0.05836902,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9734165583631296, next_state=array([ 0.03126507,  1.4363637 ,  0.39835835,  0.11163142, -0.03203804,\n",
      "       -0.05103909,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03126507,  1.4363637 ,  0.39835835,  0.11163142, -0.03203804,\n",
      "       -0.05103909,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1015710798566145, next_state=array([ 0.03535023,  1.4390025 ,  0.4105559 ,  0.11723881, -0.03405762,\n",
      "       -0.04039516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03535023,  1.4390025 ,  0.4105559 ,  0.11723881, -0.03405762,\n",
      "       -0.04039516,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2848442540681217, next_state=array([ 0.03943644,  1.442606  ,  0.4108317 ,  0.16009998, -0.0362403 ,\n",
      "       -0.04365792,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03943644,  1.442606  ,  0.4108317 ,  0.16009998, -0.0362403 ,\n",
      "       -0.04365792,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9112617842469024, next_state=array([ 0.04360952,  1.4456058 ,  0.42171702,  0.13320614, -0.04060465,\n",
      "       -0.08729512,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04360952,  1.4456058 ,  0.42171702,  0.13320614, -0.04060465,\n",
      "       -0.08729512,  0.        ,  0.        ], dtype=float32), action=1, reward=1.3053797241439338, next_state=array([ 0.04769297,  1.4480215 ,  0.41046888,  0.10730086, -0.04270026,\n",
      "       -0.04191561,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04769297,  1.4480215 ,  0.41046888,  0.10730086, -0.04270026,\n",
      "       -0.04191561,  0.        ,  0.        ], dtype=float32), action=0, reward=0.1892645002872939, next_state=array([ 0.05177651,  1.449837  ,  0.41047353,  0.08063187, -0.04479695,\n",
      "       -0.04193788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05177651,  1.449837  ,  0.41047353,  0.08063187, -0.04479695,\n",
      "       -0.04193788,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6693329672577477, next_state=array([ 0.05597105,  1.451611  ,  0.42112255,  0.07879881, -0.04644842,\n",
      "       -0.03303276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05597105,  1.451611  ,  0.42112255,  0.07879881, -0.04644842,\n",
      "       -0.03303276,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8790035588408955, next_state=array([ 0.06015835,  1.4536498 ,  0.42056876,  0.09054908, -0.0482596 ,\n",
      "       -0.03622701,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06015835,  1.4536498 ,  0.42056876,  0.09054908, -0.0482596 ,\n",
      "       -0.03622701,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1407540125133255, next_state=array([ 0.06443033,  1.4550718 ,  0.4311747 ,  0.0630668 , -0.05220697,\n",
      "       -0.07895422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06443033,  1.4550718 ,  0.4311747 ,  0.0630668 , -0.05220697,\n",
      "       -0.07895422,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.45659329049464076, next_state=array([ 0.0686429 ,  1.4566329 ,  0.42564029,  0.06921602, -0.05655229,\n",
      "       -0.08691431,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0686429 ,  1.4566329 ,  0.42564029,  0.06921602, -0.05655229,\n",
      "       -0.08691431,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7103661135683705, next_state=array([ 0.07279205,  1.4576073 ,  0.41768804,  0.04319977, -0.05928965,\n",
      "       -0.05475185,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07279205,  1.4576073 ,  0.41768804,  0.04319977, -0.05928965,\n",
      "       -0.05475185,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.7703857580345526, next_state=array([ 0.07709579,  1.4594417 ,  0.43268475,  0.08143568, -0.06157509,\n",
      "       -0.0457132 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07709579,  1.4594417 ,  0.43268475,  0.08143568, -0.06157509,\n",
      "       -0.0457132 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.9035120061146256, next_state=array([ 0.08133926,  1.4606915 ,  0.42510813,  0.05551306, -0.06232636,\n",
      "       -0.0150271 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08133926,  1.4606915 ,  0.42510813,  0.05551306, -0.06232636,\n",
      "       -0.0150271 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.279677197339754, next_state=array([ 0.08575191,  1.4622208 ,  0.44139925,  0.06796657, -0.06246053,\n",
      "       -0.00268352,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08575191,  1.4622208 ,  0.44139925,  0.06796657, -0.06246053,\n",
      "       -0.00268352,  0.        ,  0.        ], dtype=float32), action=0, reward=0.1949136425495226, next_state=array([ 0.09016456,  1.4631499 ,  0.44139844,  0.04129089, -0.06259489,\n",
      "       -0.00268731,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09016456,  1.4631499 ,  0.44139844,  0.04129089, -0.06259489,\n",
      "       -0.00268731,  0.        ,  0.        ], dtype=float32), action=0, reward=0.09435625058279129, next_state=array([ 0.09457722,  1.463479  ,  0.44139916,  0.01462541, -0.06272896,\n",
      "       -0.00268165,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09457722,  1.463479  ,  0.44139916,  0.01462541, -0.06272896,\n",
      "       -0.00268165,  0.        ,  0.        ], dtype=float32), action=1, reward=1.1293124833795798, next_state=array([ 0.09891252,  1.4632239 ,  0.43169466, -0.01126259, -0.06090419,\n",
      "        0.0364987 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09891252,  1.4632239 ,  0.43169466, -0.01126259, -0.06090419,\n",
      "        0.0364987 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0011420833449722, next_state=array([ 1.0331802e-01,  1.4623585e+00,  4.4048905e-01, -3.8456209e-02,\n",
      "       -6.0852200e-02,  1.0400640e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.0331802e-01,  1.4623585e+00,  4.4048905e-01, -3.8456209e-02,\n",
      "       -6.0852200e-02,  1.0400640e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.31784288549816325, next_state=array([ 0.10766678,  1.4619313 ,  0.43528146, -0.01900106, -0.06125543,\n",
      "       -0.0080646 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10766678,  1.4619313 ,  0.43528146, -0.01900106, -0.06125543,\n",
      "       -0.0080646 ,  0.        ,  0.        ], dtype=float32), action=1, reward=1.0925946570033045, next_state=array([ 0.1119298 ,  1.4609133 ,  0.42452678, -0.04517647, -0.05949755,\n",
      "        0.03515767,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1119298 ,  1.4609133 ,  0.42452678, -0.04517647, -0.05949755,\n",
      "        0.03515767,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7783318212182337, next_state=array([ 0.11627903,  1.4601918 ,  0.4328991 , -0.03198282, -0.05750616,\n",
      "        0.03982788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11627903,  1.4601918 ,  0.4328991 , -0.03198282, -0.05750616,\n",
      "        0.03982788,  0.        ,  0.        ], dtype=float32), action=1, reward=1.301796697075589, next_state=array([ 0.12054034,  1.4588708 ,  0.42188343, -0.05856346, -0.05331054,\n",
      "        0.08391266,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12054034,  1.4588708 ,  0.42188343, -0.05856346, -0.05331054,\n",
      "        0.08391266,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0009466698094058, next_state=array([ 0.12473698,  1.4582312 ,  0.4159309 , -0.02829063, -0.04962363,\n",
      "        0.07373793,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12473698,  1.4582312 ,  0.4159309 , -0.02829063, -0.04962363,\n",
      "        0.07373793,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7458169436181936, next_state=array([ 0.1289939 ,  1.4569865 ,  0.42349988, -0.05524865, -0.04745614,\n",
      "        0.04334965,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1289939 ,  1.4569865 ,  0.42349988, -0.05524865, -0.04745614,\n",
      "        0.04334965,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2585232889725273, next_state=array([ 0.13316002,  1.4551469 ,  0.41210723, -0.08162733, -0.04300452,\n",
      "        0.08903234,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13316002,  1.4551469 ,  0.41210723, -0.08162733, -0.04300452,\n",
      "        0.08903234,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2660373880696636, next_state=array([ 0.13724127,  1.4527086 ,  0.4014631 , -0.10819173, -0.03642157,\n",
      "        0.13165918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13724127,  1.4527086 ,  0.4014631 , -0.10819173, -0.03642157,\n",
      "        0.13165918,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.221844408131857, next_state=array([ 0.14141388,  1.449656  ,  0.41293588, -0.13557167, -0.03214455,\n",
      "        0.08554033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14141388,  1.449656  ,  0.41293588, -0.13557167, -0.03214455,\n",
      "        0.08554033,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.1542561199627528, next_state=array([ 0.14558649,  1.4460037 ,  0.41293573, -0.16223986, -0.02786754,\n",
      "        0.08554025,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14558649,  1.4460037 ,  0.41293573, -0.16223986, -0.02786754,\n",
      "        0.08554025,  0.        ,  0.        ], dtype=float32), action=2, reward=0.12212373177125074, next_state=array([ 0.14994058,  1.4433118 ,  0.43036237, -0.11955536, -0.02288492,\n",
      "        0.0996524 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14994058,  1.4433118 ,  0.43036237, -0.11955536, -0.02288492,\n",
      "        0.0996524 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0883793422444115, next_state=array([ 0.15446416,  1.4406021 ,  0.4465559 , -0.12035097, -0.01715934,\n",
      "        0.11451165,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15446416,  1.4406021 ,  0.4465559 , -0.12035097, -0.01715934,\n",
      "        0.11451165,  0.        ,  0.        ], dtype=float32), action=1, reward=1.43463955778313, next_state=array([ 0.1588935 ,  1.4373043 ,  0.43471965, -0.14649956, -0.00906037,\n",
      "        0.16197969,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1588935 ,  1.4373043 ,  0.43471965, -0.14649956, -0.00906037,\n",
      "        0.16197969,  0.        ,  0.        ], dtype=float32), action=0, reward=0.22767238308114202, next_state=array([ 1.6332273e-01,  1.4334073e+00,  4.3471962e-01, -1.7317168e-01,\n",
      "       -9.6141995e-04,  1.6197896e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.6332273e-01,  1.4334073e+00,  4.3471962e-01, -1.7317168e-01,\n",
      "       -9.6141995e-04,  1.6197896e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-2.022959527345988, next_state=array([ 0.16783467,  1.4289217 ,  0.4451024 , -0.19936548,  0.00505835,\n",
      "        0.12039523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16783467,  1.4289217 ,  0.4451024 , -0.19936548,  0.00505835,\n",
      "        0.12039523,  0.        ,  0.        ], dtype=float32), action=2, reward=2.318472139200037, next_state=array([ 0.1721693 ,  1.425169  ,  0.428171  , -0.16681872,  0.01027877,\n",
      "        0.10440862,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1721693 ,  1.425169  ,  0.428171  , -0.16681872,  0.01027877,\n",
      "        0.10440862,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5587867105516, next_state=array([ 0.17642984,  1.4208103 ,  0.41887847, -0.19378972,  0.01736124,\n",
      "        0.14164957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17642984,  1.4208103 ,  0.41887847, -0.19378972,  0.01736124,\n",
      "        0.14164957,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9408579683286848, next_state=array([ 0.18062763,  1.4158539 ,  0.41100663, -0.22041231,  0.0260196 ,\n",
      "        0.17316726,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18062763,  1.4158539 ,  0.41100663, -0.22041231,  0.0260196 ,\n",
      "        0.17316726,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6869519029116873, next_state=array([ 0.18482542,  1.4102985 ,  0.41100684, -0.24708527,  0.03467793,\n",
      "        0.1731664 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18482542,  1.4102985 ,  0.41100684, -0.24708527,  0.03467793,\n",
      "        0.1731664 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5226322553084217, next_state=array([ 0.18911771,  1.4041429 ,  0.4228665 , -0.27374506,  0.04096242,\n",
      "        0.12569049,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18911771,  1.4041429 ,  0.4228665 , -0.27374506,  0.04096242,\n",
      "        0.12569049,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.514885702040857, next_state=array([ 0.19341001,  1.3973877 ,  0.42286667, -0.30041504,  0.04724691,\n",
      "        0.12569004,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19341001,  1.3973877 ,  0.42286667, -0.30041504,  0.04724691,\n",
      "        0.12569004,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.270195819600359, next_state=array([ 0.19779882,  1.3900428 ,  0.4349826 , -0.32657164,  0.05109859,\n",
      "        0.07703329,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19779882,  1.3900428 ,  0.4349826 , -0.32657164,  0.05109859,\n",
      "        0.07703329,  0.        ,  0.        ], dtype=float32), action=2, reward=2.300462304851277, next_state=array([ 0.20204954,  1.38317   ,  0.42165104, -0.3055773 ,  0.05448183,\n",
      "        0.06766472,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20204954,  1.38317   ,  0.42165104, -0.3055773 ,  0.05448183,\n",
      "        0.06766472,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2697106602478527, next_state=array([ 0.20630017,  1.3756974 ,  0.42165107, -0.33224493,  0.05786507,\n",
      "        0.06766467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20630017,  1.3756974 ,  0.42165107, -0.33224493,  0.05786507,\n",
      "        0.06766467,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2942214386518174, next_state=array([ 0.21055087,  1.3676249 ,  0.42165112, -0.3589126 ,  0.0612483 ,\n",
      "        0.0676646 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21055087,  1.3676249 ,  0.42165112, -0.3589126 ,  0.0612483 ,\n",
      "        0.0676646 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3116243355797792, next_state=array([ 0.2148016 ,  1.3589525 ,  0.42165118, -0.3855802 ,  0.06463153,\n",
      "        0.06766455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2148016 ,  1.3589525 ,  0.42165118, -0.3855802 ,  0.06463153,\n",
      "        0.06766455,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8784415481059387, next_state=array([ 0.21913958,  1.3496926 ,  0.43260518, -0.4116052 ,  0.06580994,\n",
      "        0.02356818,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21913958,  1.3496926 ,  0.43260518, -0.4116052 ,  0.06580994,\n",
      "        0.02356818,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5642050940235481, next_state=array([ 0.22355051,  1.3398354 ,  0.44176546, -0.4380666 ,  0.06515275,\n",
      "       -0.01314376,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22355051,  1.3398354 ,  0.44176546, -0.4380666 ,  0.06515275,\n",
      "       -0.01314376,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4259460564013853, next_state=array([ 0.22788039,  1.3293778 ,  0.43159074, -0.46484324,  0.06653155,\n",
      "        0.02757589,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22788039,  1.3293778 ,  0.43159074, -0.46484324,  0.06653155,\n",
      "        0.02757589,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.655155538598932, next_state=array([ 0.23230858,  1.3183335 ,  0.4439331 , -0.490805  ,  0.06542633,\n",
      "       -0.0221043 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23230858,  1.3183335 ,  0.4439331 , -0.490805  ,  0.06542633,\n",
      "       -0.0221043 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8222672319552942, next_state=array([ 0.23673677,  1.3066893 ,  0.4439331 , -0.51747173,  0.06432112,\n",
      "       -0.02210432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23673677,  1.3066893 ,  0.4439331 , -0.51747173,  0.06432112,\n",
      "       -0.02210432,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2358765867646457, next_state=array([ 0.24124423,  1.294455  ,  0.45388356, -0.5436137 ,  0.06121454,\n",
      "       -0.06213158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24124423,  1.294455  ,  0.45388356, -0.5436137 ,  0.06121454,\n",
      "       -0.06213158,  0.        ,  0.        ], dtype=float32), action=2, reward=2.063600199974201, next_state=array([ 0.24584074,  1.2826916 ,  0.46218163, -0.52272207,  0.05872233,\n",
      "       -0.04984422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24584074,  1.2826916 ,  0.46218163, -0.52272207,  0.05872233,\n",
      "       -0.04984422,  0.        ,  0.        ], dtype=float32), action=2, reward=4.330246395224276, next_state=array([ 0.2503895 ,  1.2718694 ,  0.4573359 , -0.48088834,  0.05628876,\n",
      "       -0.04867141,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2503895 ,  1.2718694 ,  0.4573359 , -0.48088834,  0.05628876,\n",
      "       -0.04867141,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.24166777141860393, next_state=array([ 0.2548483 ,  1.2604327 ,  0.44604072, -0.508297  ,  0.05612941,\n",
      "       -0.00318668,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2548483 ,  1.2604327 ,  0.44604072, -0.508297  ,  0.05612941,\n",
      "       -0.00318668,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5273373100765457, next_state=array([ 0.25922394,  1.2483882 ,  0.43560272, -0.5353886 ,  0.05806618,\n",
      "        0.03873534,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25922394,  1.2483882 ,  0.43560272, -0.5353886 ,  0.05806618,\n",
      "        0.03873534,  0.        ,  0.        ], dtype=float32), action=2, reward=1.481036133784454, next_state=array([ 0.2637101 ,  1.2368361 ,  0.44595227, -0.51353   ,  0.06071003,\n",
      "        0.05287667,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2637101 ,  1.2368361 ,  0.44595227, -0.51353   ,  0.06071003,\n",
      "        0.05287667,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9286219234393787, next_state=array([ 0.26813585,  1.2246792 ,  0.43835455, -0.540486  ,  0.06487926,\n",
      "        0.08338453,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26813585,  1.2246792 ,  0.43835455, -0.540486  ,  0.06487926,\n",
      "        0.08338453,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2177790622097406, next_state=array([ 0.27251738,  1.2132952 ,  0.4338645 , -0.50614506,  0.06911968,\n",
      "        0.08480813,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27251738,  1.2132952 ,  0.4338645 , -0.50614506,  0.06911968,\n",
      "        0.08480813,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8362467350692941, next_state=array([ 0.27698573,  1.2013301 ,  0.44478685, -0.5318862 ,  0.07115372,\n",
      "        0.0406809 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27698573,  1.2013301 ,  0.44478685, -0.5318862 ,  0.07115372,\n",
      "        0.0406809 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.354898568549186, next_state=array([ 0.28144997,  1.1902169 ,  0.4440694 , -0.49403048,  0.07348774,\n",
      "        0.04668014,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28144997,  1.1902169 ,  0.4440694 , -0.49403048,  0.07348774,\n",
      "        0.04668014,  0.        ,  0.        ], dtype=float32), action=2, reward=2.134628509742538, next_state=array([ 0.2859415 ,  1.1797014 ,  0.4463842 , -0.46749163,  0.07621877,\n",
      "        0.05462073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2859415 ,  1.1797014 ,  0.4463842 , -0.46749163,  0.07621877,\n",
      "        0.05462073,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.254858490461686, next_state=array([ 0.29043293,  1.1685863 ,  0.4463842 , -0.49415892,  0.07894979,\n",
      "        0.05462069,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29043293,  1.1685863 ,  0.4463842 , -0.49415892,  0.07894979,\n",
      "        0.05462069,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.599757401211973, next_state=array([ 0.29498664,  1.1568794 ,  0.45419455, -0.52036256,  0.08010772,\n",
      "        0.02315843,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29498664,  1.1568794 ,  0.45419455, -0.52036256,  0.08010772,\n",
      "        0.02315843,  0.        ,  0.        ], dtype=float32), action=2, reward=4.436591700761551, next_state=array([ 0.2993186 ,  1.1458938 ,  0.43272704, -0.48827302,  0.08057001,\n",
      "        0.00924583,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2993186 ,  1.1458938 ,  0.43272704, -0.48827302,  0.08057001,\n",
      "        0.00924583,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2660246713612198, next_state=array([ 0.30360478,  1.1353309 ,  0.42811626, -0.46949276,  0.08107606,\n",
      "        0.01012066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30360478,  1.1353309 ,  0.42811626, -0.46949276,  0.08107606,\n",
      "        0.01012066,  0.        ,  0.        ], dtype=float32), action=2, reward=2.6764705642487288, next_state=array([ 0.30784798,  1.1253475 ,  0.42370638, -0.4437411 ,  0.0816784 ,\n",
      "        0.01204682,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30784798,  1.1253475 ,  0.42370638, -0.4437411 ,  0.0816784 ,\n",
      "        0.01204682,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1088446066814015, next_state=array([ 0.31209117,  1.114764  ,  0.42370638, -0.47040778,  0.08228072,\n",
      "        0.01204655,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31209117,  1.114764  ,  0.42370638, -0.47040778,  0.08228072,\n",
      "        0.01204655,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.105683824947647, next_state=array([ 0.31633425,  1.1035805 ,  0.42370638, -0.4970745 ,  0.08288305,\n",
      "        0.01204684,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31633425,  1.1035805 ,  0.42370638, -0.4970745 ,  0.08288305,\n",
      "        0.01204684,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4561325812084636, next_state=array([ 0.320642  ,  1.0918021 ,  0.43180785, -0.523425  ,  0.08185867,\n",
      "       -0.02048784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.320642  ,  1.0918021 ,  0.43180785, -0.523425  ,  0.08185867,\n",
      "       -0.02048784,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5281022313431822, next_state=array([ 0.32485256,  1.0794009 ,  0.4195869 , -0.5512488 ,  0.08330933,\n",
      "        0.02901343,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32485256,  1.0794009 ,  0.4195869 , -0.5512488 ,  0.08330933,\n",
      "        0.02901343,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6941219066874964, next_state=array([ 0.32888204,  1.0669878 ,  0.402176  , -0.5517394 ,  0.08407676,\n",
      "        0.01534856,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32888204,  1.0669878 ,  0.402176  , -0.5517394 ,  0.08407676,\n",
      "        0.01534856,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.126988107226225, next_state=array([ 0.3329115 ,  1.0539746 ,  0.40217605, -0.5784061 ,  0.08484419,\n",
      "        0.01534862,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3329115 ,  1.0539746 ,  0.40217605, -0.5784061 ,  0.08484419,\n",
      "        0.01534862,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7530027605944951, next_state=array([ 0.33696547,  1.0412929 ,  0.40426308, -0.5636998 ,  0.08596827,\n",
      "        0.02248154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33696547,  1.0412929 ,  0.40426308, -0.5636998 ,  0.08596827,\n",
      "        0.02248154,  0.        ,  0.        ], dtype=float32), action=2, reward=3.702107913677236, next_state=array([ 0.34082022,  1.0291345 ,  0.38497165, -0.54040474,  0.08647236,\n",
      "        0.01008172,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34082022,  1.0291345 ,  0.38497165, -0.54040474,  0.08647236,\n",
      "        0.01008172,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0787544517773255, next_state=array([ 0.3446514 ,  1.0170509 ,  0.38253322, -0.53708106,  0.08704744,\n",
      "        0.01150178,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3446514 ,  1.0170509 ,  0.38253322, -0.53708106,  0.08704744,\n",
      "        0.01150178,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9326130685639089, next_state=array([ 0.3484109 ,  1.0043551 ,  0.3735305 , -0.56439716,  0.08943998,\n",
      "        0.04785109,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3484109 ,  1.0043551 ,  0.3735305 , -0.56439716,  0.08943998,\n",
      "        0.04785109,  0.        ,  0.        ], dtype=float32), action=2, reward=0.09243975079239136, next_state=array([ 0.35223037,  0.99163574,  0.3790856 , -0.5654841 ,  0.09226771,\n",
      "        0.0565546 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35223037,  0.99163574,  0.3790856 , -0.5654841 ,  0.09226771,\n",
      "        0.0565546 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3893676456332855, next_state=array([ 0.35604972,  0.97831637,  0.3790857 , -0.59215146,  0.09509545,\n",
      "        0.0565546 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35604972,  0.97831637,  0.3790857 , -0.59215146,  0.09509545,\n",
      "        0.0565546 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9105268990241313, next_state=array([ 0.35985145,  0.9653515 ,  0.37712264, -0.5764124 ,  0.09812196,\n",
      "        0.06053013,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35985145,  0.9653515 ,  0.37712264, -0.5764124 ,  0.09812196,\n",
      "        0.06053013,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.730955756405648, next_state=array([ 0.36372536,  0.95178896,  0.38616946, -0.6028565 ,  0.09933724,\n",
      "        0.02430558,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36372536,  0.95178896,  0.38616946, -0.6028565 ,  0.09933724,\n",
      "        0.02430558,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2001215186055845, next_state=array([ 0.3675994 ,  0.9376266 ,  0.3861695 , -0.6295232 ,  0.10055252,\n",
      "        0.02430556,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3675994 ,  0.9376266 ,  0.3861695 , -0.6295232 ,  0.10055252,\n",
      "        0.02430556,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9887773959011656, next_state=array([ 0.37140352,  0.9228547 ,  0.37740692, -0.6567412 ,  0.10353467,\n",
      "        0.05964311,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37140352,  0.9228547 ,  0.37740692, -0.6567412 ,  0.10353467,\n",
      "        0.05964311,  0.        ,  0.        ], dtype=float32), action=2, reward=2.9514254740144112, next_state=array([ 0.37502164,  0.9084458 ,  0.35936782, -0.6405687 ,  0.10596883,\n",
      "        0.04868294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37502164,  0.9084458 ,  0.35936782, -0.6405687 ,  0.10596883,\n",
      "        0.04868294,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9214871467260195, next_state=array([ 0.3787341 ,  0.89451444,  0.36800706, -0.61939883,  0.10918883,\n",
      "        0.06439997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3787341 ,  0.89451444,  0.36800706, -0.61939883,  0.10918883,\n",
      "        0.06439997,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.279251074900144, next_state=array([ 0.38238317,  0.87997454,  0.360048  , -0.6465779 ,  0.11401433,\n",
      "        0.09651016,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38238317,  0.87997454,  0.360048  , -0.6465779 ,  0.11401433,\n",
      "        0.09651016,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5851119922835437, next_state=array([ 0.3860322 ,  0.864835  ,  0.36004832, -0.6732465 ,  0.11883984,\n",
      "        0.09651019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3860322 ,  0.864835  ,  0.36004832, -0.6732465 ,  0.11883984,\n",
      "        0.09651019,  0.        ,  0.        ], dtype=float32), action=2, reward=2.138308653437389, next_state=array([ 0.38952827,  0.8499427 ,  0.34514266, -0.6622458 ,  0.12327254,\n",
      "        0.08865424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38952827,  0.8499427 ,  0.34514266, -0.6622458 ,  0.12327254,\n",
      "        0.08865424,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4407102770474, next_state=array([ 0.39294404,  0.8344305 ,  0.3350621 , -0.68998647,  0.12975867,\n",
      "        0.1297225 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39294404,  0.8344305 ,  0.3350621 , -0.68998647,  0.12975867,\n",
      "        0.1297225 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.36256384182455, next_state=array([ 0.3962427 ,  0.81982714,  0.32328242, -0.6496267 ,  0.13630998,\n",
      "        0.13102648,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3962427 ,  0.81982714,  0.32328242, -0.6496267 ,  0.13630998,\n",
      "        0.13102648,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6883832945742074, next_state=array([ 0.39944926,  0.8046075 ,  0.31171724, -0.67727494,  0.14520624,\n",
      "        0.17792514,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39944926,  0.8046075 ,  0.31171724, -0.67727494,  0.14520624,\n",
      "        0.17792514,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0105572778818144, next_state=array([ 0.40259153,  0.78877044,  0.303673  , -0.7049338 ,  0.15575069,\n",
      "        0.21088913,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40259153,  0.78877044,  0.303673  , -0.7049338 ,  0.15575069,\n",
      "        0.21088913,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.324873431141383, next_state=array([ 0.40579337,  0.7723419 ,  0.3111419 , -0.73113436,  0.16479005,\n",
      "        0.18078712,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40579337,  0.7723419 ,  0.3111419 , -0.73113436,  0.16479005,\n",
      "        0.18078712,  0.        ,  0.        ], dtype=float32), action=2, reward=4.6040008069447085, next_state=array([ 0.40874785,  0.7567905 ,  0.2867934 , -0.69216037,  0.17344834,\n",
      "        0.17316566,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40874785,  0.7567905 ,  0.2867934 , -0.69216037,  0.17344834,\n",
      "        0.17316566,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.210076924062689, next_state=array([ 0.411794  ,  0.7406552 ,  0.29829615, -0.7178752 ,  0.17977546,\n",
      "        0.12654306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.411794  ,  0.7406552 ,  0.29829615, -0.7178752 ,  0.17977546,\n",
      "        0.12654306,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.923295076616198, next_state=array([ 0.41490537,  0.7239275 ,  0.30648404, -0.7440227 ,  0.1844543 ,\n",
      "        0.09357689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41490537,  0.7239275 ,  0.30648404, -0.7440227 ,  0.1844543 ,\n",
      "        0.09357689,  0.        ,  0.        ], dtype=float32), action=2, reward=2.919509694979763, next_state=array([ 0.4179984 ,  0.7077903 ,  0.30405834, -0.7178657 ,  0.1897233 ,\n",
      "        0.10538026,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4179984 ,  0.7077903 ,  0.30405834, -0.7178657 ,  0.1897233 ,\n",
      "        0.10538026,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8460133338097353, next_state=array([ 0.4211606 ,  0.6910626 ,  0.312709  , -0.7439055 ,  0.19324642,\n",
      "        0.07046258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4211606 ,  0.6910626 ,  0.312709  , -0.7439055 ,  0.19324642,\n",
      "        0.07046258,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5052349300455308, next_state=array([ 0.4242587 ,  0.6737153 ,  0.30466214, -0.77167743,  0.19843125,\n",
      "        0.10369692,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4242587 ,  0.6737153 ,  0.30466214, -0.77167743,  0.19843125,\n",
      "        0.10369692,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4873402453739404, next_state=array([ 0.4271199 ,  0.6566414 ,  0.28151378, -0.7594689 ,  0.20307302,\n",
      "        0.09283562,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4271199 ,  0.6566414 ,  0.28151378, -0.7594689 ,  0.20307302,\n",
      "        0.09283562,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6538042282034837, next_state=array([ 0.42998114,  0.6389676 ,  0.28151432, -0.7861374 ,  0.2077148 ,\n",
      "        0.09283548,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42998114,  0.6389676 ,  0.28151432, -0.7861374 ,  0.2077148 ,\n",
      "        0.09283548,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1386607191933082, next_state=array([ 0.43264037,  0.6215129 ,  0.2617181 , -0.7763618 ,  0.21196398,\n",
      "        0.08498327,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43264037,  0.6215129 ,  0.2617181 , -0.7763618 ,  0.21196398,\n",
      "        0.08498327,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6974065662245834, next_state=array([ 0.4352786 ,  0.6043302 ,  0.25915074, -0.7643563 ,  0.21668406,\n",
      "        0.09440176,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4352786 ,  0.6043302 ,  0.25915074, -0.7643563 ,  0.21668406,\n",
      "        0.09440176,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6957414870589946, next_state=array([ 0.43800956,  0.58658546,  0.27085346, -0.78898305,  0.2189494 ,\n",
      "        0.04530708,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43800956,  0.58658546,  0.27085346, -0.78898305,  0.2189494 ,\n",
      "        0.04530708,  0.        ,  0.        ], dtype=float32), action=2, reward=3.341415733511565, next_state=array([ 0.44043618,  0.56922555,  0.24112627, -0.77177596,  0.22050068,\n",
      "        0.0310255 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44043618,  0.56922555,  0.24112627, -0.77177596,  0.22050068,\n",
      "        0.0310255 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8267834672341905, next_state=array([ 0.44263545,  0.5519507 ,  0.2189527 , -0.76791614,  0.22148827,\n",
      "        0.01975192,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44263545,  0.5519507 ,  0.2189527 , -0.76791614,  0.22148827,\n",
      "        0.01975192,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4289491277833806, next_state=array([ 0.44485435,  0.5350939 ,  0.22014642, -0.7494547 ,  0.22325462,\n",
      "        0.03532718,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44485435,  0.5350939 ,  0.22014642, -0.7494547 ,  0.22325462,\n",
      "        0.03532718,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6912348596907794, next_state=array([ 0.44698018,  0.517602  ,  0.20840406, -0.7780541 ,  0.22747594,\n",
      "        0.08442678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44698018,  0.517602  ,  0.20840406, -0.7780541 ,  0.22747594,\n",
      "        0.08442678,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7841076656143855, next_state=array([ 0.44910583,  0.49951038,  0.20840454, -0.80472225,  0.23169726,\n",
      "        0.08442669,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44910583,  0.49951038,  0.20840454, -0.80472225,  0.23169726,\n",
      "        0.08442669,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7735814139287243, next_state=array([ 0.45123148,  0.48081887,  0.20840505, -0.8313903 ,  0.2359186 ,\n",
      "        0.0844266 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45123148,  0.48081887,  0.20840505, -0.8313903 ,  0.2359186 ,\n",
      "        0.0844266 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7223217288082242, next_state=array([ 0.45344934,  0.46154845,  0.21995561, -0.8567589 ,  0.23777637,\n",
      "        0.03715561,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45344934,  0.46154845,  0.21995561, -0.8567589 ,  0.23777637,\n",
      "        0.03715561,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6470232403557066, next_state=array([ 0.4555936 ,  0.4416564 ,  0.21071272, -0.8846948 ,  0.24154598,\n",
      "        0.07539202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4555936 ,  0.4416564 ,  0.21071272, -0.8846948 ,  0.24154598,\n",
      "        0.07539202,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.897756238906111, next_state=array([ 0.45765734,  0.4211345 ,  0.20059094, -0.9130468 ,  0.24743608,\n",
      "        0.11780217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45765734,  0.4211345 ,  0.20059094, -0.9130468 ,  0.24743608,\n",
      "        0.11780217,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8007192021474612, next_state=array([ 0.45980826,  0.40004662,  0.21157697, -0.9378358 ,  0.2510192 ,\n",
      "        0.07166286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45980826,  0.40004662,  0.21157697, -0.9378358 ,  0.2510192 ,\n",
      "        0.07166286,  0.        ,  0.        ], dtype=float32), action=2, reward=2.342380488284687, next_state=array([ 0.46169433,  0.37923482,  0.18559492, -0.92548555,  0.25408685,\n",
      "        0.06135313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46169433,  0.37923482,  0.18559492, -0.92548555,  0.25408685,\n",
      "        0.06135313,  0.        ,  0.        ], dtype=float32), action=2, reward=4.800016895257824, next_state=array([ 0.46323594,  0.35924894,  0.15158235, -0.8887093 ,  0.2567185 ,\n",
      "        0.05263277,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46323594,  0.35924894,  0.15158235, -0.8887093 ,  0.2567185 ,\n",
      "        0.05263277,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5676725063435402, next_state=array([ 0.46485424,  0.338702  ,  0.1612841 , -0.9132916 ,  0.2572707 ,\n",
      "        0.01104403,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46485424,  0.338702  ,  0.1612841 , -0.9132916 ,  0.2572707 ,\n",
      "        0.01104403,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2908797632184814, next_state=array([ 0.46647367,  0.31830692,  0.1608194 , -0.90664643,  0.25841853,\n",
      "        0.0229569 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46647367,  0.31830692,  0.1608194 , -0.90664643,  0.25841853,\n",
      "        0.0229569 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5665429747203905, next_state=array([ 0.46815404,  0.29734227,  0.16853571, -0.9316756 ,  0.25791413,\n",
      "       -0.01008792,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46815404,  0.29734227,  0.16853571, -0.9316756 ,  0.25791413,\n",
      "       -0.01008792,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8527920946530958, next_state=array([ 0.4697505 ,  0.27574253,  0.157945  , -0.9602864 ,  0.25964797,\n",
      "        0.03467635,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4697505 ,  0.27574253,  0.157945  , -0.9602864 ,  0.25964797,\n",
      "        0.03467635,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1597534457442564, next_state=array([ 0.47125894,  0.25350308,  0.1468381 , -0.98913676,  0.2637435 ,\n",
      "        0.08191074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47125894,  0.25350308,  0.1468381 , -0.98913676,  0.2637435 ,\n",
      "        0.08191074,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6932848353403187, next_state=array([ 0.47279662,  0.23141164,  0.14905074, -0.98270065,  0.26857132,\n",
      "        0.09655642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47279662,  0.23141164,  0.14905074, -0.98270065,  0.26857132,\n",
      "        0.09655642,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3036312450782646, next_state=array([ 0.47433424,  0.20872043,  0.14905152, -1.0093693 ,  0.27339914,\n",
      "        0.09655629,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47433424,  0.20872043,  0.14905152, -1.0093693 ,  0.27339914,\n",
      "        0.09655629,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.182928045037299, next_state=array([ 0.47596207,  0.1854563 ,  0.16035596, -1.034414  ,  0.2758819 ,\n",
      "        0.04965476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47596207,  0.1854563 ,  0.16035596, -1.034414  ,  0.2758819 ,\n",
      "        0.04965476,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.015751516527699, next_state=array([ 0.4776593 ,  0.16162756,  0.1691431 , -1.0591673 ,  0.27647433,\n",
      "        0.01184888,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4776593 ,  0.16162756,  0.1691431 , -1.0591673 ,  0.27647433,\n",
      "        0.01184888,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1273988295681363, next_state=array([ 0.47935647,  0.13719872,  0.16914311, -1.085834  ,  0.27706677,\n",
      "        0.01184894,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47935647,  0.13719872,  0.16914311, -1.085834  ,  0.27706677,\n",
      "        0.01184894,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9836405708293785, next_state=array([ 0.48114794,  0.11220954,  0.18102379, -1.1102759 ,  0.27514073,\n",
      "       -0.03852044,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48114794,  0.11220954,  0.18102379, -1.1102759 ,  0.27514073,\n",
      "       -0.03852044,  0.        ,  0.        ], dtype=float32), action=2, reward=4.602920510477259, next_state=array([ 0.48270112,  0.08813783,  0.1569825 , -1.0695404 ,  0.27342567,\n",
      "       -0.03430051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48270112,  0.08813783,  0.1569825 , -1.0695404 ,  0.27342567,\n",
      "       -0.03430051,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.462805734534838, next_state=array([ 4.8418808e-01,  6.3441336e-02,  1.4866792e-01, -1.0976274e+00,\n",
      "        2.7345875e-01,  6.6153065e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 4.8418808e-01,  6.3441336e-02,  1.4866792e-01, -1.0976274e+00,\n",
      "        2.7345875e-01,  6.6153065e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-2.8008181878203957, next_state=array([ 0.48561507,  0.03811119,  0.14104727, -1.1260912 ,  0.27514485,\n",
      "        0.03372187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48561507,  0.03811119,  0.14104727, -1.1260912 ,  0.27514485,\n",
      "        0.03372187,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.823700617596586, next_state=array([ 0.48704195,  0.0121811 ,  0.14104736, -1.1527581 ,  0.27683097,\n",
      "        0.03372184,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48704195,  0.0121811 ,  0.14104736, -1.1527581 ,  0.27683097,\n",
      "        0.03372184,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.727444719441222, next_state=array([ 0.48855656, -0.01431759,  0.15207058, -1.1776046 ,  0.27620566,\n",
      "       -0.01250624,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48855656, -0.01431759,  0.15207058, -1.1776046 ,  0.27620566,\n",
      "       -0.01250624,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.887822804581333, next_state=array([ 0.4900712 , -0.04141627,  0.15207061, -1.2042711 ,  0.27558035,\n",
      "       -0.01250652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4900712 , -0.04141627,  0.15207061, -1.2042711 ,  0.27558035,\n",
      "       -0.01250652,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0465831518732898, next_state=array([ 0.4912797 , -0.0682233 ,  0.12205093, -1.191196  ,  0.27434075,\n",
      "       -0.02479216,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4912797 , -0.0682233 ,  0.12205093, -1.191196  ,  0.27434075,\n",
      "       -0.02479216,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0984006191088156, next_state=array([ 0.4924881 , -0.09563033,  0.12205096, -1.2178627 ,  0.27310112,\n",
      "       -0.02479245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4924881 , -0.09563033,  0.12205096, -1.2178627 ,  0.27310112,\n",
      "       -0.02479245,  0.        ,  0.        ], dtype=float32), action=1, reward=6.4015453674796285, next_state=array([ 0.49362326, -0.12367572,  0.11277113, -1.2466022 ,  0.27386248,\n",
      "        0.01522715,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.49362326, -0.12367572,  0.11277113, -1.2466022 ,  0.27386248,\n",
      "        0.01522715,  0.        ,  1.        ], dtype=float32), action=0, reward=3.585322548840452, next_state=array([ 0.49492255, -0.15105893,  0.14715639, -1.2140542 ,  0.25818014,\n",
      "       -0.31127992,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.49492255, -0.15105893,  0.14715639, -1.2140542 ,  0.25818014,\n",
      "       -0.31127992,  0.        ,  1.        ], dtype=float32), action=3, reward=-100, next_state=array([ 0.4952964 , -0.1726093 ,  0.2180984 , -0.68873936,  0.11995035,\n",
      "       -4.5726757 ,  1.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00464802,  1.4091481 ,  0.4707675 , -0.07875498, -0.00537899,\n",
      "       -0.10663603,  0.        ,  0.        ], dtype=float32), action=2, reward=0.674929898781852, next_state=array([ 0.00919285,  1.408071  ,  0.46034274, -0.04789839, -0.01116598,\n",
      "       -0.11574985,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00919285,  1.408071  ,  0.46034274, -0.04789839, -0.01116598,\n",
      "       -0.11574985,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.36351433099828795, next_state=array([ 0.01369123,  1.4069852 ,  0.45593038, -0.04831789, -0.01719484,\n",
      "       -0.12058859,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01369123,  1.4069852 ,  0.45593038, -0.04831789, -0.01719484,\n",
      "       -0.12058859,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7984041419654488, next_state=array([ 0.01818972,  1.4052997 ,  0.45594788, -0.07499154, -0.02322292,\n",
      "       -0.1205726 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01818972,  1.4052997 ,  0.45594788, -0.07499154, -0.02322292,\n",
      "       -0.1205726 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.030832137203401555, next_state=array([ 0.0226059 ,  1.4036921 ,  0.44815764, -0.07156897, -0.0296954 ,\n",
      "       -0.12946141,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0226059 ,  1.4036921 ,  0.44815764, -0.07156897, -0.0296954 ,\n",
      "       -0.12946141,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9416202406615912, next_state=array([ 0.02708864,  1.4014872 ,  0.45650125, -0.09817616, -0.03783409,\n",
      "       -0.16278908,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02708864,  1.4014872 ,  0.45650125, -0.09817616, -0.03783409,\n",
      "       -0.16278908,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.177789276163395, next_state=array([ 0.03157158,  1.3986833 ,  0.4565262 , -0.12484661, -0.04597095,\n",
      "       -0.16275226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03157158,  1.3986833 ,  0.4565262 , -0.12484661, -0.04597095,\n",
      "       -0.16275226,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2589406204427576, next_state=array([ 0.0360549 ,  1.3952802 ,  0.45654994, -0.15151961, -0.05410688,\n",
      "       -0.16273369,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0360549 ,  1.3952802 ,  0.45654994, -0.15151961, -0.05410688,\n",
      "       -0.16273369,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3335106309098137, next_state=array([ 0.04053841,  1.3912781 ,  0.45657343, -0.17819299, -0.06224152,\n",
      "       -0.16270794,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04053841,  1.3912781 ,  0.45657343, -0.17819299, -0.06224152,\n",
      "       -0.16270794,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4008914968459294, next_state=array([ 0.0450223 ,  1.3866769 ,  0.45659694, -0.20486662, -0.07037487,\n",
      "       -0.162682  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0450223 ,  1.3866769 ,  0.45659694, -0.20486662, -0.07037487,\n",
      "       -0.162682  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4606431664349202, next_state=array([ 0.04950647,  1.3814763 ,  0.4566203 , -0.23154047, -0.07850692,\n",
      "       -0.16265626,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04950647,  1.3814763 ,  0.4566203 , -0.23154047, -0.07850692,\n",
      "       -0.16265626,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.480404661689731, next_state=array([ 0.0540575 ,  1.3756602 ,  0.4650053 , -0.2590389 , -0.08833335,\n",
      "       -0.1965464 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0540575 ,  1.3756602 ,  0.4650053 , -0.2590389 , -0.08833335,\n",
      "       -0.1965464 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1766743067302172, next_state=array([ 0.05855761,  1.3706468 ,  0.46053797, -0.22346865, -0.0987879 ,\n",
      "       -0.20910993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05855761,  1.3706468 ,  0.46053797, -0.22346865, -0.0987879 ,\n",
      "       -0.20910993,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7271834799572332, next_state=array([ 0.06305818,  1.3650347 ,  0.4605655 , -0.250158  , -0.10924057,\n",
      "       -0.20907204,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06305818,  1.3650347 ,  0.4605655 , -0.250158  , -0.10924057,\n",
      "       -0.20907204,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5163307994205286, next_state=array([ 0.06746311,  1.358828  ,  0.4485789 , -0.2764597 , -0.11728271,\n",
      "       -0.16085732,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06746311,  1.358828  ,  0.4485789 , -0.2764597 , -0.11728271,\n",
      "       -0.16085732,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3114310218987953, next_state=array([ 0.07186413,  1.3530161 ,  0.4485658 , -0.25899374, -0.1257084 ,\n",
      "       -0.16852899,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07186413,  1.3530161 ,  0.4485658 , -0.25899374, -0.1257084 ,\n",
      "       -0.16852899,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.42708225598857896, next_state=array([ 0.07617893,  1.3466321 ,  0.43767816, -0.28426182, -0.13189572,\n",
      "       -0.12375753,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07617893,  1.3466321 ,  0.43767816, -0.28426182, -0.13189572,\n",
      "       -0.12375753,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.894586414735403, next_state=array([ 0.08070393,  1.3402721 ,  0.45798126, -0.28316775, -0.1373627 ,\n",
      "       -0.10934943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08070393,  1.3402721 ,  0.45798126, -0.28316775, -0.1373627 ,\n",
      "       -0.10934943,  0.        ,  0.        ], dtype=float32), action=2, reward=0.13524246854150307, next_state=array([ 0.08535461,  1.3345997 ,  0.47050977, -0.252623  , -0.14279668,\n",
      "       -0.10868929,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08535461,  1.3345997 ,  0.47050977, -0.252623  , -0.14279668,\n",
      "       -0.10868929,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2617155289304662, next_state=array([ 0.09000549,  1.3283273 ,  0.47052306, -0.27930334, -0.14822951,\n",
      "       -0.10866649,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09000549,  1.3283273 ,  0.47052306, -0.27930334, -0.14822951,\n",
      "       -0.10866649,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.299442466764134, next_state=array([ 0.09465666,  1.3214552 ,  0.47053868, -0.30597156, -0.15366156,\n",
      "       -0.10865046,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09465666,  1.3214552 ,  0.47053868, -0.30597156, -0.15366156,\n",
      "       -0.10865046,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.44711890156078765, next_state=array([ 0.09937   ,  1.3147056 ,  0.4768134 , -0.3005633 , -0.15915   ,\n",
      "       -0.10977844,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09937   ,  1.3147056 ,  0.4768134 , -0.3005633 , -0.15915   ,\n",
      "       -0.10977844,  0.        ,  0.        ], dtype=float32), action=2, reward=0.40844048417365003, next_state=array([ 0.10406427,  1.3082035 ,  0.47540355, -0.28963265, -0.16514191,\n",
      "       -0.11984881,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10406427,  1.3082035 ,  0.47540355, -0.28963265, -0.16514191,\n",
      "       -0.11984881,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.469467135738198, next_state=array([ 0.10883522,  1.3010762 ,  0.48504752, -0.31767046, -0.17311971,\n",
      "       -0.15957043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10883522,  1.3010762 ,  0.48504752, -0.31767046, -0.17311971,\n",
      "       -0.15957043,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5735899703992118, next_state=array([ 0.11360636,  1.2933496 ,  0.4850697 , -0.34434387, -0.18109576,\n",
      "       -0.15953535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11360636,  1.2933496 ,  0.4850697 , -0.34434387, -0.18109576,\n",
      "       -0.15953535,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7906288685549883, next_state=array([ 0.11846028,  1.2849848 ,  0.495495  , -0.3730347 , -0.19124597,\n",
      "       -0.20300445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11846028,  1.2849848 ,  0.495495  , -0.3730347 , -0.19124597,\n",
      "       -0.20300445,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7800434173235147, next_state=array([ 0.12348442,  1.2766373 ,  0.5120958 , -0.37228563, -0.20098406,\n",
      "       -0.19476214,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12348442,  1.2766373 ,  0.5120958 , -0.37228563, -0.20098406,\n",
      "       -0.19476214,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7372299785831444, next_state=array([ 0.12850885,  1.2676909 ,  0.5120934 , -0.39896008, -0.2107221 ,\n",
      "       -0.19476092,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12850885,  1.2676909 ,  0.5120934 , -0.39896008, -0.2107221 ,\n",
      "       -0.19476092,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.2912213973095447, next_state=array([ 0.13377151,  1.2595584 ,  0.53574693, -0.3628298 , -0.22029282,\n",
      "       -0.19141425,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13377151,  1.2595584 ,  0.53574693, -0.3628298 , -0.22029282,\n",
      "       -0.19141425,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7474725289222011, next_state=array([ 0.13896504,  1.2508497 ,  0.52700615, -0.38822132, -0.2280499 ,\n",
      "       -0.15514177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13896504,  1.2508497 ,  0.52700615, -0.38822132, -0.2280499 ,\n",
      "       -0.15514177,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3040526663916967, next_state=array([ 0.14406843,  1.2415781 ,  0.5156293 , -0.4128941 , -0.23341705,\n",
      "       -0.10734256,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14406843,  1.2415781 ,  0.5156293 , -0.4128941 , -0.23341705,\n",
      "       -0.10734256,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9095011093355196, next_state=array([ 0.14925012,  1.232922  ,  0.5239563 , -0.38565078, -0.239298  ,\n",
      "       -0.11761913,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14925012,  1.232922  ,  0.5239563 , -0.38565078, -0.239298  ,\n",
      "       -0.11761913,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3871487804566687, next_state=array([ 0.15435915,  1.2236907 ,  0.51482546, -0.4109167 , -0.243277  ,\n",
      "       -0.07958008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15435915,  1.2236907 ,  0.51482546, -0.4109167 , -0.243277  ,\n",
      "       -0.07958008,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0587772268301294, next_state=array([ 0.1595294 ,  1.2138327 ,  0.5225372 , -0.43904945, -0.24888839,\n",
      "       -0.11222786,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1595294 ,  1.2138327 ,  0.5225372 , -0.43904945, -0.24888839,\n",
      "       -0.11222786,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3387430319447162, next_state=array([ 0.16469975,  1.2033753 ,  0.5225362 , -0.4657187 , -0.25449976,\n",
      "       -0.1122276 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16469975,  1.2033753 ,  0.5225362 , -0.4657187 , -0.25449976,\n",
      "       -0.1122276 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6015143061049162, next_state=array([ 0.16981164,  1.1923392 ,  0.51518625, -0.49119392, -0.2585733 ,\n",
      "       -0.08147042,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16981164,  1.1923392 ,  0.51518625, -0.49119392, -0.2585733 ,\n",
      "       -0.08147042,  0.        ,  0.        ], dtype=float32), action=2, reward=0.07978048101405194, next_state=array([ 0.17495175,  1.1813163 ,  0.5183449 , -0.49068734, -0.26300406,\n",
      "       -0.0886162 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17495175,  1.1813163 ,  0.5183449 , -0.49068734, -0.26300406,\n",
      "       -0.0886162 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.20528888140321896, next_state=array([ 0.18001337,  1.1697309 ,  0.50842035, -0.5153106 , -0.26531476,\n",
      "       -0.04621399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18001337,  1.1697309 ,  0.50842035, -0.5153106 , -0.26531476,\n",
      "       -0.04621399,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.027602530620129, next_state=array([ 0.185075  ,  1.1575456 ,  0.5084201 , -0.5419777 , -0.26762554,\n",
      "       -0.04621479,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.185075  ,  1.1575456 ,  0.5084201 , -0.5419777 , -0.26762554,\n",
      "       -0.04621479,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0173304363196962, next_state=array([ 0.19013663,  1.1447604 ,  0.50842   , -0.5686447 , -0.2699363 ,\n",
      "       -0.04621478,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19013663,  1.1447604 ,  0.50842   , -0.5686447 , -0.2699363 ,\n",
      "       -0.04621478,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3524458423149894, next_state=array([ 0.19517097,  1.1321827 ,  0.50645834, -0.55956936, -0.2730322 ,\n",
      "       -0.06191811,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19517097,  1.1321827 ,  0.50645834, -0.55956936, -0.2730322 ,\n",
      "       -0.06191811,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1625172169889992, next_state=array([ 0.20032816,  1.120089  ,  0.5190739 , -0.5381259 , -0.27648228,\n",
      "       -0.06900124,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20032816,  1.120089  ,  0.5190739 , -0.5381259 , -0.27648228,\n",
      "       -0.06900124,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3469339606861695, next_state=array([ 0.20580187,  1.1086963 ,  0.55043685, -0.50692   , -0.27961716,\n",
      "       -0.06269781,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20580187,  1.1086963 ,  0.55043685, -0.50692   , -0.27961716,\n",
      "       -0.06269781,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2155570569599647, next_state=array([ 0.21136284,  1.096679  ,  0.56133753, -0.5351202 , -0.28500986,\n",
      "       -0.10785417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21136284,  1.096679  ,  0.56133753, -0.5351202 , -0.28500986,\n",
      "       -0.10785417,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4074547763739418, next_state=array([ 0.21725646,  1.0848954 ,  0.59386563, -0.5246112 , -0.2896479 ,\n",
      "       -0.09276082,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21725646,  1.0848954 ,  0.59386563, -0.5246112 , -0.2896479 ,\n",
      "       -0.09276082,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6212756074274524, next_state=array([ 0.22337255,  1.0733835 ,  0.61590636, -0.5125    , -0.2940665 ,\n",
      "       -0.08837225,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22337255,  1.0733835 ,  0.61590636, -0.5125    , -0.2940665 ,\n",
      "       -0.08837225,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6001698418264596, next_state=array([ 0.22985181,  1.0626019 ,  0.65180004, -0.4799661 , -0.29806614,\n",
      "       -0.07999279,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22985181,  1.0626019 ,  0.65180004, -0.4799661 , -0.29806614,\n",
      "       -0.07999279,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9102059150263073, next_state=array([ 0.2365098 ,  1.0527573 ,  0.6702551 , -0.43845797, -0.3026662 ,\n",
      "       -0.09200075,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2365098 ,  1.0527573 ,  0.6702551 , -0.43845797, -0.3026662 ,\n",
      "       -0.09200075,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0808989871731853, next_state=array([ 0.24316788,  1.042313  ,  0.67025423, -0.46512637, -0.3072662 ,\n",
      "       -0.09200064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24316788,  1.042313  ,  0.67025423, -0.46512637, -0.3072662 ,\n",
      "       -0.09200064,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.13976078968019465, next_state=array([ 0.24975844,  1.0313017 ,  0.66171634, -0.48995093, -0.3100259 ,\n",
      "       -0.05519412,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24975844,  1.0313017 ,  0.66171634, -0.48995093, -0.3100259 ,\n",
      "       -0.05519412,  0.        ,  0.        ], dtype=float32), action=2, reward=0.04551752301581474, next_state=array([ 0.25651875,  1.0207496 ,  0.6789385 , -0.46960604, -0.31303304,\n",
      "       -0.0601429 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25651875,  1.0207496 ,  0.6789385 , -0.46960604, -0.31303304,\n",
      "       -0.0601429 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8058225890694632, next_state=array([ 0.26333466,  1.0095605 ,  0.6859935 , -0.49825478, -0.31761527,\n",
      "       -0.09164409,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26333466,  1.0095605 ,  0.6859935 , -0.49825478, -0.31761527,\n",
      "       -0.09164409,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2046712417578918, next_state=array([ 0.27022782,  0.997741  ,  0.69570106, -0.5267241 , -0.3242568 ,\n",
      "       -0.13283049,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27022782,  0.997741  ,  0.69570106, -0.5267241 , -0.3242568 ,\n",
      "       -0.13283049,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4614719129402818, next_state=array([ 0.27705938,  0.9853449 ,  0.6879529 , -0.5520187 , -0.32926244,\n",
      "       -0.1001127 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27705938,  0.9853449 ,  0.6879529 , -0.5520187 , -0.32926244,\n",
      "       -0.1001127 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1324705339290517, next_state=array([ 0.2838909 ,  0.9723491 ,  0.6879519 , -0.57868737, -0.33426806,\n",
      "       -0.10011258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2838909 ,  0.9723491 ,  0.6879519 , -0.57868737, -0.33426806,\n",
      "       -0.10011258,  0.        ,  0.        ], dtype=float32), action=1, reward=0.05863019602046052, next_state=array([ 0.29063788,  0.9588035 ,  0.67721283, -0.602619  , -0.33690286,\n",
      "       -0.05269572,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29063788,  0.9588035 ,  0.67721283, -0.602619  , -0.33690286,\n",
      "       -0.05269572,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4542952115832975, next_state=array([ 0.29748327,  0.945523  ,  0.68749034, -0.59092754, -0.33998945,\n",
      "       -0.06173198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29748327,  0.945523  ,  0.68749034, -0.59092754, -0.33998945,\n",
      "       -0.06173198,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9562980473680227, next_state=array([ 0.30432874,  0.93164295,  0.68748987, -0.6175949 , -0.34307605,\n",
      "       -0.06173196,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30432874,  0.93164295,  0.68748987, -0.6175949 , -0.34307605,\n",
      "       -0.06173196,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.954025920845254, next_state=array([ 0.3111742 ,  0.91716284,  0.6874895 , -0.6442623 , -0.34616265,\n",
      "       -0.06173195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3111742 ,  0.91716284,  0.6874895 , -0.6442623 , -0.34616265,\n",
      "       -0.06173195,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9504468396021082, next_state=array([ 0.31801957,  0.902083  ,  0.6874891 , -0.67092973, -0.3492492 ,\n",
      "       -0.061732  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31801957,  0.902083  ,  0.6874891 , -0.67092973, -0.3492492 ,\n",
      "       -0.061732  ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.09732960465535825, next_state=array([ 0.32478446,  0.8864381 ,  0.67735374, -0.6955382 , -0.3501627 ,\n",
      "       -0.01827003,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32478446,  0.8864381 ,  0.67735374, -0.6955382 , -0.3501627 ,\n",
      "       -0.01827003,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2636757938531116, next_state=array([ 0.33147144,  0.87022823,  0.66755307, -0.7201632 , -0.3489682 ,\n",
      "        0.02389025,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33147144,  0.87022823,  0.66755307, -0.7201632 , -0.3489682 ,\n",
      "        0.02389025,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5279319271740803, next_state=array([ 0.3381583 ,  0.8534183 ,  0.66755307, -0.7468299 , -0.34777367,\n",
      "        0.02389057,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3381583 ,  0.8534183 ,  0.66755307, -0.7468299 , -0.34777367,\n",
      "        0.02389057,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6383802353389274, next_state=array([ 0.34492284,  0.835955  ,  0.67744106, -0.7763844 , -0.348813  ,\n",
      "       -0.0207863 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34492284,  0.835955  ,  0.67744106, -0.7763844 , -0.348813  ,\n",
      "       -0.0207863 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9230816975769016, next_state=array([ 0.35189685,  0.8192707 ,  0.69890577, -0.74188584, -0.35039437,\n",
      "       -0.03162725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35189685,  0.8192707 ,  0.69890577, -0.74188584, -0.35039437,\n",
      "       -0.03162725,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0423611139908915, next_state=array([ 0.35896167,  0.8019442 ,  0.7103374 , -0.77101225, -0.35444477,\n",
      "       -0.08100835,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35896167,  0.8019442 ,  0.7103374 , -0.77101225, -0.35444477,\n",
      "       -0.08100835,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0449810343019976, next_state=array([ 0.36602658,  0.78401786,  0.7103367 , -0.79768014, -0.35849518,\n",
      "       -0.08100825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36602658,  0.78401786,  0.7103367 , -0.79768014, -0.35849518,\n",
      "       -0.08100825,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7565334508912998, next_state=array([ 0.37325487,  0.766     ,  0.72652185, -0.80172276, -0.36238754,\n",
      "       -0.07784752,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37325487,  0.766     ,  0.72652185, -0.80172276, -0.36238754,\n",
      "       -0.07784752,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.990169894352248, next_state=array([ 0.3805502 ,  0.7473404 ,  0.7350047 , -0.8307155 , -0.36817998,\n",
      "       -0.11584957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3805502 ,  0.7473404 ,  0.7350047 , -0.8307155 , -0.36817998,\n",
      "       -0.11584957,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9192771575489018, next_state=array([ 0.38798618,  0.7291607 ,  0.74962246, -0.8095481 , -0.37456325,\n",
      "       -0.1276649 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38798618,  0.7291607 ,  0.74962246, -0.8095481 , -0.37456325,\n",
      "       -0.1276649 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3157193882789215, next_state=array([ 0.39542216,  0.71038157,  0.7496206 , -0.8362179 , -0.3809465 ,\n",
      "       -0.12766454,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39542216,  0.71038157,  0.7496206 , -0.8362179 , -0.3809465 ,\n",
      "       -0.12766454,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3222214925202138, next_state=array([ 0.40285844,  0.69100285,  0.74961877, -0.8628877 , -0.38732973,\n",
      "       -0.12766416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40285844,  0.69100285,  0.74961877, -0.8628877 , -0.38732973,\n",
      "       -0.12766416,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3621037533891625, next_state=array([ 0.41037074,  0.670986  ,  0.7591838 , -0.8918224 , -0.39580992,\n",
      "       -0.16960357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41037074,  0.670986  ,  0.7591838 , -0.8918224 , -0.39580992,\n",
      "       -0.16960357,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6204342104408327, next_state=array([ 0.41796333,  0.6503294 ,  0.7692268 , -0.9208804 , -0.4064937 ,\n",
      "       -0.21367562,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41796333,  0.6503294 ,  0.7692268 , -0.9208804 , -0.4064937 ,\n",
      "       -0.21367562,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7707610444167585, next_state=array([ 0.42555636,  0.62907416,  0.7692212 , -0.94755584, -0.41717738,\n",
      "       -0.21367392,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42555636,  0.62907416,  0.7692212 , -0.94755584, -0.41717738,\n",
      "       -0.21367392,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0230544478948491, next_state=array([ 0.43308705,  0.6072498 ,  0.7613798 , -0.9724554 , -0.42615494,\n",
      "       -0.17955077,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43308705,  0.6072498 ,  0.7613798 , -0.9724554 , -0.42615494,\n",
      "       -0.17955077,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6451322752855901, next_state=array([ 0.44061813,  0.58482623,  0.76137567, -0.99912816, -0.43513244,\n",
      "       -0.17954978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44061813,  0.58482623,  0.76137567, -0.99912816, -0.43513244,\n",
      "       -0.17954978,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.600486421172205, next_state=array([ 0.44821033,  0.56174827,  0.7691991 , -1.0288191 , -0.44601244,\n",
      "       -0.21760051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44821033,  0.56174827,  0.7691991 , -1.0288191 , -0.44601244,\n",
      "       -0.21760051,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3046404464690682, next_state=array([ 0.45617455,  0.53896457,  0.80601007, -1.015704  , -0.45652926,\n",
      "       -0.2103364 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45617455,  0.53896457,  0.80601007, -1.015704  , -0.45652926,\n",
      "       -0.2103364 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7938200120891452, next_state=array([ 0.46454793,  0.51644546,  0.84641254, -1.0038509 , -0.46652153,\n",
      "       -0.19984548,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46454793,  0.51644546,  0.84641254, -1.0038509 , -0.46652153,\n",
      "       -0.19984548,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.012332915205479, next_state=array([ 0.4731907 ,  0.49390227,  0.8730184 , -1.0048871 , -0.4761993 ,\n",
      "       -0.1935555 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4731907 ,  0.49390227,  0.8730184 , -1.0048871 , -0.4761993 ,\n",
      "       -0.1935555 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9128900086099336, next_state=array([ 0.4819005 ,  0.47071767,  0.88139564, -1.0340548 , -0.4878006 ,\n",
      "       -0.23202606,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4819005 ,  0.47071767,  0.88139564, -1.0340548 , -0.4878006 ,\n",
      "       -0.23202606,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.509953749209461, next_state=array([ 0.4912013 ,  0.4480976 ,  0.93976957, -1.0088108 , -0.4986695 ,\n",
      "       -0.21737814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4912013 ,  0.4480976 ,  0.93976957, -1.0088108 , -0.4986695 ,\n",
      "       -0.21737814,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.214200337773633, next_state=array([ 0.50050247,  0.42487887,  0.9397626 , -1.0354861 , -0.50953835,\n",
      "       -0.21737638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.50050247,  0.42487887,  0.9397626 , -1.0354861 , -0.50953835,\n",
      "       -0.21737638,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2858611466845673, next_state=array([ 0.5098041 ,  0.4010615 ,  0.93975544, -1.0621614 , -0.5204071 ,\n",
      "       -0.21737461,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5098041 ,  0.4010615 ,  0.93975544, -1.0621614 , -0.5204071 ,\n",
      "       -0.21737461,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.206133032573716, next_state=array([ 0.51916444,  0.37660912,  0.9470142 , -1.0910274 , -0.53294927,\n",
      "       -0.25084257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51916444,  0.37660912,  0.9470142 , -1.0910274 , -0.53294927,\n",
      "       -0.25084257,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8270901747269364, next_state=array([ 0.529024  ,  0.35293594,  0.9970133 , -1.0565445 , -0.545662  ,\n",
      "       -0.25425488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.529024  ,  0.35293594,  0.9970133 , -1.0565445 , -0.545662  ,\n",
      "       -0.25425488,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9004191796985015, next_state=array([ 0.53882474,  0.3287078 ,  0.98949945, -1.0806648 , -0.556589  ,\n",
      "       -0.21854098,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.53882474,  0.3287078 ,  0.98949945, -1.0806648 , -0.556589  ,\n",
      "       -0.21854098,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9186011227253903, next_state=array([ 0.5485736 ,  0.30392182,  0.9828842 , -1.1049489 , -0.56591564,\n",
      "       -0.18653281,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5485736 ,  0.30392182,  0.9828842 , -1.1049489 , -0.56591564,\n",
      "       -0.18653281,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.753878407162051, next_state=array([ 0.5589015 ,  0.27945387,  1.0401225 , -1.0905896 , -0.57449806,\n",
      "       -0.17164789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5589015 ,  0.27945387,  1.0401225 , -1.0905896 , -0.57449806,\n",
      "       -0.17164789,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.801614942124188, next_state=array([ 0.56917447,  0.25444007,  1.0330408 , -1.1142186 , -0.58126616,\n",
      "       -0.13536164,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.56917447,  0.25444007,  1.0330408 , -1.1142186 , -0.58126616,\n",
      "       -0.13536164,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.679936851351715, next_state=array([ 0.5799407 ,  0.22962005,  1.0818641 , -1.1054221 , -0.5874708 ,\n",
      "       -0.12409173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5799407 ,  0.22962005,  1.0818641 , -1.1054221 , -0.5874708 ,\n",
      "       -0.12409173,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.663599174887281, next_state=array([ 0.5907071 ,  0.20420052,  1.0818614 , -1.1320914 , -0.5936753 ,\n",
      "       -0.12409142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5907071 ,  0.20420052,  1.0818614 , -1.1320914 , -0.5936753 ,\n",
      "       -0.12409142,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7895751163466116, next_state=array([ 0.6014738 ,  0.17818137,  1.0818588 , -1.1587607 , -0.59987986,\n",
      "       -0.12409081,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6014738 ,  0.17818137,  1.0818588 , -1.1587607 , -0.59987986,\n",
      "       -0.12409081,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.920995211516413, next_state=array([ 0.61224043,  0.15156263,  1.081856  , -1.18543   , -0.60608435,\n",
      "       -0.12409048,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.61224043,  0.15156263,  1.081856  , -1.18543   , -0.60608435,\n",
      "       -0.12409048,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0574780598407187, next_state=array([ 0.6230074 ,  0.12434429,  1.0818534 , -1.2120994 , -0.61228883,\n",
      "       -0.12409035,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6230074 ,  0.12434429,  1.0818534 , -1.2120994 , -0.61228883,\n",
      "       -0.12409035,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.198340082449249, next_state=array([ 0.6337746 ,  0.09652641,  1.0818506 , -1.2387688 , -0.6184933 ,\n",
      "       -0.12408999,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6337746 ,  0.09652641,  1.0818506 , -1.2387688 , -0.6184933 ,\n",
      "       -0.12408999,  0.        ,  0.        ], dtype=float32), action=1, reward=7.808196661688698, next_state=array([ 0.6444656 ,  0.06817683,  1.0721884 , -1.2614574 , -0.62225044,\n",
      "       -0.07514204,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6444656 ,  0.06817683,  1.0721884 , -1.2614574 , -0.62225044,\n",
      "       -0.07514204,  1.        ,  0.        ], dtype=float32), action=3, reward=43.560115314803596, next_state=array([ 0.65323865,  0.04987973,  0.87907076, -0.81422114, -0.63661   ,\n",
      "       -0.30240643,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.65323865,  0.04987973,  0.87907076, -0.81422114, -0.63661   ,\n",
      "       -0.30240643,  1.        ,  0.        ], dtype=float32), action=3, reward=-16.050473002696435, next_state=array([ 0.66261595,  0.03107766,  0.9348011 , -0.83434266, -0.6338378 ,\n",
      "        0.05457523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.66261595,  0.03107766,  0.9348011 , -0.83434266, -0.6338378 ,\n",
      "        0.05457523,  0.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.67192745,  0.01650532,  0.7593499 , -0.07259669, -0.5969062 ,\n",
      "        1.7190489 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-6.7996979e-04,  1.4034433e+00, -6.8885952e-02, -3.3230111e-01,\n",
      "        7.9466274e-04,  1.5603719e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.5327076474475223, next_state=array([-1.2711525e-03,  1.3953893e+00, -5.7644479e-02, -3.5795945e-01,\n",
      "       -6.7023648e-04, -2.9299637e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.2711525e-03,  1.3953893e+00, -5.7644479e-02, -3.5795945e-01,\n",
      "       -6.7023648e-04, -2.9299637e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.9182905992773556, next_state=array([-0.00186243,  1.3867347 , -0.05763974, -0.38464946, -0.0021341 ,\n",
      "       -0.02928006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00186243,  1.3867347 , -0.05763974, -0.38464946, -0.0021341 ,\n",
      "       -0.02928006,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.001952676020663, next_state=array([-0.00236588,  1.3774734 , -0.04664525, -0.41162145, -0.00580232,\n",
      "       -0.07337137,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00236588,  1.3774734 , -0.04664525, -0.41162145, -0.00580232,\n",
      "       -0.07337137,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.166859214031119, next_state=array([-0.00278254,  1.3676153 , -0.03574573, -0.4381765 , -0.01165202,\n",
      "       -0.11700487,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00278254,  1.3676153 , -0.03574573, -0.4381765 , -0.01165202,\n",
      "       -0.11700487,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3880898125110535, next_state=array([-0.0031045 ,  1.3571585 , -0.02388125, -0.46483248, -0.01987552,\n",
      "       -0.16448532,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0031045 ,  1.3571585 , -0.02388125, -0.46483248, -0.01987552,\n",
      "       -0.16448532,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7536465860746773, next_state=array([-0.00332928,  1.3468753 , -0.01458489, -0.45715097, -0.02768371,\n",
      "       -0.15617831,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00332928,  1.3468753 , -0.01458489, -0.45715097, -0.02768371,\n",
      "       -0.15617831,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3559097936003015, next_state=array([-0.00366926,  1.3374059 , -0.02541867, -0.42104486, -0.03616524,\n",
      "       -0.16964641,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00366926,  1.3374059 , -0.02541867, -0.42104486, -0.03616524,\n",
      "       -0.16964641,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.504686570318569, next_state=array([-0.00400896,  1.3273374 , -0.02539399, -0.4477268 , -0.04464468,\n",
      "       -0.16960451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00400896,  1.3273374 , -0.02539399, -0.4477268 , -0.04464468,\n",
      "       -0.16960451,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.709059255749223, next_state=array([-0.00425081,  1.3166627 , -0.01314509, -0.4747957 , -0.05557796,\n",
      "       -0.21868575,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00425081,  1.3166627 , -0.01314509, -0.4747957 , -0.05557796,\n",
      "       -0.21868575,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1779164013787067, next_state=array([-0.00430098,  1.3063145 ,  0.00526596, -0.460329  , -0.06576526,\n",
      "       -0.20376508,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00430098,  1.3063145 ,  0.00526596, -0.460329  , -0.06576526,\n",
      "       -0.20376508,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5923410254556813, next_state=array([-0.00435085,  1.2953675 ,  0.00529385, -0.48701373, -0.07595205,\n",
      "       -0.20375443,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00435085,  1.2953675 ,  0.00529385, -0.48701373, -0.07595205,\n",
      "       -0.20375443,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3096723979277543, next_state=array([-0.00447836,  1.2838316 , -0.00447315, -0.5131437 , -0.0841635 ,\n",
      "       -0.16424383,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00447836,  1.2838316 , -0.00447315, -0.5131437 , -0.0841635 ,\n",
      "       -0.16424383,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.500763357941905, next_state=array([-0.00453491,  1.2716947 ,  0.00439606, -0.54000586, -0.09414718,\n",
      "       -0.19969168,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00453491,  1.2716947 ,  0.00439606, -0.54000586, -0.09414718,\n",
      "       -0.19969168,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.702428003699764, next_state=array([-0.00451784,  1.258944  ,  0.01364032, -0.5674864 , -0.10599549,\n",
      "       -0.23698783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00451784,  1.258944  ,  0.01364032, -0.5674864 , -0.10599549,\n",
      "       -0.23698783,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5171613864775964, next_state=array([-0.0045001 ,  1.2455952 ,  0.01367302, -0.5941674 , -0.1178415 ,\n",
      "       -0.23694141,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0045001 ,  1.2455952 ,  0.01367302, -0.5941674 , -0.1178415 ,\n",
      "       -0.23694141,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.848065099963519, next_state=array([-0.00438852,  1.2316332 ,  0.02543533, -0.6217297 , -0.1320595 ,\n",
      "       -0.28438634,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00438852,  1.2316332 ,  0.02543533, -0.6217297 , -0.1320595 ,\n",
      "       -0.28438634,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7159587440714406, next_state=array([-0.0040926 ,  1.2183911 ,  0.04351938, -0.5898259 , -0.14596342,\n",
      "       -0.278104  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0040926 ,  1.2183911 ,  0.04351938, -0.5898259 , -0.14596342,\n",
      "       -0.278104  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.451092615224296, next_state=array([-0.00386038,  1.2045556 ,  0.03551932, -0.6161634 , -0.15825348,\n",
      "       -0.24582359,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00386038,  1.2045556 ,  0.03551932, -0.6161634 , -0.15825348,\n",
      "       -0.24582359,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.859882574768362, next_state=array([-0.00355139,  1.190099  ,  0.04514106, -0.6441017 , -0.17251456,\n",
      "       -0.28524747,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00355139,  1.190099  ,  0.04514106, -0.6441017 , -0.17251456,\n",
      "       -0.28524747,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.004888847113732, next_state=array([-0.00316849,  1.1750194 ,  0.05438065, -0.67215234, -0.18867703,\n",
      "       -0.32327905,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00316849,  1.1750194 ,  0.05438065, -0.67215234, -0.18867703,\n",
      "       -0.32327905,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0997594948174183, next_state=array([-0.00271072,  1.1593277 ,  0.06369072, -0.69979566, -0.20672798,\n",
      "       -0.3610518 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00271072,  1.1593277 ,  0.06369072, -0.69979566, -0.20672798,\n",
      "       -0.3610518 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.0881865975509129, next_state=array([-0.00217705,  1.143806  ,  0.07135734, -0.69246745, -0.22492267,\n",
      "       -0.36392698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00217705,  1.143806  ,  0.07135734, -0.69246745, -0.22492267,\n",
      "       -0.36392698,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4521601283985874, next_state=array([-0.00171404,  1.1277199 ,  0.06232108, -0.7174658 , -0.24119803,\n",
      "       -0.32553643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00171404,  1.1277199 ,  0.06232108, -0.7174658 , -0.24119803,\n",
      "       -0.32553643,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.055814994200999, next_state=array([-0.00117331,  1.1110165 ,  0.07197386, -0.74540675, -0.25945425,\n",
      "       -0.3651578 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00117331,  1.1110165 ,  0.07197386, -0.74540675, -0.25945425,\n",
      "       -0.3651578 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.956351397948265, next_state=array([-2.9706955e-04,  1.0949556e+00,  1.0495211e-01, -7.1699238e-01,\n",
      "       -2.7719265e-01, -3.5476798e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.9706955e-04,  1.0949556e+00,  1.0495211e-01, -7.1699238e-01,\n",
      "       -2.7719265e-01, -3.5476798e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=1.680478300856305, next_state=array([ 7.1792601e-04,  1.0794621e+00,  1.1909293e-01, -6.9204271e-01,\n",
      "       -2.9529887e-01, -3.6212462e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 7.1792601e-04,  1.0794621e+00,  1.1909293e-01, -6.9204271e-01,\n",
      "       -2.9529887e-01, -3.6212462e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-2.8336062508986117, next_state=array([ 0.00173378,  1.0633727 ,  0.1190813 , -0.7187357 , -0.3134047 ,\n",
      "       -0.3621165 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00173378,  1.0633727 ,  0.1190813 , -0.7187357 , -0.3134047 ,\n",
      "       -0.3621165 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.233569631823285, next_state=array([ 0.00267811,  1.0467312 ,  0.10990276, -0.74304384, -0.32948586,\n",
      "       -0.32162294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00267811,  1.0467312 ,  0.10990276, -0.74304384, -0.32948586,\n",
      "       -0.32162294,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.525406230598435, next_state=array([ 0.0036232 ,  1.0294932 ,  0.10989249, -0.7697311 , -0.3455667 ,\n",
      "       -0.321617  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0036232 ,  1.0294932 ,  0.10989249, -0.7697311 , -0.3455667 ,\n",
      "       -0.321617  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.125781251391969, next_state=array([ 0.00465088,  1.0116118 ,  0.12021364, -0.79901814, -0.3639269 ,\n",
      "       -0.36720428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00465088,  1.0116118 ,  0.12021364, -0.79901814, -0.3639269 ,\n",
      "       -0.36720428,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2874934548807289, next_state=array([ 0.00581598,  0.9939437 ,  0.13411708, -0.78983337, -0.38258517,\n",
      "       -0.3731656 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00581598,  0.9939437 ,  0.13411708, -0.78983337, -0.38258517,\n",
      "       -0.3731656 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0288274782972437, next_state=array([ 0.00689077,  0.97572243,  0.1226377 , -0.813985  , -0.39875504,\n",
      "       -0.32339767,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00689077,  0.97572243,  0.1226377 , -0.813985  , -0.39875504,\n",
      "       -0.32339767,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1774409754535895, next_state=array([ 0.00845118,  0.9579805 ,  0.1703765 , -0.7926298 , -0.414147  ,\n",
      "       -0.30783945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00845118,  0.9579805 ,  0.1703765 , -0.7926298 , -0.414147  ,\n",
      "       -0.30783945,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1105278460012458, next_state=array([ 0.01009073,  0.939581  ,  0.18033078, -0.8226615 , -0.4318749 ,\n",
      "       -0.3545588 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01009073,  0.939581  ,  0.18033078, -0.8226615 , -0.4318749 ,\n",
      "       -0.3545588 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9710629184684751, next_state=array([ 0.0116704,  0.9206234,  0.1726301, -0.8471506, -0.4478568,\n",
      "       -0.3196382,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.0116704,  0.9206234,  0.1726301, -0.8471506, -0.4478568,\n",
      "       -0.3196382,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.2612364110371175, next_state=array([ 0.01325111,  0.90106887,  0.17261645, -0.8738365 , -0.46383843,\n",
      "       -0.31963256,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01325111,  0.90106887,  0.17261645, -0.8738365 , -0.46383843,\n",
      "       -0.31963256,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5436514665610277, next_state=array([ 0.01523647,  0.88232505,  0.21320872, -0.8380459 , -0.48009214,\n",
      "       -0.32507396,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01523647,  0.88232505,  0.21320872, -0.8380459 , -0.48009214,\n",
      "       -0.32507396,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2836018761302626, next_state=array([ 0.01722288,  0.8629841 ,  0.21319366, -0.8647323 , -0.49634555,\n",
      "       -0.32506806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01722288,  0.8629841 ,  0.21319366, -0.8647323 , -0.49634555,\n",
      "       -0.32506806,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.016669264116301, next_state=array([ 0.01928082,  0.8429857 ,  0.22213669, -0.89483637, -0.51479125,\n",
      "       -0.36891395,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01928082,  0.8429857 ,  0.22213669, -0.89483637, -0.51479125,\n",
      "       -0.36891395,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.611887136556361, next_state=array([ 0.02126322,  0.82245326,  0.21236381, -0.91796595, -0.5308742 ,\n",
      "       -0.3216594 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02126322,  0.82245326,  0.21236381, -0.91796595, -0.5308742 ,\n",
      "       -0.3216594 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4462918275259426, next_state=array([ 0.02343559,  0.8018958 ,  0.23134832, -0.91927606, -0.54709697,\n",
      "       -0.3244541 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02343559,  0.8018958 ,  0.23134832, -0.91927606, -0.54709697,\n",
      "       -0.3244541 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4768349287598699, next_state=array([ 0.02555618,  0.78080076,  0.22447081, -0.94266886, -0.5614986 ,\n",
      "       -0.2880323 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02555618,  0.78080076,  0.22447081, -0.94266886, -0.5614986 ,\n",
      "       -0.2880323 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.819538318887082, next_state=array([ 0.02775679,  0.7590307 ,  0.23456538, -0.9737489 , -0.57849836,\n",
      "       -0.33999506,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02775679,  0.7590307 ,  0.23456538, -0.9737489 , -0.57849836,\n",
      "       -0.33999506,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0693387826922844, next_state=array([ 0.02995872,  0.73666364,  0.23454574, -1.000436  , -0.5954978 ,\n",
      "       -0.3399883 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02995872,  0.73666364,  0.23454574, -1.000436  , -0.5954978 ,\n",
      "       -0.3399883 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9399192010689306, next_state=array([ 0.03223219,  0.7136177 ,  0.24359746, -1.0317397 , -0.6149795 ,\n",
      "       -0.38963428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03223219,  0.7136177 ,  0.24359746, -1.0317397 , -0.6149795 ,\n",
      "       -0.38963428,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8498100937579225, next_state=array([ 0.03455601,  0.6899185 ,  0.24979325, -1.0616715 , -0.63618463,\n",
      "       -0.42410287,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03455601,  0.6899185 ,  0.24979325, -1.0616715 , -0.63618463,\n",
      "       -0.42410287,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3063134945782053, next_state=array([ 0.03688202,  0.66562414,  0.24976015, -1.0883687 , -0.6573891 ,\n",
      "       -0.42408973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03688202,  0.66562414,  0.24976015, -1.0883687 , -0.6573891 ,\n",
      "       -0.42408973,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2520149989840945, next_state=array([ 0.03921061,  0.6407344 ,  0.2497261 , -1.1150652 , -0.6785929 ,\n",
      "       -0.42407662,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03921061,  0.6407344 ,  0.2497261 , -1.1150652 , -0.6785929 ,\n",
      "       -0.42407662,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.493724991500925, next_state=array([ 0.04148436,  0.6153168 ,  0.24237256, -1.1378758 , -0.697734  ,\n",
      "       -0.38282186,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04148436,  0.6153168 ,  0.24237256, -1.1378758 , -0.697734  ,\n",
      "       -0.38282186,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3426645225663936, next_state=array([ 0.04370756,  0.5893588 ,  0.23567495, -1.1612737 , -0.71505266,\n",
      "       -0.34637377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04370756,  0.5893588 ,  0.23567495, -1.1612737 , -0.71505266,\n",
      "       -0.34637377,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.706246733758745, next_state=array([ 0.0460022 ,  0.56271124,  0.24464948, -1.1932805 , -0.7350493 ,\n",
      "       -0.399934  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0460022 ,  0.56271124,  0.24464948, -1.1932805 , -0.7350493 ,\n",
      "       -0.399934  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9201966336842986, next_state=array([ 0.04829922,  0.5354677 ,  0.24461615, -1.219972  , -0.7550455 ,\n",
      "       -0.39992318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04829922,  0.5354677 ,  0.24461615, -1.219972  , -0.7550455 ,\n",
      "       -0.39992318,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2103787395170003, next_state=array([ 0.05102177,  0.5080425 ,  0.28647983, -1.2279803 , -0.7744925 ,\n",
      "       -0.3889406 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05102177,  0.5080425 ,  0.28647983, -1.2279803 , -0.7744925 ,\n",
      "       -0.3889406 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7867613636881856, next_state=array([ 0.05374651,  0.48002094,  0.2864469 , -1.2546699 , -0.79393905,\n",
      "       -0.38893053,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05374651,  0.48002094,  0.2864469 , -1.2546699 , -0.79393905,\n",
      "       -0.38893053,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7372955237698875, next_state=array([ 0.05647392,  0.45140284,  0.28641334, -1.281359  , -0.81338507,\n",
      "       -0.3889204 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05647392,  0.45140284,  0.28641334, -1.281359  , -0.81338507,\n",
      "       -0.3889204 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6894159454543, next_state=array([ 0.05920362,  0.42218828,  0.28637913, -1.3080477 , -0.8328306 ,\n",
      "       -0.3889103 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05920362,  0.42218828,  0.28637913, -1.3080477 , -0.8328306 ,\n",
      "       -0.3889103 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.16443161643662735, next_state=array([ 0.06266613,  0.3932848 ,  0.35922557, -1.2942888 , -0.85207444,\n",
      "       -0.38487697,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06266613,  0.3932848 ,  0.35922557, -1.2942888 , -0.85207444,\n",
      "       -0.38487697,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6468377792626825, next_state=array([ 0.06613092,  0.36378452,  0.35919082, -1.320976  , -0.8713178 ,\n",
      "       -0.384867  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06613092,  0.36378452,  0.35919082, -1.320976  , -0.8713178 ,\n",
      "       -0.384867  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6125295928322885, next_state=array([ 0.06959839,  0.33368754,  0.35915548, -1.347663  , -0.8905607 ,\n",
      "       -0.38485724,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06959839,  0.33368754,  0.35915548, -1.347663  , -0.8905607 ,\n",
      "       -0.38485724,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5847373958941944, next_state=array([ 0.07306824,  0.30299366,  0.35911956, -1.3743495 , -0.90980303,\n",
      "       -0.38484743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07306824,  0.30299366,  0.35911956, -1.3743495 , -0.90980303,\n",
      "       -0.38484743,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6318754737187351, next_state=array([ 0.07648249,  0.27179584,  0.35169533, -1.3955166 , -0.92649233,\n",
      "       -0.33378592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07648249,  0.27179584,  0.35169533, -1.3955166 , -0.92649233,\n",
      "       -0.33378592,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3167244514053777, next_state=array([ 0.07989855,  0.2400002 ,  0.35166752, -1.4221975 , -0.9431813 ,\n",
      "       -0.33377954,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07989855,  0.2400002 ,  0.35166752, -1.4221975 , -0.9431813 ,\n",
      "       -0.33377954,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.147576245950829, next_state=array([ 0.08334942,  0.20752095,  0.35609508, -1.4538236 , -0.9619057 ,\n",
      "       -0.37448907,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08334942,  0.20752095,  0.35609508, -1.4538236 , -0.9619057 ,\n",
      "       -0.37448907,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.738189942828767, next_state=array([ 0.08675413,  0.17453243,  0.34988683, -1.4752864 , -0.97830623,\n",
      "       -0.32801026,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-5.05352044e-04,  1.40635443e+00, -5.12031987e-02, -2.02914655e-01,\n",
      "        5.92375873e-04,  1.15982685e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=2, reward=-0.28763562686670524, next_state=array([-1.1607170e-03,  1.4017725e+00, -6.5382235e-02, -2.0364095e-01,\n",
      "        4.4592327e-04, -2.9286887e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.1607170e-03,  1.4017725e+00, -6.5382235e-02, -2.0364095e-01,\n",
      "        4.4592327e-04, -2.9286887e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.9423960984945825, next_state=array([-0.00172729,  1.3965884 , -0.0542503 , -0.23039976, -0.00193238,\n",
      "       -0.04757087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00172729,  1.3965884 , -0.0542503 , -0.23039976, -0.00193238,\n",
      "       -0.04757087,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3583492551443315, next_state=array([-0.00219851,  1.3907938 , -0.04228606, -0.25755456, -0.00670766,\n",
      "       -0.09551473,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00219851,  1.3907938 , -0.04228606, -0.25755456, -0.00670766,\n",
      "       -0.09551473,  0.        ,  0.        ], dtype=float32), action=2, reward=1.096339975770104, next_state=array([-0.00275316,  1.3853464 , -0.05022391, -0.2421365 , -0.01190308,\n",
      "       -0.10391787,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00275316,  1.3853464 , -0.05022391, -0.2421365 , -0.01190308,\n",
      "       -0.10391787,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.532163116627629, next_state=array([-0.00330782,  1.3792992 , -0.05020869, -0.26881447, -0.01709782,\n",
      "       -0.10390458,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00330782,  1.3792992 , -0.05020869, -0.26881447, -0.01709782,\n",
      "       -0.10390458,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.480003710317362, next_state=array([-0.00386229,  1.3726524 , -0.05019341, -0.29548153, -0.02229196,\n",
      "       -0.10389205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00386229,  1.3726524 , -0.05019341, -0.29548153, -0.02229196,\n",
      "       -0.10389205,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.364600819294877, next_state=array([-0.00450449,  1.3654189 , -0.06121429, -0.32154077, -0.02526804,\n",
      "       -0.059527  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00450449,  1.3654189 , -0.06121429, -0.32154077, -0.02526804,\n",
      "       -0.059527  ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.522310055172835, next_state=array([-0.0051198 ,  1.3582654 , -0.05860153, -0.3179856 , -0.02817176,\n",
      "       -0.0580797 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0051198 ,  1.3582654 , -0.05860153, -0.3179856 , -0.02817176,\n",
      "       -0.0580797 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.144973481237655, next_state=array([-0.00581141,  1.3505129 , -0.06816097, -0.34457827, -0.02915647,\n",
      "       -0.01969575,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00581141,  1.3505129 , -0.06816097, -0.34457827, -0.02915647,\n",
      "       -0.01969575,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0123534694916985, next_state=array([-0.00641823,  1.3421466 , -0.05753674, -0.37189662, -0.0322773 ,\n",
      "       -0.06242226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00641823,  1.3421466 , -0.05753674, -0.37189662, -0.0322773 ,\n",
      "       -0.06242226,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9266472937270691, next_state=array([-0.00692511,  1.3339028 , -0.04793446, -0.3664543 , -0.03499697,\n",
      "       -0.05439789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00692511,  1.3339028 , -0.04793446, -0.3664543 , -0.03499697,\n",
      "       -0.05439789,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.15905415812682, next_state=array([-0.00736809,  1.3250546 , -0.03992844, -0.39336577, -0.03932234,\n",
      "       -0.08651531,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00736809,  1.3250546 , -0.03992844, -0.39336577, -0.03932234,\n",
      "       -0.08651531,  0.        ,  0.        ], dtype=float32), action=2, reward=2.034633347104358, next_state=array([-0.00763588,  1.3165932 , -0.02312386, -0.37616977, -0.04294301,\n",
      "       -0.07242037,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00763588,  1.3165932 , -0.02312386, -0.37616977, -0.04294301,\n",
      "       -0.07242037,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.02675206471241, next_state=array([-0.00798826,  1.3075266 , -0.03371182, -0.40300238, -0.04444474,\n",
      "       -0.030037  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00798826,  1.3075266 , -0.03371182, -0.40300238, -0.04444474,\n",
      "       -0.030037  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6803319245591684, next_state=array([-0.00843134,  1.2978737 , -0.04512033, -0.42899093, -0.0436506 ,\n",
      "        0.01588422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00843134,  1.2978737 , -0.04512033, -0.42899093, -0.0436506 ,\n",
      "        0.01588422,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.548784341491512, next_state=array([-0.00887451,  1.2876208 , -0.04512302, -0.4556595 , -0.0428571 ,\n",
      "        0.01587146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00887451,  1.2876208 , -0.04512302, -0.4556595 , -0.0428571 ,\n",
      "        0.01587146,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4902862256654146, next_state=array([-0.00931778,  1.276768  , -0.04512526, -0.48232815, -0.04206324,\n",
      "        0.01587886,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00931778,  1.276768  , -0.04512526, -0.48232815, -0.04206324,\n",
      "        0.01587886,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.431590154569335, next_state=array([-0.00976105,  1.265315  , -0.04512764, -0.5089968 , -0.04126951,\n",
      "        0.01587599,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00976105,  1.265315  , -0.04512764, -0.5089968 , -0.04126951,\n",
      "        0.01587599,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6058422635363445, next_state=array([-0.01012373,  1.2532462 , -0.0350099 , -0.53643185, -0.04251383,\n",
      "       -0.0248886 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01012373,  1.2532462 , -0.0350099 , -0.53643185, -0.04251383,\n",
      "       -0.0248886 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4241356873142752, next_state=array([-0.01057482,  1.2405717 , -0.04609939, -0.56327575, -0.04153948,\n",
      "        0.01948871,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01057482,  1.2405717 , -0.04609939, -0.56327575, -0.04153948,\n",
      "        0.01948871,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.421625462303324, next_state=array([-0.01094923,  1.2272915 , -0.03646585, -0.59026533, -0.04250064,\n",
      "       -0.01922522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01094923,  1.2272915 , -0.03646585, -0.59026533, -0.04250064,\n",
      "       -0.01922522,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3703627430659537, next_state=array([-0.01132355,  1.2134111 , -0.03646253, -0.61693436, -0.04346044,\n",
      "       -0.01919749,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01132355,  1.2134111 , -0.03646253, -0.61693436, -0.04346044,\n",
      "       -0.01919749,  0.        ,  0.        ], dtype=float32), action=2, reward=2.9140535420766414, next_state=array([-0.01179552,  1.2000026 , -0.04561839, -0.5959733 , -0.04501745,\n",
      "       -0.0311429 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01179552,  1.2000026 , -0.04561839, -0.5959733 , -0.04501745,\n",
      "       -0.0311429 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2553993287235687, next_state=array([-0.01234264,  1.1860104 , -0.05507813, -0.62187314, -0.04466667,\n",
      "        0.00701613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01234264,  1.1860104 , -0.05507813, -0.62187314, -0.04466667,\n",
      "        0.00701613,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2160762615175134, next_state=array([-0.01295872,  1.1713902 , -0.06368359, -0.6497221 , -0.0426119 ,\n",
      "        0.04109537,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01295872,  1.1713902 , -0.06368359, -0.6497221 , -0.0426119 ,\n",
      "        0.04109537,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8224049728322871, next_state=array([-0.01364889,  1.1561787 , -0.0729865 , -0.6759565 , -0.0386888 ,\n",
      "        0.07846211,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01364889,  1.1561787 , -0.0729865 , -0.6759565 , -0.0386888 ,\n",
      "        0.07846211,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6794940211639755, next_state=array([-0.01433897,  1.1403675 , -0.07298658, -0.7026244 , -0.03476571,\n",
      "        0.07846203,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01433897,  1.1403675 , -0.07298658, -0.7026244 , -0.03476571,\n",
      "        0.07846203,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5908561573529585, next_state=array([-0.01509686,  1.123951  , -0.08147521, -0.72950244, -0.02914646,\n",
      "        0.11238495,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01509686,  1.123951  , -0.08147521, -0.72950244, -0.02914646,\n",
      "        0.11238495,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3887003098760431, next_state=array([-0.01585465,  1.1069348 , -0.08147533, -0.75617176, -0.02352724,\n",
      "        0.11238465,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01585465,  1.1069348 , -0.08147533, -0.75617176, -0.02352724,\n",
      "        0.11238465,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3299283842109162, next_state=array([-0.01661243,  1.0893192 , -0.08147544, -0.78284097, -0.01790803,\n",
      "        0.11238446,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01661243,  1.0893192 , -0.08147544, -0.78284097, -0.01790803,\n",
      "        0.11238446,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2710422383119351, next_state=array([-0.01737022,  1.0711039 , -0.08147553, -0.8095103 , -0.01228883,\n",
      "        0.11238424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01737022,  1.0711039 , -0.08147553, -0.8095103 , -0.01228883,\n",
      "        0.11238424,  0.        ,  0.        ], dtype=float32), action=2, reward=3.236901301663562, next_state=array([-0.0182929 ,  1.0532155 , -0.09714888, -0.79500955, -0.00746707,\n",
      "        0.09643527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0182929 ,  1.0532155 , -0.09714888, -0.79500955, -0.00746707,\n",
      "        0.09643527,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.40447225849126656, next_state=array([-0.01915607,  1.0347296 , -0.08968312, -0.821582  , -0.00414014,\n",
      "        0.06653868,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01915607,  1.0347296 , -0.08968312, -0.821582  , -0.00414014,\n",
      "        0.06653868,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4122262342988279, next_state=array([-2.0019149e-02,  1.0156438e+00, -8.9683123e-02, -8.4824955e-01,\n",
      "       -8.1320328e-04,  6.6538677e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.0019149e-02,  1.0156438e+00, -8.9683123e-02, -8.4824955e-01,\n",
      "       -8.1320328e-04,  6.6538677e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=2.181472219219825, next_state=array([-0.02098398,  0.99674493, -0.09937625, -0.8399517 ,  0.00204121,\n",
      "        0.05708836,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02098398,  0.99674493, -0.09937625, -0.8399517 ,  0.00204121,\n",
      "        0.05708836,  0.        ,  0.        ], dtype=float32), action=2, reward=5.381887663165583, next_state=array([-0.02186871,  0.97878015, -0.09174107, -0.7984441 ,  0.00527633,\n",
      "        0.0647024 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02186871,  0.97878015, -0.09174107, -0.7984441 ,  0.00527633,\n",
      "        0.0647024 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4501441015891305, next_state=array([-0.02283707,  0.9602234 , -0.10224301, -0.8247776 ,  0.01061392,\n",
      "        0.10675184,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02283707,  0.9602234 , -0.10224301, -0.8247776 ,  0.01061392,\n",
      "        0.10675184,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2683294214881187, next_state=array([-0.02380543,  0.94106686, -0.10224298, -0.8514467 ,  0.0159515 ,\n",
      "        0.10675166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02380543,  0.94106686, -0.10224298, -0.8514467 ,  0.0159515 ,\n",
      "        0.10675166,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4751470009147727, next_state=array([-0.02483511,  0.92131376, -0.10993655, -0.878001  ,  0.02282896,\n",
      "        0.1375489 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02483511,  0.92131376, -0.10993655, -0.878001  ,  0.02282896,\n",
      "        0.1375489 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.40986512552696, next_state=array([-0.02597847,  0.9023811 , -0.12087314, -0.841564  ,  0.02928055,\n",
      "        0.12903208,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02597847,  0.9023811 , -0.12087314, -0.841564  ,  0.02928055,\n",
      "        0.12903208,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7382852178124029, next_state=array([-0.02719774,  0.88284004, -0.13039431, -0.8686846 ,  0.03764312,\n",
      "        0.16725107,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02719774,  0.88284004, -0.13039431, -0.8686846 ,  0.03764312,\n",
      "        0.16725107,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8513622204617366, next_state=array([-0.02848587,  0.8626887 , -0.13903144, -0.8959076 ,  0.04774204,\n",
      "        0.20197825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02848587,  0.8626887 , -0.13903144, -0.8959076 ,  0.04774204,\n",
      "        0.20197825,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.02961159134142, next_state=array([-0.02985487,  0.8419263 , -0.14918499, -0.92321336,  0.05988347,\n",
      "        0.24282876,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02985487,  0.8419263 , -0.14918499, -0.92321336,  0.05988347,\n",
      "        0.24282876,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3415750583567787, next_state=array([-0.03114576,  0.8215689 , -0.14191146, -0.9053272 ,  0.07257125,\n",
      "        0.253756  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03114576,  0.8215689 , -0.14191146, -0.9053272 ,  0.07257125,\n",
      "        0.253756  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.81664429039256, next_state=array([-0.03243666,  0.80061394, -0.1419101 , -0.9320074 ,  0.08525892,\n",
      "        0.25375316,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03243666,  0.80061394, -0.1419101 , -0.9320074 ,  0.08525892,\n",
      "        0.25375316,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2300223903641823, next_state=array([-0.03381691,  0.7790537 , -0.1531075 , -0.9591526 ,  0.100196  ,\n",
      "        0.29874158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03381691,  0.7790537 , -0.1531075 , -0.9591526 ,  0.100196  ,\n",
      "        0.29874158,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9224169406084002, next_state=array([-0.03519745,  0.7568967 , -0.1531049 , -0.9858378 ,  0.11513283,\n",
      "        0.298737  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03519745,  0.7568967 , -0.1531049 , -0.9858378 ,  0.11513283,\n",
      "        0.298737  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2912607368031375, next_state=array([-0.03665151,  0.7341302 , -0.1622965 , -1.0132264 ,  0.13192916,\n",
      "        0.33592644,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03665151,  0.7341302 , -0.1622965 , -1.0132264 ,  0.13192916,\n",
      "        0.33592644,  0.        ,  0.        ], dtype=float32), action=2, reward=2.258582208432796, next_state=array([-0.03831482,  0.7118973 , -0.18267965, -0.98965776,  0.14822559,\n",
      "        0.3259288 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03831482,  0.7118973 , -0.18267965, -0.98965776,  0.14822559,\n",
      "        0.3259288 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9851019629782343, next_state=array([-0.0399785 ,  0.68906796, -0.182675  , -1.0163465 ,  0.16452175,\n",
      "        0.32592285,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0399785 ,  0.68906796, -0.182675  , -1.0163465 ,  0.16452175,\n",
      "        0.32592285,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4929119937370787, next_state=array([-0.04167042,  0.66701   , -0.18601418, -0.9823028 ,  0.1813816 ,\n",
      "        0.33719686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04167042,  0.66701   , -0.18601418, -0.9823028 ,  0.1813816 ,\n",
      "        0.33719686,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.059736774222216, next_state=array([-0.04336271,  0.6443559 , -0.18600802, -1.0089929 ,  0.19824111,\n",
      "        0.33719027,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04336271,  0.6443559 , -0.18600802, -1.0089929 ,  0.19824111,\n",
      "        0.33719027,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6122907329423402, next_state=array([-0.04498339,  0.6211185 , -0.1769791 , -1.0348364 ,  0.213266  ,\n",
      "        0.3004976 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04498339,  0.6211185 , -0.1769791 , -1.0348364 ,  0.213266  ,\n",
      "        0.3004976 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.366381608446061, next_state=array([-0.04653196,  0.59730095, -0.16786733, -1.0604953 ,  0.22642638,\n",
      "        0.26320764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04653196,  0.59730095, -0.16786733, -1.0604953 ,  0.22642638,\n",
      "        0.26320764,  0.        ,  0.        ], dtype=float32), action=2, reward=3.5588753395683286, next_state=array([-0.04823713,  0.57421017, -0.18369529, -1.028337  ,  0.23979944,\n",
      "        0.267461  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04823713,  0.57421017, -0.18369529, -1.028337  ,  0.23979944,\n",
      "        0.267461  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6197533889669842, next_state=array([-0.04994259,  0.5505217 , -0.1836901 , -1.0550183 ,  0.25317234,\n",
      "        0.26745772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04994259,  0.5505217 , -0.1836901 , -1.0550183 ,  0.25317234,\n",
      "        0.26745772,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9343630229380995, next_state=array([-0.05156012,  0.5262812 , -0.17249537, -1.0792464 ,  0.2641433 ,\n",
      "        0.21941893,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05156012,  0.5262812 , -0.17249537, -1.0792464 ,  0.2641433 ,\n",
      "        0.21941893,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2773580074344295, next_state=array([-0.05317783,  0.50144225, -0.17249148, -1.1059228 ,  0.27511415,\n",
      "        0.21941726,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05317783,  0.50144225, -0.17249148, -1.1059228 ,  0.27511415,\n",
      "        0.21941726,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.222946633512663, next_state=array([-0.05479603,  0.47600484, -0.17248745, -1.1325991 ,  0.28608492,\n",
      "        0.21941535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05479603,  0.47600484, -0.17248745, -1.1325991 ,  0.28608492,\n",
      "        0.21941535,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1692486757753784, next_state=array([-0.05641432,  0.44996896, -0.17248327, -1.1592755 ,  0.2970556 ,\n",
      "        0.21941352,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05641432,  0.44996896, -0.17248327, -1.1592755 ,  0.2970556 ,\n",
      "        0.21941352,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1164694506610715, next_state=array([-0.05803309,  0.42333472, -0.17247891, -1.185952  ,  0.3080262 ,\n",
      "        0.2194117 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05803309,  0.42333472, -0.17247891, -1.185952  ,  0.3080262 ,\n",
      "        0.2194117 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7870427668487128, next_state=array([-0.05974464,  0.39605242, -0.18417504, -1.2153667 ,  0.32154348,\n",
      "        0.27034557,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05974464,  0.39605242, -0.18417504, -1.2153667 ,  0.32154348,\n",
      "        0.27034557,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.263538558937455, next_state=array([-0.06145658,  0.36817247, -0.18416795, -1.2420478 ,  0.33506054,\n",
      "        0.27034158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06145658,  0.36817247, -0.18416795, -1.2420478 ,  0.33506054,\n",
      "        0.27034158,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.689055880264134, next_state=array([-0.06308756,  0.33972833, -0.1739076 , -1.2667358 ,  0.34639093,\n",
      "        0.22660768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06308756,  0.33972833, -0.1739076 , -1.2667358 ,  0.34639093,\n",
      "        0.22660768,  0.        ,  0.        ], dtype=float32), action=2, reward=4.0338017648291045, next_state=array([-0.06491566,  0.312     , -0.19408002, -1.2351296 ,  0.35824057,\n",
      "        0.23699267,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06491566,  0.312     , -0.19408002, -1.2351296 ,  0.35824057,\n",
      "        0.23699267,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0947696582402955, next_state=array([-0.06674423,  0.28367344, -0.19407395, -1.2618073 ,  0.3700901 ,\n",
      "        0.2369904 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06674423,  0.28367344, -0.19407395, -1.2618073 ,  0.3700901 ,\n",
      "        0.2369904 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.061921658277413, next_state=array([-0.06857319,  0.25474858, -0.19406766, -1.288485  ,  0.3819395 ,\n",
      "        0.2369881 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06857319,  0.25474858, -0.19406766, -1.288485  ,  0.3819395 ,\n",
      "        0.2369881 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5142022180725963, next_state=array([-0.07034121,  0.22527424, -0.1861923 , -1.3125205 ,  0.39195406,\n",
      "        0.2002914 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07034121,  0.22527424, -0.1861923 , -1.3125205 ,  0.39195406,\n",
      "        0.2002914 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.166186486997742, next_state=array([-0.07238922,  0.19655186, -0.21451935, -1.2792699 ,  0.40236425,\n",
      "        0.20820387,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07238922,  0.19655186, -0.21451935, -1.2792699 ,  0.40236425,\n",
      "        0.20820387,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0315159693163594, next_state=array([-0.07443742,  0.16723067, -0.21451406, -1.3059449 ,  0.41277438,\n",
      "        0.20820233,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07443742,  0.16723067, -0.21451406, -1.3059449 ,  0.41277438,\n",
      "        0.20820233,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.38210069232522303, next_state=array([-0.07639809,  0.13736588, -0.20337267, -1.329478  ,  0.42066547,\n",
      "        0.15782198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07639809,  0.13736588, -0.20337267, -1.329478  ,  0.42066547,\n",
      "        0.15782198,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1504306851605122, next_state=array([-0.0786171 ,  0.10755201, -0.22894116, -1.3271774 ,  0.42828497,\n",
      "        0.15239017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0786171 ,  0.10755201, -0.22894116, -1.3271774 ,  0.42828497,\n",
      "        0.15239017,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4552801919160004, next_state=array([-0.08114529,  0.07771805, -0.25931054, -1.3279458 ,  0.43534672,\n",
      "        0.14123495,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08114529,  0.07771805, -0.25931054, -1.3279458 ,  0.43534672,\n",
      "        0.14123495,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.699717097771952, next_state=array([-0.08367357,  0.04728471, -0.25930792, -1.3546163 ,  0.44240844,\n",
      "        0.1412345 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08367357,  0.04728471, -0.25930792, -1.3546163 ,  0.44240844,\n",
      "        0.1412345 ,  0.        ,  0.        ], dtype=float32), action=0, reward=17.087538973703573, next_state=array([-0.08589945,  0.01776803, -0.2105025 , -1.3076545 ,  0.43464804,\n",
      "       -0.14804271,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.08589945,  0.01776803, -0.2105025 , -1.3076545 ,  0.43464804,\n",
      "       -0.14804271,  0.        ,  1.        ], dtype=float32), action=2, reward=2.1530408541809267, next_state=array([-0.08884297, -0.01161599, -0.2687301 , -1.2982953 ,  0.40691012,\n",
      "       -0.5547806 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.08884297, -0.01161599, -0.2687301 , -1.2982953 ,  0.40691012,\n",
      "       -0.5547806 ,  0.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.09244003, -0.02635591, -0.12921888, -0.56392354,  0.18213508,\n",
      "       -4.716083  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00446997,  1.4113772 ,  0.45273763,  0.02031593, -0.0051727 ,\n",
      "       -0.10255171,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7582752291314592, next_state=array([ 0.00900097,  1.4126885 ,  0.4579563 ,  0.05825071, -0.00996975,\n",
      "       -0.09594906,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00900097,  1.4126885 ,  0.4579563 ,  0.05825071, -0.00996975,\n",
      "       -0.09594906,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2954234489116345, next_state=array([ 0.01353226,  1.4133998 ,  0.45797104,  0.03158044, -0.01476399,\n",
      "       -0.09589375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01353226,  1.4133998 ,  0.45797104,  0.03158044, -0.01476399,\n",
      "       -0.09589375,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.342874501014477, next_state=array([ 0.01812487,  1.413504  ,  0.4656724 ,  0.00455168, -0.02110114,\n",
      "       -0.12675475,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01812487,  1.413504  ,  0.4656724 ,  0.00455168, -0.02110114,\n",
      "       -0.12675475,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6009573563951836, next_state=array([ 0.02277937,  1.4130132 ,  0.47343317, -0.02194611, -0.02898721,\n",
      "       -0.15773633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02277937,  1.4130132 ,  0.47343317, -0.02194611, -0.02898721,\n",
      "       -0.15773633,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.097234542479174, next_state=array([ 0.02754908,  1.4125377 ,  0.4844442 , -0.02129876, -0.03637942,\n",
      "       -0.14785784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02754908,  1.4125377 ,  0.4844442 , -0.02129876, -0.03637942,\n",
      "       -0.14785784,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1224598652848554, next_state=array([ 0.03243513,  1.4127889 ,  0.49566945,  0.01097277, -0.04337043,\n",
      "       -0.13983339,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03243513,  1.4127889 ,  0.49566945,  0.01097277, -0.04337043,\n",
      "       -0.13983339,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.690923018272855, next_state=array([ 0.03732147,  1.4124403 ,  0.4956892 , -0.0157077 , -0.05036044,\n",
      "       -0.13981307,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03732147,  1.4124403 ,  0.4956892 , -0.0157077 , -0.05036044,\n",
      "       -0.13981307,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7758688168767094, next_state=array([ 0.04220791,  1.4114926 ,  0.49570984, -0.04237465, -0.05734922,\n",
      "       -0.13978846,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04220791,  1.4114926 ,  0.49570984, -0.04237465, -0.05734922,\n",
      "       -0.13978846,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8593474011319131, next_state=array([ 0.04709463,  1.4099455 ,  0.49572977, -0.0690469 , -0.0643369 ,\n",
      "       -0.13976654,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04709463,  1.4099455 ,  0.49572977, -0.0690469 , -0.0643369 ,\n",
      "       -0.13976654,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9404237672485465, next_state=array([ 0.05198164,  1.4077991 ,  0.49574995, -0.09571945, -0.07132349,\n",
      "       -0.13974461,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05198164,  1.4077991 ,  0.49574995, -0.09571945, -0.07132349,\n",
      "       -0.13974461,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3191421406525763, next_state=array([ 0.05695124,  1.406055  ,  0.5038464 , -0.07786063, -0.07814468,\n",
      "       -0.13643669,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05695124,  1.406055  ,  0.5038464 , -0.07786063, -0.07814468,\n",
      "       -0.13643669,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9457010787202478, next_state=array([ 0.06192112,  1.4037113 ,  0.5038644 , -0.10454144, -0.08496493,\n",
      "       -0.13641754,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06192112,  1.4037113 ,  0.5038644 , -0.10454144, -0.08496493,\n",
      "       -0.13641754,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.03362752259161425, next_state=array([ 0.06682234,  1.4007717 ,  0.49524015, -0.13094433, -0.09004921,\n",
      "       -0.10169443,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06682234,  1.4007717 ,  0.49524015, -0.13094433, -0.09004921,\n",
      "       -0.10169443,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.246386292522742, next_state=array([ 0.07181092,  1.3972172 ,  0.50621116, -0.1584385 , -0.09734859,\n",
      "       -0.14600106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07181092,  1.3972172 ,  0.50621116, -0.1584385 , -0.09734859,\n",
      "       -0.14600106,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2003279024042683, next_state=array([ 0.07679977,  1.3930631 ,  0.5062327 , -0.18511245, -0.10464554,\n",
      "       -0.1459526 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07679977,  1.3930631 ,  0.5062327 , -0.18511245, -0.10464554,\n",
      "       -0.1459526 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.30698675393548913, next_state=array([ 0.08172169,  1.3883256 ,  0.4978001 , -0.21096125, -0.11022451,\n",
      "       -0.11158947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08172169,  1.3883256 ,  0.4978001 , -0.21096125, -0.11022451,\n",
      "       -0.11158947,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1516948822685436, next_state=array([ 0.08664379,  1.3829883 ,  0.49781418, -0.23763353, -0.11580337,\n",
      "       -0.111587  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08664379,  1.3829883 ,  0.49781418, -0.23763353, -0.11580337,\n",
      "       -0.111587  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4025500409014726, next_state=array([ 0.09164762,  1.3770278 ,  0.5081024 , -0.26552522, -0.12347909,\n",
      "       -0.1535284 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09164762,  1.3770278 ,  0.5081024 , -0.26552522, -0.12347909,\n",
      "       -0.1535284 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.18684595918173727, next_state=array([ 0.0965601 ,  1.3704842 ,  0.4965993 , -0.29127914, -0.12881832,\n",
      "       -0.10679469,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0965601 ,  1.3704842 ,  0.4965993 , -0.29127914, -0.12881832,\n",
      "       -0.10679469,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.03163352972165853, next_state=array([ 0.10138007,  1.363354  ,  0.48501092, -0.31715906, -0.13181446,\n",
      "       -0.05992833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10138007,  1.363354  ,  0.48501092, -0.31715906, -0.13181446,\n",
      "       -0.05992833,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.337426338966934, next_state=array([ 0.10629396,  1.3556128 ,  0.4967679 , -0.34454614, -0.13717969,\n",
      "       -0.10731429,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10629396,  1.3556128 ,  0.4967679 , -0.34454614, -0.13717969,\n",
      "       -0.10731429,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.304390640599678, next_state=array([ 0.11120816,  1.3472716 ,  0.49678358, -0.37121865, -0.14254268,\n",
      "       -0.10726924,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11120816,  1.3472716 ,  0.49678358, -0.37121865, -0.14254268,\n",
      "       -0.10726924,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3160820342681052, next_state=array([ 0.11604099,  1.3383391 ,  0.48659152, -0.39732784, -0.14585139,\n",
      "       -0.06618005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11604099,  1.3383391 ,  0.48659152, -0.39732784, -0.14585139,\n",
      "       -0.06618005,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1446548632566476, next_state=array([ 0.12087402,  1.3288064 ,  0.48659903, -0.42399853, -0.14916046,\n",
      "       -0.06618708,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12087402,  1.3288064 ,  0.48659903, -0.42399853, -0.14916046,\n",
      "       -0.06618708,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.07268246586579494, next_state=array([ 0.12561569,  1.3186822 ,  0.47516948, -0.45006236, -0.15015918,\n",
      "       -0.01997438,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12561569,  1.3186822 ,  0.47516948, -0.45006236, -0.15015918,\n",
      "       -0.01997438,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1931304831975342, next_state=array([ 0.13029452,  1.3079739 ,  0.46727285, -0.47586626, -0.14954548,\n",
      "        0.01227376,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13029452,  1.3079739 ,  0.46727285, -0.47586626, -0.14954548,\n",
      "        0.01227376,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7891872297677196, next_state=array([ 0.13497344,  1.2966655 ,  0.46727282, -0.50253296, -0.1489318 ,\n",
      "        0.01227384,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13497344,  1.2966655 ,  0.46727282, -0.50253296, -0.1489318 ,\n",
      "        0.01227384,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5983912101056592, next_state=array([ 0.13972206,  1.2847515 ,  0.47600612, -0.52962446, -0.15007143,\n",
      "       -0.02279247,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13972206,  1.2847515 ,  0.47600612, -0.52962446, -0.15007143,\n",
      "       -0.02279247,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6824175038907458, next_state=array([ 0.14453402,  1.2722278 ,  0.48395413, -0.5568873 , -0.15281849,\n",
      "       -0.05494131,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14453402,  1.2722278 ,  0.48395413, -0.5568873 , -0.15281849,\n",
      "       -0.05494131,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0596318749476552, next_state=array([ 0.14934607,  1.2591043 ,  0.48395404, -0.58355445, -0.15556554,\n",
      "       -0.05494129,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14934607,  1.2591043 ,  0.48395404, -0.58355445, -0.15556554,\n",
      "       -0.05494129,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.40309274626588265, next_state=array([ 0.15409717,  1.245389  ,  0.47631478, -0.6096906 , -0.15677021,\n",
      "       -0.02409363,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15409717,  1.245389  ,  0.47631478, -0.6096906 , -0.15677021,\n",
      "       -0.02409363,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7023483342783539, next_state=array([ 0.15892068,  1.2310605 ,  0.4853972 , -0.6371457 , -0.15981796,\n",
      "       -0.06095476,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15892068,  1.2310605 ,  0.4853972 , -0.6371457 , -0.15981796,\n",
      "       -0.06095476,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9003274479544645, next_state=array([ 0.16372652,  1.2176695 ,  0.48446727, -0.5955816 , -0.16369988,\n",
      "       -0.07763825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16372652,  1.2176695 ,  0.48446727, -0.5955816 , -0.16369988,\n",
      "       -0.07763825,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9716492415120956, next_state=array([ 0.16860208,  1.2036636 ,  0.4932228 , -0.6231261 , -0.16936581,\n",
      "       -0.11331838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16860208,  1.2036636 ,  0.4932228 , -0.6231261 , -0.16936581,\n",
      "       -0.11331838,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.041217355103838, next_state=array([ 0.17354241,  1.1890457 ,  0.5013148 , -0.65052354, -0.17667554,\n",
      "       -0.1461943 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17354241,  1.1890457 ,  0.5013148 , -0.65052354, -0.17667554,\n",
      "       -0.1461943 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3828801406884395, next_state=array([ 0.17880812,  1.1750108 ,  0.53302085, -0.6245578 , -0.18314305,\n",
      "       -0.12935005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17880812,  1.1750108 ,  0.53302085, -0.6245578 , -0.18314305,\n",
      "       -0.12935005,  0.        ,  0.        ], dtype=float32), action=2, reward=0.19251033405658974, next_state=array([ 0.18428259,  1.1613297 ,  0.55347234, -0.6088072 , -0.1891963 ,\n",
      "       -0.12106524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18428259,  1.1613297 ,  0.55347234, -0.6088072 , -0.1891963 ,\n",
      "       -0.12106524,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6076890833561095, next_state=array([ 0.18999843,  1.147831  ,  0.57696384, -0.6006456 , -0.19460608,\n",
      "       -0.10819553,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18999843,  1.147831  ,  0.57696384, -0.6006456 , -0.19460608,\n",
      "       -0.10819553,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9623292928787908, next_state=array([ 0.19577341,  1.1337116 ,  0.58441013, -0.6284542 , -0.2015624 ,\n",
      "       -0.13912642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19577341,  1.1337116 ,  0.58441013, -0.6284542 , -0.2015624 ,\n",
      "       -0.13912642,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3626989556643536, next_state=array([ 0.20159808,  1.1200695 ,  0.5898011 , -0.60733026, -0.2089583 ,\n",
      "       -0.14791776,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20159808,  1.1200695 ,  0.5898011 , -0.60733026, -0.2089583 ,\n",
      "       -0.14791776,  0.        ,  0.        ], dtype=float32), action=2, reward=0.23541660772054912, next_state=array([ 0.20764942,  1.1069553 ,  0.61215496, -0.58386415, -0.21604922,\n",
      "       -0.14181897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20764942,  1.1069553 ,  0.61215496, -0.58386415, -0.21604922,\n",
      "       -0.14181897,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5370852276248557, next_state=array([ 0.21378918,  1.093204  ,  0.62331635, -0.6125637 , -0.22548816,\n",
      "       -0.1887793 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21378918,  1.093204  ,  0.62331635, -0.6125637 , -0.22548816,\n",
      "       -0.1887793 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2538274084495072, next_state=array([ 0.22005758,  1.0798639 ,  0.6362617 , -0.59437054, -0.23504429,\n",
      "       -0.19112264,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22005758,  1.0798639 ,  0.6362617 , -0.59437054, -0.23504429,\n",
      "       -0.19112264,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.31978389258616174, next_state=array([ 0.22636032,  1.066546  ,  0.6399612 , -0.5934855 , -0.24489252,\n",
      "       -0.19696455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22636032,  1.066546  ,  0.6399612 , -0.5934855 , -0.24489252,\n",
      "       -0.19696455,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5932107156814936, next_state=array([ 0.23266315,  1.0526295 ,  0.63995826, -0.62016   , -0.2547407 ,\n",
      "       -0.19696324,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23266315,  1.0526295 ,  0.63995826, -0.62016   , -0.2547407 ,\n",
      "       -0.19696324,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5573428826423583, next_state=array([ 0.23888198,  1.0381364 ,  0.629384  , -0.64546   , -0.2624094 ,\n",
      "       -0.1533741 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23888198,  1.0381364 ,  0.629384  , -0.64546   , -0.2624094 ,\n",
      "       -0.1533741 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3680431201332794, next_state=array([ 0.24510078,  1.023044  ,  0.6293821 , -0.67213136, -0.27007806,\n",
      "       -0.15337346,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24510078,  1.023044  ,  0.6293821 , -0.67213136, -0.27007806,\n",
      "       -0.15337346,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4599954910526083, next_state=array([ 0.25125074,  1.0073911 ,  0.62063414, -0.69674015, -0.2758505 ,\n",
      "       -0.11544921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25125074,  1.0073911 ,  0.62063414, -0.69674015, -0.2758505 ,\n",
      "       -0.11544921,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.279668020197106, next_state=array([ 0.25749007,  0.991111  ,  0.63180566, -0.72506523, -0.28394604,\n",
      "       -0.16191027,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25749007,  0.991111  ,  0.63180566, -0.72506523, -0.28394604,\n",
      "       -0.16191027,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.46746782699440703, next_state=array([ 0.2636589 ,  0.97427076,  0.62286735, -0.7496303 , -0.2901004 ,\n",
      "       -0.12308693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2636589 ,  0.97427076,  0.62286735, -0.7496303 , -0.2901004 ,\n",
      "       -0.12308693,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2885925880388798, next_state=array([ 0.2699172 ,  0.9567978 ,  0.6341046 , -0.7782486 , -0.29862183,\n",
      "       -0.1704288 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2699172 ,  0.9567978 ,  0.6341046 , -0.7782486 , -0.29862183,\n",
      "       -0.1704288 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.31531894193650944, next_state=array([ 0.27608785,  0.938763  ,  0.62302864, -0.8027845 , -0.30478635,\n",
      "       -0.12329043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27608785,  0.938763  ,  0.62302864, -0.8027845 , -0.30478635,\n",
      "       -0.12329043,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1290201737112966, next_state=array([ 0.2822586 ,  0.9201286 ,  0.6230272 , -0.8294542 , -0.31095085,\n",
      "       -0.12329011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2822586 ,  0.9201286 ,  0.6230272 , -0.8294542 , -0.31095085,\n",
      "       -0.12329011,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9165553757534155, next_state=array([ 0.2884881 ,  0.9019999 ,  0.62964004, -0.8071689 , -0.31789958,\n",
      "       -0.1389739 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2884881 ,  0.9019999 ,  0.62964004, -0.8071689 , -0.31789958,\n",
      "       -0.1389739 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3646487136991083, next_state=array([ 0.29494667,  0.8845627 ,  0.6527613 , -0.77652663, -0.3250856 ,\n",
      "       -0.14372054,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29494667,  0.8845627 ,  0.6527613 , -0.77652663, -0.3250856 ,\n",
      "       -0.14372054,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3353466660679192, next_state=array([ 0.30133182,  0.8665681 ,  0.643444  , -0.8008701 , -0.33022285,\n",
      "       -0.10274418,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30133182,  0.8665681 ,  0.643444  , -0.8008701 , -0.33022285,\n",
      "       -0.10274418,  0.        ,  0.        ], dtype=float32), action=2, reward=2.406374755073739, next_state=array([ 0.30791777,  0.8495268 ,  0.6641604 , -0.7586754 , -0.33603352,\n",
      "       -0.11621416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30791777,  0.8495268 ,  0.6641604 , -0.7586754 , -0.33603352,\n",
      "       -0.11621416,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9098907089890418, next_state=array([ 0.3148757 ,  0.8327946 ,  0.7006694 , -0.744801  , -0.341144  ,\n",
      "       -0.10220967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3148757 ,  0.8327946 ,  0.7006694 , -0.744801  , -0.341144  ,\n",
      "       -0.10220967,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1205689429935135, next_state=array([ 0.3219041 ,  0.815417  ,  0.7096251 , -0.77396643, -0.3482607 ,\n",
      "       -0.14233357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3219041 ,  0.815417  ,  0.7096251 , -0.77396643, -0.3482607 ,\n",
      "       -0.14233357,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.288503827691585, next_state=array([ 0.32893258,  0.79743993,  0.709623  , -0.80063707, -0.35537735,\n",
      "       -0.14233306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32893258,  0.79743993,  0.709623  , -0.80063707, -0.35537735,\n",
      "       -0.14233306,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2078490049135824, next_state=array([ 0.33602476,  0.77881896,  0.7177192 , -0.82973033, -0.36433318,\n",
      "       -0.179117  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33602476,  0.77881896,  0.7177192 , -0.82973033, -0.36433318,\n",
      "       -0.179117  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2548630360049047, next_state=array([ 0.3431738 ,  0.7595637 ,  0.7248771 , -0.85836166, -0.37489277,\n",
      "       -0.21119177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3431738 ,  0.7595637 ,  0.7248771 , -0.85836166, -0.37489277,\n",
      "       -0.21119177,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5704687351777964, next_state=array([ 0.35038853,  0.73965853,  0.73321927, -0.8878001 , -0.38739046,\n",
      "       -0.24995363,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35038853,  0.73965853,  0.73321927, -0.8878001 , -0.38739046,\n",
      "       -0.24995363,  0.        ,  0.        ], dtype=float32), action=2, reward=1.08537341978315, next_state=array([ 0.357771  ,  0.72048455,  0.7507238 , -0.8556275 , -0.40071884,\n",
      "       -0.26656732,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.357771  ,  0.72048455,  0.7507238 , -0.8556275 , -0.40071884,\n",
      "       -0.26656732,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1371450112108892, next_state=array([ 0.3650915 ,  0.7007425 ,  0.7428509 , -0.8805183 , -0.41233346,\n",
      "       -0.23229174,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3650915 ,  0.7007425 ,  0.7428509 , -0.8805183 , -0.41233346,\n",
      "       -0.23229174,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.671988301777246, next_state=array([ 0.37248087,  0.68037045,  0.7513984 , -0.9091204 , -0.42580855,\n",
      "       -0.26950175,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37248087,  0.68037045,  0.7513984 , -0.9091204 , -0.42580855,\n",
      "       -0.26950175,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9489892977240402, next_state=array([ 0.3798708 ,  0.6594006 ,  0.751389  , -0.93580097, -0.43928346,\n",
      "       -0.26949835,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3798708 ,  0.6594006 ,  0.751389  , -0.93580097, -0.43928346,\n",
      "       -0.26949835,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7594325894114307, next_state=array([ 0.3873147 ,  0.63778955,  0.7581924 , -0.9648889 , -0.45438007,\n",
      "       -0.30193198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3873147 ,  0.63778955,  0.7581924 , -0.9648889 , -0.45438007,\n",
      "       -0.30193198,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.127994988076381, next_state=array([ 0.39475948,  0.6155813 ,  0.75818   , -0.9915727 , -0.46947643,\n",
      "       -0.30192727,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39475948,  0.6155813 ,  0.75818   , -0.9915727 , -0.46947643,\n",
      "       -0.30192727,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1660314552740931, next_state=array([ 0.4021283 ,  0.59282064,  0.7485123 , -1.015573  , -0.48239002,\n",
      "       -0.25827155,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4021283 ,  0.59282064,  0.7485123 , -1.015573  , -0.48239002,\n",
      "       -0.25827155,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.043582198820927, next_state=array([ 0.4095686 ,  0.56939495,  0.75760734, -1.0459594 , -0.49756882,\n",
      "       -0.3035759 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4095686 ,  0.56939495,  0.75760734, -1.0459594 , -0.49756882,\n",
      "       -0.3035759 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8383749991325147, next_state=array([ 0.41710034,  0.54602486,  0.76716447, -1.0438161 , -0.5133404 ,\n",
      "       -0.31543294,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41710034,  0.54602486,  0.76716447, -1.0438161 , -0.5133404 ,\n",
      "       -0.31543294,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3199469879297965, next_state=array([ 0.42463312,  0.5220579 ,  0.7671493 , -1.0705009 , -0.52911174,\n",
      "       -0.31542748,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42463312,  0.5220579 ,  0.7671493 , -1.0705009 , -0.52911174,\n",
      "       -0.31542748,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.474930521940762, next_state=array([ 0.4322401 ,  0.49742532,  0.77646315, -1.1010433 , -0.54723144,\n",
      "       -0.36239427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4322401 ,  0.49742532,  0.77646315, -1.1010433 , -0.54723144,\n",
      "       -0.36239427,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.855708001945884, next_state=array([ 0.439927  ,  0.4721185 ,  0.78649795, -1.1321329 , -0.56793535,\n",
      "       -0.4140795 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.439927  ,  0.4721185 ,  0.78649795, -1.1321329 , -0.56793535,\n",
      "       -0.4140795 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.8214476703247144, next_state=array([ 0.44767112,  0.44615966,  0.7935565 , -1.1620483 , -0.59048927,\n",
      "       -0.45107841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44767112,  0.44615966,  0.7935565 , -1.1620483 , -0.59048927,\n",
      "       -0.45107841,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.440180889632841, next_state=array([ 0.45549887,  0.41952726,  0.8038505 , -1.1933064 , -0.6157187 ,\n",
      "       -0.50458926,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45549887,  0.41952726,  0.8038505 , -1.1933064 , -0.6157187 ,\n",
      "       -0.50458926,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.214711393961056, next_state=array([ 0.46368274,  0.39333767,  0.83950377, -1.1741871 , -0.6414589 ,\n",
      "       -0.51480454,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46368274,  0.39333767,  0.83950377, -1.1741871 , -0.6414589 ,\n",
      "       -0.51480454,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.551718490311287, next_state=array([ 0.47192526,  0.36650464,  0.8463877 , -1.2038833 , -0.6689846 ,\n",
      "       -0.5505138 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47192526,  0.36650464,  0.8463877 , -1.2038833 , -0.6689846 ,\n",
      "       -0.5505138 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.9257321991862275, next_state=array([ 0.4802228 ,  0.3390054 ,  0.85298526, -1.2347698 , -0.69853157,\n",
      "       -0.59094006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4802228 ,  0.3390054 ,  0.85298526, -1.2347698 , -0.69853157,\n",
      "       -0.59094006,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.281682358325895, next_state=array([ 0.4885254 ,  0.31091517,  0.85291594, -1.2614932 , -0.7280768 ,\n",
      "       -0.5909046 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4885254 ,  0.31091517,  0.85291594, -1.2614932 , -0.7280768 ,\n",
      "       -0.5909046 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-5.43610479272101, next_state=array([ 0.49689618,  0.2821648 ,  0.860789  , -1.2922881 , -0.759831  ,\n",
      "       -0.63508385,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49689618,  0.2821648 ,  0.860789  , -1.2922881 , -0.759831  ,\n",
      "       -0.63508385,  0.        ,  0.        ], dtype=float32), action=3, reward=-5.689435938114314, next_state=array([ 0.5053212 ,  0.25275022,  0.8669468 , -1.32327   , -0.7935959 ,\n",
      "       -0.6752982 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5053212 ,  0.25275022,  0.8669468 , -1.32327   , -0.7935959 ,\n",
      "       -0.6752982 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.332241311305636, next_state=array([ 0.51370823,  0.22280961,  0.861067  , -1.3462917 , -0.82554716,\n",
      "       -0.639025  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51370823,  0.22280961,  0.861067  , -1.3462917 , -0.82554716,\n",
      "       -0.639025  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.078920865386112, next_state=array([ 0.522755  ,  0.19338599,  0.92660886, -1.3240167 , -0.85795665,\n",
      "       -0.6481901 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.522755  ,  0.19338599,  0.92660886, -1.3240167 , -0.85795665,\n",
      "       -0.6481901 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.544118031691055, next_state=array([ 0.5317742 ,  0.16344817,  0.9218353 , -1.3463567 , -0.8884984 ,\n",
      "       -0.61083543,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5317742 ,  0.16344817,  0.9218353 , -1.3463567 , -0.8884984 ,\n",
      "       -0.61083543,  0.        ,  0.        ], dtype=float32), action=2, reward=-7.183256193671798, next_state=array([ 0.5414177 ,  0.13345522,  0.9831964 , -1.348929  , -0.9185213 ,\n",
      "       -0.6004573 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5414177 ,  0.13345522,  0.9831964 , -1.348929  , -0.9185213 ,\n",
      "       -0.6004573 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-6.699204825830377, next_state=array([ 0.5511209 ,  0.1027593 ,  0.99009895, -1.3820626 , -0.9513186 ,\n",
      "       -0.65594757,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5511209 ,  0.1027593 ,  0.99009895, -1.3820626 , -0.9513186 ,\n",
      "       -0.65594757,  0.        ,  0.        ], dtype=float32), action=2, reward=-8.191441334451145, next_state=array([ 0.5612725 ,  0.07161248,  1.0335944 , -1.4020574 , -0.9832833 ,\n",
      "       -0.6392937 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5612725 ,  0.07161248,  1.0335944 , -1.4020574 , -0.9832833 ,\n",
      "       -0.6392937 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-6.895607177142295, next_state=array([ 0.57146704,  0.03979805,  1.038038  , -1.4332019 , -1.0171424 ,\n",
      "       -0.677183  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.57146704,  0.03979805,  1.038038  , -1.4332019 , -1.0171424 ,\n",
      "       -0.677183  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-7.655460239830659, next_state=array([ 0.5817149 ,  0.00727402,  1.043814  , -1.4667974 , -1.0538284 ,\n",
      "       -0.73371893,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5817149 ,  0.00727402,  1.043814  , -1.4667974 , -1.0538284 ,\n",
      "       -0.73371893,  0.        ,  0.        ], dtype=float32), action=3, reward=2.0841828272877776, next_state=array([ 0.59200525, -0.02594117,  1.047979  , -1.4993676 , -1.0928563 ,\n",
      "       -0.7805605 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.59200525, -0.02594117,  1.047979  , -1.4993676 , -1.0928563 ,\n",
      "       -0.7805605 ,  1.        ,  0.        ], dtype=float32), action=1, reward=31.636983586486252, next_state=array([ 0.6042404 , -0.03411493,  1.2662208 , -0.50893867, -1.2281904 ,\n",
      "       -2.4832616 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6042404 , -0.03411493,  1.2662208 , -0.50893867, -1.2281904 ,\n",
      "       -2.4832616 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-14.668912668551457, next_state=array([ 0.6165644 , -0.0441568 ,  1.2648222 , -0.53491795, -1.3533268 ,\n",
      "       -2.4834895 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6165644 , -0.0441568 ,  1.2648222 , -0.53491795, -1.3533268 ,\n",
      "       -2.4834895 ,  1.        ,  0.        ], dtype=float32), action=1, reward=-15.604878377886306, next_state=array([ 0.6291443 , -0.05343195,  1.260159  , -0.5549516 , -1.4921523 ,\n",
      "       -2.4315526 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6291443 , -0.05343195,  1.260159  , -0.5549516 , -1.4921523 ,\n",
      "       -2.4315526 ,  1.        ,  0.        ], dtype=float32), action=1, reward=-15.154267324020706, next_state=array([ 0.64186823, -0.06349492,  1.257323  , -0.57344955, -1.6248251 ,\n",
      "       -2.3662305 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.64186823, -0.06349492,  1.257323  , -0.57344955, -1.6248251 ,\n",
      "       -2.3662305 ,  1.        ,  0.        ], dtype=float32), action=2, reward=-23.08593003527061, next_state=array([ 0.65557116, -0.07497592,  1.3495904 , -0.5976145 , -1.7437749 ,\n",
      "       -2.3704045 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.65557116, -0.07497592,  1.3495904 , -0.5976145 , -1.7437749 ,\n",
      "       -2.3704045 ,  1.        ,  0.        ], dtype=float32), action=2, reward=-22.73420620860809, next_state=array([ 0.6702162 , -0.08738436,  1.4289917 , -0.63737077, -1.8633684 ,\n",
      "       -2.3617015 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6702162 , -0.08738436,  1.4289917 , -0.63737077, -1.8633684 ,\n",
      "       -2.3617015 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-14.53365286518624, next_state=array([ 0.68497294, -0.10046528,  1.4272631 , -0.6633791 , -1.9830866 ,\n",
      "       -2.3602078 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.68497294, -0.10046528,  1.4272631 , -0.6633791 , -1.9830866 ,\n",
      "       -2.3602078 ,  1.        ,  0.        ], dtype=float32), action=3, reward=-14.816084008195814, next_state=array([ 0.6998213 , -0.11432114,  1.4228953 , -0.6942682 , -2.1048114 ,\n",
      "       -2.3963773 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6998213 , -0.11432114,  1.4228953 , -0.6942682 , -2.1048114 ,\n",
      "       -2.3963773 ,  1.        ,  0.        ], dtype=float32), action=3, reward=-25.470765194423308, next_state=array([ 0.71490175, -0.12782405,  1.4227349 , -0.68406105, -2.2466712 ,\n",
      "       -2.8016994 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.71490175, -0.12782405,  1.4227349 , -0.68406105, -2.2466712 ,\n",
      "       -2.8016994 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.73068124, -0.13146332,  1.5355135 , -0.15523484, -2.3117108 ,\n",
      "       -1.2451668 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00502958,  1.4132881 , -0.509465  ,  0.10523459,  0.00583488,\n",
      "        0.11540119,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.22568711668853325, next_state=array([-0.01005964,  1.4150786 , -0.5087757 ,  0.07954894,  0.01153737,\n",
      "        0.11406066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01005964,  1.4150786 , -0.5087757 ,  0.07954894,  0.01153737,\n",
      "        0.11406066,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9086773359163101, next_state=array([-0.01500368,  1.4162784 , -0.4979592 ,  0.05328646,  0.01506214,\n",
      "        0.07050198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01500368,  1.4162784 , -0.4979592 ,  0.05328646,  0.01506214,\n",
      "        0.07050198,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.20627210810309293, next_state=array([-0.01994782,  1.416878  , -0.4979682 ,  0.02661419,  0.01858751,\n",
      "        0.07051375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01994782,  1.416878  , -0.4979682 ,  0.02661419,  0.01858751,\n",
      "        0.07051375,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.85802149078778, next_state=array([-0.02507296,  1.4184282 , -0.5152978 ,  0.06886201,  0.02133657,\n",
      "        0.05498637,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02507296,  1.4184282 , -0.5152978 ,  0.06886201,  0.02133657,\n",
      "        0.05498637,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.09490658354189918, next_state=array([-0.03019819,  1.4193783 , -0.51530534,  0.04218042,  0.02408585,\n",
      "        0.05499085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03019819,  1.4193783 , -0.51530534,  0.04218042,  0.02408585,\n",
      "        0.05499085,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.1735407793005379, next_state=array([-0.03532352,  1.4197284 , -0.51531374,  0.0155178 ,  0.02683439,\n",
      "        0.05497582,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03532352,  1.4197284 , -0.51531374,  0.0155178 ,  0.02683439,\n",
      "        0.05497582,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.253026873892793, next_state=array([-0.04044895,  1.4194787 , -0.5153218 , -0.0111511 ,  0.0295825 ,\n",
      "        0.05496722,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04044895,  1.4194787 , -0.5153218 , -0.0111511 ,  0.0295825 ,\n",
      "        0.05496722,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.0210899415860863, next_state=array([-0.04573412,  1.4191812 , -0.53058463, -0.01326256,  0.03162234,\n",
      "        0.04080085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04573412,  1.4191812 , -0.53058463, -0.01326256,  0.03162234,\n",
      "        0.04080085,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.394438118150673, next_state=array([-0.05109224,  1.4182718 , -0.53972524, -0.04051328,  0.03549968,\n",
      "        0.07755424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05109224,  1.4182718 , -0.53972524, -0.04051328,  0.03549968,\n",
      "        0.07755424,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5229387558527776, next_state=array([-0.05645046,  1.4167622 , -0.5397377 , -0.0671808 ,  0.03937538,\n",
      "        0.07752071,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05645046,  1.4167622 , -0.5397377 , -0.0671808 ,  0.03937538,\n",
      "        0.07752071,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6547132641974815, next_state=array([-0.06187849,  1.4146601 , -0.54847616, -0.09358917,  0.04499511,\n",
      "        0.11240474,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06187849,  1.4146601 , -0.54847616, -0.09358917,  0.04499511,\n",
      "        0.11240474,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8286435878131897, next_state=array([-0.06730671,  1.4119585 , -0.5484938 , -0.12026059,  0.05061323,\n",
      "        0.11237261,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06730671,  1.4119585 , -0.5484938 , -0.12026059,  0.05061323,\n",
      "        0.11237261,  0.        ,  0.        ], dtype=float32), action=3, reward=0.06542675185974758, next_state=array([-0.07266855,  1.4086668 , -0.5401579 , -0.14643258,  0.05454936,\n",
      "        0.07872936,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07266855,  1.4086668 , -0.5401579 , -0.14643258,  0.05454936,\n",
      "        0.07872936,  0.        ,  0.        ], dtype=float32), action=2, reward=0.91754431258978, next_state=array([-0.07792626,  1.4058092 , -0.5304114 , -0.12719075,  0.0591528 ,\n",
      "        0.09207703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07792626,  1.4058092 , -0.5304114 , -0.12719075,  0.0591528 ,\n",
      "        0.09207703,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8293778434148749, next_state=array([-0.08318405,  1.4023513 , -0.53042406, -0.15386958,  0.06375463,\n",
      "        0.09204496,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08318405,  1.4023513 , -0.53042406, -0.15386958,  0.06375463,\n",
      "        0.09204496,  0.        ,  0.        ], dtype=float32), action=2, reward=0.18323004290804762, next_state=array([-0.08846702,  1.399825  , -0.5331308 , -0.11248741,  0.06854334,\n",
      "        0.0957828 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08846702,  1.399825  , -0.5331308 , -0.11248741,  0.06854334,\n",
      "        0.0957828 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1956576052839012, next_state=array([-0.09383278,  1.3974675 , -0.54117227, -0.10499158,  0.07310939,\n",
      "        0.09132928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09383278,  1.3974675 , -0.54117227, -0.10499158,  0.07310939,\n",
      "        0.09132928,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7693106167436099, next_state=array([-0.09919854,  1.3945104 , -0.5411846 , -0.13166271,  0.07767504,\n",
      "        0.09132113,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09919854,  1.3945104 , -0.5411846 , -0.13166271,  0.07767504,\n",
      "        0.09132113,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2208123133751756, next_state=array([-0.10465746,  1.3909514 , -0.5528443 , -0.15855409,  0.08457296,\n",
      "        0.13797109,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10465746,  1.3909514 , -0.5528443 , -0.15855409,  0.08457296,\n",
      "        0.13797109,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4240651367135784, next_state=array([-0.11020317,  1.3867735 , -0.5637472 , -0.1862257 ,  0.09367342,\n",
      "        0.18202582,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11020317,  1.3867735 , -0.5637472 , -0.1862257 ,  0.09367342,\n",
      "        0.18202582,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2412905648132153, next_state=array([-0.11589555,  1.3834217 , -0.5781375 , -0.14955007,  0.10250665,\n",
      "        0.17668067,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11589555,  1.3834217 , -0.5781375 , -0.14955007,  0.10250665,\n",
      "        0.17668067,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4837904965538769, next_state=array([-0.12149429,  1.3807693 , -0.569602  , -0.11857535,  0.1121859 ,\n",
      "        0.19360197,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12149429,  1.3807693 , -0.569602  , -0.11857535,  0.1121859 ,\n",
      "        0.19360197,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2984916640836843, next_state=array([-0.12709332,  1.3775182 , -0.56962746, -0.14525819,  0.12186279,\n",
      "        0.19355503,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12709332,  1.3775182 , -0.56962746, -0.14525819,  0.12186279,\n",
      "        0.19355503,  0.        ,  0.        ], dtype=float32), action=3, reward=0.012699114980194964, next_state=array([-0.13259725,  1.3736742 , -0.557702  , -0.17145327,  0.12914036,\n",
      "        0.14556451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13259725,  1.3736742 , -0.557702  , -0.17145327,  0.12914036,\n",
      "        0.14556451,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6870652234591887, next_state=array([-0.13814573,  1.3702549 , -0.562363  , -0.1526404 ,  0.13662045,\n",
      "        0.14960158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13814573,  1.3702549 , -0.562363  , -0.1526404 ,  0.13662045,\n",
      "        0.14960158,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1598193166417161, next_state=array([-0.14369431,  1.3662363 , -0.5623621 , -0.17931172,  0.1441005 ,\n",
      "        0.14960097,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14369431,  1.3662363 , -0.5623621 , -0.17931172,  0.1441005 ,\n",
      "        0.14960097,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.3006337148756186, next_state=array([-0.14947662,  1.3626766 , -0.58511645, -0.1588916 ,  0.15097925,\n",
      "        0.13757515,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14947662,  1.3626766 , -0.58511645, -0.1588916 ,  0.15097925,\n",
      "        0.13757515,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.561921388656674, next_state=array([-0.15549994,  1.3594635 , -0.60855424, -0.14345434,  0.15719382,\n",
      "        0.12429136,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15549994,  1.3594635 , -0.60855424, -0.14345434,  0.15719382,\n",
      "        0.12429136,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1235978291034017, next_state=array([-0.16159754,  1.3556322 , -0.61787987, -0.17115669,  0.16531418,\n",
      "        0.16240725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16159754,  1.3556322 , -0.61787987, -0.17115669,  0.16531418,\n",
      "        0.16240725,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8286707672363776, next_state=array([-0.1677988 ,  1.3517439 , -0.6280409 , -0.1737144 ,  0.17323658,\n",
      "        0.158448  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1677988 ,  1.3517439 , -0.6280409 , -0.1737144 ,  0.17323658,\n",
      "        0.158448  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.8297117632069044, next_state=array([-0.17428493,  1.3484576 , -0.6558479 , -0.14691529,  0.18049978,\n",
      "        0.14526372,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17428493,  1.3484576 , -0.6558479 , -0.14691529,  0.18049978,\n",
      "        0.14526372,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.058720091598076, next_state=array([-0.18077107,  1.3445722 , -0.6558467 , -0.1735863 ,  0.18776296,\n",
      "        0.14526324,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18077107,  1.3445722 , -0.6558467 , -0.1735863 ,  0.18776296,\n",
      "        0.14526324,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.354601851196054, next_state=array([-0.18726692,  1.3413205 , -0.65747166, -0.1455378 ,  0.19569148,\n",
      "        0.15857074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18726692,  1.3413205 , -0.65747166, -0.1455378 ,  0.19569148,\n",
      "        0.15857074,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.3510824978647404, next_state=array([-0.1939516 ,  1.3384595 , -0.6760787 , -0.12818734,  0.20335664,\n",
      "        0.15330347,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1939516 ,  1.3384595 , -0.6760787 , -0.12818734,  0.20335664,\n",
      "        0.15330347,  0.        ,  0.        ], dtype=float32), action=3, reward=0.1814754127821925, next_state=array([-0.20055299,  1.33503   , -0.66556346, -0.15318045,  0.20883144,\n",
      "        0.10949607,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20055299,  1.33503   , -0.66556346, -0.15318045,  0.20883144,\n",
      "        0.10949607,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.973201851006354, next_state=array([-0.20725498,  1.3325682 , -0.6761641 , -0.11026128,  0.2148523 ,\n",
      "        0.12041698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20725498,  1.3325682 , -0.6761641 , -0.11026128,  0.2148523 ,\n",
      "        0.12041698,  0.        ,  0.        ], dtype=float32), action=3, reward=0.18806478784617411, next_state=array([-0.21388379,  1.3295203 , -0.66699463, -0.13606578,  0.21900973,\n",
      "        0.08314871,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21388379,  1.3295203 , -0.66699463, -0.13606578,  0.21900973,\n",
      "        0.08314871,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7455182013039803, next_state=array([-0.22051263,  1.3258727 , -0.6669941 , -0.16273385,  0.22316715,\n",
      "        0.08314847,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22051263,  1.3258727 , -0.6669941 , -0.16273385,  0.22316715,\n",
      "        0.08314847,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8220935057825034, next_state=array([-0.22720838,  1.3216093 , -0.67537254, -0.19037773,  0.22904246,\n",
      "        0.11750595,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22720838,  1.3216093 , -0.67537254, -0.19037773,  0.22904246,\n",
      "        0.11750595,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.0073874605436854, next_state=array([-0.23422027,  1.3178473 , -0.70633775, -0.16800256,  0.23426405,\n",
      "        0.10443194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23422027,  1.3178473 , -0.70633775, -0.16800256,  0.23426405,\n",
      "        0.10443194,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.01866549005589377, next_state=array([-0.24117503,  1.313515  , -0.69909346, -0.19313273,  0.2379395 ,\n",
      "        0.07350922,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24117503,  1.313515  , -0.69909346, -0.19313273,  0.2379395 ,\n",
      "        0.07350922,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1591574465862196, next_state=array([-0.24822068,  1.3085594 , -0.71049035, -0.22121328,  0.24395879,\n",
      "        0.12038517,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24822068,  1.3085594 , -0.71049035, -0.22121328,  0.24395879,\n",
      "        0.12038517,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.087819728220114, next_state=array([-0.2555534 ,  1.3036468 , -0.7383893 , -0.2191894 ,  0.24916816,\n",
      "        0.10418759,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2555534 ,  1.3036468 , -0.7383893 , -0.2191894 ,  0.24916816,\n",
      "        0.10418759,  0.        ,  0.        ], dtype=float32), action=3, reward=0.26353807176795496, next_state=array([-0.26280552,  1.2981606 , -0.7282577 , -0.2443579 ,  0.25227165,\n",
      "        0.06206992,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26280552,  1.2981606 , -0.7282577 , -0.2443579 ,  0.25227165,\n",
      "        0.06206992,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1718843501878085, next_state=array([-0.27014834,  1.2920334 , -0.7397069 , -0.27325836,  0.25780624,\n",
      "        0.11069153,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27014834,  1.2920334 , -0.7397069 , -0.27325836,  0.25780624,\n",
      "        0.11069153,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.8202939255522663, next_state=array([-0.27785787,  1.2866149 , -0.77576923, -0.24168137,  0.26272866,\n",
      "        0.09844865,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27785787,  1.2866149 , -0.77576923, -0.24168137,  0.26272866,\n",
      "        0.09844865,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0721013567320186, next_state=array([-0.28564277,  1.2805711 , -0.7852306 , -0.269838  ,  0.26962692,\n",
      "        0.13796502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28564277,  1.2805711 , -0.7852306 , -0.269838  ,  0.26962692,\n",
      "        0.13796502,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.1276269998969599, next_state=array([-0.29336104,  1.273957  , -0.7768203 , -0.2948908 ,  0.27473912,\n",
      "        0.10224465,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29336104,  1.273957  , -0.7768203 , -0.2948908 ,  0.27473912,\n",
      "        0.10224465,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9680154356740047, next_state=array([-0.30107945,  1.2667431 , -0.77681935, -0.32155955,  0.27985138,\n",
      "        0.10224448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30107945,  1.2667431 , -0.77681935, -0.32155955,  0.27985138,\n",
      "        0.10224448,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.988468739220906, next_state=array([-0.30879793,  1.2589296 , -0.77681845, -0.34822834,  0.28496358,\n",
      "        0.10224428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30879793,  1.2589296 , -0.77681845, -0.34822834,  0.28496358,\n",
      "        0.10224428,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2360142762953488, next_state=array([-0.3165936 ,  1.2504711 , -0.78661174, -0.37732446,  0.2922162 ,\n",
      "        0.14505279,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3165936 ,  1.2504711 , -0.78661174, -0.37732446,  0.2922162 ,\n",
      "        0.14505279,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3190739388864174, next_state=array([-0.32446057,  1.2413845 , -0.7955581 , -0.40565345,  0.3013653 ,\n",
      "        0.18298157,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32446057,  1.2413845 , -0.7955581 , -0.40565345,  0.3013653 ,\n",
      "        0.18298157,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.769447157022738, next_state=array([-0.3324131 ,  1.2316492 , -0.80638933, -0.43502572,  0.3128892 ,\n",
      "        0.23047826,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3324131 ,  1.2316492 , -0.80638933, -0.43502572,  0.3128892 ,\n",
      "        0.23047826,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6620398394573215, next_state=array([-0.34036604,  1.2213156 , -0.8063844 , -0.46170297,  0.32441303,\n",
      "        0.23047619,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34036604,  1.2213156 , -0.8063844 , -0.46170297,  0.32441303,\n",
      "        0.23047619,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5784582850839672, next_state=array([-0.34824246,  1.2104142 , -0.79672873, -0.48657656,  0.3338879 ,\n",
      "        0.1894974 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34824246,  1.2104142 , -0.79672873, -0.48657656,  0.3338879 ,\n",
      "        0.1894974 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4819716969847434, next_state=array([-0.35611916,  1.1989138 , -0.79672503, -0.51325035,  0.34336272,\n",
      "        0.1894962 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35611916,  1.1989138 , -0.79672503, -0.51325035,  0.34336272,\n",
      "        0.1894962 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4871515206422146, next_state=array([-0.36399618,  1.1868147 , -0.7967213 , -0.539924  ,  0.35283747,\n",
      "        0.18949503,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36399618,  1.1868147 , -0.7967213 , -0.539924  ,  0.35283747,\n",
      "        0.18949503,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5348107301012306, next_state=array([-0.37187552,  1.174685  , -0.7974919 , -0.54148406,  0.3629084 ,\n",
      "        0.20141833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37187552,  1.174685  , -0.7974919 , -0.54148406,  0.3629084 ,\n",
      "        0.20141833,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3726032679721516, next_state=array([-0.37967604,  1.1620104 , -0.78742087, -0.56519216,  0.37069643,\n",
      "        0.15576051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37967604,  1.1620104 , -0.78742087, -0.56519216,  0.37069643,\n",
      "        0.15576051,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3437117890215973, next_state=array([-0.38747686,  1.148737  , -0.7874181 , -0.5918635 ,  0.37848443,\n",
      "        0.15575986,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38747686,  1.148737  , -0.7874181 , -0.5918635 ,  0.37848443,\n",
      "        0.15575986,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4530902102281107, next_state=array([-0.39521226,  1.1348913 , -0.77921784, -0.6168802 ,  0.38451624,\n",
      "        0.12063593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39521226,  1.1348913 , -0.77921784, -0.6168802 ,  0.38451624,\n",
      "        0.12063593,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.48398114410229026, next_state=array([-0.4030683 ,  1.1211942 , -0.79159456, -0.6103808 ,  0.39089647,\n",
      "        0.12760486,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4030683 ,  1.1211942 , -0.79159456, -0.6103808 ,  0.39089647,\n",
      "        0.12760486,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2926611215504977, next_state=array([-0.41120028,  1.1078193 , -0.8190772 , -0.5960709 ,  0.39717954,\n",
      "        0.12566158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41120028,  1.1078193 , -0.8190772 , -0.5960709 ,  0.39717954,\n",
      "        0.12566158,  0.        ,  0.        ], dtype=float32), action=3, reward=0.03464444955855697, next_state=array([-0.4192485 ,  1.0938977 , -0.80844605, -0.6197525 ,  0.40106294,\n",
      "        0.07766785,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4192485 ,  1.0938977 , -0.80844605, -0.6197525 ,  0.40106294,\n",
      "        0.07766785,  0.        ,  0.        ], dtype=float32), action=2, reward=0.048303298542077766, next_state=array([-0.42741638,  1.080288  , -0.82095414, -0.60606027,  0.40553397,\n",
      "        0.08942063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42741638,  1.080288  , -0.82095414, -0.60606027,  0.40553397,\n",
      "        0.08942063,  0.        ,  0.        ], dtype=float32), action=3, reward=0.23470216001064273, next_state=array([-0.43549615,  1.066129  , -0.8098326 , -0.6298179 ,  0.4075249 ,\n",
      "        0.03981977,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43549615,  1.066129  , -0.8098326 , -0.6298179 ,  0.4075249 ,\n",
      "        0.03981977,  0.        ,  0.        ], dtype=float32), action=3, reward=0.22840594762468072, next_state=array([-4.4350275e-01,  1.0514096e+00, -8.0062139e-01, -6.5418470e-01,\n",
      "        4.0747815e-01, -9.3529263e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.4350275e-01,  1.0514096e+00, -8.0062139e-01, -6.5418470e-01,\n",
      "        4.0747815e-01, -9.3529263e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.610440010115326, next_state=array([-4.5150942e-01,  1.0360901e+00, -8.0062139e-01, -6.8085140e-01,\n",
      "        4.0743139e-01, -9.3523518e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.5150942e-01,  1.0360901e+00, -8.0062139e-01, -6.8085140e-01,\n",
      "        4.0743139e-01, -9.3523518e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=0.2754072113951065, next_state=array([-0.45945725,  1.0202198 , -0.79308164, -0.7048665 ,  0.405601  ,\n",
      "       -0.0366079 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45945725,  1.0202198 , -0.79308164, -0.7048665 ,  0.405601  ,\n",
      "       -0.0366079 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5612898206408545, next_state=array([-0.46767348,  1.0045042 , -0.8197096 , -0.6979233 ,  0.40354803,\n",
      "       -0.04105924,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46767348,  1.0045042 , -0.8197096 , -0.6979233 ,  0.40354803,\n",
      "       -0.04105924,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3280110203972117, next_state=array([-0.47594723,  0.9881448 , -0.82705534, -0.7269831 ,  0.40320328,\n",
      "       -0.00689491,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47594723,  0.9881448 , -0.82705534, -0.7269831 ,  0.40320328,\n",
      "       -0.00689491,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6829050953790101, next_state=array([-0.4843778 ,  0.97219265, -0.8432468 , -0.7090419 ,  0.4034094 ,\n",
      "        0.00412203,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4843778 ,  0.97219265, -0.8432468 , -0.7090419 ,  0.4034094 ,\n",
      "        0.00412203,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6591703435957175, next_state=array([-0.49287528,  0.9556023 , -0.85169184, -0.73790187,  0.40549612,\n",
      "        0.04173413,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49287528,  0.9556023 , -0.85169184, -0.73790187,  0.40549612,\n",
      "        0.04173413,  0.        ,  0.        ], dtype=float32), action=3, reward=0.24415010188212818, next_state=array([-0.50129724,  0.93846244, -0.8420979 , -0.76174265,  0.40539613,\n",
      "       -0.002     ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.50129724,  0.93846244, -0.8420979 , -0.76174265,  0.40539613,\n",
      "       -0.002     ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7460713271423856, next_state=array([-0.51001364,  0.9221203 , -0.8719627 , -0.7264095 ,  0.40574342,\n",
      "        0.00694571,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.51001364,  0.9221203 , -0.8719627 , -0.7264095 ,  0.40574342,\n",
      "        0.00694571,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9559301097340722, next_state=array([-0.5190336 ,  0.9056331 , -0.9016364 , -0.73266643,  0.40535358,\n",
      "       -0.00779717,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5190336 ,  0.9056331 , -0.9016364 , -0.73266643,  0.40535358,\n",
      "       -0.00779717,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8174414256526348, next_state=array([-0.5284373 ,  0.88928074, -0.9393222 , -0.7264738 ,  0.4042257 ,\n",
      "       -0.02255723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5284373 ,  0.88928074, -0.9393222 , -0.7264738 ,  0.4042257 ,\n",
      "       -0.02255723,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4526861660106533, next_state=array([-0.53803813,  0.8730878 , -0.9591029 , -0.71940815,  0.4031806 ,\n",
      "       -0.02090228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.53803813,  0.8730878 , -0.9591029 , -0.71940815,  0.4031806 ,\n",
      "       -0.02090228,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6369290867681048, next_state=array([-0.5477084 ,  0.85626113, -0.9678318 , -0.7480839 ,  0.40404087,\n",
      "        0.01720545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5477084 ,  0.85626113, -0.9678318 , -0.7480839 ,  0.40404087,\n",
      "        0.01720545,  0.        ,  0.        ], dtype=float32), action=3, reward=0.3375667246703824, next_state=array([-0.55730194,  0.838888  , -0.95807254, -0.77177846,  0.40266252,\n",
      "       -0.02756693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.55730194,  0.838888  , -0.95807254, -0.77177846,  0.40266252,\n",
      "       -0.02756693,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.865585228923378, next_state=array([-0.566975  ,  0.82085294, -0.96823007, -0.8018173 ,  0.40365523,\n",
      "        0.01985442,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.566975  ,  0.82085294, -0.96823007, -0.8018173 ,  0.40365523,\n",
      "        0.01985442,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4014455500277904, next_state=array([-0.57685924,  0.80309844, -0.98950404, -0.7894015 ,  0.40481544,\n",
      "        0.02320415,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.57685924,  0.80309844, -0.98950404, -0.7894015 ,  0.40481544,\n",
      "        0.02320415,  0.        ,  0.        ], dtype=float32), action=3, reward=0.1526372646210075, next_state=array([-0.5866735 ,  0.7847969 , -0.9805657 , -0.8131534 ,  0.40389636,\n",
      "       -0.01838146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5866735 ,  0.7847969 , -0.9805657 , -0.8131534 ,  0.40389636,\n",
      "       -0.01838146,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9443004289693977, next_state=array([-0.5965661 ,  0.7658383 , -0.9905516 , -0.8429702 ,  0.40528414,\n",
      "        0.02775556,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5965661 ,  0.7658383 , -0.9905516 , -0.8429702 ,  0.40528414,\n",
      "        0.02775556,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2445150894790345, next_state=array([-0.6066624 ,  0.7474208 , -1.0114105 , -0.81906384,  0.40719253,\n",
      "        0.03816768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6066624 ,  0.7474208 , -1.0114105 , -0.81906384,  0.40719253,\n",
      "        0.03816768,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0656765611885817, next_state=array([-0.61675876,  0.72840345, -1.0114102 , -0.8457308 ,  0.40910092,\n",
      "        0.03816801,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.61675876,  0.72840345, -1.0114102 , -0.8457308 ,  0.40910092,\n",
      "        0.03816801,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.263046962965261, next_state=array([-0.6269324 ,  0.7087386 , -1.0211792 , -0.87510103,  0.41321048,\n",
      "        0.08219148,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6269324 ,  0.7087386 , -1.0211792 , -0.87510103,  0.41321048,\n",
      "        0.08219148,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.21926060601012295, next_state=array([-0.6370256 ,  0.68851733, -1.0110576 , -0.89923495,  0.41507965,\n",
      "        0.03738399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6370256 ,  0.68851733, -1.0110576 , -0.89923495,  0.41507965,\n",
      "        0.03738399,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1557156908791058, next_state=array([-0.64711887,  0.66769594, -1.0110576 , -0.92590183,  0.41694885,\n",
      "        0.03738401,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.64711887,  0.66769594, -1.0110576 , -0.92590183,  0.41694885,\n",
      "        0.03738401,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.07378015220493125, next_state=array([-0.6571337 ,  0.646326  , -1.00112   , -0.9496781 ,  0.41655618,\n",
      "       -0.00785323,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6571337 ,  0.646326  , -1.00112   , -0.9496781 ,  0.41655618,\n",
      "       -0.00785323,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.025848379089597973, next_state=array([-0.6675397 ,  0.62578195, -1.0403514 , -0.9129886 ,  0.41628763,\n",
      "       -0.00537091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6675397 ,  0.62578195, -1.0403514 , -0.9129886 ,  0.41628763,\n",
      "       -0.00537091,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1910166938608584, next_state=array([-0.67801964,  0.60459447, -1.049685  , -0.9421658 ,  0.41811204,\n",
      "        0.03648788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.67801964,  0.60459447, -1.049685  , -0.9421658 ,  0.41811204,\n",
      "        0.03648788,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.37493650786032506, next_state=array([-0.68842936,  0.5828441 , -1.0408537 , -0.9666469 ,  0.41798517,\n",
      "       -0.0025372 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.68842936,  0.5828441 , -1.0408537 , -0.9666469 ,  0.41798517,\n",
      "       -0.0025372 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3842661454495713, next_state=array([-0.698916  ,  0.5604369 , -1.0506507 , -0.9964651 ,  0.42013487,\n",
      "        0.04299375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.698916  ,  0.5604369 , -1.0506507 , -0.9964651 ,  0.42013487,\n",
      "        0.04299375,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4753939725607097, next_state=array([-0.7094026 ,  0.5374298 , -1.0506504 , -1.0231321 ,  0.4222846 ,\n",
      "        0.04299374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7094026 ,  0.5374298 , -1.0506504 , -1.0231321 ,  0.4222846 ,\n",
      "        0.04299374,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8092074646622109, next_state=array([-0.7201855 ,  0.51488   , -1.080353  , -1.0028335 ,  0.42452   ,\n",
      "        0.04470759,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7201855 ,  0.51488   , -1.080353  , -1.0028335 ,  0.42452   ,\n",
      "        0.04470759,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4259242082273136, next_state=array([-0.73088557,  0.49178588, -1.0698428 , -1.0263586 ,  0.4243486 ,\n",
      "       -0.00342807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.73088557,  0.49178588, -1.0698428 , -1.0263586 ,  0.4243486 ,\n",
      "       -0.00342807,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.559871381275086, next_state=array([-0.7416592 ,  0.46804097, -1.0791957 , -1.0558796 ,  0.42632815,\n",
      "        0.0395907 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7416592 ,  0.46804097, -1.0791957 , -1.0558796 ,  0.42632815,\n",
      "        0.0395907 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1887323925236501, next_state=array([-0.75273955,  0.44470406, -1.1098496 , -1.0377512 ,  0.42830107,\n",
      "        0.03945817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.75273955,  0.44470406, -1.1098496 , -1.0377512 ,  0.42830107,\n",
      "        0.03945817,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8068664942234705, next_state=array([-0.7638199 ,  0.42076716, -1.1098492 , -1.0644182 ,  0.43027398,\n",
      "        0.03945818,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7638199 ,  0.42076716, -1.1098492 , -1.0644182 ,  0.43027398,\n",
      "        0.03945818,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8858868231398833, next_state=array([-0.7748333 ,  0.39628482, -1.1012868 , -1.0880843 ,  0.43021527,\n",
      "       -0.00117423,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7748333 ,  0.39628482, -1.1012868 , -1.0880843 ,  0.43021527,\n",
      "       -0.00117423,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6838999299460784, next_state=array([-0.78576976,  0.37125134, -1.0915574 , -1.1119609 ,  0.42794618,\n",
      "       -0.0453817 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.78576976,  0.37125134, -1.0915574 , -1.1119609 ,  0.42794618,\n",
      "       -0.0453817 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2678504239508355, next_state=array([-0.79700285,  0.3461471 , -1.120689  , -1.1149504 ,  0.4251057 ,\n",
      "       -0.05680979,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.79700285,  0.3461471 , -1.120689  , -1.1149504 ,  0.4251057 ,\n",
      "       -0.05680979,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.30556107761372, next_state=array([-0.8083626 ,  0.32095113, -1.133454  , -1.119064  ,  0.42237765,\n",
      "       -0.0545608 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8083626 ,  0.32095113, -1.133454  , -1.119064  ,  0.42237765,\n",
      "       -0.0545608 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9782528761537876, next_state=array([-0.81980586,  0.29510593, -1.1439917 , -1.1485746 ,  0.42201468,\n",
      "       -0.00725919,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.81980586,  0.29510593, -1.1439917 , -1.1485746 ,  0.42201468,\n",
      "       -0.00725919,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0922386481727244, next_state=array([-0.8312491 ,  0.26866078, -1.1439917 , -1.1752412 ,  0.42165172,\n",
      "       -0.00725913,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8312491 ,  0.26866078, -1.1439917 , -1.1752412 ,  0.42165172,\n",
      "       -0.00725913,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1220198046091125, next_state=array([-0.8431753 ,  0.24280587, -1.1917843 , -1.1488569 ,  0.42075226,\n",
      "       -0.01798918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8431753 ,  0.24280587, -1.1917843 , -1.1488569 ,  0.42075226,\n",
      "       -0.01798918,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2325442236328854, next_state=array([-0.85510147,  0.21635099, -1.1917841 , -1.1755235 ,  0.41985285,\n",
      "       -0.01798837,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.85510147,  0.21635099, -1.1917841 , -1.1755235 ,  0.41985285,\n",
      "       -0.01798837,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3338038693993326, next_state=array([-0.86702764,  0.18929623, -1.1917841 , -1.2021903 ,  0.41895345,\n",
      "       -0.01798825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.86702764,  0.18929623, -1.1917841 , -1.2021903 ,  0.41895345,\n",
      "       -0.01798825,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.754204682407105, next_state=array([-0.87904036,  0.16157764, -1.20281   , -1.2323941 ,  0.420615  ,\n",
      "        0.03323087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.87904036,  0.16157764, -1.20281   , -1.2323941 ,  0.420615  ,\n",
      "        0.03323087,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5732130991715099, next_state=array([-0.89096487,  0.13331488, -1.1916481 , -1.2558821 ,  0.41974577,\n",
      "       -0.01738451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.89096487,  0.13331488, -1.1916481 , -1.2558821 ,  0.41974577,\n",
      "       -0.01738451,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7125696555965237, next_state=array([-0.9028245 ,  0.10450481, -1.1833451 , -1.2796731 ,  0.41691506,\n",
      "       -0.05661455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9028245 ,  0.10450481, -1.1833451 , -1.2796731 ,  0.41691506,\n",
      "       -0.05661455,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.420500499213449, next_state=array([-0.9148515 ,  0.07558066, -1.1999801 , -1.28472   ,  0.41398317,\n",
      "       -0.05863761,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9148515 ,  0.07558066, -1.1999801 , -1.28472   ,  0.41398317,\n",
      "       -0.05863761,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.30111637697438, next_state=array([-0.9270886 ,  0.04670649, -1.2209122 , -1.2824798 ,  0.41096726,\n",
      "       -0.06031782,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9270886 ,  0.04670649, -1.2209122 , -1.2824798 ,  0.41096726,\n",
      "       -0.06031782,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8114244818330463, next_state=array([-0.93962616,  0.01862613, -1.2513655 , -1.2473234 ,  0.40839365,\n",
      "       -0.0514722 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.93962616,  0.01862613, -1.2513655 , -1.2473234 ,  0.40839365,\n",
      "       -0.0514722 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9264923658822568, next_state=array([-0.95250225, -0.00886773, -1.285225  , -1.2212642 ,  0.4058355 ,\n",
      "       -0.05116259,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.95250225, -0.00886773, -1.285225  , -1.2212642 ,  0.4058355 ,\n",
      "       -0.05116259,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.270528348955309, next_state=array([-9.6546382e-01, -3.7026420e-02, -1.2961420e+00, -1.2514918e+00,\n",
      "        4.0581748e-01, -3.6083243e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.6546382e-01, -3.7026420e-02, -1.2961420e+00, -1.2514918e+00,\n",
      "        4.0581748e-01, -3.6083243e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-3.49678035155124, next_state=array([-0.9786508 , -0.06523718, -1.3184129 , -1.2537287 ,  0.40550804,\n",
      "       -0.00618851,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9786508 , -0.06523718, -1.3184129 , -1.2537287 ,  0.40550804,\n",
      "       -0.00618851,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3474684417379763, next_state=array([-0.99201626, -0.09281629, -1.3369424 , -1.2258542 ,  0.4059379 ,\n",
      "        0.00859764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.99201626, -0.09281629, -1.3369424 , -1.2258542 ,  0.4059379 ,\n",
      "        0.00859764,  0.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([-1.0054405 , -0.12102173, -1.3443027 , -1.254114  ,  0.40795934,\n",
      "        0.04042856,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-1.2331009e-04,  1.4194398e+00, -1.2515163e-02,  3.7865612e-01,\n",
      "        1.4977895e-04,  2.8348938e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.9471344021249477, next_state=array([-2.5157927e-04,  1.4283519e+00, -1.2936734e-02,  3.9609244e-01,\n",
      "        2.6826590e-04,  2.3705508e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.5157927e-04,  1.4283519e+00, -1.2936734e-02,  3.9609244e-01,\n",
      "        2.6826590e-04,  2.3705508e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=1.5297994565437716, next_state=array([-4.5576095e-04,  1.4366693e+00, -2.2488343e-02,  3.6967090e-01,\n",
      "        2.3020189e-03,  4.0678892e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.5576095e-04,  1.4366693e+00, -2.2488343e-02,  3.6967090e-01,\n",
      "        2.3020189e-03,  4.0678892e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-3.6034754124921333, next_state=array([-5.0907134e-04,  1.4454833e+00, -8.1139216e-03,  3.9172509e-01,\n",
      "        5.0679725e-03,  5.5324215e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-5.0907134e-04,  1.4454833e+00, -8.1139216e-03,  3.9172509e-01,\n",
      "        5.0679725e-03,  5.5324215e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=1.829948283740323, next_state=array([-4.6815872e-04,  1.4536866e+00,  3.6814273e-03,  3.6458832e-01,\n",
      "        5.4674447e-03,  7.9897400e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.6815872e-04,  1.4536866e+00,  3.6814273e-03,  3.6458832e-01,\n",
      "        5.4674447e-03,  7.9897400e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=1.865827709220639, next_state=array([-4.2734147e-04,  1.4612901e+00,  3.6807419e-03,  3.3792445e-01,\n",
      "        5.8681425e-03,  8.0147590e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.2734147e-04,  1.4612901e+00,  3.6807419e-03,  3.3792445e-01,\n",
      "        5.8681425e-03,  8.0147590e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=1.7004171255456424, next_state=array([-4.8360825e-04,  1.4682808e+00, -8.5004317e-03,  3.1068990e-01,\n",
      "        8.7115234e-03,  5.6873012e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-4.8360825e-04,  1.4682808e+00, -8.5004317e-03,  3.1068990e-01,\n",
      "        8.7115234e-03,  5.6873012e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-3.2716937913070465, next_state=array([-6.8149564e-04,  1.4757098e+00, -2.2021558e-02,  3.3016488e-01,\n",
      "        1.0907142e-02,  4.3916248e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-6.8149564e-04,  1.4757098e+00, -2.2021558e-02,  3.3016488e-01,\n",
      "        1.0907142e-02,  4.3916248e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=1.7587129058322262, next_state=array([-8.79573810e-04,  1.48253858e+00, -2.20274366e-02,  3.03487718e-01,\n",
      "        1.31034935e-02,  4.39311750e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-8.79573810e-04,  1.48253858e+00, -2.20274366e-02,  3.03487718e-01,\n",
      "        1.31034935e-02,  4.39311750e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=0, reward=1.8163361462389105, next_state=array([-1.07765198e-03,  1.48876750e+00, -2.20340472e-02,  2.76822448e-01,\n",
      "        1.52992075e-02,  4.39189784e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.07765198e-03,  1.48876750e+00, -2.20340472e-02,  2.76822448e-01,\n",
      "        1.52992075e-02,  4.39189784e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=3, reward=2.118041890801608, next_state=array([-1.1983871e-03,  1.4943933e+00, -1.2334976e-02,  2.5003666e-01,\n",
      "        1.5550010e-02,  5.0166640e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.1983871e-03,  1.4943933e+00, -1.2334976e-02,  2.5003666e-01,\n",
      "        1.5550010e-02,  5.0166640e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=2.13546184746491, next_state=array([-1.3191223e-03,  1.4994192e+00, -1.2335289e-02,  2.2336826e-01,\n",
      "        1.5801612e-02,  5.0325869e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.3191223e-03,  1.4994192e+00, -1.2335289e-02,  2.2336826e-01,\n",
      "        1.5801612e-02,  5.0325869e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.360952125670951, next_state=array([-1.4011383e-03,  1.5047815e+00, -8.6918548e-03,  2.3831630e-01,\n",
      "        1.6282646e-02,  9.6215867e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.4011383e-03,  1.5047815e+00, -8.6918548e-03,  2.3831630e-01,\n",
      "        1.6282646e-02,  9.6215867e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=-2.9162159459821337, next_state=array([-0.00161448,  1.5105875 , -0.02125089,  0.25804237,  0.0161974 ,\n",
      "       -0.00170486,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00161448,  1.5105875 , -0.02125089,  0.25804237,  0.0161974 ,\n",
      "       -0.00170486,  0.        ,  0.        ], dtype=float32), action=1, reward=1.798085606977936, next_state=array([-0.00190916,  1.5157931 , -0.03145475,  0.2313401 ,  0.01815779,\n",
      "        0.03921139,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00190916,  1.5157931 , -0.03145475,  0.2313401 ,  0.01815779,\n",
      "        0.03921139,  0.        ,  0.        ], dtype=float32), action=0, reward=1.9824532124861776, next_state=array([-0.00220394,  1.520399  , -0.03146104,  0.20467514,  0.02011677,\n",
      "        0.03918316,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00220394,  1.520399  , -0.03146104,  0.20467514,  0.02011677,\n",
      "        0.03918316,  0.        ,  0.        ], dtype=float32), action=0, reward=2.0347295615096357, next_state=array([-0.00249872,  1.5244048 , -0.03146645,  0.17800649,  0.02207587,\n",
      "        0.0391858 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00249872,  1.5244048 , -0.03146645,  0.17800649,  0.02207587,\n",
      "        0.0391858 ,  0.        ,  0.        ], dtype=float32), action=0, reward=2.082606199182891, next_state=array([-0.0027936 ,  1.5278105 , -0.03147201,  0.15133746,  0.02403469,\n",
      "        0.03918008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0027936 ,  1.5278105 , -0.03147201,  0.15133746,  0.02403469,\n",
      "        0.03918008,  0.        ,  0.        ], dtype=float32), action=3, reward=2.4628630607786035, next_state=array([-0.00301704,  1.5306156 , -0.02250955,  0.12466303,  0.02419689,\n",
      "        0.0032443 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00301704,  1.5306156 , -0.02250955,  0.12466303,  0.02419689,\n",
      "        0.0032443 ,  0.        ,  0.        ], dtype=float32), action=0, reward=2.376439753487773, next_state=array([-0.00324049,  1.5328203 , -0.02250955,  0.0979943 ,  0.02435981,\n",
      "        0.00325874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00324049,  1.5328203 , -0.02250955,  0.0979943 ,  0.02435981,\n",
      "        0.00325874,  0.        ,  0.        ], dtype=float32), action=3, reward=2.748973905576834, next_state=array([-0.00339966,  1.5344208 , -0.0144604 ,  0.07114927,  0.02291171,\n",
      "       -0.02896441,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00339966,  1.5344208 , -0.0144604 ,  0.07114927,  0.02291171,\n",
      "       -0.02896441,  0.        ,  0.        ], dtype=float32), action=3, reward=2.916169258895992, next_state=array([-0.00349474,  1.5354265 , -0.00641459,  0.04473876,  0.01985176,\n",
      "       -0.06120505,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00349474,  1.5354265 , -0.00641459,  0.04473876,  0.01985176,\n",
      "       -0.06120505,  0.        ,  0.        ], dtype=float32), action=0, reward=2.867853364291477, next_state=array([-0.00358973,  1.5358322 , -0.00640553,  0.01806924,  0.01679257,\n",
      "       -0.06118935,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00358973,  1.5358322 , -0.00640553,  0.01806924,  0.01679257,\n",
      "       -0.06118935,  0.        ,  0.        ], dtype=float32), action=3, reward=1.4654008053841505, next_state=array([-0.00359058,  1.5356462 ,  0.00539708, -0.00821192,  0.01136885,\n",
      "       -0.10848404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00359058,  1.5356462 ,  0.00539708, -0.00821192,  0.01136885,\n",
      "       -0.10848404,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2294443710676135, next_state=array([-0.00368929,  1.5348604 , -0.00687745, -0.03489561,  0.00840865,\n",
      "       -0.05920917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00368929,  1.5348604 , -0.00687745, -0.03489561,  0.00840865,\n",
      "       -0.05920917,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5967919444186394, next_state=array([-0.00385466,  1.5334637 , -0.01523905, -0.06207187,  0.00712464,\n",
      "       -0.02567992,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00385466,  1.5334637 , -0.01523905, -0.06207187,  0.00712464,\n",
      "       -0.02567992,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.284240001554622, next_state=array([-0.00402012,  1.5314671 , -0.01523905, -0.08873868,  0.00584066,\n",
      "       -0.02567989,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00402012,  1.5314671 , -0.01523905, -0.08873868,  0.00584066,\n",
      "       -0.02567989,  0.        ,  0.        ], dtype=float32), action=2, reward=0.10905605811758506, next_state=array([-0.00405645,  1.5294743 , -0.00295449, -0.08856691,  0.00516434,\n",
      "       -0.01352633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00405645,  1.5294743 , -0.00295449, -0.08856691,  0.00516434,\n",
      "       -0.01352633,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6505348967753535, next_state=array([-0.00416679,  1.5268735 , -0.01222236, -0.11559726,  0.00634475,\n",
      "        0.02360817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00416679,  1.5268735 , -0.01222236, -0.11559726,  0.00634475,\n",
      "        0.02360817,  0.        ,  0.        ], dtype=float32), action=2, reward=1.886832357933497, next_state=array([-0.00432453,  1.5247581 , -0.01676755, -0.0940226 ,  0.00732687,\n",
      "        0.01964257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00432453,  1.5247581 , -0.01676755, -0.0940226 ,  0.00732687,\n",
      "        0.01964257,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.785626302071647, next_state=array([-0.00455227,  1.5220506 , -0.02555281, -0.12034575,  0.01006737,\n",
      "        0.05481026,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00455227,  1.5220506 , -0.02555281, -0.12034575,  0.01006737,\n",
      "        0.05481026,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.969617042404478, next_state=array([-0.00485439,  1.5187432 , -0.03488776, -0.14703915,  0.01467735,\n",
      "        0.09219976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00485439,  1.5187432 , -0.03488776, -0.14703915,  0.01467735,\n",
      "        0.09219976,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.45673580441156786, next_state=array([-0.00532589,  1.5155216 , -0.0510617 , -0.14322089,  0.01853494,\n",
      "        0.07715202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00532589,  1.5155216 , -0.0510617 , -0.14322089,  0.01853494,\n",
      "        0.07715202,  0.        ,  0.        ], dtype=float32), action=2, reward=0.25004734061748196, next_state=array([-0.00563355,  1.5123583 , -0.0354811 , -0.14065334,  0.02318813,\n",
      "        0.09306382,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00563355,  1.5123583 , -0.0354811 , -0.14065334,  0.02318813,\n",
      "        0.09306382,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.2488849705428025, next_state=array([-0.00603876,  1.5085983 , -0.04771044, -0.16723329,  0.03028898,\n",
      "        0.14201723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00603876,  1.5085983 , -0.04771044, -0.16723329,  0.03028898,\n",
      "        0.14201723,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.534044726824844, next_state=array([-0.00638447,  1.5042464 , -0.04024584, -0.19355439,  0.03589163,\n",
      "        0.11205274,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00638447,  1.5042464 , -0.04024584, -0.19355439,  0.03589163,\n",
      "        0.11205274,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4312615421412134, next_state=array([-0.00666142,  1.4992868 , -0.03162144, -0.2205289 ,  0.0397724 ,\n",
      "        0.07761531,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00666142,  1.4992868 , -0.03162144, -0.2205289 ,  0.0397724 ,\n",
      "        0.07761531,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.945361629727556, next_state=array([-0.00703306,  1.4937234 , -0.04350108, -0.24744335,  0.04603408,\n",
      "        0.12523356,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00703306,  1.4937234 , -0.04350108, -0.24744335,  0.04603408,\n",
      "        0.12523356,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.242435324429009, next_state=array([-0.00731697,  1.4875717 , -0.03249484, -0.2735394 ,  0.05008394,\n",
      "        0.08099739,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00731697,  1.4875717 , -0.03249484, -0.2735394 ,  0.05008394,\n",
      "        0.08099739,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3730075041031398, next_state=array([-0.00761499,  1.4815329 , -0.03394654, -0.26853773,  0.0541789 ,\n",
      "        0.08189887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00761499,  1.4815329 , -0.03394654, -0.26853773,  0.0541789 ,\n",
      "        0.08189887,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3934198219298253, next_state=array([-0.00791311,  1.4748943 , -0.03394643, -0.2952058 ,  0.05827383,\n",
      "        0.08189874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00791311,  1.4748943 , -0.03394643, -0.2952058 ,  0.05827383,\n",
      "        0.08189874,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.336610231644329, next_state=array([-0.00821123,  1.4676559 , -0.03394632, -0.32187387,  0.06236877,\n",
      "        0.08189863,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00821123,  1.4676559 , -0.03394632, -0.32187387,  0.06236877,\n",
      "        0.08189863,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2790684633986587, next_state=array([-0.00850935,  1.4598176 , -0.03394619, -0.34854192,  0.06646372,\n",
      "        0.08189855,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00850935,  1.4598176 , -0.03394619, -0.34854192,  0.06646372,\n",
      "        0.08189855,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.482407938650424, next_state=array([-0.00886974,  1.451382  , -0.04174853, -0.3751796 ,  0.07211696,\n",
      "        0.11306459,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00886974,  1.451382  , -0.04174853, -0.3751796 ,  0.07211696,\n",
      "        0.11306459,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0372791388914195, next_state=array([-0.00915318,  1.4423503 , -0.03210277, -0.40159708,  0.07583671,\n",
      "        0.07439498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00915318,  1.4423503 , -0.03210277, -0.40159708,  0.07583671,\n",
      "        0.07439498,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4524597597300883, next_state=array([-0.00953016,  1.4327179 , -0.04383133, -0.42842966,  0.0819032 ,\n",
      "        0.12133004,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00953016,  1.4327179 , -0.04383133, -0.42842966,  0.0819032 ,\n",
      "        0.12133004,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6476753602422307, next_state=array([-0.0099926 ,  1.4224775 , -0.0545449 , -0.4556058 ,  0.09012375,\n",
      "        0.16441146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0099926 ,  1.4224775 , -0.0545449 , -0.4556058 ,  0.09012375,\n",
      "        0.16441146,  0.        ,  0.        ], dtype=float32), action=2, reward=2.06359687330085, next_state=array([-0.01065588,  1.4127913 , -0.07400699, -0.4309804 ,  0.09773963,\n",
      "        0.15231733,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01065588,  1.4127913 , -0.07400699, -0.4309804 ,  0.09773963,\n",
      "        0.15231733,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7070959987406966, next_state=array([-0.01137924,  1.4025002 , -0.08153716, -0.4580132 ,  0.10686976,\n",
      "        0.18260221,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01137924,  1.4025002 , -0.08153716, -0.4580132 ,  0.10686976,\n",
      "        0.18260221,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4529245520330107, next_state=array([-0.0121027 ,  1.3916101 , -0.0815361 , -0.48468682,  0.11599982,\n",
      "        0.18260114,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0121027 ,  1.3916101 , -0.0815361 , -0.48468682,  0.11599982,\n",
      "        0.18260114,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.8440609358904383, next_state=array([-0.01289682,  1.3801038 , -0.09040616, -0.5122852 ,  0.12693499,\n",
      "        0.21870331,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01289682,  1.3801038 , -0.09040616, -0.5122852 ,  0.12693499,\n",
      "        0.21870331,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0369796204534496, next_state=array([-0.01377916,  1.3679858 , -0.10145315, -0.53976   ,  0.14010312,\n",
      "        0.26336247,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01377916,  1.3679858 , -0.10145315, -0.53976   ,  0.14010312,\n",
      "        0.26336247,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3239970856146897, next_state=array([-0.01459312,  1.3562685 , -0.09533654, -0.5221354 ,  0.1540154 ,\n",
      "        0.27824575,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01459312,  1.3562685 , -0.09533654, -0.5221354 ,  0.1540154 ,\n",
      "        0.27824575,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7875941005867446, next_state=array([-0.01540728,  1.3439538 , -0.09533299, -0.54881805,  0.1679275 ,\n",
      "        0.27824205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01540728,  1.3439538 , -0.09533299, -0.54881805,  0.1679275 ,\n",
      "        0.27824205,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.250929521999693, next_state=array([-0.01614323,  1.3310711 , -0.08542211, -0.5739397 ,  0.17978457,\n",
      "        0.2371413 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01614323,  1.3310711 , -0.08542211, -0.5739397 ,  0.17978457,\n",
      "        0.2371413 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3440936233786374, next_state=array([-0.01681156,  1.3185517 , -0.07948247, -0.5580035 ,  0.19247983,\n",
      "        0.2539053 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01681156,  1.3185517 , -0.07948247, -0.5580035 ,  0.19247983,\n",
      "        0.2539053 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8915772376365851, next_state=array([-0.01769247,  1.3059597 , -0.10004617, -0.5612418 ,  0.20452161,\n",
      "        0.24083526,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01769247,  1.3059597 , -0.10004617, -0.5612418 ,  0.20452161,\n",
      "        0.24083526,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0672516909912404, next_state=array([-0.01849365,  1.292789  , -0.09001993, -0.58676696,  0.21450944,\n",
      "        0.19975685,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01849365,  1.292789  , -0.09001993, -0.58676696,  0.21450944,\n",
      "        0.19975685,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7670615418361126, next_state=array([-0.01920977,  1.2790477 , -0.07927724, -0.61185855,  0.22226828,\n",
      "        0.15517697,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01920977,  1.2790477 , -0.07927724, -0.61185855,  0.22226828,\n",
      "        0.15517697,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.537107775391944, next_state=array([-0.01984606,  1.264736  , -0.06922875, -0.6369302 ,  0.22793123,\n",
      "        0.11325934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01984606,  1.264736  , -0.06922875, -0.6369302 ,  0.22793123,\n",
      "        0.11325934,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3064538415819402, next_state=array([-0.02039299,  1.2498435 , -0.05801728, -0.6624169 ,  0.23130643,\n",
      "        0.06750403,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02039299,  1.2498435 , -0.05801728, -0.6624169 ,  0.23130643,\n",
      "        0.06750403,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1537271740588142, next_state=array([-0.02087545,  1.2343667 , -0.04994817, -0.6881268 ,  0.23302595,\n",
      "        0.03439001,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02087545,  1.2343667 , -0.04994817, -0.6881268 ,  0.23302595,\n",
      "        0.03439001,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1258083190600816, next_state=array([-0.02160683,  1.2191708 , -0.07434195, -0.67555445,  0.23425321,\n",
      "        0.02454517,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02160683,  1.2191708 , -0.07434195, -0.67555445,  0.23425321,\n",
      "        0.02454517,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.677543565335269, next_state=array([-0.02224569,  1.2034106 , -0.06269647, -0.7002659 ,  0.23304044,\n",
      "       -0.02425536,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02224569,  1.2034106 , -0.06269647, -0.7002659 ,  0.23304044,\n",
      "       -0.02425536,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4208971581457195, next_state=array([-0.0229763 ,  1.1870254 , -0.07420246, -0.7284162 ,  0.23419897,\n",
      "        0.02317034,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0229763 ,  1.1870254 , -0.07420246, -0.7284162 ,  0.23419897,\n",
      "        0.02317034,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.536495751502655, next_state=array([-0.02378349,  1.1700162 , -0.08382078, -0.7564582 ,  0.23735164,\n",
      "        0.06305377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02378349,  1.1700162 , -0.08382078, -0.7564582 ,  0.23735164,\n",
      "        0.06305377,  0.        ,  0.        ], dtype=float32), action=2, reward=4.752482282293113, next_state=array([-0.02467709,  1.1539025 , -0.09315508, -0.7167786 ,  0.2411998 ,\n",
      "        0.07696311,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02467709,  1.1539025 , -0.09315508, -0.7167786 ,  0.2411998 ,\n",
      "        0.07696311,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7631896839825447, next_state=array([-0.02563572,  1.1371722 , -0.10128908, -0.7444631 ,  0.24672146,\n",
      "        0.11043318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02563572,  1.1371722 , -0.10128908, -0.7444631 ,  0.24672146,\n",
      "        0.11043318,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7673194786048441, next_state=array([-0.02654161,  1.1204351 , -0.09667829, -0.7449081 ,  0.2529264 ,\n",
      "        0.12409874,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02654161,  1.1204351 , -0.09667829, -0.7449081 ,  0.2529264 ,\n",
      "        0.12409874,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1802713233297755, next_state=array([-0.02738047,  1.1031173 , -0.08827588, -0.77044123,  0.25739506,\n",
      "        0.08937304,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02738047,  1.1031173 , -0.08827588, -0.77044123,  0.25739506,\n",
      "        0.08937304,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.761043188432011, next_state=array([-0.02828827,  1.0851743 , -0.09693195, -0.79856044,  0.26367974,\n",
      "        0.12569389,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02828827,  1.0851743 , -0.09693195, -0.79856044,  0.26367974,\n",
      "        0.12569389,  0.        ,  0.        ], dtype=float32), action=2, reward=2.766534393950491, next_state=array([-0.02951546,  1.0677645 , -0.12835553, -0.77479804,  0.2694489 ,\n",
      "        0.11538343,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02951546,  1.0677645 , -0.12835553, -0.77479804,  0.2694489 ,\n",
      "        0.11538343,  0.        ,  0.        ], dtype=float32), action=2, reward=2.530758656843955, next_state=array([-0.03097239,  1.050839  , -0.15119405, -0.75326884,  0.2750837 ,\n",
      "        0.11269561,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03097239,  1.050839  , -0.15119405, -0.75326884,  0.2750837 ,\n",
      "        0.11269561,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4326749587778238, next_state=array([-0.03242951,  1.0333138 , -0.15119298, -0.7799379 ,  0.28071848,\n",
      "        0.11269536,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03242951,  1.0333138 , -0.15119298, -0.7799379 ,  0.28071848,\n",
      "        0.11269536,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7886846523354325, next_state=array([-0.03380518,  1.0152292 , -0.1409072 , -0.804402  ,  0.2841432 ,\n",
      "        0.06849508,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03380518,  1.0152292 , -0.1409072 , -0.804402  ,  0.2841432 ,\n",
      "        0.06849508,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1078618729060281, next_state=array([-0.03518095,  0.99654496, -0.14090678, -0.8310695 ,  0.28756797,\n",
      "        0.06849504,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03518095,  0.99654496, -0.14090678, -0.8310695 ,  0.28756797,\n",
      "        0.06849504,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5800356243935585, next_state=array([-0.0366272 ,  0.977231  , -0.14977358, -0.85941815,  0.2928757 ,\n",
      "        0.1061548 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0366272 ,  0.977231  , -0.14977358, -0.85941815,  0.2928757 ,\n",
      "        0.1061548 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7698749916260954, next_state=array([-0.03800802,  0.95734006, -0.14156038, -0.8847521 ,  0.29646337,\n",
      "        0.07175353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03800802,  0.95734006, -0.14156038, -0.8847521 ,  0.29646337,\n",
      "        0.07175353,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4622041106368033, next_state=array([-0.03946247,  0.936825  , -0.15077351, -0.91288483,  0.30197722,\n",
      "        0.11027688,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03946247,  0.936825  , -0.15077351, -0.91288483,  0.30197722,\n",
      "        0.11027688,  0.        ,  0.        ], dtype=float32), action=2, reward=3.0470430528938666, next_state=array([-0.04130421,  0.9168935 , -0.18890288, -0.8868296 ,  0.30686575,\n",
      "        0.09777089,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04130421,  0.9168935 , -0.18890288, -0.8868296 ,  0.30686575,\n",
      "        0.09777089,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6249713123345362, next_state=array([-0.04308672,  0.89639026, -0.18140966, -0.91192573,  0.31014448,\n",
      "        0.06557445,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04308672,  0.89639026, -0.18140966, -0.91192573,  0.31014448,\n",
      "        0.06557445,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.845909922335693, next_state=array([-0.04486914,  0.87528723, -0.18140924, -0.9385932 ,  0.31342322,\n",
      "        0.06557439,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04486914,  0.87528723, -0.18140924, -0.9385932 ,  0.31342322,\n",
      "        0.06557439,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3012597988764003, next_state=array([-0.04659224,  0.8536254 , -0.17382167, -0.96307766,  0.31500188,\n",
      "        0.03157349,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04659224,  0.8536254 , -0.17382167, -0.96307766,  0.31500188,\n",
      "        0.03157349,  0.        ,  0.        ], dtype=float32), action=3, reward=0.08507247333236137, next_state=array([-0.04822235,  0.83140683, -0.16211727, -0.9872944 ,  0.31406516,\n",
      "       -0.01873437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04822235,  0.83140683, -0.16211727, -0.9872944 ,  0.31406516,\n",
      "       -0.01873437,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7941834515768551, next_state=array([-0.04991923,  0.80855614, -0.17053558, -1.0157722 ,  0.31494328,\n",
      "        0.01756256,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04991923,  0.80855614, -0.17053558, -1.0157722 ,  0.31494328,\n",
      "        0.01756256,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8843627908145482, next_state=array([-0.05167284,  0.7850694 , -0.17773819, -1.0443673 ,  0.3174188 ,\n",
      "        0.04951059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05167284,  0.7850694 , -0.17773819, -1.0443673 ,  0.3174188 ,\n",
      "        0.04951059,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9806889011197473, next_state=array([-0.0534872 ,  0.7609517 , -0.18542208, -1.0727798 ,  0.3215622 ,\n",
      "        0.08286743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0534872 ,  0.7609517 , -0.18542208, -1.0727798 ,  0.3215622 ,\n",
      "        0.08286743,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.04813446565040522, next_state=array([-0.05523052,  0.736277  , -0.17640033, -1.0971103 ,  0.32371226,\n",
      "        0.04300063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05523052,  0.736277  , -0.17640033, -1.0971103 ,  0.32371226,\n",
      "        0.04300063,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.950036748914896, next_state=array([-0.05704365,  0.71095693, -0.18528272, -1.1262342 ,  0.3278443 ,\n",
      "        0.08264142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05704365,  0.71095693, -0.18528272, -1.1262342 ,  0.3278443 ,\n",
      "        0.08264142,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2060467915281083, next_state=array([-0.05894031,  0.6849818 , -0.19589339, -1.1558745 ,  0.3343502 ,\n",
      "        0.1301181 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05894031,  0.6849818 , -0.19589339, -1.1558745 ,  0.3343502 ,\n",
      "        0.1301181 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6508139715209893, next_state=array([-0.06083708,  0.6584074 , -0.19589165, -1.1825446 ,  0.3408561 ,\n",
      "        0.13011771,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06083708,  0.6584074 , -0.19589165, -1.1825446 ,  0.3408561 ,\n",
      "        0.13011771,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5955719233742798, next_state=array([-0.06273393,  0.6312334 , -0.1958899 , -1.2092146 ,  0.34736198,\n",
      "        0.13011734,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06273393,  0.6312334 , -0.1958899 , -1.2092146 ,  0.34736198,\n",
      "        0.13011734,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5407535033185695, next_state=array([-0.06463089,  0.6034599 , -0.19588812, -1.2358844 ,  0.3538678 ,\n",
      "        0.13011657,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06463089,  0.6034599 , -0.19588812, -1.2358844 ,  0.3538678 ,\n",
      "        0.13011657,  0.        ,  0.        ], dtype=float32), action=2, reward=2.8085296910246713, next_state=array([-0.06658306,  0.5759682 , -0.20205805, -1.2235535 ,  0.36107656,\n",
      "        0.14417545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06658306,  0.5759682 , -0.20205805, -1.2235535 ,  0.36107656,\n",
      "        0.14417545,  0.        ,  0.        ], dtype=float32), action=2, reward=2.764164951948442, next_state=array([-0.06859092,  0.5487749 , -0.20830786, -1.2105039 ,  0.36902308,\n",
      "        0.15892997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06859092,  0.5487749 , -0.20830786, -1.2105039 ,  0.36902308,\n",
      "        0.15892997,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4121083862802652, next_state=array([-0.07067785,  0.52092797, -0.21833701, -1.2401611 ,  0.3792505 ,\n",
      "        0.20454817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07067785,  0.52092797, -0.21833701, -1.2401611 ,  0.3792505 ,\n",
      "        0.20454817,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8634015395431902, next_state=array([-0.07276516,  0.49248242, -0.21833225, -1.266836  ,  0.38947782,\n",
      "        0.20454672,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07276516,  0.49248242, -0.21833225, -1.266836  ,  0.38947782,\n",
      "        0.20454672,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.25666618877440217, next_state=array([-0.07477321,  0.4634737 , -0.20836374, -1.2913657 ,  0.3975518 ,\n",
      "        0.16147968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07477321,  0.4634737 , -0.20836374, -1.2913657 ,  0.3975518 ,\n",
      "        0.16147968,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.09052147281778275, next_state=array([-0.07671766,  0.43389982, -0.2003155 , -1.3160535 ,  0.40385023,\n",
      "        0.12596835,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07671766,  0.43389982, -0.2003155 , -1.3160535 ,  0.40385023,\n",
      "        0.12596835,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.335840363293471, next_state=array([-0.0786622 ,  0.4037264 , -0.20031357, -1.3427231 ,  0.41014862,\n",
      "        0.12596795,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0786622 ,  0.4037264 , -0.20031357, -1.3427231 ,  0.41014862,\n",
      "        0.12596795,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2928098512948054, next_state=array([-0.08060684,  0.37295353, -0.20031159, -1.3693928 ,  0.416447  ,\n",
      "        0.1259676 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08060684,  0.37295353, -0.20031159, -1.3693928 ,  0.416447  ,\n",
      "        0.1259676 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.25422085609378087, next_state=array([-0.08255167,  0.3415811 , -0.20030959, -1.3960625 ,  0.42274538,\n",
      "        0.12596706,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08255167,  0.3415811 , -0.20030959, -1.3960625 ,  0.42274538,\n",
      "        0.12596706,  0.        ,  0.        ], dtype=float32), action=2, reward=4.938603539804672, next_state=array([-0.08489676,  0.31103334, -0.2404258 , -1.3594685 ,  0.4291576 ,\n",
      "        0.12824547,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08489676,  0.31103334, -0.2404258 , -1.3594685 ,  0.4291576 ,\n",
      "        0.12824547,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1026584165655438, next_state=array([-0.08742476,  0.28061152, -0.25884277, -1.3539397 ,  0.43573242,\n",
      "        0.13149592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08742476,  0.28061152, -0.25884277, -1.3539397 ,  0.43573242,\n",
      "        0.13149592,  0.        ,  0.        ], dtype=float32), action=3, reward=0.010998740900732856, next_state=array([-0.08989458,  0.24961811, -0.25156146, -1.3789115 ,  0.4407153 ,\n",
      "        0.09965788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08989458,  0.24961811, -0.25156146, -1.3789115 ,  0.4407153 ,\n",
      "        0.09965788,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8395994394982995, next_state=array([-0.09242878,  0.21798779, -0.25963324, -1.4077655 ,  0.44751245,\n",
      "        0.13594298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09242878,  0.21798779, -0.25963324, -1.4077655 ,  0.44751245,\n",
      "        0.13594298,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4883047237760536, next_state=array([-0.09496317,  0.18575794, -0.25963074, -1.4344356 ,  0.45430958,\n",
      "        0.13594255,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09496317,  0.18575794, -0.25963074, -1.4344356 ,  0.45430958,\n",
      "        0.13594255,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3641390077402196, next_state=array([-0.0975851 ,  0.1528752 , -0.27065733, -1.4642367 ,  0.46361014,\n",
      "        0.18601125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0975851 ,  0.1528752 , -0.27065733, -1.4642367 ,  0.46361014,\n",
      "        0.18601125,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6685242477584383, next_state=array([-0.10054378,  0.12072638, -0.30468768, -1.4318042 ,  0.4733574 ,\n",
      "        0.19494572,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10054378,  0.12072638, -0.30468768, -1.4318042 ,  0.4733574 ,\n",
      "        0.19494572,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3531516644495682, next_state=array([-0.10358457,  0.08790658, -0.31513056, -1.4624828 ,  0.48565704,\n",
      "        0.24599262,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10358457,  0.08790658, -0.31513056, -1.4624828 ,  0.48565704,\n",
      "        0.24599262,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5484326186276405, next_state=array([-0.10683908,  0.05557467, -0.33704966, -1.4411124 ,  0.49864826,\n",
      "        0.25982377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10683908,  0.05557467, -0.33704966, -1.4411124 ,  0.49864826,\n",
      "        0.25982377,  0.        ,  0.        ], dtype=float32), action=0, reward=6.905085554297301, next_state=array([-0.11009426,  0.02264479, -0.33703965, -1.4677914 ,  0.5116393 ,\n",
      "        0.2598208 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.11009426,  0.02264479, -0.33703965, -1.4677914 ,  0.5116393 ,\n",
      "        0.2598208 ,  0.        ,  1.        ], dtype=float32), action=1, reward=6.4502497678353174, next_state=array([-0.11288147, -0.00894555, -0.28816557, -1.4083415 ,  0.5144705 ,\n",
      "        0.04597649,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.11288147, -0.00894555, -0.28816557, -1.4083415 ,  0.5144705 ,\n",
      "        0.04597649,  0.        ,  1.        ], dtype=float32), action=3, reward=-100, next_state=array([-0.11636229, -0.0178542 , -0.14584404, -0.3835789 ,  0.2967791 ,\n",
      "       -4.118038  ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 0.00285606,  1.3999505 ,  0.2892547 , -0.48754552, -0.0033025 ,\n",
      "       -0.0655205 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0316313887047657, next_state=array([ 0.00578108,  1.3883971 ,  0.29753748, -0.513504  , -0.00828018,\n",
      "       -0.09956287,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00578108,  1.3883971 ,  0.29753748, -0.513504  , -0.00828018,\n",
      "       -0.09956287,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1277764084018418, next_state=array([ 0.00864229,  1.3762343 ,  0.28951317, -0.5405961 , -0.01164363,\n",
      "       -0.06727467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00864229,  1.3762343 ,  0.28951317, -0.5405961 , -0.01164363,\n",
      "       -0.06727467,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4264082153893582, next_state=array([ 0.0115036 ,  1.3634714 ,  0.28952235, -0.5672685 , -0.01500771,\n",
      "       -0.06728761,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0115036 ,  1.3634714 ,  0.28952235, -0.5672685 , -0.01500771,\n",
      "       -0.06728761,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3899412448843407, next_state=array([ 0.01436501,  1.3501086 ,  0.2895325 , -0.59393907, -0.01837091,\n",
      "       -0.06727009,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01436501,  1.3501086 ,  0.2895325 , -0.59393907, -0.01837091,\n",
      "       -0.06727009,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9524841039735168, next_state=array([ 0.01730318,  1.3361552 ,  0.29916963, -0.6202203 , -0.02366095,\n",
      "       -0.10581038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01730318,  1.3361552 ,  0.29916963, -0.6202203 , -0.02366095,\n",
      "       -0.10581038,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9807228622682487, next_state=array([ 0.02010088,  1.3221827 ,  0.2858447 , -0.621107  , -0.02966378,\n",
      "       -0.12006782,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02010088,  1.3221827 ,  0.2858447 , -0.621107  , -0.02966378,\n",
      "       -0.12006782,  0.        ,  0.        ], dtype=float32), action=2, reward=2.606402505299724, next_state=array([ 0.0227746 ,  1.3086413 ,  0.27413183, -0.60198915, -0.03635415,\n",
      "       -0.13381928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0227746 ,  1.3086413 ,  0.27413183, -0.60198915, -0.03635415,\n",
      "       -0.13381928,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.481248687144982, next_state=array([ 0.02553835,  1.2944846 ,  0.28543133, -0.62942886, -0.04531361,\n",
      "       -0.17920552,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02553835,  1.2944846 ,  0.28543133, -0.62942886, -0.04531361,\n",
      "       -0.17920552,  0.        ,  0.        ], dtype=float32), action=2, reward=2.432235211718461, next_state=array([ 0.02816916,  1.2807807 ,  0.27291128, -0.6093862 , -0.05505423,\n",
      "       -0.1948305 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02816916,  1.2807807 ,  0.27291128, -0.6093862 , -0.05505423,\n",
      "       -0.1948305 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9950924645915507, next_state=array([ 0.03080025,  1.2664778 ,  0.2729388 , -0.63607025, -0.06479311,\n",
      "       -0.19479522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03080025,  1.2664778 ,  0.2729388 , -0.63607025, -0.06479311,\n",
      "       -0.19479522,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3565279507446621, next_state=array([ 0.03334665,  1.2515768 ,  0.26231346, -0.6626169 , -0.07239684,\n",
      "       -0.15208799,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03334665,  1.2515768 ,  0.26231346, -0.6626169 , -0.07239684,\n",
      "       -0.15208799,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0073773798635546, next_state=array([ 0.0357996 ,  1.236093  ,  0.25055772, -0.6884291 , -0.07762228,\n",
      "       -0.10451839,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0357996 ,  1.236093  ,  0.25055772, -0.6884291 , -0.07762228,\n",
      "       -0.10451839,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.434564468944103, next_state=array([ 0.03825254,  1.2200096 ,  0.250572  , -0.7151006 , -0.08284748,\n",
      "       -0.10451357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03825254,  1.2200096 ,  0.250572  , -0.7151006 , -0.08284748,\n",
      "       -0.10451357,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9633275343339391, next_state=array([ 0.04070292,  1.2042229 ,  0.25054675, -0.70195186, -0.08831756,\n",
      "       -0.10941158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04070292,  1.2042229 ,  0.25054675, -0.70195186, -0.08831756,\n",
      "       -0.10941158,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.436145095936979, next_state=array([ 0.04315348,  1.1878362 ,  0.25056142, -0.72863066, -0.09378655,\n",
      "       -0.10938984,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04315348,  1.1878362 ,  0.25056142, -0.72863066, -0.09378655,\n",
      "       -0.10938984,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6005783939942093, next_state=array([ 0.04560156,  1.1721503 ,  0.250713  , -0.69753635, -0.0996477 ,\n",
      "       -0.11723383,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04560156,  1.1721503 ,  0.250713  , -0.69753635, -0.0996477 ,\n",
      "       -0.11723383,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1099597342795833, next_state=array([ 0.04812727,  1.1558495 ,  0.26044878, -0.7250205 , -0.10747598,\n",
      "       -0.15657982,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04812727,  1.1558495 ,  0.26044878, -0.7250205 , -0.10747598,\n",
      "       -0.15657982,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6208533487044292, next_state=array([ 0.05065327,  1.1389494 ,  0.26047152, -0.7516902 , -0.11530241,\n",
      "       -0.15654323,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05065327,  1.1389494 ,  0.26047152, -0.7516902 , -0.11530241,\n",
      "       -0.15654323,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0056449904270426, next_state=array([ 0.0531003 ,  1.1214666 ,  0.25053984, -0.7774713 , -0.1211082 ,\n",
      "       -0.1161265 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0531003 ,  1.1214666 ,  0.25053984, -0.7774713 , -0.1211082 ,\n",
      "       -0.1161265 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7984084562145017, next_state=array([ 0.05561104,  1.1033779 ,  0.2584985 , -0.8045597 , -0.12851271,\n",
      "       -0.1481032 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05561104,  1.1033779 ,  0.2584985 , -0.8045597 , -0.12851271,\n",
      "       -0.1481032 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4310607536820044, next_state=array([ 0.05812197,  1.0846897 ,  0.25851923, -0.8312349 , -0.13591503,\n",
      "       -0.14805934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05812197,  1.0846897 ,  0.25851923, -0.8312349 , -0.13591503,\n",
      "       -0.14805934,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8882983311039243, next_state=array([ 0.06056833,  1.0654273 ,  0.25035447, -0.85664326, -0.14162706,\n",
      "       -0.11425084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06056833,  1.0654273 ,  0.25035447, -0.85664326, -0.14162706,\n",
      "       -0.11425084,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.166354236627086, next_state=array([ 0.06301489,  1.0455652 ,  0.25036904, -0.88331646, -0.14733896,\n",
      "       -0.11424799,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06301489,  1.0455652 ,  0.25036904, -0.88331646, -0.14733896,\n",
      "       -0.11424799,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2510033987111173, next_state=array([ 0.06549902,  1.026257  ,  0.25447673, -0.8587469 , -0.1534011 ,\n",
      "       -0.1212538 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06549902,  1.026257  ,  0.25447673, -0.8587469 , -0.1534011 ,\n",
      "       -0.1212538 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.267119982496365, next_state=array([ 0.06789617,  1.0069771 ,  0.24647358, -0.85759825, -0.16015655,\n",
      "       -0.13510859,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06789617,  1.0069771 ,  0.24647358, -0.85759825, -0.16015655,\n",
      "       -0.13510859,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2751728630332195, next_state=array([ 0.07029343,  0.98709786,  0.24647267, -0.88426876, -0.16691197,\n",
      "       -0.13510822,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07029343,  0.98709786,  0.24647267, -0.88426876, -0.16691197,\n",
      "       -0.13510822,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7251078609265267, next_state=array([ 0.0727603 ,  0.96660864,  0.25519937, -0.9116134 , -0.17543313,\n",
      "       -0.17042325,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0727603 ,  0.96660864,  0.25519937, -0.9116134 , -0.17543313,\n",
      "       -0.17042325,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3397412437481933, next_state=array([ 0.07522736,  0.94552034,  0.2551978 , -0.938286  , -0.18395424,\n",
      "       -0.17042258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07522736,  0.94552034,  0.2551978 , -0.938286  , -0.18395424,\n",
      "       -0.17042258,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2868839305253914, next_state=array([ 0.07769451,  0.9238329 ,  0.25519615, -0.9649586 , -0.19247532,\n",
      "       -0.17042181,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07769451,  0.9238329 ,  0.25519615, -0.9649586 , -0.19247532,\n",
      "       -0.17042181,  0.        ,  0.        ], dtype=float32), action=2, reward=4.48672822840332, next_state=array([ 0.08029918,  0.90308106,  0.26922643, -0.92347056, -0.20127648,\n",
      "       -0.17602332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08029918,  0.90308106,  0.26922643, -0.92347056, -0.20127648,\n",
      "       -0.17602332,  0.        ,  0.        ], dtype=float32), action=2, reward=1.689072268289476, next_state=array([ 0.08315964,  0.882692  ,  0.29421812, -0.9073213 , -0.2095119 ,\n",
      "       -0.16470852,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08315964,  0.882692  ,  0.29421812, -0.9073213 , -0.2095119 ,\n",
      "       -0.16470852,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.302698149101957, next_state=array([ 0.08602028,  0.86170363,  0.2942164 , -0.9339935 , -0.21774729,\n",
      "       -0.16470757,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08602028,  0.86170363,  0.2942164 , -0.9339935 , -0.21774729,\n",
      "       -0.16470757,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5568934282552209, next_state=array([ 0.0887867 ,  0.84014153,  0.28237653, -0.959173  , -0.2235461 ,\n",
      "       -0.11597645,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0887867 ,  0.84014153,  0.28237653, -0.959173  , -0.2235461 ,\n",
      "       -0.11597645,  0.        ,  0.        ], dtype=float32), action=2, reward=3.656115926516134, next_state=array([ 0.09157143,  0.819201  ,  0.28494325, -0.93168014, -0.23009703,\n",
      "       -0.13101865,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09157143,  0.819201  ,  0.28494325, -0.93168014, -0.23009703,\n",
      "       -0.13101865,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0487122425089808, next_state=array([ 0.09457465,  0.7983948 ,  0.30630833, -0.9256721 , -0.23618062,\n",
      "       -0.12167136,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09457465,  0.7983948 ,  0.30630833, -0.9256721 , -0.23618062,\n",
      "       -0.12167136,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2508799827710504, next_state=array([ 0.09751625,  0.7775993 ,  0.3008538 , -0.9253324 , -0.24298128,\n",
      "       -0.1360137 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09751625,  0.7775993 ,  0.3008538 , -0.9253324 , -0.24298128,\n",
      "       -0.1360137 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.283935014630157, next_state=array([ 0.10072565,  0.7575576 ,  0.32742575, -0.8918304 , -0.24958354,\n",
      "       -0.13204513,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10072565,  0.7575576 ,  0.32742575, -0.8918304 , -0.24958354,\n",
      "       -0.13204513,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3188283360530136, next_state=array([ 0.10416327,  0.7375331 ,  0.34970397, -0.89100194, -0.2556322 ,\n",
      "       -0.12097318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10416327,  0.7375331 ,  0.34970397, -0.89100194, -0.2556322 ,\n",
      "       -0.12097318,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9141933418553652, next_state=array([ 0.10768652,  0.7168765 ,  0.3604622 , -0.919508  , -0.26394096,\n",
      "       -0.16617562,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10768652,  0.7168765 ,  0.3604622 , -0.919508  , -0.26394096,\n",
      "       -0.16617562,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1143345752813603, next_state=array([ 0.11129866,  0.6955875 ,  0.37160987, -0.94808596, -0.2745931 ,\n",
      "       -0.21304289,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11129866,  0.6955875 ,  0.37160987, -0.94808596, -0.2745931 ,\n",
      "       -0.21304289,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2561234903357217, next_state=array([ 0.11489916,  0.67445916,  0.37109548, -0.9411526 , -0.28593215,\n",
      "       -0.22678065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11489916,  0.67445916,  0.37109548, -0.9411526 , -0.28593215,\n",
      "       -0.22678065,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2539507009044812, next_state=array([ 0.11857672,  0.65270865,  0.38068968, -0.9692791 , -0.29926956,\n",
      "       -0.2667483 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11857672,  0.65270865,  0.38068968, -0.9692791 , -0.29926956,\n",
      "       -0.2667483 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9968966304479909, next_state=array([ 0.12218037,  0.6303977 ,  0.37130493, -0.99388576, -0.31058103,\n",
      "       -0.22622915,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12218037,  0.6303977 ,  0.37130493, -0.99388576, -0.31058103,\n",
      "       -0.22622915,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2702435103633705, next_state=array([ 0.12586717,  0.60745114,  0.38171592, -1.0226971 , -0.32412493,\n",
      "       -0.2708779 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12586717,  0.60745114,  0.38171592, -1.0226971 , -0.32412493,\n",
      "       -0.2708779 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6329481643276722, next_state=array([ 0.12955455,  0.5839068 ,  0.3817087 , -1.0493784 , -0.33766866,\n",
      "       -0.2708745 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12955455,  0.5839068 ,  0.3817087 , -1.0493784 , -0.33766866,\n",
      "       -0.2708745 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.0077961983383377, next_state=array([ 0.13351497,  0.56122404,  0.4092381 , -1.0112762 , -0.35151303,\n",
      "       -0.27688742,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13351497,  0.56122404,  0.4092381 , -1.0112762 , -0.35151303,\n",
      "       -0.27688742,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.533855493439232, next_state=array([ 0.13755122,  0.5378965 ,  0.41879192, -1.040568  , -0.36749473,\n",
      "       -0.31963435,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13755122,  0.5378965 ,  0.41879192, -1.040568  , -0.36749473,\n",
      "       -0.31963435,  0.        ,  0.        ], dtype=float32), action=2, reward=0.22876468730374883, next_state=array([ 0.14173488,  0.51471364,  0.4336148 , -1.0343444 , -0.3836648 ,\n",
      "       -0.32340086,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14173488,  0.51471364,  0.4336148 , -1.0343444 , -0.3836648 ,\n",
      "       -0.32340086,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4689680844310374, next_state=array([ 0.14591894,  0.4916344 ,  0.4343009 , -1.0301176 , -0.40064523,\n",
      "       -0.3396086 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14591894,  0.4916344 ,  0.4343009 , -1.0301176 , -0.40064523,\n",
      "       -0.3396086 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.282687430672495, next_state=array([ 0.15002966,  0.467998  ,  0.4249565 , -1.0545002 , -0.4155651 ,\n",
      "       -0.2983973 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15002966,  0.467998  ,  0.4249565 , -1.0545002 , -0.4155651 ,\n",
      "       -0.2983973 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0534592532637521, next_state=array([ 0.15406446,  0.44380346,  0.4153017 , -1.0788445 , -0.42836136,\n",
      "       -0.25592524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15406446,  0.44380346,  0.4153017 , -1.0788445 , -0.42836136,\n",
      "       -0.25592524,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1698364433945985, next_state=array([ 0.15835257,  0.4202695 ,  0.4410788 , -1.0497484 , -0.44170517,\n",
      "       -0.26687613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15835257,  0.4202695 ,  0.4410788 , -1.0497484 , -0.44170517,\n",
      "       -0.26687613,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7800099250852086, next_state=array([ 0.16272621,  0.3960655 ,  0.45193094, -1.0804054 , -0.45765787,\n",
      "       -0.31905416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16272621,  0.3960655 ,  0.45193094, -1.0804054 , -0.45765787,\n",
      "       -0.31905416,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2680105250955467, next_state=array([ 0.16703758,  0.37130815,  0.44390082, -1.1045862 , -0.4717521 ,\n",
      "       -0.28188488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16703758,  0.37130815,  0.44390082, -1.1045862 , -0.4717521 ,\n",
      "       -0.28188488,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7800100939585377, next_state=array([ 0.17134972,  0.3459532 ,  0.44388962, -1.1312677 , -0.48584613,\n",
      "       -0.2818805 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17134972,  0.3459532 ,  0.44388962, -1.1312677 , -0.48584613,\n",
      "       -0.2818805 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.42909339072811, next_state=array([ 0.1759266 ,  0.32114562,  0.47078577, -1.1072415 , -0.5005084 ,\n",
      "       -0.29324582,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1759266 ,  0.32114562,  0.47078577, -1.1072415 , -0.5005084 ,\n",
      "       -0.29324582,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3153592299102684, next_state=array([ 0.1808217 ,  0.2967152 ,  0.50263387, -1.0906582 , -0.5153249 ,\n",
      "       -0.29632953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1808217 ,  0.2967152 ,  0.50263387, -1.0906582 , -0.5153249 ,\n",
      "       -0.29632953,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.24256071610263347, next_state=array([ 0.18607864,  0.27262667,  0.53869265, -1.0755767 , -0.5301157 ,\n",
      "       -0.29581758,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18607864,  0.27262667,  0.53869265, -1.0755767 , -0.5301157 ,\n",
      "       -0.29581758,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8017872892401783, next_state=array([ 0.19171457,  0.24927293,  0.5769602 , -1.0432522 , -0.54547495,\n",
      "       -0.307184  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19171457,  0.24927293,  0.5769602 , -1.0432522 , -0.54547495,\n",
      "       -0.307184  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3829442957870697, next_state=array([ 0.19735155,  0.2253218 ,  0.57694495, -1.0699356 , -0.5608339 ,\n",
      "       -0.307179  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19735155,  0.2253218 ,  0.57694495, -1.0699356 , -0.5608339 ,\n",
      "       -0.307179  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.488155158786725, next_state=array([ 0.20298958,  0.20077343,  0.5769294 , -1.096619  , -0.57619256,\n",
      "       -0.30717403,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20298958,  0.20077343,  0.5769294 , -1.096619  , -0.57619256,\n",
      "       -0.30717403,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7773372571855066, next_state=array([ 0.2085679 ,  0.17569007,  0.5690934 , -1.1197643 , -0.5895096 ,\n",
      "       -0.26634043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2085679 ,  0.17569007,  0.5690934 , -1.1197643 , -0.5895096 ,\n",
      "       -0.26634043,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5908429573435114, next_state=array([ 0.214147  ,  0.15000866,  0.5690811 , -1.1464435 , -0.6028265 ,\n",
      "       -0.26633754,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.214147  ,  0.15000866,  0.5690811 , -1.1464435 , -0.6028265 ,\n",
      "       -0.26633754,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.797014277046827, next_state=array([ 0.21972713,  0.12372917,  0.56906855, -1.1731225 , -0.61614317,\n",
      "       -0.2663343 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21972713,  0.12372917,  0.56906855, -1.1731225 , -0.61614317,\n",
      "       -0.2663343 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.044017732980734, next_state=array([ 0.22530814,  0.09685165,  0.56905574, -1.1998013 , -0.62945974,\n",
      "       -0.26633102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22530814,  0.09685165,  0.56905574, -1.1998013 , -0.62945974,\n",
      "       -0.26633102,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.379923451229529, next_state=array([ 0.23096208,  0.06930286,  0.57822406, -1.2307088 , -0.64520246,\n",
      "       -0.31485555,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23096208,  0.06930286,  0.57822406, -1.2307088 , -0.64520246,\n",
      "       -0.31485555,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.896611258466976, next_state=array([ 0.23661728,  0.04115675,  0.5782055 , -1.257392  , -0.66094494,\n",
      "       -0.31485015,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23661728,  0.04115675,  0.5782055 , -1.257392  , -0.66094494,\n",
      "       -0.31485015,  0.        ,  0.        ], dtype=float32), action=2, reward=7.773839869499949, next_state=array([ 0.24286194,  0.0136581 ,  0.6371526 , -1.2288381 , -0.6768959 ,\n",
      "       -0.31901985,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24286194,  0.0136581 ,  0.6371526 , -1.2288381 , -0.6768959 ,\n",
      "       -0.31901985,  1.        ,  0.        ], dtype=float32), action=1, reward=4.770340670511275, next_state=array([ 0.24913521, -0.01279667,  0.6260551 , -1.1753099 , -0.67522097,\n",
      "        0.03384558,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24913521, -0.01279667,  0.6260551 , -1.1753099 , -0.67522097,\n",
      "        0.03384558,  1.        ,  0.        ], dtype=float32), action=3, reward=-2.782647682765371, next_state=array([ 0.2558635 , -0.0398314 ,  0.6604023 , -1.1950036 , -0.65957403,\n",
      "        0.31295162,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2558635 , -0.0398314 ,  0.6604023 , -1.1950036 , -0.65957403,\n",
      "        0.31295162,  1.        ,  0.        ], dtype=float32), action=2, reward=-100, next_state=array([ 0.2656067 , -0.05846743,  0.8673851 , -0.70122135, -0.5083145 ,\n",
      "        3.4587142 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([ 0.00233908,  1.403744  ,  0.23691075, -0.3189308 , -0.00270364,\n",
      "       -0.05366374,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4854162943490494, next_state=array([ 0.00476809,  1.3959854 ,  0.2478685 , -0.34484944, -0.00761757,\n",
      "       -0.09828721,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00476809,  1.3959854 ,  0.2478685 , -0.34484944, -0.00761757,\n",
      "       -0.09828721,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2839043363491374, next_state=array([ 0.00713005,  1.3876169 ,  0.23945165, -0.3719531 , -0.01083862,\n",
      "       -0.06442702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00713005,  1.3876169 ,  0.23945165, -0.3719531 , -0.01083862,\n",
      "       -0.06442702,  0.        ,  0.        ], dtype=float32), action=2, reward=3.155849321704591, next_state=array([ 0.00935526,  1.3798845 ,  0.22648661, -0.34368876, -0.01475906,\n",
      "       -0.07841613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00935526,  1.3798845 ,  0.22648661, -0.34368876, -0.01475906,\n",
      "       -0.07841613,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6159623470229563, next_state=array([ 0.01166763,  1.37156   ,  0.23741174, -0.37005588, -0.02086425,\n",
      "       -0.12211502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01166763,  1.37156   ,  0.23741174, -0.37005588, -0.02086425,\n",
      "       -0.12211502,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9879557105442984, next_state=array([ 0.0139802 ,  1.3626359 ,  0.2374305 , -0.39672187, -0.02696779,\n",
      "       -0.12208247,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0139802 ,  1.3626359 ,  0.2374305 , -0.39672187, -0.02696779,\n",
      "       -0.12208247,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5646941244894321, next_state=array([ 0.01629448,  1.3538754 ,  0.23766768, -0.38948217, -0.03312846,\n",
      "       -0.12322482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01629448,  1.3538754 ,  0.23766768, -0.38948217, -0.03312846,\n",
      "       -0.12322482,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.829819933343144, next_state=array([ 0.01870136,  1.3445162 ,  0.24926135, -0.4161806 , -0.04160791,\n",
      "       -0.16960448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01870136,  1.3445162 ,  0.24926135, -0.4161806 , -0.04160791,\n",
      "       -0.16960448,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3551398919134374, next_state=array([ 0.0210146 ,  1.3345648 ,  0.2374945 , -0.44246516, -0.04771695,\n",
      "       -0.12219197,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0210146 ,  1.3345648 ,  0.2374945 , -0.44246516, -0.04771695,\n",
      "       -0.12219197,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.518078079806655, next_state=array([ 0.02339048,  1.3240036 ,  0.24536438, -0.4696521 , -0.05540835,\n",
      "       -0.15384242,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02339048,  1.3240036 ,  0.24536438, -0.4696521 , -0.05540835,\n",
      "       -0.15384242,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8413492431679956, next_state=array([ 0.02585545,  1.3128325 ,  0.25651467, -0.49688658, -0.06533642,\n",
      "       -0.19857924,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02585545,  1.3128325 ,  0.25651467, -0.49688658, -0.06533642,\n",
      "       -0.19857924,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6477297536876552, next_state=array([ 0.02825384,  1.3010745 ,  0.24814825, -0.5229556 , -0.07356806,\n",
      "       -0.16464768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02825384,  1.3010745 ,  0.24814825, -0.5229556 , -0.07356806,\n",
      "       -0.16464768,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4857930382439395, next_state=array([ 0.03058128,  1.2887199 ,  0.23923782, -0.54943395, -0.08000842,\n",
      "       -0.12881902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03058128,  1.2887199 ,  0.23923782, -0.54943395, -0.08000842,\n",
      "       -0.12881902,  0.        ,  0.        ], dtype=float32), action=2, reward=3.0267488830454683, next_state=array([ 0.03309584,  1.2772479 ,  0.2574334 , -0.51019675, -0.08594152,\n",
      "       -0.11867287,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03309584,  1.2772479 ,  0.2574334 , -0.51019675, -0.08594152,\n",
      "       -0.11867287,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.403144407480822, next_state=array([ 0.0356821 ,  1.2651753 ,  0.26642   , -0.5370115 , -0.09366921,\n",
      "       -0.15456763,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0356821 ,  1.2651753 ,  0.26642   , -0.5370115 , -0.09366921,\n",
      "       -0.15456763,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9147923399084448, next_state=array([ 0.03826876,  1.2525039 ,  0.2664431 , -0.5636799 , -0.10139475,\n",
      "       -0.1545249 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03826876,  1.2525039 ,  0.2664431 , -0.5636799 , -0.10139475,\n",
      "       -0.1545249 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4893143561987174, next_state=array([ 0.04091978,  1.239215  ,  0.27452272, -0.5912832 , -0.11076174,\n",
      "       -0.187357  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04091978,  1.239215  ,  0.27452272, -0.5912832 , -0.11076174,\n",
      "       -0.187357  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.455331803080951, next_state=array([ 0.04351034,  1.2253488 ,  0.2668927 , -0.616871  , -0.11855618,\n",
      "       -0.15590313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04351034,  1.2253488 ,  0.2668927 , -0.616871  , -0.11855618,\n",
      "       -0.15590313,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0478850974599527, next_state=array([ 0.04601164,  1.2109107 ,  0.25563267, -0.64214844, -0.12404327,\n",
      "       -0.10975184,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04601164,  1.2109107 ,  0.25563267, -0.64214844, -0.12404327,\n",
      "       -0.10975184,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9524790743856044, next_state=array([ 0.04869843,  1.1967232 ,  0.27364674, -0.6309669 , -0.12899846,\n",
      "       -0.09911276,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04869843,  1.1967232 ,  0.27364674, -0.6309669 , -0.12899846,\n",
      "       -0.09911276,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4853150971443085, next_state=array([ 0.05138531,  1.181936  ,  0.2736588 , -0.6576458 , -0.13395287,\n",
      "       -0.09909703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05138531,  1.181936  ,  0.2736588 , -0.6576458 , -0.13395287,\n",
      "       -0.09909703,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9147271160935861, next_state=array([ 0.05400915,  1.1665702 ,  0.26570004, -0.68323004, -0.13726845,\n",
      "       -0.06631762,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05400915,  1.1665702 ,  0.26570004, -0.68323004, -0.13726845,\n",
      "       -0.06631762,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.790393914193628, next_state=array([ 0.05656967,  1.1506125 ,  0.2577799 , -0.70939654, -0.1389848 ,\n",
      "       -0.03432954,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05656967,  1.1506125 ,  0.2577799 , -0.70939654, -0.1389848 ,\n",
      "       -0.03432954,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7646932213698223, next_state=array([ 0.05916824,  1.1351042 ,  0.26184583, -0.68944997, -0.14097685,\n",
      "       -0.03984446,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05916824,  1.1351042 ,  0.26184583, -0.68944997, -0.14097685,\n",
      "       -0.03984446,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7455459829300242, next_state=array([ 0.06183891,  1.118973  ,  0.2709188 , -0.71731013, -0.1448294 ,\n",
      "       -0.07705815,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06183891,  1.118973  ,  0.2709188 , -0.71731013, -0.1448294 ,\n",
      "       -0.07705815,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8208903399119822, next_state=array([ 0.06443615,  1.1022263 ,  0.2617893 , -0.7445029 , -0.14688875,\n",
      "       -0.04118656,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06443615,  1.1022263 ,  0.2617893 , -0.7445029 , -0.14688875,\n",
      "       -0.04118656,  0.        ,  0.        ], dtype=float32), action=2, reward=1.073878943510249, next_state=array([ 0.06711407,  1.0855248 ,  0.26977843, -0.74248666, -0.14886992,\n",
      "       -0.03962338,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06711407,  1.0855248 ,  0.26977843, -0.74248666, -0.14886992,\n",
      "       -0.03962338,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4511636901599718, next_state=array([ 0.06971093,  1.0682293 ,  0.259626  , -0.7686813 , -0.1488141 ,\n",
      "        0.00111652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06971093,  1.0682293 ,  0.259626  , -0.7686813 , -0.1488141 ,\n",
      "        0.00111652,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1641535363138462, next_state=array([ 0.07222614,  1.0503533 ,  0.24936981, -0.79427296, -0.14666677,\n",
      "        0.04294667,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07222614,  1.0503533 ,  0.24936981, -0.79427296, -0.14666677,\n",
      "        0.04294667,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3727617655597557, next_state=array([ 0.07476254,  1.0329151 ,  0.25186336, -0.77485937, -0.1448896 ,\n",
      "        0.03554321,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07476254,  1.0329151 ,  0.25186336, -0.77485937, -0.1448896 ,\n",
      "        0.03554321,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5823320617427896, next_state=array([ 0.07729902,  1.014877  ,  0.2518633 , -0.8015263 , -0.14311242,\n",
      "        0.03554337,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07729902,  1.014877  ,  0.2518633 , -0.8015263 , -0.14311242,\n",
      "        0.03554337,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2470328564663749, next_state=array([ 0.07993412,  0.9962277 ,  0.2642135 , -0.82892406, -0.14382255,\n",
      "       -0.01420258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07993412,  0.9962277 ,  0.2642135 , -0.82892406, -0.14382255,\n",
      "       -0.01420258,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2318710140069686, next_state=array([ 0.08249263,  0.9769853 ,  0.2546429 , -0.85510296, -0.1426095 ,\n",
      "        0.02426064,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08249263,  0.9769853 ,  0.2546429 , -0.85510296, -0.1426095 ,\n",
      "        0.02426064,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1657497171743774, next_state=array([ 0.08513413,  0.95711344,  0.2650928 , -0.88327765, -0.14354911,\n",
      "       -0.0187922 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08513413,  0.95711344,  0.2650928 , -0.88327765, -0.14354911,\n",
      "       -0.0187922 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.268050714053442, next_state=array([ 0.08802529,  0.9380645 ,  0.28953683, -0.84666425, -0.14397313,\n",
      "       -0.0084804 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08802529,  0.9380645 ,  0.28953683, -0.84666425, -0.14397313,\n",
      "       -0.0084804 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2972175101643575, next_state=array([ 0.09099932,  0.9184005 ,  0.29994732, -0.87420195, -0.1465076 ,\n",
      "       -0.05068956,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09099932,  0.9184005 ,  0.29994732, -0.87420195, -0.1465076 ,\n",
      "       -0.05068956,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5145127255821922, next_state=array([ 0.09405651,  0.898108  ,  0.31042185, -0.9023575 , -0.15119955,\n",
      "       -0.09383907,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09405651,  0.898108  ,  0.31042185, -0.9023575 , -0.15119955,\n",
      "       -0.09383907,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2501498889199627, next_state=array([ 0.09701872,  0.87723744,  0.29846838, -0.9278125 , -0.15345596,\n",
      "       -0.04512814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09701872,  0.87723744,  0.29846838, -0.9278125 , -0.15345596,\n",
      "       -0.04512814,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.09872385987472285, next_state=array([ 0.09990577,  0.85579246,  0.28901702, -0.9531433 , -0.15376456,\n",
      "       -0.00617171,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09990577,  0.85579246,  0.28901702, -0.9531433 , -0.15376456,\n",
      "       -0.00617171,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4313148254967132, next_state=array([ 0.10279293,  0.83374745,  0.28901702, -0.97981   , -0.15407315,\n",
      "       -0.00617185,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10279293,  0.83374745,  0.28901702, -0.97981   , -0.15407315,\n",
      "       -0.00617185,  0.        ,  0.        ], dtype=float32), action=1, reward=0.33445438771480096, next_state=array([ 0.10558414,  0.8111368 ,  0.2769375 , -1.004699  , -0.15188803,\n",
      "        0.04370207,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10558414,  0.8111368 ,  0.2769375 , -1.004699  , -0.15188803,\n",
      "        0.04370207,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.09112385904700204, next_state=array([ 0.10837545,  0.787926  ,  0.27693743, -1.031366  , -0.14970292,\n",
      "        0.04370205,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10837545,  0.787926  ,  0.27693743, -1.031366  , -0.14970292,\n",
      "        0.04370205,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5245633058493115, next_state=array([ 0.11123352,  0.7641031 ,  0.28532416, -1.0587445 , -0.14921866,\n",
      "        0.00968488,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11123352,  0.7641031 ,  0.28532416, -1.0587445 , -0.14921866,\n",
      "        0.00968488,  0.        ,  0.        ], dtype=float32), action=1, reward=0.44829100625750695, next_state=array([ 0.11400471,  0.7397072 ,  0.2743925 , -1.0839899 , -0.14648958,\n",
      "        0.05458171,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11400471,  0.7397072 ,  0.2743925 , -1.0839899 , -0.14648958,\n",
      "        0.05458171,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4341665875554941, next_state=array([ 0.11685982,  0.714705  ,  0.28487772, -1.1111534 , -0.14586508,\n",
      "        0.01249007,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11685982,  0.714705  ,  0.28487772, -1.1111534 , -0.14586508,\n",
      "        0.01249007,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.04537214451980276, next_state=array([ 0.11971493,  0.6891026 ,  0.28487772, -1.13782   , -0.14524059,\n",
      "        0.01248997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11971493,  0.6891026 ,  0.28487772, -1.13782   , -0.14524059,\n",
      "        0.01248997,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5932677562650508, next_state=array([ 0.12247686,  0.66292065,  0.27318537, -1.1633507 , -0.14223708,\n",
      "        0.06007054,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12247686,  0.66292065,  0.27318537, -1.1633507 , -0.14223708,\n",
      "        0.06007054,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7366810423473293, next_state=array([ 0.12516956,  0.6361613 ,  0.26445085, -1.1888505 , -0.1374394 ,\n",
      "        0.09595369,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12516956,  0.6361613 ,  0.26445085, -1.1888505 , -0.1374394 ,\n",
      "        0.09595369,  0.        ,  0.        ], dtype=float32), action=1, reward=1.0963041498078223, next_state=array([ 0.12776919,  0.60883003,  0.2527409 , -1.2140781 , -0.13024414,\n",
      "        0.14390543,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12776919,  0.60883003,  0.2527409 , -1.2140781 , -0.13024414,\n",
      "        0.14390543,  0.        ,  0.        ], dtype=float32), action=3, reward=0.29983643454707587, next_state=array([ 0.13043766,  0.5808796 ,  0.26138094, -1.2417738 , -0.12481508,\n",
      "        0.1085811 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13043766,  0.5808796 ,  0.26138094, -1.2417738 , -0.12481508,\n",
      "        0.1085811 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.6915435469152955, next_state=array([ 0.13307743,  0.55335176,  0.25904846, -1.223058  , -0.11990931,\n",
      "        0.09811543,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13307743,  0.55335176,  0.25904846, -1.223058  , -0.11990931,\n",
      "        0.09811543,  0.        ,  0.        ], dtype=float32), action=1, reward=0.83707854334432, next_state=array([ 0.1356575 ,  0.5252264 ,  0.25157246, -1.2495141 , -0.11350766,\n",
      "        0.1280327 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1356575 ,  0.5252264 ,  0.25157246, -1.2495141 , -0.11350766,\n",
      "        0.1280327 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7321648888556638, next_state=array([ 0.13823767,  0.4965015 ,  0.25157183, -1.2761842 , -0.10710605,\n",
      "        0.12803228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13823767,  0.4965015 ,  0.25157183, -1.2761842 , -0.10710605,\n",
      "        0.12803228,  0.        ,  0.        ], dtype=float32), action=2, reward=6.053531427073421, next_state=array([ 0.14089422,  0.46852648,  0.25929832, -1.2428907 , -0.10079779,\n",
      "        0.12616518,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14089422,  0.46852648,  0.25929832, -1.2428907 , -0.10079779,\n",
      "        0.12616518,  0.        ,  0.        ], dtype=float32), action=2, reward=6.200504136041116, next_state=array([ 0.14377193,  0.44142166,  0.28084868, -1.2042075 , -0.09392713,\n",
      "        0.13741295,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14377193,  0.44142166,  0.28084868, -1.2042075 , -0.09392713,\n",
      "        0.13741295,  0.        ,  0.        ], dtype=float32), action=1, reward=1.1916652153127256, next_state=array([ 0.1465561 ,  0.4137387 ,  0.26906663, -1.2297914 , -0.08466891,\n",
      "        0.18516436,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1465561 ,  0.4137387 ,  0.26906663, -1.2297914 , -0.08466891,\n",
      "        0.18516436,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2359656391192015, next_state=array([ 0.1492732 ,  0.38546586,  0.260659  , -1.2559795 , -0.07371771,\n",
      "        0.21902426,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1492732 ,  0.38546586,  0.260659  , -1.2559795 , -0.07371771,\n",
      "        0.21902426,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6724660553813362, next_state=array([ 0.15205964,  0.35659626,  0.26933077, -1.2826611 , -0.06449881,\n",
      "        0.18437755,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15205964,  0.35659626,  0.26933077, -1.2826611 , -0.06449881,\n",
      "        0.18437755,  0.        ,  0.        ], dtype=float32), action=1, reward=1.192478525981728, next_state=array([ 0.1547781 ,  0.32712516,  0.2607893 , -1.3093841 , -0.05357441,\n",
      "        0.2184881 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1547781 ,  0.32712516,  0.2607893 , -1.3093841 , -0.05357441,\n",
      "        0.2184881 ,  0.        ,  0.        ], dtype=float32), action=1, reward=1.4502875826780166, next_state=array([ 0.15742102,  0.29706967,  0.25129986, -1.3353869 , -0.04073894,\n",
      "        0.25670975,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15742102,  0.29706967,  0.25129986, -1.3353869 , -0.04073894,\n",
      "        0.25670975,  0.        ,  0.        ], dtype=float32), action=2, reward=4.9423511910111815, next_state=array([ 0.15995589,  0.26732984,  0.24112158, -1.3214787 , -0.02851712,\n",
      "        0.24443626,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15995589,  0.26732984,  0.24112158, -1.3214787 , -0.02851712,\n",
      "        0.24443626,  0.        ,  0.        ], dtype=float32), action=1, reward=1.4073814411466128, next_state=array([ 0.16240788,  0.23699835,  0.2307078 , -1.3478547 , -0.01420763,\n",
      "        0.28618994,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16240788,  0.23699835,  0.2307078 , -1.3478547 , -0.01420763,\n",
      "        0.28618994,  0.        ,  0.        ], dtype=float32), action=0, reward=1.1202707760759552, next_state=array([ 1.6485986e-01,  2.0606954e-01,  2.3070720e-01, -1.3745385e+00,\n",
      "        1.0167399e-04,  2.8618592e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.6485986e-01,  2.0606954e-01,  2.3070720e-01, -1.3745385e+00,\n",
      "        1.0167399e-04,  2.8618592e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.8402402814320442, next_state=array([ 0.16739483,  0.17454572,  0.2411063 , -1.4011066 ,  0.01232815,\n",
      "        0.24452946,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16739483,  0.17454572,  0.2411063 , -1.4011066 ,  0.01232815,\n",
      "        0.24452946,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9042876245045466, next_state=array([ 0.1698412 ,  0.14242502,  0.23000614, -1.4277729 ,  0.02677725,\n",
      "        0.2889822 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1698412 ,  0.14242502,  0.23000614, -1.4277729 ,  0.02677725,\n",
      "        0.2889822 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.427601992176817, next_state=array([ 0.17219429,  0.10970622,  0.21830812, -1.4545561 ,  0.04356913,\n",
      "        0.33583724,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17219429,  0.10970622,  0.21830812, -1.4545561 ,  0.04356913,\n",
      "        0.33583724,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.920066015629628, next_state=array([ 0.17464514,  0.07639182,  0.23057668, -1.4811232 ,  0.05790425,\n",
      "        0.2867027 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17464514,  0.07639182,  0.23057668, -1.4811232 ,  0.05790425,\n",
      "        0.2867027 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.204719479081716, next_state=array([ 0.17719431,  0.04247754,  0.24292079, -1.5078075 ,  0.06977156,\n",
      "        0.2373461 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17719431,  0.04247754,  0.24292079, -1.5078075 ,  0.06977156,\n",
      "        0.2373461 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.824728688778879, next_state=array([ 0.17970876,  0.00865124,  0.23947799, -1.5039936 ,  0.081627  ,\n",
      "        0.23710878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17970876,  0.00865124,  0.23947799, -1.5039936 ,  0.081627  ,\n",
      "        0.23710878,  0.        ,  0.        ], dtype=float32), action=2, reward=27.1332147874687, next_state=array([ 0.18234968, -0.02341714,  0.2742998 , -1.4243253 ,  0.07580718,\n",
      "       -0.11092671,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.18234968, -0.02341714,  0.2742998 , -1.4243253 ,  0.07580718,\n",
      "       -0.11092671,  1.        ,  1.        ], dtype=float32), action=0, reward=-100, next_state=array([ 1.8342943e-01, -3.8249042e-02,  1.4630417e-02,  7.2354137e-04,\n",
      "        5.4082099e-02,  4.0019783e-03,  1.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([-0.00219927,  1.4203746 , -0.22277927,  0.42018983,  0.00255522,\n",
      "        0.05046285,  0.        ,  0.        ], dtype=float32), action=1, reward=0.35432376654535, next_state=array([-0.00447903,  1.4292618 , -0.23254192,  0.3949763 ,  0.00706689,\n",
      "        0.09024228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00447903,  1.4292618 , -0.23254192,  0.3949763 ,  0.00706689,\n",
      "        0.09024228,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.8763470218167866, next_state=array([-0.00692015,  1.4385386 , -0.24790458,  0.4122725 ,  0.01082421,\n",
      "        0.07515304,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00692015,  1.4385386 , -0.24790458,  0.4122725 ,  0.01082421,\n",
      "        0.07515304,  0.        ,  0.        ], dtype=float32), action=3, reward=1.895531553014224, next_state=array([-0.00926685,  1.4472047 , -0.23607525,  0.38515407,  0.01220973,\n",
      "        0.02771309,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00926685,  1.4472047 , -0.23607525,  0.38515407,  0.01220973,\n",
      "        0.02771309,  0.        ,  0.        ], dtype=float32), action=0, reward=1.303625314995628, next_state=array([-0.01161365,  1.455271  , -0.23607883,  0.3584899 ,  0.0135958 ,\n",
      "        0.0277237 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01161365,  1.455271  , -0.23607883,  0.3584899 ,  0.0135958 ,\n",
      "        0.0277237 ,  0.        ,  0.        ], dtype=float32), action=0, reward=1.3133568445636001, next_state=array([-0.01396046,  1.4627373 , -0.23608312,  0.33182213,  0.01498111,\n",
      "        0.02770898,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01396046,  1.4627373 , -0.23608312,  0.33182213,  0.01498111,\n",
      "        0.02770898,  0.        ,  0.        ], dtype=float32), action=0, reward=1.314208963050163, next_state=array([-0.01630735,  1.4696037 , -0.2360874 ,  0.3051537 ,  0.01636622,\n",
      "        0.02770474,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01630735,  1.4696037 , -0.2360874 ,  0.3051537 ,  0.01636622,\n",
      "        0.02770474,  0.        ,  0.        ], dtype=float32), action=3, reward=1.9972883875251466, next_state=array([-0.01858587,  1.4758687 , -0.22752006,  0.27845588,  0.01603302,\n",
      "       -0.00666461,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01858587,  1.4758687 , -0.22752006,  0.27845588,  0.01603302,\n",
      "       -0.00666461,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.149851320678823, next_state=array([-0.02096396,  1.4826105 , -0.23704278,  0.29963914,  0.015282  ,\n",
      "       -0.01502187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02096396,  1.4826105 , -0.23704278,  0.29963914,  0.015282  ,\n",
      "       -0.01502187,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6021370671479813, next_state=array([-0.0232749 ,  1.4899108 , -0.23071301,  0.32446468,  0.01490542,\n",
      "       -0.00753251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0232749 ,  1.4899108 , -0.23071301,  0.32446468,  0.01490542,\n",
      "       -0.00753251,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6197639431437676, next_state=array([-0.02566967,  1.4966092 , -0.24122842,  0.29769465,  0.01663678,\n",
      "        0.0346306 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02566967,  1.4966092 , -0.24122842,  0.29769465,  0.01663678,\n",
      "        0.0346306 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.508710089426587, next_state=array([-0.02813273,  1.5026968 , -0.24978575,  0.27051064,  0.02008425,\n",
      "        0.06895554,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02813273,  1.5026968 , -0.24978575,  0.27051064,  0.02008425,\n",
      "        0.06895554,  0.        ,  0.        ], dtype=float32), action=1, reward=0.05058403055571262, next_state=array([-0.03067808,  1.5081785 , -0.2601267 ,  0.24354324,  0.02560347,\n",
      "        0.11039434,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03067808,  1.5081785 , -0.2601267 ,  0.24354324,  0.02560347,\n",
      "        0.11039434,  0.        ,  0.        ], dtype=float32), action=3, reward=1.6717124292116534, next_state=array([-0.03314257,  1.5130591 , -0.2499586 ,  0.21685383,  0.02908097,\n",
      "        0.06955659,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03314257,  1.5130591 , -0.2499586 ,  0.21685383,  0.02908097,\n",
      "        0.06955659,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.6578241201192894, next_state=array([-0.03569136,  1.5185686 , -0.2581069 ,  0.24480113,  0.03227442,\n",
      "        0.06387477,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03569136,  1.5185686 , -0.2581069 ,  0.24480113,  0.03227442,\n",
      "        0.06387477,  0.        ,  0.        ], dtype=float32), action=1, reward=0.059453892537960656, next_state=array([-0.03831539,  1.5234648 , -0.26754305,  0.21749114,  0.03736319,\n",
      "        0.10178468,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03831539,  1.5234648 , -0.26754305,  0.21749114,  0.03736319,\n",
      "        0.10178468,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.35285479227169847, next_state=array([-0.04101801,  1.5277586 , -0.27740696,  0.19063668,  0.0444252 ,\n",
      "        0.14125298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04101801,  1.5277586 , -0.27740696,  0.19063668,  0.0444252 ,\n",
      "        0.14125298,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7733269861847976, next_state=array([-0.04380589,  1.5314354 , -0.28809306,  0.16311863,  0.05363514,\n",
      "        0.18421522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04380589,  1.5314354 , -0.28809306,  0.16311863,  0.05363514,\n",
      "        0.18421522,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.1435315517309332, next_state=array([-0.04664583,  1.535581  , -0.29323834,  0.18389574,  0.06277926,\n",
      "        0.18289931,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04664583,  1.535581  , -0.29323834,  0.18389574,  0.06277926,\n",
      "        0.18289931,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8548062073073777, next_state=array([-0.04942379,  1.5391359 , -0.2854245 ,  0.15766878,  0.07034421,\n",
      "        0.15131259,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04942379,  1.5391359 , -0.2854245 ,  0.15766878,  0.07034421,\n",
      "        0.15131259,  0.        ,  0.        ], dtype=float32), action=0, reward=0.1397869923189603, next_state=array([-0.05220184,  1.5420918 , -0.2854452 ,  0.13099867,  0.07790863,\n",
      "        0.15130198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05220184,  1.5420918 , -0.2854452 ,  0.13099867,  0.07790863,\n",
      "        0.15130198,  0.        ,  0.        ], dtype=float32), action=0, reward=0.01230685146734345, next_state=array([-0.05498028,  1.5444483 , -0.28546637,  0.10432447,  0.08547156,\n",
      "        0.1512725 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05498028,  1.5444483 , -0.28546637,  0.10432447,  0.08547156,\n",
      "        0.1512725 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.13462540409531698, next_state=array([-0.0577589 ,  1.5462055 , -0.28548747,  0.07764985,  0.09303335,\n",
      "        0.15124935,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0577589 ,  1.5462055 , -0.28548747,  0.07764985,  0.09303335,\n",
      "        0.15124935,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9445317213878195, next_state=array([-0.06045141,  1.547377  , -0.27464542,  0.05171716,  0.09840139,\n",
      "        0.10737002,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06045141,  1.547377  , -0.27464542,  0.05171716,  0.09840139,\n",
      "        0.10737002,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2373139413124079, next_state=array([-0.06314401,  1.5479486 , -0.27465922,  0.02504494,  0.1037695 ,\n",
      "        0.10737193,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06314401,  1.5479486 , -0.27465922,  0.02504494,  0.1037695 ,\n",
      "        0.10737193,  0.        ,  0.        ], dtype=float32), action=3, reward=0.7247382356625576, next_state=array([-6.5757751e-02,  1.5479230e+00, -2.6478440e-01, -1.3777629e-03,\n",
      "        1.0714971e-01,  6.7604177e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-6.5757751e-02,  1.5479230e+00, -2.6478440e-01, -1.3777629e-03,\n",
      "        1.0714971e-01,  6.7604177e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.43459442119890923, next_state=array([-0.06837158,  1.5472976 , -0.26478428, -0.02804538,  0.11052994,\n",
      "        0.06760417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06837158,  1.5472976 , -0.26478428, -0.02804538,  0.11052994,\n",
      "        0.06760417,  0.        ,  0.        ], dtype=float32), action=3, reward=0.27486276110454466, next_state=array([-0.07092285,  1.5460858 , -0.25691715, -0.05398851,  0.11231405,\n",
      "        0.03568223,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07092285,  1.5460858 , -0.25691715, -0.05398851,  0.11231405,\n",
      "        0.03568223,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6844949170780978, next_state=array([-0.07347412,  1.5442741 , -0.2569171 , -0.08065544,  0.11409817,\n",
      "        0.03568223,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07347412,  1.5442741 , -0.2569171 , -0.08065544,  0.11409817,\n",
      "        0.03568223,  0.        ,  0.        ], dtype=float32), action=3, reward=0.12237992815497137, next_state=array([-7.5954534e-02,  1.5418712e+00, -2.4802892e-01, -1.0679414e-01,\n",
      "        1.1409117e-01, -1.3986295e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-7.5954534e-02,  1.5418712e+00, -2.4802892e-01, -1.0679414e-01,\n",
      "        1.1409117e-01, -1.3986295e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-0.8730828219750606, next_state=array([-7.8434847e-02,  1.5388683e+00, -2.4802892e-01, -1.3346080e-01,\n",
      "        1.1408418e-01, -1.3981662e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-7.8434847e-02,  1.5388683e+00, -2.4802892e-01, -1.3346080e-01,\n",
      "        1.1408418e-01, -1.3981662e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.0094607068759274, next_state=array([-8.09152573e-02,  1.53526545e+00, -2.48028919e-01, -1.60127476e-01,\n",
      "        1.14077196e-01, -1.39814409e-04,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-8.09152573e-02,  1.53526545e+00, -2.48028919e-01, -1.60127476e-01,\n",
      "        1.14077196e-01, -1.39814409e-04,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=3, reward=-0.10276099717057605, next_state=array([-0.08331518,  1.5310751 , -0.23793395, -0.18608035,  0.11203096,\n",
      "       -0.04092448,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08331518,  1.5310751 , -0.23793395, -0.18608035,  0.11203096,\n",
      "       -0.04092448,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.12379475242485569, next_state=array([-0.08563843,  1.5262961 , -0.22830646, -0.21210402,  0.10804162,\n",
      "       -0.07978689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08563843,  1.5262961 , -0.22830646, -0.21210402,  0.10804162,\n",
      "       -0.07978689,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9501834182200639, next_state=array([-0.08796177,  1.5209172 , -0.22830622, -0.238772  ,  0.10405229,\n",
      "       -0.07978682,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08796177,  1.5209172 , -0.22830622, -0.238772  ,  0.10405229,\n",
      "       -0.07978682,  0.        ,  0.        ], dtype=float32), action=2, reward=2.14910785907166, next_state=array([-0.09033756,  1.5161835 , -0.23371379, -0.21012555,  0.10021991,\n",
      "       -0.07664777,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09033756,  1.5161835 , -0.23371379, -0.21012555,  0.10021991,\n",
      "       -0.07664777,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9545146595823268, next_state=array([-0.09269867,  1.5119436 , -0.23266295, -0.18820962,  0.09679193,\n",
      "       -0.06855948,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09269867,  1.5119436 , -0.23266295, -0.18820962,  0.09679193,\n",
      "       -0.06855948,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9339360896557309, next_state=array([-0.09505987,  1.5071039 , -0.2326628 , -0.21487728,  0.09336395,\n",
      "       -0.06855939,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09505987,  1.5071039 , -0.2326628 , -0.21487728,  0.09336395,\n",
      "       -0.06855939,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7877513141893917, next_state=array([-0.09748821,  1.5016652 , -0.24107075, -0.2416108 ,  0.09161474,\n",
      "       -0.03498433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09748821,  1.5016652 , -0.24107075, -0.2416108 ,  0.09161474,\n",
      "       -0.03498433,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9846332595826481, next_state=array([-0.10003433,  1.496704  , -0.25261247, -0.22038144,  0.0896264 ,\n",
      "       -0.03976645,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10003433,  1.496704  , -0.25261247, -0.22038144,  0.0896264 ,\n",
      "       -0.03976645,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.32507782789085016, next_state=array([-0.1025177 ,  1.4911594 , -0.24471161, -0.24621604,  0.08603394,\n",
      "       -0.07184912,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1025177 ,  1.4911594 , -0.24471161, -0.24621604,  0.08603394,\n",
      "       -0.07184912,  0.        ,  0.        ], dtype=float32), action=3, reward=0.0325534728046091, next_state=array([-0.10490503,  1.4850161 , -0.23267913, -0.27270022,  0.08003487,\n",
      "       -0.11998154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10490503,  1.4850161 , -0.23267913, -0.27270022,  0.08003487,\n",
      "       -0.11998154,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8129151476528591, next_state=array([-0.10729237,  1.4782733 , -0.23267877, -0.29936987,  0.07403582,\n",
      "       -0.11998123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10729237,  1.4782733 , -0.23267877, -0.29936987,  0.07403582,\n",
      "       -0.11998123,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.15852758041412926, next_state=array([-0.10961179,  1.4709387 , -0.2241466 , -0.3256127 ,  0.06632087,\n",
      "       -0.1542987 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10961179,  1.4709387 , -0.2241466 , -0.3256127 ,  0.06632087,\n",
      "       -0.1542987 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5687166993684218, next_state=array([-0.11202326,  1.4630077 , -0.23567414, -0.3522635 ,  0.06090897,\n",
      "       -0.10823783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11202326,  1.4630077 , -0.23567414, -0.3522635 ,  0.06090897,\n",
      "       -0.10823783,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8114462776808, next_state=array([-0.11453161,  1.4544749 , -0.24783583, -0.37911302,  0.05793229,\n",
      "       -0.05953344,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11453161,  1.4544749 , -0.24783583, -0.37911302,  0.05793229,\n",
      "       -0.05953344,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7599844175022372, next_state=array([-0.11711197,  1.4453422 , -0.25684807, -0.40585998,  0.05675916,\n",
      "       -0.02346249,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11711197,  1.4453422 , -0.25684807, -0.40585998,  0.05675916,\n",
      "       -0.02346249,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5496267261215155, next_state=array([-0.11961775,  1.4356153 , -0.24749282, -0.43219504,  0.05370842,\n",
      "       -0.06101507,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11961775,  1.4356153 , -0.24749282, -0.43219504,  0.05370842,\n",
      "       -0.06101507,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.37133625762871136, next_state=array([-0.12204609,  1.4252938 , -0.2377713 , -0.45855692,  0.0487074 ,\n",
      "       -0.10002029,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12204609,  1.4252938 , -0.2377713 , -0.45855692,  0.0487074 ,\n",
      "       -0.10002029,  0.        ,  0.        ], dtype=float32), action=2, reward=2.852341865191886, next_state=array([-0.12461539,  1.4155664 , -0.2513923 , -0.43215367,  0.04323389,\n",
      "       -0.10946979,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12461539,  1.4155664 , -0.2513923 , -0.43215367,  0.04323389,\n",
      "       -0.10946979,  0.        ,  0.        ], dtype=float32), action=2, reward=2.6928953084152285, next_state=array([-0.1273735 ,  1.4064909 , -0.269554  , -0.40319395,  0.03705444,\n",
      "       -0.123589  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1273735 ,  1.4064909 , -0.269554  , -0.40319395,  0.03705444,\n",
      "       -0.123589  ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.786498146965312, next_state=array([-0.13003473,  1.3982978 , -0.26049992, -0.36400205,  0.03149144,\n",
      "       -0.11125992,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13003473,  1.3982978 , -0.26049992, -0.36400205,  0.03149144,\n",
      "       -0.11125992,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5604806466990329, next_state=array([-0.1327757 ,  1.3895115 , -0.27048463, -0.39043558,  0.02792424,\n",
      "       -0.07134385,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1327757 ,  1.3895115 , -0.27048463, -0.39043558,  0.02792424,\n",
      "       -0.07134385,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2027970146403095, next_state=array([-0.13543072,  1.38012   , -0.25970525, -0.417305  ,  0.02220132,\n",
      "       -0.11445848,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13543072,  1.38012   , -0.25970525, -0.417305  ,  0.02220132,\n",
      "       -0.11445848,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7552853138499358, next_state=array([-0.1380372 ,  1.3708271 , -0.25513047, -0.41294953,  0.01675039,\n",
      "       -0.10901853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1380372 ,  1.3708271 , -0.25513047, -0.41294953,  0.01675039,\n",
      "       -0.10901853,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6590974378942576, next_state=array([-0.14055634,  1.3615692 , -0.24683535, -0.41141793,  0.01173629,\n",
      "       -0.10028206,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14055634,  1.3615692 , -0.24683535, -0.41141793,  0.01173629,\n",
      "       -0.10028206,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8499463978346284, next_state=array([-0.14307556,  1.3517115 , -0.2468353 , -0.4380867 ,  0.0067222 ,\n",
      "       -0.10028187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14307556,  1.3517115 , -0.2468353 , -0.4380867 ,  0.0067222 ,\n",
      "       -0.10028187,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6412915030994373, next_state=array([-0.14568901,  1.3412589 , -0.25866356, -0.46455523,  0.00407635,\n",
      "       -0.05291705,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14568901,  1.3412589 , -0.25866356, -0.46455523,  0.00407635,\n",
      "       -0.05291705,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3259844374708623, next_state=array([-0.14825945,  1.3313828 , -0.25458354, -0.43893462,  0.0016438 ,\n",
      "       -0.04865101,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14825945,  1.3313828 , -0.25458354, -0.43893462,  0.0016438 ,\n",
      "       -0.04865101,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8467673746990545, next_state=array([-0.15092078,  1.3209164 , -0.26597783, -0.46516925,  0.00149286,\n",
      "       -0.00301891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15092078,  1.3209164 , -0.26597783, -0.46516925,  0.00149286,\n",
      "       -0.00301891,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.022318781993532, next_state=array([-0.15367278,  1.3098588 , -0.27735072, -0.4914451 ,  0.00361929,\n",
      "        0.04252876,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15367278,  1.3098588 , -0.27735072, -0.4914451 ,  0.00361929,\n",
      "        0.04252876,  0.        ,  0.        ], dtype=float32), action=2, reward=3.075106414278946, next_state=array([-0.15649052,  1.2995566 , -0.2836374 , -0.45788336,  0.00545613,\n",
      "        0.0367366 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15649052,  1.2995566 , -0.2836374 , -0.45788336,  0.00545613,\n",
      "        0.0367366 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5845563854697662, next_state=array([-0.15921088,  1.2886574 , -0.27141184, -0.4844097 ,  0.00484436,\n",
      "       -0.01223569,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15921088,  1.2886574 , -0.27141184, -0.4844097 ,  0.00484436,\n",
      "       -0.01223569,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.172667359745219, next_state=array([-0.16193123,  1.2771583 , -0.27141184, -0.51107633,  0.00423257,\n",
      "       -0.01223562,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16193123,  1.2771583 , -0.27141184, -0.51107633,  0.00423257,\n",
      "       -0.01223562,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1415518441877168, next_state=array([-0.16465159,  1.2650588 , -0.27141184, -0.537743  ,  0.00362079,\n",
      "       -0.01223554,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16465159,  1.2650588 , -0.27141184, -0.537743  ,  0.00362079,\n",
      "       -0.01223554,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7111323018414157, next_state=array([-0.16744843,  1.2523705 , -0.28101406, -0.5639316 ,  0.00493134,\n",
      "        0.02621099,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16744843,  1.2523705 , -0.28101406, -0.5639316 ,  0.00493134,\n",
      "        0.02621099,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9121576170522987, next_state=array([-0.17021914,  1.2404664 , -0.27853793, -0.5290794 ,  0.00638386,\n",
      "        0.02905033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17021914,  1.2404664 , -0.27853793, -0.5290794 ,  0.00638386,\n",
      "        0.02905033,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8274251716024696, next_state=array([-0.1729291 ,  1.2279694 , -0.27091792, -0.5554228 ,  0.00630961,\n",
      "       -0.00148507,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1729291 ,  1.2279694 , -0.27091792, -0.5554228 ,  0.00630961,\n",
      "       -0.00148507,  0.        ,  0.        ], dtype=float32), action=2, reward=1.001493842693418, next_state=array([-0.17558165,  1.2154429 , -0.26546878, -0.5567293 ,  0.00651136,\n",
      "        0.00403511,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17558165,  1.2154429 , -0.26546878, -0.5567293 ,  0.00651136,\n",
      "        0.00403511,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9832437553291402, next_state=array([-0.17832737,  1.2023046 , -0.27715084, -0.58394176,  0.00905393,\n",
      "        0.05085145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17832737,  1.2023046 , -0.27715084, -0.58394176,  0.00905393,\n",
      "        0.05085145,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8133864752711009, next_state=array([-0.18099432,  1.1885583 , -0.2672544 , -0.6109469 ,  0.00961583,\n",
      "        0.01123806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18099432,  1.1885583 , -0.2672544 , -0.6109469 ,  0.00961583,\n",
      "        0.01123806,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1304285307388113, next_state=array([-0.18366118,  1.174212  , -0.2672544 , -0.6376136 ,  0.01017774,\n",
      "        0.01123809,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18366118,  1.174212  , -0.2672544 , -0.6376136 ,  0.01017774,\n",
      "        0.01123809,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6155032138010188, next_state=array([-0.18626384,  1.1592765 , -0.2592018 , -0.6637972 ,  0.00912519,\n",
      "       -0.02105082,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18626384,  1.1592765 , -0.2592018 , -0.6637972 ,  0.00912519,\n",
      "       -0.02105082,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4863251738182999, next_state=array([-0.18894663,  1.1437411 , -0.26926318, -0.69046694,  0.01008751,\n",
      "        0.01924658,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18894663,  1.1437411 , -0.26926318, -0.69046694,  0.01008751,\n",
      "        0.01924658,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0397838507195445, next_state=array([-0.1916295 ,  1.1276058 , -0.2692632 , -0.7171336 ,  0.01104982,\n",
      "        0.01924648,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1916295 ,  1.1276058 , -0.2692632 , -0.7171336 ,  0.01104982,\n",
      "        0.01924648,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4756879501207425, next_state=array([-0.19422951,  1.1108681 , -0.2588651 , -0.74389285,  0.00993027,\n",
      "       -0.022391  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19422951,  1.1108681 , -0.2588651 , -0.74389285,  0.00993027,\n",
      "       -0.022391  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7496051763184823, next_state=array([-0.19682951,  1.0935303 , -0.25886506, -0.7705596 ,  0.00881072,\n",
      "       -0.02239098,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19682951,  1.0935303 , -0.25886506, -0.7705596 ,  0.00881072,\n",
      "       -0.02239098,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.22912355301852358, next_state=array([-0.19934416,  1.0755832 , -0.24815576, -0.7976254 ,  0.00554789,\n",
      "       -0.06525662,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19934416,  1.0755832 , -0.24815576, -0.7976254 ,  0.00554789,\n",
      "       -0.06525662,  0.        ,  0.        ], dtype=float32), action=3, reward=0.06842735468356523, next_state=array([-2.01762825e-01,  1.05703378e+00, -2.36119434e-01, -8.24410856e-01,\n",
      "       -1.25114864e-04, -1.13460064e-01,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.01762825e-01,  1.05703378e+00, -2.36119434e-01, -8.24410856e-01,\n",
      "       -1.25114864e-04, -1.13460064e-01,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.300295304714382, next_state=array([-0.20418148,  1.0378848 , -0.23611942, -0.85108024, -0.00579811,\n",
      "       -0.11345981,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20418148,  1.0378848 , -0.23611942, -0.85108024, -0.00579811,\n",
      "       -0.11345981,  0.        ,  0.        ], dtype=float32), action=2, reward=2.898818946849542, next_state=array([-0.20645532,  1.0190952 , -0.22230192, -0.835118  , -0.01081862,\n",
      "       -0.10041048,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20645532,  1.0190952 , -0.22230192, -0.835118  , -0.01081862,\n",
      "       -0.10041048,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3464435289242942, next_state=array([-0.20860223,  1.0003037 , -0.21018057, -0.835216  , -0.01527189,\n",
      "       -0.0890652 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20860223,  1.0003037 , -0.21018057, -0.835216  , -0.01527189,\n",
      "       -0.0890652 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2857224285650932, next_state=array([-0.21081853,  0.9809033 , -0.21887617, -0.8622738 , -0.01798618,\n",
      "       -0.0542859 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21081853,  0.9809033 , -0.21887617, -0.8622738 , -0.01798618,\n",
      "       -0.0542859 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9868006934272546, next_state=array([-0.21311593,  0.96091205, -0.22905858, -0.88850516, -0.01865864,\n",
      "       -0.01344925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21311593,  0.96091205, -0.22905858, -0.88850516, -0.01865864,\n",
      "       -0.01344925,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6936364071239325, next_state=array([-0.21541333,  0.94032097, -0.2290586 , -0.91517174, -0.0193311 ,\n",
      "       -0.01344927,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21541333,  0.94032097, -0.2290586 , -0.91517174, -0.0193311 ,\n",
      "       -0.01344927,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6445421658415569, next_state=array([-0.21771073,  0.9191298 , -0.22905862, -0.9418384 , -0.02000356,\n",
      "       -0.01344927,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21771073,  0.9191298 , -0.22905862, -0.9418384 , -0.02000356,\n",
      "       -0.01344927,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5856443358599224, next_state=array([-0.22006011,  0.8981984 , -0.23396213, -0.9302998 , -0.02096982,\n",
      "       -0.01932499,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22006011,  0.8981984 , -0.23396213, -0.9302998 , -0.02096982,\n",
      "       -0.01932499,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6754456157306652, next_state=array([-0.22250485,  0.87668055, -0.24593005, -0.9563294 , -0.01953478,\n",
      "        0.02870097,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22250485,  0.87668055, -0.24593005, -0.9563294 , -0.01953478,\n",
      "        0.02870097,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9582638196048494, next_state=array([-0.22481188,  0.85556805, -0.23273793, -0.93830526, -0.01752331,\n",
      "        0.04022923,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22481188,  0.85556805, -0.23273793, -0.93830526, -0.01752331,\n",
      "        0.04022923,  0.        ,  0.        ], dtype=float32), action=2, reward=5.002331112904312, next_state=array([-0.22714396,  0.83521503, -0.23504996, -0.9045574 , -0.01570142,\n",
      "        0.03643759,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22714396,  0.83521503, -0.23504996, -0.9045574 , -0.01570142,\n",
      "        0.03643759,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.40251491153284635, next_state=array([-0.22939786,  0.8142696 , -0.22525096, -0.93090504, -0.0158398 ,\n",
      "       -0.00276754,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22939786,  0.8142696 , -0.22525096, -0.93090504, -0.0158398 ,\n",
      "       -0.00276754,  0.        ,  0.        ], dtype=float32), action=2, reward=5.762164085049915, next_state=array([-0.23149662,  0.79420197, -0.21039052, -0.89188856, -0.01533304,\n",
      "        0.01013533,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23149662,  0.79420197, -0.21039052, -0.89188856, -0.01533304,\n",
      "        0.01013533,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6497568933846753, next_state=array([-0.23351908,  0.7735315 , -0.20081715, -0.91870373, -0.01674413,\n",
      "       -0.02822166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23351908,  0.7735315 , -0.20081715, -0.91870373, -0.01674413,\n",
      "       -0.02822166,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7897109618164098, next_state=array([-0.23546414,  0.7522638 , -0.191106  , -0.9452706 , -0.02009911,\n",
      "       -0.06709968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23546414,  0.7522638 , -0.191106  , -0.9452706 , -0.02009911,\n",
      "       -0.06709968,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3662172580672634, next_state=array([-0.23736429,  0.7312151 , -0.18677919, -0.93554914, -0.02329755,\n",
      "       -0.06396867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23736429,  0.7312151 , -0.18677919, -0.93554914, -0.02329755,\n",
      "       -0.06396867,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9407557641190181, next_state=array([-0.23926449,  0.7095663 , -0.18677919, -0.9622167 , -0.02649597,\n",
      "       -0.06396867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23926449,  0.7095663 , -0.18677919, -0.9622167 , -0.02649597,\n",
      "       -0.06396867,  0.        ,  0.        ], dtype=float32), action=2, reward=2.656289185867746, next_state=array([-0.24115697,  0.6882175 , -0.18597256, -0.9488994 , -0.0297326 ,\n",
      "       -0.06473231,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24115697,  0.6882175 , -0.18597256, -0.9488994 , -0.0297326 ,\n",
      "       -0.06473231,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.965573073916629, next_state=array([-0.24312945,  0.66626734, -0.19600467, -0.97558844, -0.03096127,\n",
      "       -0.02457339,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24312945,  0.66626734, -0.19600467, -0.97558844, -0.03096127,\n",
      "       -0.02457339,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7185223683041773, next_state=array([-0.24519253,  0.6437173 , -0.20737334, -1.0021948 , -0.02991359,\n",
      "        0.02095366,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24519253,  0.6437173 , -0.20737334, -1.0021948 , -0.02991359,\n",
      "        0.02095366,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4257998748341265, next_state=array([-0.24725565,  0.6205675 , -0.20737335, -1.0288615 , -0.0288659 ,\n",
      "        0.02095377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24725565,  0.6205675 , -0.20737335, -1.0288615 , -0.0288659 ,\n",
      "        0.02095377,  0.        ,  0.        ], dtype=float32), action=2, reward=1.839948498737823, next_state=array([-0.2492928 ,  0.59739697, -0.20484416, -1.0297788 , -0.02774973,\n",
      "        0.02232321,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2492928 ,  0.59739697, -0.20484416, -1.0297788 , -0.02774973,\n",
      "        0.02232321,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.39954670115682234, next_state=array([-0.25132996,  0.5736265 , -0.20484419, -1.0564456 , -0.02663357,\n",
      "        0.02232317,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25132996,  0.5736265 , -0.20484419, -1.0564456 , -0.02663357,\n",
      "        0.02232317,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.37294906562749364, next_state=array([-0.25343528,  0.54925984, -0.21340516, -1.0829166 , -0.02380158,\n",
      "        0.05663977,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25343528,  0.54925984, -0.21340516, -1.0829166 , -0.02380158,\n",
      "        0.05663977,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.13466316040708534, next_state=array([-0.2556018 ,  0.5243068 , -0.2210804 , -1.1089597 , -0.01942731,\n",
      "        0.08748534,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2556018 ,  0.5243068 , -0.2210804 , -1.1089597 , -0.01942731,\n",
      "        0.08748534,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.006837993570285333, next_state=array([-0.25783834,  0.49875686, -0.22986956, -1.1354824 , -0.01329216,\n",
      "        0.12270309,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25783834,  0.49875686, -0.22986956, -1.1354824 , -0.01329216,\n",
      "        0.12270309,  0.        ,  0.        ], dtype=float32), action=0, reward=0.20040180437612776, next_state=array([-0.2600749 ,  0.47260752, -0.22986963, -1.1621522 , -0.00715701,\n",
      "        0.12270279,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2600749 ,  0.47260752, -0.22986963, -1.1621522 , -0.00715701,\n",
      "        0.12270279,  0.        ,  0.        ], dtype=float32), action=2, reward=3.946330522211622, next_state=array([-0.26238886,  0.44684708, -0.2372256 , -1.1448926 , -0.00140205,\n",
      "        0.11509943,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26238886,  0.44684708, -0.2372256 , -1.1448926 , -0.00140205,\n",
      "        0.11509943,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.215345608146804, next_state=array([-0.26477712,  0.42048004, -0.24654701, -1.1718818 ,  0.00621951,\n",
      "        0.15243085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26477712,  0.42048004, -0.24654701, -1.1718818 ,  0.00621951,\n",
      "        0.15243085,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2470129528435905, next_state=array([-0.26716536,  0.39351377, -0.24654703, -1.1985533 ,  0.01384102,\n",
      "        0.15243022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26716536,  0.39351377, -0.24654703, -1.1985533 ,  0.01384102,\n",
      "        0.15243022,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7334977333056247, next_state=array([-0.26964444,  0.3659541 , -0.2579306 , -1.2249942 ,  0.02374083,\n",
      "        0.19799605,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26964444,  0.3659541 , -0.2579306 , -1.2249942 ,  0.02374083,\n",
      "        0.19799605,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9425638224026602, next_state=array([-0.27219576,  0.3377924 , -0.2670006 , -1.2518584 ,  0.03545821,\n",
      "        0.23434749,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27219576,  0.3377924 , -0.2670006 , -1.2518584 ,  0.03545821,\n",
      "        0.23434749,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1782869638174815, next_state=array([-0.27464724,  0.30975425, -0.25755626, -1.2464777 ,  0.04771614,\n",
      "        0.24515891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27464724,  0.30975425, -0.25755626, -1.2464777 ,  0.04771614,\n",
      "        0.24515891,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4874121658762351, next_state=array([-0.2770242 ,  0.2811352 , -0.24818873, -1.2723233 ,  0.05808518,\n",
      "        0.20738073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2770242 ,  0.2811352 , -0.24818873, -1.2723233 ,  0.05808518,\n",
      "        0.20738073,  0.        ,  0.        ], dtype=float32), action=2, reward=3.416616793199222, next_state=array([-0.2794982 ,  0.25324446, -0.2576669 , -1.2400173 ,  0.06824384,\n",
      "        0.20317309,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2794982 ,  0.25324446, -0.2576669 , -1.2400173 ,  0.06824384,\n",
      "        0.20317309,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6632808673452348, next_state=array([-0.28191203,  0.22476104, -0.25011083, -1.266354  ,  0.07688417,\n",
      "        0.17280681,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28191203,  0.22476104, -0.25011083, -1.266354  ,  0.07688417,\n",
      "        0.17280681,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4487877183657916, next_state=array([-0.284411  ,  0.19567038, -0.26079565, -1.2935123 ,  0.08767217,\n",
      "        0.21575978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.284411  ,  0.19567038, -0.26079565, -1.2935123 ,  0.08767217,\n",
      "        0.21575978,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3190939494474776, next_state=array([-0.28691012,  0.16598132, -0.26079446, -1.3201888 ,  0.09846007,\n",
      "        0.21575804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28691012,  0.16598132, -0.26079446, -1.3201888 ,  0.09846007,\n",
      "        0.21575804,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5147043313232302, next_state=array([-0.2894093 ,  0.13569382, -0.2607931 , -1.3468652 ,  0.10924788,\n",
      "        0.21575646,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2894093 ,  0.13569382, -0.2607931 , -1.3468652 ,  0.10924788,\n",
      "        0.21575646,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1642062876057198, next_state=array([-0.2920816 ,  0.10608524, -0.2777241 , -1.3167393 ,  0.11966926,\n",
      "        0.20842755,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2920816 ,  0.10608524, -0.2777241 , -1.3167393 ,  0.11966926,\n",
      "        0.20842755,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.4999930934792745, next_state=array([-0.2948292 ,  0.07586704, -0.287147  , -1.3440698 ,  0.13199398,\n",
      "        0.24649434,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2948292 ,  0.07586704, -0.287147  , -1.3440698 ,  0.13199398,\n",
      "        0.24649434,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.9063499358517206, next_state=array([-0.2976429 ,  0.0450461 , -0.2954068 , -1.3711209 ,  0.1459772 ,\n",
      "        0.27966455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2976429 ,  0.0450461 , -0.2954068 , -1.3711209 ,  0.1459772 ,\n",
      "        0.27966455,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.5736506693960437, next_state=array([-0.30038327,  0.01363629, -0.28617948, -1.3972284 ,  0.1581011 ,\n",
      "        0.2424781 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30038327,  0.01363629, -0.28617948, -1.3972284 ,  0.1581011 ,\n",
      "        0.2424781 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.5970742094931607, next_state=array([-0.30333814, -0.01786801, -0.30687043, -1.401441  ,  0.16949041,\n",
      "        0.22778621,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30333814, -0.01786801, -0.30687043, -1.401441  ,  0.16949041,\n",
      "        0.22778621,  0.        ,  0.        ], dtype=float32), action=2, reward=8.29819081087059, next_state=array([-0.30636588, -0.04924496, -0.3141803 , -1.3958726 ,  0.18092562,\n",
      "        0.2287041 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30636588, -0.04924496, -0.3141803 , -1.3958726 ,  0.18092562,\n",
      "        0.2287041 ,  1.        ,  0.        ], dtype=float32), action=2, reward=-10.010739837997466, next_state=array([-0.30993706, -0.07917565, -0.38740408, -1.3343852 ,  0.20975061,\n",
      "        0.57436216,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30993706, -0.07917565, -0.38740408, -1.3343852 ,  0.20975061,\n",
      "        0.57436216,  0.        ,  0.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.3135852 , -0.10680959, -0.6040324 , -0.95334786,  0.27973655,\n",
      "        4.3140326 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00571375,  1.4223646 , -0.57875645,  0.5086329 ,  0.00662761,\n",
      "        0.13109717,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.004384664214938994, next_state=array([-0.01142797,  1.433231  , -0.5779731 ,  0.48290893,  0.01310581,\n",
      "        0.12957591,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01142797,  1.433231  , -0.5779731 ,  0.48290893,  0.01310581,\n",
      "        0.12957591,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9954449750746346, next_state=array([-0.01706037,  1.4434925 , -0.56770617,  0.45601973,  0.01751854,\n",
      "        0.0882632 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01706037,  1.4434925 , -0.56770617,  0.45601973,  0.01751854,\n",
      "        0.0882632 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.22392119041592196, next_state=array([-0.02269297,  1.4531541 , -0.567718  ,  0.4293472 ,  0.02193173,\n",
      "        0.08827159,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02269297,  1.4531541 , -0.567718  ,  0.4293472 ,  0.02193173,\n",
      "        0.08827159,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2663185503007413, next_state=array([-0.02822351,  1.4629098 , -0.5580541 ,  0.4335107 ,  0.02688131,\n",
      "        0.09900065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02822351,  1.4629098 , -0.5580541 ,  0.4335107 ,  0.02688131,\n",
      "        0.09900065,  0.        ,  0.        ], dtype=float32), action=3, reward=1.102315234635172, next_state=array([-0.03367786,  1.4720693 , -0.5485007 ,  0.40702927,  0.02990996,\n",
      "        0.06057887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03367786,  1.4720693 , -0.5485007 ,  0.40702927,  0.02990996,\n",
      "        0.06057887,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6098061928456662, next_state=array([-0.03920593,  1.4806366 , -0.55772686,  0.38066292,  0.0347832 ,\n",
      "        0.09747346,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03920593,  1.4806366 , -0.55772686,  0.38066292,  0.0347832 ,\n",
      "        0.09747346,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0452663957998982, next_state=array([-0.0448267 ,  1.4885904 , -0.5693686 ,  0.35331517,  0.04199323,\n",
      "        0.144214  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0448267 ,  1.4885904 , -0.5693686 ,  0.35331517,  0.04199323,\n",
      "        0.144214  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.774502770998583, next_state=array([-0.05064859,  1.4974958 , -0.58871245,  0.39559942,  0.04845293,\n",
      "        0.12920566,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05064859,  1.4974958 , -0.58871245,  0.39559942,  0.04845293,\n",
      "        0.12920566,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.04522384622103459, next_state=array([-0.05647068,  1.5058014 , -0.5887296 ,  0.3689149 ,  0.05491276,\n",
      "        0.12920848,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05647068,  1.5058014 , -0.5887296 ,  0.3689149 ,  0.05491276,\n",
      "        0.12920848,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.06195570784808524, next_state=array([-0.06229296,  1.5135077 , -0.5887487 ,  0.3422485 ,  0.06137126,\n",
      "        0.12918189,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06229296,  1.5135077 , -0.5887487 ,  0.3422485 ,  0.06137126,\n",
      "        0.12918189,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.2371637901175516, next_state=array([-0.06827374,  1.5213166 , -0.6039808 ,  0.34680387,  0.06721616,\n",
      "        0.11690869,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06827374,  1.5213166 , -0.6039808 ,  0.34680387,  0.06721616,\n",
      "        0.11690869,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.044667446518076304, next_state=array([-0.0742548 ,  1.5285257 , -0.60399675,  0.32012647,  0.07306068,\n",
      "        0.11690114,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0742548 ,  1.5285257 , -0.60399675,  0.32012647,  0.07306068,\n",
      "        0.11690114,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.193764984065285, next_state=array([-0.08020888,  1.5364908 , -0.6017486 ,  0.35367882,  0.07934202,\n",
      "        0.12563829,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08020888,  1.5364908 , -0.6017486 ,  0.35367882,  0.07934202,\n",
      "        0.12563829,  0.        ,  0.        ], dtype=float32), action=3, reward=1.051833039668993, next_state=array([-0.0860754 ,  1.5438635 , -0.5907446 ,  0.32745197,  0.08340672,\n",
      "        0.08130129,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0860754 ,  1.5438635 , -0.5907446 ,  0.32745197,  0.08340672,\n",
      "        0.08130129,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.1540877935252523, next_state=array([-0.0918623 ,  1.5517719 , -0.5834557 ,  0.35121247,  0.08814175,\n",
      "        0.0947094 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0918623 ,  1.5517719 , -0.5834557 ,  0.35121247,  0.08814175,\n",
      "        0.0947094 ,  0.        ,  0.        ], dtype=float32), action=3, reward=1.012717551474368, next_state=array([-0.09757604,  1.5590968 , -0.5742773 ,  0.32538092,  0.09101218,\n",
      "        0.05741405,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09757604,  1.5590968 , -0.5742773 ,  0.32538092,  0.09101218,\n",
      "        0.05741405,  0.        ,  0.        ], dtype=float32), action=0, reward=0.277359220675379, next_state=array([-0.10328998,  1.5658221 , -0.5742847 ,  0.29871553,  0.09388324,\n",
      "        0.05742645,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10328998,  1.5658221 , -0.5742847 ,  0.29871553,  0.09388324,\n",
      "        0.05742645,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.8149959751436766, next_state=array([-0.10908632,  1.5733488 , -0.5825611 ,  0.33433452,  0.09677856,\n",
      "        0.05791165,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10908632,  1.5733488 , -0.5825611 ,  0.33433452,  0.09677856,\n",
      "        0.05791165,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0051495734201683, next_state=array([-0.11497498,  1.5802724 , -0.59410185,  0.30737048,  0.10198387,\n",
      "        0.10411553,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11497498,  1.5802724 , -0.59410185,  0.30737048,  0.10198387,\n",
      "        0.10411553,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1447855271458411, next_state=array([-0.12094526,  1.5865841 , -0.6043298 ,  0.28001282,  0.10924939,\n",
      "        0.14532319,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12094526,  1.5865841 , -0.6043298 ,  0.28001282,  0.10924939,\n",
      "        0.14532319,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9515619216697371, next_state=array([-0.12682533,  1.5923057 , -0.5930173 ,  0.2539099 ,  0.11423308,\n",
      "        0.09968288,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12682533,  1.5923057 , -0.5930173 ,  0.2539099 ,  0.11423308,\n",
      "        0.09968288,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0570550945003572, next_state=array([-0.13262406,  1.5974314 , -0.5828411 ,  0.22758172,  0.11717506,\n",
      "        0.05884526,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13262406,  1.5974314 , -0.5828411 ,  0.22758172,  0.11717506,\n",
      "        0.05884526,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.013570792325395, next_state=array([-0.13850126,  1.6019496 , -0.5926519 ,  0.20041126,  0.12208945,\n",
      "        0.09829631,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13850126,  1.6019496 , -0.5926519 ,  0.20041126,  0.12208945,\n",
      "        0.09829631,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0986983493070295, next_state=array([-0.14428958,  1.6058959 , -0.581462  ,  0.17517157,  0.12470832,\n",
      "        0.05238221,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14428958,  1.6058959 , -0.581462  ,  0.17517157,  0.12470832,\n",
      "        0.05238221,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.5828817183499835, next_state=array([-0.15023908,  1.6098804 , -0.5974626 ,  0.17688192,  0.12720563,\n",
      "        0.04994528,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15023908,  1.6098804 , -0.5974626 ,  0.17688192,  0.12720563,\n",
      "        0.04994528,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.157166601214526, next_state=array([-0.1562789 ,  1.6132385 , -0.6082504 ,  0.14887667,  0.13145365,\n",
      "        0.08496055,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1562789 ,  1.6132385 , -0.6082504 ,  0.14887667,  0.13145365,\n",
      "        0.08496055,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.17865439147394113, next_state=array([-0.1623188 ,  1.6159967 , -0.6082501 ,  0.1222085 ,  0.13570167,\n",
      "        0.08496046,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1623188 ,  1.6159967 , -0.6082501 ,  0.1222085 ,  0.13570167,\n",
      "        0.08496046,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8475643576460652, next_state=array([-0.16828346,  1.6181751 , -0.5987965 ,  0.09659901,  0.13801979,\n",
      "        0.04636234,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16828346,  1.6181751 , -0.5987965 ,  0.09659901,  0.13801979,\n",
      "        0.04636234,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.321629092308444, next_state=array([-0.17436925,  1.6207507 , -0.61076957,  0.11426373,  0.14020686,\n",
      "        0.04374138,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17436925,  1.6207507 , -0.61076957,  0.11426373,  0.14020686,\n",
      "        0.04374138,  0.        ,  0.        ], dtype=float32), action=3, reward=1.1011923531083323, next_state=array([-0.1803753 ,  1.6227545 , -0.6007261 ,  0.08904887,  0.14032556,\n",
      "        0.0023741 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1803753 ,  1.6227545 , -0.6007261 ,  0.08904887,  0.14032556,\n",
      "        0.0023741 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.3797301825888894, next_state=array([-0.18633184,  1.6249826 , -0.5963479 ,  0.09896445,  0.14102706,\n",
      "        0.01403011,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18633184,  1.6249826 , -0.5963479 ,  0.09896445,  0.14102706,\n",
      "        0.01403011,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1876100107665082, next_state=array([-0.19234057,  1.627218  , -0.60160244,  0.09927975,  0.14175244,\n",
      "        0.01450704,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19234057,  1.627218  , -0.60160244,  0.09927975,  0.14175244,\n",
      "        0.01450704,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9161472443996399, next_state=array([-0.19829044,  1.6288693 , -0.5941936 ,  0.07347187,  0.14096309,\n",
      "       -0.01578698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19829044,  1.6288693 , -0.5941936 ,  0.07347187,  0.14096309,\n",
      "       -0.01578698,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.154218622763209, next_state=array([-0.20432682,  1.629911  , -0.6050346 ,  0.0461559 ,  0.14235762,\n",
      "        0.02789043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20432682,  1.629911  , -0.6050346 ,  0.0461559 ,  0.14235762,\n",
      "        0.02789043,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3652290783108743, next_state=array([-0.21044421,  1.6303349 , -0.61520964,  0.01850447,  0.14582197,\n",
      "        0.06928716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21044421,  1.6303349 , -0.61520964,  0.01850447,  0.14582197,\n",
      "        0.06928716,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6468711121768422, next_state=array([-0.21653871,  1.6308577 , -0.6133391 ,  0.02285245,  0.1497042 ,\n",
      "        0.07764453,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21653871,  1.6308577 , -0.6133391 ,  0.02285245,  0.1497042 ,\n",
      "        0.07764453,  0.        ,  0.        ], dtype=float32), action=3, reward=0.7675564825595995, next_state=array([-0.22255254,  1.6307961 , -0.6032137 , -0.00292454,  0.15153128,\n",
      "        0.03654157,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22255254,  1.6307961 , -0.6032137 , -0.00292454,  0.15153128,\n",
      "        0.03654157,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0171460163752226, next_state=array([-0.22847891,  1.6301446 , -0.59225756, -0.02891583,  0.15115099,\n",
      "       -0.00760572,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22847891,  1.6301446 , -0.59225756, -0.02891583,  0.15115099,\n",
      "       -0.00760572,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.681841999384676, next_state=array([-2.3444071e-01,  1.6299481e+00, -5.9612608e-01, -8.7276129e-03,\n",
      "        1.5109891e-01, -1.0416285e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.3444071e-01,  1.6299481e+00, -5.9612608e-01, -8.7276129e-03,\n",
      "        1.5109891e-01, -1.0416285e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.493068753864775, next_state=array([-0.24049215,  1.6291277 , -0.6073991 , -0.03669089,  0.15335244,\n",
      "        0.04507054,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24049215,  1.6291277 , -0.6073991 , -0.03669089,  0.15335244,\n",
      "        0.04507054,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0412512727743615, next_state=array([-0.2464467 ,  1.6277238 , -0.59524983, -0.06237722,  0.15314499,\n",
      "       -0.00414915,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2464467 ,  1.6277238 , -0.59524983, -0.06237722,  0.15314499,\n",
      "       -0.00414915,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2078143167186397, next_state=array([-0.2524013 ,  1.6257199 , -0.59524983, -0.08904388,  0.15293753,\n",
      "       -0.00414914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2524013 ,  1.6257199 , -0.59524983, -0.08904388,  0.15293753,\n",
      "       -0.00414914,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5988175858436489, next_state=array([-0.25829753,  1.6231385 , -0.587894  , -0.11454847,  0.15120718,\n",
      "       -0.03460695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25829753,  1.6231385 , -0.587894  , -0.11454847,  0.15120718,\n",
      "       -0.03460695,  0.        ,  0.        ], dtype=float32), action=3, reward=1.0023486072367132, next_state=array([-0.264115  ,  1.6199869 , -0.577955  , -0.13969295,  0.14742236,\n",
      "       -0.07569642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.264115  ,  1.6199869 , -0.577955  , -0.13969295,  0.14742236,\n",
      "       -0.07569642,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8636367142140113, next_state=array([-0.26987195,  1.6162578 , -0.5703163 , -0.16521464,  0.14206074,\n",
      "       -0.10723238,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26987195,  1.6162578 , -0.5703163 , -0.16521464,  0.14206074,\n",
      "       -0.10723238,  0.        ,  0.        ], dtype=float32), action=0, reward=0.07049791721047427, next_state=array([-0.2756289 ,  1.611929  , -0.5703158 , -0.19188371,  0.13669913,\n",
      "       -0.10723217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2756289 ,  1.611929  , -0.5703158 , -0.19188371,  0.13669913,\n",
      "       -0.10723217,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.206256748508905, next_state=array([-0.28146854,  1.6069922 , -0.58067214, -0.21911897,  0.13342132,\n",
      "       -0.06555618,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28146854,  1.6069922 , -0.58067214, -0.21911897,  0.13342132,\n",
      "       -0.06555618,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2198498980051795, next_state=array([-0.28730816,  1.6014555 , -0.580672  , -0.2457865 ,  0.13014351,\n",
      "       -0.06555612,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28730816,  1.6014555 , -0.580672  , -0.2457865 ,  0.13014351,\n",
      "       -0.06555612,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.613456267999054, next_state=array([-0.29324085,  1.5953069 , -0.5923346 , -0.27319002,  0.12921755,\n",
      "       -0.01851887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29324085,  1.5953069 , -0.5923346 , -0.27319002,  0.12921755,\n",
      "       -0.01851887,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9640408225759416, next_state=array([-0.29932398,  1.5891775 , -0.6069364 , -0.27230066,  0.12784792,\n",
      "       -0.02739272,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29932398,  1.5891775 , -0.6069364 , -0.27230066,  0.12784792,\n",
      "       -0.02739272,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6412400944457783, next_state=array([-0.30533013,  1.5824727 , -0.59724104, -0.2977047 ,  0.12449158,\n",
      "       -0.06712683,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30533013,  1.5824727 , -0.59724104, -0.2977047 ,  0.12449158,\n",
      "       -0.06712683,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8976628229311927, next_state=array([-0.31146878,  1.5766274 , -0.6104436 , -0.25951234,  0.1210864 ,\n",
      "       -0.06810366,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31146878,  1.5766274 , -0.6104436 , -0.25951234,  0.1210864 ,\n",
      "       -0.06810366,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.23579819587001793, next_state=array([-0.3176075 ,  1.5701821 , -0.6104435 , -0.28618005,  0.11768121,\n",
      "       -0.06810378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3176075 ,  1.5701821 , -0.6104435 , -0.28618005,  0.11768121,\n",
      "       -0.06810378,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.26686019083271617, next_state=array([-0.32374614,  1.563137  , -0.61044323, -0.31284767,  0.11427601,\n",
      "       -0.06810372,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32374614,  1.563137  , -0.61044323, -0.31284767,  0.11427601,\n",
      "       -0.06810372,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6113750657352284, next_state=array([-0.3298079 ,  1.5563242 , -0.6033943 , -0.3025803 ,  0.11151718,\n",
      "       -0.05517693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3298079 ,  1.5563242 , -0.6033943 , -0.3025803 ,  0.11151718,\n",
      "       -0.05517693,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5202877087649143, next_state=array([-0.33603948,  1.5497273 , -0.6198766 , -0.2929565 ,  0.1082581 ,\n",
      "       -0.06518151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33603948,  1.5497273 , -0.6198766 , -0.2929565 ,  0.1082581 ,\n",
      "       -0.06518151,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6124961055898279, next_state=array([-0.34220523,  1.542541  , -0.61160916, -0.3190376 ,  0.10332914,\n",
      "       -0.09857903,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34220523,  1.542541  , -0.61160916, -0.3190376 ,  0.10332914,\n",
      "       -0.09857903,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2680584301684916, next_state=array([-0.34845227,  1.5360203 , -0.6197622 , -0.2894768 ,  0.09842936,\n",
      "       -0.09799577,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34845227,  1.5360203 , -0.6197622 , -0.2894768 ,  0.09842936,\n",
      "       -0.09799577,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7413875941022752, next_state=array([-0.35471362,  1.5296221 , -0.6213497 , -0.2840614 ,  0.09368261,\n",
      "       -0.09493504,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35471362,  1.5296221 , -0.6213497 , -0.2840614 ,  0.09368261,\n",
      "       -0.09493504,  0.        ,  0.        ], dtype=float32), action=3, reward=0.780465078346283, next_state=array([-0.3609062 ,  1.5226244 , -0.6127373 , -0.3106043 ,  0.08721439,\n",
      "       -0.12936437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3609062 ,  1.5226244 , -0.6127373 , -0.3106043 ,  0.08721439,\n",
      "       -0.12936437,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.005026044516171169, next_state=array([-0.3670989 ,  1.5150275 , -0.6127368 , -0.33727452,  0.08074619,\n",
      "       -0.129364  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3670989 ,  1.5150275 , -0.6127368 , -0.33727452,  0.08074619,\n",
      "       -0.129364  ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9591234256928203, next_state=array([-0.3733167 ,  1.5080823 , -0.6154537 , -0.30834982,  0.07447337,\n",
      "       -0.12545614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3733167 ,  1.5080823 , -0.6154537 , -0.30834982,  0.07447337,\n",
      "       -0.12545614,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2649996115960096, next_state=array([-0.3796236 ,  1.5005387 , -0.6265952 , -0.33507293,  0.0704271 ,\n",
      "       -0.08092526,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3796236 ,  1.5005387 , -0.6265952 , -0.33507293,  0.0704271 ,\n",
      "       -0.08092526,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.25851465260302575, next_state=array([-0.38593045,  1.4923954 , -0.62659514, -0.36174095,  0.06638085,\n",
      "       -0.08092518,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38593045,  1.4923954 , -0.62659514, -0.36174095,  0.06638085,\n",
      "       -0.08092518,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4168444305743424, next_state=array([-0.3923193 ,  1.4836438 , -0.63688135, -0.38887066,  0.06440158,\n",
      "       -0.03958531,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3923193 ,  1.4836438 , -0.63688135, -0.38887066,  0.06440158,\n",
      "       -0.03958531,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5059041956803025, next_state=array([-0.3986291 ,  1.4742888 , -0.62697923, -0.41561154,  0.06044528,\n",
      "       -0.07912605,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3986291 ,  1.4742888 , -0.62697923, -0.41561154,  0.06044528,\n",
      "       -0.07912605,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3161958597612511, next_state=array([-0.40493888,  1.4643339 , -0.6269791 , -0.4422795 ,  0.05648897,\n",
      "       -0.07912621,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40493888,  1.4643339 , -0.6269791 , -0.4422795 ,  0.05648897,\n",
      "       -0.07912621,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.32542409315783516, next_state=array([-0.41124868,  1.4537793 , -0.626979  , -0.46894747,  0.05253267,\n",
      "       -0.07912602,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41124868,  1.4537793 , -0.626979  , -0.46894747,  0.05253267,\n",
      "       -0.07912602,  0.        ,  0.        ], dtype=float32), action=2, reward=1.480161169451219, next_state=array([-0.41769186,  1.443847  , -0.6398927 , -0.44128793,  0.04815898,\n",
      "       -0.08747374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41769186,  1.443847  , -0.6398927 , -0.44128793,  0.04815898,\n",
      "       -0.08747374,  0.        ,  0.        ], dtype=float32), action=2, reward=2.531001255227932, next_state=array([-0.4241709 ,  1.4347364 , -0.6435255 , -0.40478075,  0.04383116,\n",
      "       -0.08655648,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4241709 ,  1.4347364 , -0.6435255 , -0.40478075,  0.04383116,\n",
      "       -0.08655648,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2619816507192467, next_state=array([-0.43078384,  1.4263163 , -0.65646136, -0.37409294,  0.03905992,\n",
      "       -0.09542481,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43078384,  1.4263163 , -0.65646136, -0.37409294,  0.03905992,\n",
      "       -0.09542481,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6304618265105943, next_state=array([-0.43747082,  1.4186177 , -0.66368484, -0.34202403,  0.03410603,\n",
      "       -0.09907768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43747082,  1.4186177 , -0.66368484, -0.34202403,  0.03410603,\n",
      "       -0.09907768,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6241553878109982, next_state=array([-0.4442358 ,  1.4112043 , -0.6712123 , -0.32938305,  0.02888519,\n",
      "       -0.10441687,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4442358 ,  1.4112043 , -0.6712123 , -0.32938305,  0.02888519,\n",
      "       -0.10441687,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4696424483090709, next_state=array([-0.4511211 ,  1.4042053 , -0.68277043, -0.31096193,  0.0231992 ,\n",
      "       -0.11371981,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4511211 ,  1.4042053 , -0.68277043, -0.31096193,  0.0231992 ,\n",
      "       -0.11371981,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8584757665103961, next_state=array([-0.4579362 ,  1.3966002 , -0.67397195, -0.33791277,  0.0157542 ,\n",
      "       -0.14890012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4579362 ,  1.3966002 , -0.67397195, -0.33791277,  0.0157542 ,\n",
      "       -0.14890012,  0.        ,  0.        ], dtype=float32), action=3, reward=1.3589248570870052, next_state=array([-0.46465436,  1.3883945 , -0.6618074 , -0.36462593,  0.00587374,\n",
      "       -0.19760917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46465436,  1.3883945 , -0.6618074 , -0.36462593,  0.00587374,\n",
      "       -0.19760917,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.517188231087033, next_state=array([-0.47137251,  1.3795902 , -0.6618073 , -0.3913008 , -0.00400665,\n",
      "       -0.19760783,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47137251,  1.3795902 , -0.6618073 , -0.3913008 , -0.00400665,\n",
      "       -0.19760783,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9922423911015243, next_state=array([-0.47802886,  1.3713176 , -0.65590394, -0.36772382, -0.01361486,\n",
      "       -0.19216426,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47802886,  1.3713176 , -0.65590394, -0.36772382, -0.01361486,\n",
      "       -0.19216426,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2688397281440573, next_state=array([-0.48474985,  1.3624372 , -0.66400397, -0.3947749 , -0.02160302,\n",
      "       -0.15976319,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48474985,  1.3624372 , -0.66400397, -0.3947749 , -0.02160302,\n",
      "       -0.15976319,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5306191420297068, next_state=array([-0.4914708 ,  1.3529577 , -0.6640042 , -0.42144692, -0.02959114,\n",
      "       -0.1597625 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4914708 ,  1.3529577 , -0.6640042 , -0.42144692, -0.02959114,\n",
      "       -0.1597625 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5452947713619665, next_state=array([-0.49819174,  1.3428792 , -0.66400445, -0.44811898, -0.03757923,\n",
      "       -0.15976177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49819174,  1.3428792 , -0.66400445, -0.44811898, -0.03757923,\n",
      "       -0.15976177,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1970579081121557, next_state=array([-0.5049898 ,  1.3321952 , -0.6736752 , -0.47500935, -0.04363515,\n",
      "       -0.12111859,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5049898 ,  1.3321952 , -0.6736752 , -0.47500935, -0.04363515,\n",
      "       -0.12111859,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9313756278553729, next_state=array([-0.51186407,  1.3209255 , -0.6832448 , -0.50100404, -0.04776533,\n",
      "       -0.08260357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.51186407,  1.3209255 , -0.6832448 , -0.50100404, -0.04776533,\n",
      "       -0.08260357,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9431914423357852, next_state=array([-0.5187777 ,  1.3105454 , -0.68678206, -0.4614851 , -0.05229611,\n",
      "       -0.09061565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5187777 ,  1.3105454 , -0.68678206, -0.4614851 , -0.05229611,\n",
      "       -0.09061565,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.776723655960352, next_state=array([-0.5257658 ,  1.2995795 , -0.69611907, -0.4874731 , -0.05494615,\n",
      "       -0.05300086,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5257658 ,  1.2995795 , -0.69611907, -0.4874731 , -0.05494615,\n",
      "       -0.05300086,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6775923394773702, next_state=array([-0.5328363 ,  1.2880116 , -0.7064677 , -0.5141505 , -0.05552715,\n",
      "       -0.01162005,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5328363 ,  1.2880116 , -0.7064677 , -0.5141505 , -0.05552715,\n",
      "       -0.01162005,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4681620482912752, next_state=array([-0.5399929 ,  1.2758466 , -0.71726775, -0.5406034 , -0.0539442 ,\n",
      "        0.03165891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5399929 ,  1.2758466 , -0.71726775, -0.5406034 , -0.0539442 ,\n",
      "        0.03165891,  0.        ,  0.        ], dtype=float32), action=2, reward=1.953221146859488, next_state=array([-0.5470897 ,  1.2639828 , -0.7114033 , -0.52722305, -0.05223397,\n",
      "        0.03420478,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5470897 ,  1.2639828 , -0.7114033 , -0.52722305, -0.05223397,\n",
      "        0.03420478,  0.        ,  0.        ], dtype=float32), action=2, reward=3.5970624156608837, next_state=array([-0.5540174 ,  1.2527276 , -0.6950966 , -0.5001438 , -0.04993758,\n",
      "        0.04592789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5540174 ,  1.2527276 , -0.6950966 , -0.5001438 , -0.04993758,\n",
      "        0.04592789,  0.        ,  0.        ], dtype=float32), action=3, reward=0.09199123805919499, next_state=array([-0.560849  ,  1.2408583 , -0.6830243 , -0.52753466, -0.05006948,\n",
      "       -0.00263814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.560849  ,  1.2408583 , -0.6830243 , -0.52753466, -0.05006948,\n",
      "       -0.00263814,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8184296730616154, next_state=array([-0.5676806 ,  1.2283889 , -0.68302435, -0.55420136, -0.05020138,\n",
      "       -0.00263816,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5676806 ,  1.2283889 , -0.68302435, -0.55420136, -0.05020138,\n",
      "       -0.00263816,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8225748424141273, next_state=array([-0.5745122 ,  1.2153194 , -0.68302435, -0.580868  , -0.0503333 ,\n",
      "       -0.00263816,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5745122 ,  1.2153194 , -0.68302435, -0.580868  , -0.0503333 ,\n",
      "       -0.00263816,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.11799788828431018, next_state=array([-0.58149886,  1.2024413 , -0.6976823 , -0.57238925, -0.05130348,\n",
      "       -0.01940369,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.58149886,  1.2024413 , -0.6976823 , -0.57238925, -0.05130348,\n",
      "       -0.01940369,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.550694131979468, next_state=array([-0.58857894,  1.188979  , -0.7094162 , -0.598281  , -0.04991186,\n",
      "        0.02783231,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.58857894,  1.188979  , -0.7094162 , -0.598281  , -0.04991186,\n",
      "        0.02783231,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.13113530111792102, next_state=array([-0.5955771 ,  1.1749165 , -0.69915116, -0.625028  , -0.05057485,\n",
      "       -0.01325978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5955771 ,  1.1749165 , -0.69915116, -0.625028  , -0.05057485,\n",
      "       -0.01325978,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5125232918277038, next_state=array([-0.60266566,  1.160254  , -0.7104693 , -0.6516161 , -0.04897268,\n",
      "        0.03204342,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.60266566,  1.160254  , -0.7104693 , -0.6516161 , -0.04897268,\n",
      "        0.03204342,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6410709835347177, next_state=array([-0.6097541 ,  1.1449914 , -0.7104693 , -0.6782829 , -0.04737053,\n",
      "        0.03204326,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6097541 ,  1.1449914 , -0.7104693 , -0.6782829 , -0.04737053,\n",
      "        0.03204326,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.2413526627667568, next_state=array([-6.1677754e-01,  1.1291337e+00, -7.0231724e-01, -7.0478171e-01,\n",
      "       -4.7396019e-02, -5.0985703e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-6.1677754e-01,  1.1291337e+00, -7.0231724e-01, -7.0478171e-01,\n",
      "       -4.7396019e-02, -5.0985703e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-0.30361756283659136, next_state=array([-0.62371665,  1.112682  , -0.6917501 , -0.7312577 , -0.04953184,\n",
      "       -0.04271634,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.62371665,  1.112682  , -0.6917501 , -0.7312577 , -0.04953184,\n",
      "       -0.04271634,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5408995036908777, next_state=array([-0.63063276,  1.0964884 , -0.689427  , -0.719798  , -0.05169209,\n",
      "       -0.04320516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.63063276,  1.0964884 , -0.689427  , -0.719798  , -0.05169209,\n",
      "       -0.04320516,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6446454644441804, next_state=array([-0.6374777 ,  1.0797    , -0.6805047 , -0.7462901 , -0.05563327,\n",
      "       -0.07882359,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6374777 ,  1.0797    , -0.6805047 , -0.7462901 , -0.05563327,\n",
      "       -0.07882359,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9001730755745256, next_state=array([-0.6443554 ,  1.0634613 , -0.68343276, -0.72188693, -0.05992233,\n",
      "       -0.08578123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6443554 ,  1.0634613 , -0.68343276, -0.72188693, -0.05992233,\n",
      "       -0.08578123,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.748550681721041, next_state=array([-0.651305  ,  1.0466279 , -0.6924563 , -0.7482522 , -0.06240074,\n",
      "       -0.04956837,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.651305  ,  1.0466279 , -0.6924563 , -0.7482522 , -0.06240074,\n",
      "       -0.04956837,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6530368068210055, next_state=array([-0.65834033,  1.0291934 , -0.7031955 , -0.77488405, -0.06273194,\n",
      "       -0.00662404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.65834033,  1.0291934 , -0.7031955 , -0.77488405, -0.06273194,\n",
      "       -0.00662404,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8929135439310585, next_state=array([-0.66537565,  1.0111587 , -0.7031955 , -0.80155075, -0.06306314,\n",
      "       -0.00662422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.66537565,  1.0111587 , -0.7031955 , -0.80155075, -0.06306314,\n",
      "       -0.00662422,  0.        ,  0.        ], dtype=float32), action=2, reward=2.709272899346627, next_state=array([-0.67239213,  0.99368393, -0.70117795, -0.7766796 , -0.0635325 ,\n",
      "       -0.00938716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.67239213,  0.99368393, -0.70117795, -0.7766796 , -0.0635325 ,\n",
      "       -0.00938716,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.46582872920814, next_state=array([-0.6793147 ,  0.9756031 , -0.68939084, -0.80372006, -0.06636654,\n",
      "       -0.05668063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6793147 ,  0.9756031 , -0.68939084, -0.80372006, -0.06636654,\n",
      "       -0.05668063,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7585428450518747, next_state=array([-0.68603826,  0.95750356, -0.67030233, -0.8045165 , -0.06840143,\n",
      "       -0.04069772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.68603826,  0.95750356, -0.67030233, -0.8045165 , -0.06840143,\n",
      "       -0.04069772,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5474218792204215, next_state=array([-0.6928302 ,  0.9388035 , -0.67887074, -0.8311301 , -0.06872308,\n",
      "       -0.00643334,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6928302 ,  0.9388035 , -0.67887074, -0.8311301 , -0.06872308,\n",
      "       -0.00643334,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9732529380956123, next_state=array([-0.6996222 ,  0.91950345, -0.6788708 , -0.8577967 , -0.06904475,\n",
      "       -0.00643344,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6996222 ,  0.91950345, -0.6788708 , -0.8577967 , -0.06904475,\n",
      "       -0.00643344,  0.        ,  0.        ], dtype=float32), action=2, reward=3.320517911808037, next_state=array([-0.70650184,  0.9011334 , -0.68690085, -0.81649876, -0.07009541,\n",
      "       -0.02101322,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.70650184,  0.9011334 , -0.68690085, -0.81649876, -0.07009541,\n",
      "       -0.02101322,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6180475048807057, next_state=array([-0.7134719 ,  0.88216513, -0.69824314, -0.84297925, -0.06887536,\n",
      "        0.02440091,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7134719 ,  0.88216513, -0.69824314, -0.84297925, -0.06887536,\n",
      "        0.02440091,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4015996018332089, next_state=array([-0.72049487,  0.8634716 , -0.7030942 , -0.83078164, -0.06808425,\n",
      "        0.01582245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.72049487,  0.8634716 , -0.7030942 , -0.83078164, -0.06808425,\n",
      "        0.01582245,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3277688506593666, next_state=array([-0.7275845 ,  0.84418344, -0.7114594 , -0.85713804, -0.06561383,\n",
      "        0.04940854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7275845 ,  0.84418344, -0.7114594 , -0.85713804, -0.06561383,\n",
      "        0.04940854,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7893126588064092, next_state=array([-0.7346741 ,  0.82429534, -0.71145946, -0.8838052 , -0.0631434 ,\n",
      "        0.04940858,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7346741 ,  0.82429534, -0.71145946, -0.8838052 , -0.0631434 ,\n",
      "        0.04940858,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.38363276337241703, next_state=array([-0.74167365,  0.80380255, -0.70016444, -0.91078365, -0.06293782,\n",
      "        0.00411161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.74167365,  0.80380255, -0.70016444, -0.91078365, -0.06293782,\n",
      "        0.00411161,  0.        ,  0.        ], dtype=float32), action=2, reward=5.264549071318112, next_state=array([-0.7484677 ,  0.7842483 , -0.68026525, -0.86904186, -0.06208145,\n",
      "        0.01712731,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7484677 ,  0.7842483 , -0.68026525, -0.86904186, -0.06208145,\n",
      "        0.01712731,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4356357183960415, next_state=array([-0.7553408 ,  0.76410884, -0.69020957, -0.8949699 , -0.05922012,\n",
      "        0.05722662,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7553408 ,  0.76410884, -0.69020957, -0.8949699 , -0.05922012,\n",
      "        0.05722662,  0.        ,  0.        ], dtype=float32), action=2, reward=0.889686645508516, next_state=array([-0.76221436,  0.74396324, -0.6901366 , -0.8952523 , -0.05646862,\n",
      "        0.05503017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.76221436,  0.74396324, -0.6901366 , -0.8952523 , -0.05646862,\n",
      "        0.05503017,  0.        ,  0.        ], dtype=float32), action=2, reward=3.2748633881725597, next_state=array([-0.76897866,  0.72431475, -0.6795301 , -0.87315243, -0.0534033 ,\n",
      "        0.06130638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.76897866,  0.72431475, -0.6795301 , -0.87315243, -0.0534033 ,\n",
      "        0.06130638,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2909064711296425, next_state=array([-0.77558863,  0.704802  , -0.6646938 , -0.867109  , -0.04974619,\n",
      "        0.07314207,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.77558863,  0.704802  , -0.6646938 , -0.867109  , -0.04974619,\n",
      "        0.07314207,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9171166258899746, next_state=array([-0.78219855,  0.68468946, -0.66469383, -0.8937767 , -0.04608911,\n",
      "        0.07314178,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.78219855,  0.68468946, -0.66469383, -0.8937767 , -0.04608911,\n",
      "        0.07314178,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3582303292864697, next_state=array([-0.7888878 ,  0.6639762 , -0.67464334, -0.920422  , -0.04044129,\n",
      "        0.1129562 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7888878 ,  0.6639762 , -0.67464334, -0.920422  , -0.04044129,\n",
      "        0.1129562 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0915949439585393, next_state=array([-0.7956486 ,  0.64267474, -0.6836189 , -0.9465445 , -0.03298916,\n",
      "        0.14904252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7956486 ,  0.64267474, -0.6836189 , -0.9465445 , -0.03298916,\n",
      "        0.14904252,  0.        ,  0.        ], dtype=float32), action=2, reward=2.703354057450679, next_state=array([-0.80247736,  0.621912  , -0.6899878 , -0.9226499 , -0.02596662,\n",
      "        0.14045082,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.80247736,  0.621912  , -0.6899878 , -0.9226499 , -0.02596662,\n",
      "        0.14045082,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3973227069155587, next_state=array([-0.8092349 ,  0.600545  , -0.68105304, -0.9495617 , -0.02073519,\n",
      "        0.10462878,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8092349 ,  0.600545  , -0.68105304, -0.9495617 , -0.02073519,\n",
      "        0.10462878,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5841150273975291, next_state=array([-0.8159063 ,  0.57856554, -0.67023826, -0.976827  , -0.01767379,\n",
      "        0.06122781,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8159063 ,  0.57856554, -0.67023826, -0.976827  , -0.01767379,\n",
      "        0.06122781,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.600802144202446, next_state=array([-0.8226686 ,  0.5559887 , -0.68165267, -1.0033585 , -0.01232599,\n",
      "        0.10695608,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8226686 ,  0.5559887 , -0.68165267, -1.0033585 , -0.01232599,\n",
      "        0.10695608,  0.        ,  0.        ], dtype=float32), action=2, reward=2.500563216036494, next_state=array([-0.8293548 ,  0.533727  , -0.6743594 , -0.9893747 , -0.00666059,\n",
      "        0.11330794,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8293548 ,  0.533727  , -0.6743594 , -0.9893747 , -0.00666059,\n",
      "        0.11330794,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9782299215490979, next_state=array([-8.3599073e-01,  5.1141018e-01, -6.6955495e-01, -9.9184388e-01,\n",
      "       -7.7370770e-04,  1.1773763e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-8.3599073e-01,  5.1141018e-01, -6.6955495e-01, -9.9184388e-01,\n",
      "       -7.7370770e-04,  1.1773763e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.8175534378243128, next_state=array([-0.842644  ,  0.48938772, -0.6712022 , -0.9787844 ,  0.0050314 ,\n",
      "        0.11610226,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.842644  ,  0.48938772, -0.6712022 , -0.9787844 ,  0.0050314 ,\n",
      "        0.11610226,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2556616608570152, next_state=array([-0.84929717,  0.46676576, -0.6712021 , -1.0054538 ,  0.0108365 ,\n",
      "        0.11610194,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.84929717,  0.46676576, -0.6712021 , -1.0054538 ,  0.0108365 ,\n",
      "        0.11610194,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.082576892404886, next_state=array([-0.8560273 ,  0.44353846, -0.6808521 , -1.0323987 ,  0.01857512,\n",
      "        0.1547723 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8560273 ,  0.44353846, -0.6808521 , -1.0323987 ,  0.01857512,\n",
      "        0.1547723 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7198184902592402, next_state=array([-0.8628663 ,  0.42083338, -0.6912935 , -1.0092257 ,  0.02587523,\n",
      "        0.1460022 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8628663 ,  0.42083338, -0.6912935 , -1.0092257 ,  0.02587523,\n",
      "        0.1460022 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5626231710769503, next_state=array([-0.8697053 ,  0.39752892, -0.69129336, -1.0358968 ,  0.03317531,\n",
      "        0.14600167,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8697053 ,  0.39752892, -0.69129336, -1.0358968 ,  0.03317531,\n",
      "        0.14600167,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.617140770193629, next_state=array([-0.87654436,  0.37362522, -0.6912931 , -1.0625681 ,  0.04047536,\n",
      "        0.14600112,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.87654436,  0.37362522, -0.6912931 , -1.0625681 ,  0.04047536,\n",
      "        0.14600112,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.6756549163142154, next_state=array([-0.8833834 ,  0.3491223 , -0.6912929 , -1.0892392 ,  0.04777539,\n",
      "        0.14600056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8833834 ,  0.3491223 , -0.6912929 , -1.0892392 ,  0.04777539,\n",
      "        0.14600056,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1932114442018347, next_state=array([-0.8901599 ,  0.32401887, -0.683449  , -1.1158993 ,  0.05350626,\n",
      "        0.11461733,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8901599 ,  0.32401887, -0.683449  , -1.1158993 ,  0.05350626,\n",
      "        0.11461733,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9301518570933627, next_state=array([-0.8968596 ,  0.29832882, -0.67380273, -1.1419241 ,  0.0572951 ,\n",
      "        0.0757767 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.8968596 ,  0.29832882, -0.67380273, -1.1419241 ,  0.0572951 ,\n",
      "        0.0757767 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.4152136978525207, next_state=array([-0.9036465 ,  0.27202058, -0.6847619 , -1.1695004 ,  0.06329472,\n",
      "        0.11999265,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9036465 ,  0.27202058, -0.6847619 , -1.1695004 ,  0.06329472,\n",
      "        0.11999265,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1433895813374577, next_state=array([-0.91035783,  0.24512173, -0.67526203, -1.1956866 ,  0.06738418,\n",
      "        0.08178903,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.91035783,  0.24512173, -0.67526203, -1.1956866 ,  0.06738418,\n",
      "        0.08178903,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.894805072179621, next_state=array([-0.9169723 ,  0.21762379, -0.6631274 , -1.2222065 ,  0.06904536,\n",
      "        0.0332238 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9169723 ,  0.21762379, -0.6631274 , -1.2222065 ,  0.06904536,\n",
      "        0.0332238 ,  0.        ,  0.        ], dtype=float32), action=3, reward=7.981246532080548, next_state=array([-0.9235257 ,  0.1895362 , -0.6554509 , -1.2483422 ,  0.06915903,\n",
      "        0.00227335,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9235257 ,  0.1895362 , -0.6554509 , -1.2483422 ,  0.06915903,\n",
      "        0.00227335,  1.        ,  0.        ], dtype=float32), action=0, reward=-3.9990458417184414, next_state=array([-0.9306268 ,  0.16178349, -0.7267393 , -1.2341957 ,  0.08502747,\n",
      "        0.31663883,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9306268 ,  0.16178349, -0.7267393 , -1.2341957 ,  0.08502747,\n",
      "        0.31663883,  1.        ,  0.        ], dtype=float32), action=0, reward=-4.396293754281544, next_state=array([-0.93766594,  0.1340817 , -0.74087495, -1.2336336 ,  0.11962888,\n",
      "        0.6894337 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.93766594,  0.1340817 , -0.74087495, -1.2336336 ,  0.11962888,\n",
      "        0.6894337 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-5.864310294001882, next_state=array([-0.9446068 ,  0.10611392, -0.7388445 , -1.2472386 ,  0.1642833 ,\n",
      "        0.8931235 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.9446068 ,  0.10611392, -0.7388445 , -1.2472386 ,  0.1642833 ,\n",
      "        0.8931235 ,  1.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.95191395,  0.08069301, -0.95491886, -0.9789304 ,  0.2756661 ,\n",
      "        3.8009236 ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([ 0.00760107,  1.4093963 ,  0.7699038 , -0.06775675, -0.00880109,\n",
      "       -0.17439467,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3027958308551615, next_state=array([ 0.01512518,  1.4072891 ,  0.7591641 , -0.0936996 , -0.01547436,\n",
      "       -0.13347724,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01512518,  1.4072891 ,  0.7591641 , -0.0936996 , -0.01547436,\n",
      "       -0.13347724,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9185330189214824, next_state=array([ 0.02269869,  1.4061372 ,  0.7639314 , -0.05127452, -0.02198409,\n",
      "       -0.13020687,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02269869,  1.4061372 ,  0.7639314 , -0.05127452, -0.02198409,\n",
      "       -0.13020687,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.716784192963587, next_state=array([ 0.03027239,  1.4043858 ,  0.7639502 , -0.07796169, -0.02849268,\n",
      "       -0.13018382,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03027239,  1.4043858 ,  0.7639502 , -0.07796169, -0.02849268,\n",
      "       -0.13018382,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0520695816846513, next_state=array([ 0.03787146,  1.4025803 ,  0.7664193 , -0.08038215, -0.03492875,\n",
      "       -0.1287334 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03787146,  1.4025803 ,  0.7664193 , -0.08038215, -0.03492875,\n",
      "       -0.1287334 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7610682697520474, next_state=array([ 0.04546862,  1.4008365 ,  0.7663068 , -0.07766462, -0.04144734,\n",
      "       -0.13038377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04546862,  1.4008365 ,  0.7663068 , -0.07766462, -0.04144734,\n",
      "       -0.13038377,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.216916402792036, next_state=array([ 0.05316114,  1.3984873 ,  0.77825755, -0.10467634, -0.05036022,\n",
      "       -0.17827436,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05316114,  1.3984873 ,  0.77825755, -0.10467634, -0.05036022,\n",
      "       -0.17827436,  0.        ,  0.        ], dtype=float32), action=1, reward=0.04242838840431887, next_state=array([ 0.06078024,  1.3955439 ,  0.769029  , -0.13107662, -0.05741229,\n",
      "       -0.1410541 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06078024,  1.3955439 ,  0.769029  , -0.13107662, -0.05741229,\n",
      "       -0.1410541 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8806299974617673, next_state=array([ 0.06839953,  1.3920009 ,  0.7690479 , -0.15774897, -0.06446455,\n",
      "       -0.14105839,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06839953,  1.3920009 ,  0.7690479 , -0.15774897, -0.06446455,\n",
      "       -0.14105839,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7945356864347388, next_state=array([ 0.0759058 ,  1.3892184 ,  0.75856876, -0.12402547, -0.07232822,\n",
      "       -0.15728769,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0759058 ,  1.3892184 ,  0.75856876, -0.12402547, -0.07232822,\n",
      "       -0.15728769,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.11330811202515065, next_state=array([ 0.08335333,  1.3858451 ,  0.75117004, -0.1502515 , -0.07869381,\n",
      "       -0.12732348,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08335333,  1.3858451 ,  0.75117004, -0.1502515 , -0.07869381,\n",
      "       -0.12732348,  0.        ,  0.        ], dtype=float32), action=2, reward=0.23476631016562238, next_state=array([ 0.09075394,  1.3832607 ,  0.7470478 , -0.11524892, -0.08562521,\n",
      "       -0.13864066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09075394,  1.3832607 ,  0.7470478 , -0.11524892, -0.08562521,\n",
      "       -0.13864066,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.16703390431202364, next_state=array([ 0.09811898,  1.3814559 ,  0.74402577, -0.08066133, -0.09309419,\n",
      "       -0.14939328,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09811898,  1.3814559 ,  0.74402577, -0.08066133, -0.09309419,\n",
      "       -0.14939328,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8974736834476857, next_state=array([ 0.1054842 ,  1.3790516 ,  0.7440456 , -0.10734079, -0.10056177,\n",
      "       -0.14936516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1054842 ,  1.3790516 ,  0.7440456 , -0.10734079, -0.10056177,\n",
      "       -0.14936516,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9306496675233393, next_state=array([ 0.11291371,  1.376034  ,  0.75210154, -0.13475728, -0.10965912,\n",
      "       -0.18196361,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11291371,  1.376034  ,  0.75210154, -0.13475728, -0.10965912,\n",
      "       -0.18196361,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.216648686896433, next_state=array([ 0.12041321,  1.3723955 ,  0.760881  , -0.16255149, -0.1205447 ,\n",
      "       -0.21773191,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12041321,  1.3723955 ,  0.760881  , -0.16255149, -0.1205447 ,\n",
      "       -0.21773191,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3378019372588028, next_state=array([ 0.12791309,  1.3681583 ,  0.7609113 , -0.18923138, -0.13142817,\n",
      "       -0.21768911,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12791309,  1.3681583 ,  0.7609113 , -0.18923138, -0.13142817,\n",
      "       -0.21768911,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7914688275327237, next_state=array([ 0.13550778,  1.3633137 ,  0.7727651 , -0.21655008, -0.14469105,\n",
      "       -0.2652814 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13550778,  1.3633137 ,  0.7727651 , -0.21655008, -0.14469105,\n",
      "       -0.2652814 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.686310154522913, next_state=array([ 0.1431717 ,  1.3578509 ,  0.78142035, -0.2443126 , -0.15971856,\n",
      "       -0.30057785,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1431717 ,  1.3578509 ,  0.78142035, -0.2443126 , -0.15971856,\n",
      "       -0.30057785,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8221153395412273, next_state=array([ 0.15083647,  1.351791  ,  0.7814596 , -0.27100298, -0.17474337,\n",
      "       -0.3005235 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15083647,  1.351791  ,  0.7814596 , -0.27100298, -0.17474337,\n",
      "       -0.3005235 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9966242590699597, next_state=array([ 0.15844241,  1.3451474 ,  0.77402604, -0.2969119 , -0.18824057,\n",
      "       -0.26996806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15844241,  1.3451474 ,  0.77402604, -0.2969119 , -0.18824057,\n",
      "       -0.26996806,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1463021336916754, next_state=array([ 0.16614266,  1.3378732 ,  0.7858381 , -0.325384  , -0.20418073,\n",
      "       -0.31883174,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16614266,  1.3378732 ,  0.7858381 , -0.325384  , -0.20418073,\n",
      "       -0.31883174,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6581262293566101, next_state=array([ 0.17375079,  1.3300192 ,  0.774238  , -0.35098696, -0.21775022,\n",
      "       -0.27141386,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17375079,  1.3300192 ,  0.774238  , -0.35098696, -0.21775022,\n",
      "       -0.27141386,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.759186653702443, next_state=array([ 0.18135968,  1.3215672 ,  0.7742689 , -0.37767574, -0.23131901,\n",
      "       -0.27140006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18135968,  1.3215672 ,  0.7742689 , -0.37767574, -0.23131901,\n",
      "       -0.27140006,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5302704078312093, next_state=array([ 0.1888812 ,  1.3125417 ,  0.76325524, -0.40291768, -0.24260616,\n",
      "       -0.22576275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1888812 ,  1.3125417 ,  0.76325524, -0.40291768, -0.24260616,\n",
      "       -0.22576275,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.668488395474202, next_state=array([ 0.19680949,  1.3043553 ,  0.80352056, -0.3656475 , -0.2535063 ,\n",
      "       -0.21800976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19680949,  1.3043553 ,  0.80352056, -0.3656475 , -0.2535063 ,\n",
      "       -0.21800976,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4668015693732173, next_state=array([ 0.20474252,  1.2955575 ,  0.8035835 , -0.39282647, -0.26400214,\n",
      "       -0.20991632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20474252,  1.2955575 ,  0.8035835 , -0.39282647, -0.26400214,\n",
      "       -0.20991632,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.582236696822888, next_state=array([ 0.21261397,  1.2861803 ,  0.79583615, -0.41835544, -0.27288792,\n",
      "       -0.17771521,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21261397,  1.2861803 ,  0.79583615, -0.41835544, -0.27288792,\n",
      "       -0.17771521,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3075445536484267, next_state=array([ 0.2204856 ,  1.2762041 ,  0.7958335 , -0.44502848, -0.2817736 ,\n",
      "       -0.17771444,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2204856 ,  1.2762041 ,  0.7958335 , -0.44502848, -0.2817736 ,\n",
      "       -0.17771444,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.07720963749601423, next_state=array([ 0.22850466,  1.2670764 ,  0.81110495, -0.4074774 , -0.29124692,\n",
      "       -0.18946643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22850466,  1.2670764 ,  0.81110495, -0.4074774 , -0.29124692,\n",
      "       -0.18946643,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.010429217451842304, next_state=array([ 0.23643179,  1.2573929 ,  0.79948026, -0.43175218, -0.2982306 ,\n",
      "       -0.13967301,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23643179,  1.2573929 ,  0.79948026, -0.43175218, -0.2982306 ,\n",
      "       -0.13967301,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1349964800855616, next_state=array([ 0.24435902,  1.2471098 ,  0.7994784 , -0.45842278, -0.3052142 ,\n",
      "       -0.13967249,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24435902,  1.2471098 ,  0.7994784 , -0.45842278, -0.3052142 ,\n",
      "       -0.13967249,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1418638887065242, next_state=array([ 0.25228634,  1.2362274 ,  0.7994765 , -0.48509338, -0.31219777,\n",
      "       -0.13967189,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25228634,  1.2362274 ,  0.7994765 , -0.48509338, -0.31219777,\n",
      "       -0.13967189,  0.        ,  0.        ], dtype=float32), action=1, reward=0.05764118076413752, next_state=array([ 0.2601325 ,  1.224794  ,  0.78915584, -0.5091356 , -0.31690958,\n",
      "       -0.09423597,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2601325 ,  1.224794  ,  0.78915584, -0.5091356 , -0.31690958,\n",
      "       -0.09423597,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9267061767886731, next_state=array([ 0.26810542,  1.2133453 ,  0.80183303, -0.5098332 , -0.32162595,\n",
      "       -0.09432761,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26810542,  1.2133453 ,  0.80183303, -0.5098332 , -0.32162595,\n",
      "       -0.09432761,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2834484479751904, next_state=array([ 0.2759939 ,  1.2013373 ,  0.7911639 , -0.53419703, -0.32404026,\n",
      "       -0.04828647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2759939 ,  1.2013373 ,  0.7911639 , -0.53419703, -0.32404026,\n",
      "       -0.04828647,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.385330730932867, next_state=array([ 0.28408784,  1.1892473 ,  0.81133443, -0.53777856, -0.3260621 ,\n",
      "       -0.04043672,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28408784,  1.1892473 ,  0.81133443, -0.53777856, -0.3260621 ,\n",
      "       -0.04043672,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5635153162373581, next_state=array([ 0.29209423,  1.1765922 ,  0.8003319 , -0.5623779 , -0.32574674,\n",
      "        0.0063072 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29209423,  1.1765922 ,  0.8003319 , -0.5623779 , -0.32574674,\n",
      "        0.0063072 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8304313314758656, next_state=array([ 0.30000848,  1.1633726 ,  0.7887723 , -0.5869474 , -0.32298493,\n",
      "        0.05523602,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30000848,  1.1633726 ,  0.7887723 , -0.5869474 , -0.32298493,\n",
      "        0.05523602,  0.        ,  0.        ], dtype=float32), action=2, reward=0.33398157239390686, next_state=array([ 0.30820197,  1.1507785 ,  0.8166648 , -0.5591417 , -0.32019824,\n",
      "        0.05573388,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30820197,  1.1507785 ,  0.8166648 , -0.5591417 , -0.32019824,\n",
      "        0.05573388,  0.        ,  0.        ], dtype=float32), action=1, reward=1.069994809430342, next_state=array([ 0.31630707,  1.13763   ,  0.8054894 , -0.58328116, -0.3149868 ,\n",
      "        0.10422947,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31630707,  1.13763   ,  0.8054894 , -0.58328116, -0.3149868 ,\n",
      "        0.10422947,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8088432839793824, next_state=array([ 0.3244691 ,  1.1249492 ,  0.8119221 , -0.5626651 , -0.31054434,\n",
      "        0.08884951,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3244691 ,  1.1249492 ,  0.8119221 , -0.5626651 , -0.31054434,\n",
      "        0.08884951,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.05454404018968262, next_state=array([ 0.3326312 ,  1.1116688 ,  0.8119213 , -0.5893333 , -0.3061019 ,\n",
      "        0.08884934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3326312 ,  1.1116688 ,  0.8119213 , -0.5893333 , -0.3061019 ,\n",
      "        0.08884934,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7388957966095131, next_state=array([ 0.34073782,  1.0978222 ,  0.80486536, -0.6141999 , -0.30010694,\n",
      "        0.11989901,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34073782,  1.0978222 ,  0.80486536, -0.6141999 , -0.30010694,\n",
      "        0.11989901,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7650882198127806, next_state=array([ 0.34890613,  1.0833594 ,  0.8125714 , -0.64191115, -0.29570255,\n",
      "        0.08808786,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34890613,  1.0833594 ,  0.8125714 , -0.64191115, -0.29570255,\n",
      "        0.08808786,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.05695231980905646, next_state=array([ 0.35707456,  1.0682971 ,  0.8125707 , -0.6685793 , -0.29129818,\n",
      "        0.08808704,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35707456,  1.0682971 ,  0.8125707 , -0.6685793 , -0.29129818,\n",
      "        0.08808704,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2111572195632448, next_state=array([ 0.3656001 ,  1.0538473 ,  0.84778845, -0.6412663 , -0.28638577,\n",
      "        0.09824803,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3656001 ,  1.0538473 ,  0.84778845, -0.6412663 , -0.28638577,\n",
      "        0.09824803,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2677029357032825, next_state=array([ 0.37421113,  1.0387529 ,  0.85860044, -0.67037696, -0.28381136,\n",
      "        0.05148825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37421113,  1.0387529 ,  0.85860044, -0.67037696, -0.28381136,\n",
      "        0.05148825,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.22719699557256945, next_state=array([ 0.38282222,  1.0230584 ,  0.85860014, -0.6970442 , -0.28123695,\n",
      "        0.05148806,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38282222,  1.0230584 ,  0.85860014, -0.6970442 , -0.28123695,\n",
      "        0.05148806,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5716398293833322, next_state=array([ 0.39180908,  1.0077924 ,  0.8954128 , -0.6778699 , -0.2778731 ,\n",
      "        0.06727729,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39180908,  1.0077924 ,  0.8954128 , -0.6778699 , -0.2778731 ,\n",
      "        0.06727729,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.14924427514853278, next_state=array([ 0.40079603,  0.99192625,  0.89541245, -0.70453745, -0.27450925,\n",
      "        0.06727725,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40079603,  0.99192625,  0.89541245, -0.70453745, -0.27450925,\n",
      "        0.06727725,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3325669979637087, next_state=array([ 0.40986365,  0.97541916,  0.9056169 , -0.733431  , -0.27334058,\n",
      "        0.02337351,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40986365,  0.97541916,  0.9056169 , -0.733431  , -0.27334058,\n",
      "        0.02337351,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4853271675258657, next_state=array([ 0.41900864,  0.9582749 ,  0.91540146, -0.76213944, -0.27426702,\n",
      "       -0.01852849,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41900864,  0.9582749 ,  0.91540146, -0.76213944, -0.27426702,\n",
      "       -0.01852849,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.568458374431998, next_state=array([ 0.4281536 ,  0.9405307 ,  0.9154016 , -0.7888062 , -0.27519342,\n",
      "       -0.01852784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4281536 ,  0.9405307 ,  0.9154016 , -0.7888062 , -0.27519342,\n",
      "       -0.01852784,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7592534978031142, next_state=array([ 0.43738326,  0.9221509 ,  0.92607486, -0.817467  , -0.2783816 ,\n",
      "       -0.06376299,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.43738326,  0.9221509 ,  0.92607486, -0.817467  , -0.2783816 ,\n",
      "       -0.06376299,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0715388250406874, next_state=array([ 0.44676122,  0.90435135,  0.9412279 , -0.79175013, -0.28191042,\n",
      "       -0.07057671,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44676122,  0.90435135,  0.9412279 , -0.79175013, -0.28191042,\n",
      "       -0.07057671,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.09535885681860917, next_state=array([ 0.4563052 ,  0.88679755,  0.95781153, -0.7808398 , -0.2854273 ,\n",
      "       -0.07033705,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4563052 ,  0.88679755,  0.95781153, -0.7808398 , -0.2854273 ,\n",
      "       -0.07033705,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7043032514879133, next_state=array([ 0.46590835,  0.8686283 ,  0.96521217, -0.80848867, -0.29047045,\n",
      "       -0.1008633 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46590835,  0.8686283 ,  0.96521217, -0.80848867, -0.29047045,\n",
      "       -0.1008633 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2985198060019616, next_state=array([ 0.47545308,  0.8498776 ,  0.95788604, -0.8340453 , -0.293988  ,\n",
      "       -0.07034993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47545308,  0.8498776 ,  0.95788604, -0.8340453 , -0.293988  ,\n",
      "       -0.07034993,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9123134287805783, next_state=array([ 0.48499793,  0.83052725,  0.95788556, -0.86071295, -0.2975055 ,\n",
      "       -0.07035036,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48499793,  0.83052725,  0.95788556, -0.86071295, -0.2975055 ,\n",
      "       -0.07035036,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9197094192241366, next_state=array([ 0.49475154,  0.8111994 ,  0.9784176 , -0.859643  , -0.30066258,\n",
      "       -0.06314136,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49475154,  0.8111994 ,  0.9784176 , -0.859643  , -0.30066258,\n",
      "       -0.06314136,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7641250826597161, next_state=array([ 0.5045657 ,  0.7912484 ,  0.9860233 , -0.8876738 , -0.30542696,\n",
      "       -0.09528781,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5045657 ,  0.7912484 ,  0.9860233 , -0.8876738 , -0.30542696,\n",
      "       -0.09528781,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0903656663342076, next_state=array([ 0.51438   ,  0.77069753,  0.9860226 , -0.9143422 , -0.31019133,\n",
      "       -0.09528768,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51438   ,  0.77069753,  0.9860226 , -0.9143422 , -0.31019133,\n",
      "       -0.09528768,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1110029025997505, next_state=array([ 0.52419424,  0.7495471 ,  0.98602164, -0.9410107 , -0.3149557 ,\n",
      "       -0.0952878 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.52419424,  0.7495471 ,  0.98602164, -0.9410107 , -0.3149557 ,\n",
      "       -0.0952878 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.134412286337522, next_state=array([ 0.5340086 ,  0.7277969 ,  0.9860207 , -0.9676792 , -0.31972012,\n",
      "       -0.09528792,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5340086 ,  0.7277969 ,  0.9860207 , -0.9676792 , -0.31972012,\n",
      "       -0.09528792,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.160989950727128, next_state=array([ 0.54382306,  0.705447  ,  0.9860198 , -0.99434775, -0.3244845 ,\n",
      "       -0.09528757,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.54382306,  0.705447  ,  0.9860198 , -0.99434775, -0.3244845 ,\n",
      "       -0.09528757,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5366283163839511, next_state=array([ 0.5539775 ,  0.6839642 ,  1.0199621 , -0.9558144 , -0.329201  ,\n",
      "       -0.09433012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5539775 ,  0.6839642 ,  1.0199621 , -0.9558144 , -0.329201  ,\n",
      "       -0.09433012,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.258930836340653, next_state=array([ 0.5641319 ,  0.6618816 ,  1.0199611 , -0.98248273, -0.3339175 ,\n",
      "       -0.09432989,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5641319 ,  0.6618816 ,  1.0199611 , -0.98248273, -0.3339175 ,\n",
      "       -0.09432989,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2962836123080024, next_state=array([ 0.57428646,  0.6391993 ,  1.0199602 , -1.0091511 , -0.33863398,\n",
      "       -0.09432974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.57428646,  0.6391993 ,  1.0199602 , -1.0091511 , -0.33863398,\n",
      "       -0.09432974,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.33786463814954, next_state=array([ 0.584441  ,  0.61591744,  1.0199592 , -1.0358195 , -0.34335047,\n",
      "       -0.09432957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.584441  ,  0.61591744,  1.0199592 , -1.0358195 , -0.34335047,\n",
      "       -0.09432957,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.357109132211508, next_state=array([ 0.59482086,  0.5926348 ,  1.0421493 , -1.035782  , -0.34770766,\n",
      "       -0.0871439 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.59482086,  0.5926348 ,  1.0421493 , -1.035782  , -0.34770766,\n",
      "       -0.0871439 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.1537016208691398, next_state=array([ 0.6052612 ,  0.56953335,  1.0487189 , -1.0278707 , -0.35262245,\n",
      "       -0.09829588,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6052612 ,  0.56953335,  1.0487189 , -1.0278707 , -0.35262245,\n",
      "       -0.09829588,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6854882447821342, next_state=array([ 0.6156418 ,  0.5458769 ,  1.0410527 , -1.0521381 , -0.35578305,\n",
      "       -0.06321263,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6156418 ,  0.5458769 ,  1.0410527 , -1.0521381 , -0.35578305,\n",
      "       -0.06321263,  0.        ,  0.        ], dtype=float32), action=2, reward=0.21297608338040847, next_state=array([ 0.62608016,  0.5224138 ,  1.0473958 , -1.0436953 , -0.35954496,\n",
      "       -0.07523853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.62608016,  0.5224138 ,  1.0473958 , -1.0436953 , -0.35954496,\n",
      "       -0.07523853,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.523150295824762, next_state=array([ 0.63643897,  0.49838856,  1.0373923 , -1.0681655 , -0.3611398 ,\n",
      "       -0.03189756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.63643897,  0.49838856,  1.0373923 , -1.0681655 , -0.3611398 ,\n",
      "       -0.03189756,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4226591493242609, next_state=array([ 0.64679754,  0.47376347,  1.0373921 , -1.0948323 , -0.3627347 ,\n",
      "       -0.03189723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.64679754,  0.47376347,  1.0373921 , -1.0948323 , -0.3627347 ,\n",
      "       -0.03189723,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.739653100648893, next_state=array([ 0.65724087,  0.44847974,  1.0481546 , -1.1246922 , -0.36677292,\n",
      "       -0.08076467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.65724087,  0.44847974,  1.0481546 , -1.1246922 , -0.36677292,\n",
      "       -0.08076467,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.913833382847342, next_state=array([ 0.667765  ,  0.42255938,  1.0582845 , -1.153536  , -0.37299955,\n",
      "       -0.12453245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.667765  ,  0.42255938,  1.0582845 , -1.153536  , -0.37299955,\n",
      "       -0.12453245,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.119278846311886, next_state=array([ 0.67828906,  0.3960395 ,  1.0582826 , -1.1802057 , -0.37922612,\n",
      "       -0.12453213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.67828906,  0.3960395 ,  1.0582826 , -1.1802057 , -0.37922612,\n",
      "       -0.12453213,  0.        ,  0.        ], dtype=float32), action=2, reward=8.43114282686265, next_state=array([ 0.68906176,  0.3697182 ,  1.0829647 , -1.171363  , -0.38529715,\n",
      "       -0.1214207 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.68906176,  0.3697182 ,  1.0829647 , -1.171363  , -0.38529715,\n",
      "       -0.1214207 ,  1.        ,  0.        ], dtype=float32), action=2, reward=56.47134997111495, next_state=array([ 0.69636214,  0.3541858 ,  0.7378281 , -0.69325507, -0.40116256,\n",
      "       -0.32624596,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.69636214,  0.3541858 ,  0.7378281 , -0.69325507, -0.40116256,\n",
      "       -0.32624596,  1.        ,  0.        ], dtype=float32), action=0, reward=-2.4055467409713174, next_state=array([ 0.7042866 ,  0.33851725,  0.78296393, -0.6943027 , -0.39101517,\n",
      "        0.193075  ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7042866 ,  0.33851725,  0.78296393, -0.6943027 , -0.39101517,\n",
      "        0.193075  ,  1.        ,  0.        ], dtype=float32), action=2, reward=-100, next_state=array([ 0.7101324 ,  0.33219224,  0.3703674 , -0.03933381, -0.32065675,\n",
      "        1.8340538 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-5.71727753e-04,  1.41567111e+00, -5.79296276e-02,  2.11157367e-01,\n",
      "        6.69329602e-04,  1.31219085e-02,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32), action=1, reward=1.4426307510216543, next_state=array([-1.2169838e-03,  1.4198523e+00, -6.7046620e-02,  1.8583409e-01,\n",
      "        3.1619072e-03,  4.9856793e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.2169838e-03,  1.4198523e+00, -6.7046620e-02,  1.8583409e-01,\n",
      "        3.1619072e-03,  4.9856793e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=2.449331633034633, next_state=array([-0.00177526,  1.4234362 , -0.05613009,  0.15928034,  0.00346207,\n",
      "        0.00600357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00177526,  1.4234362 , -0.05613009,  0.15928034,  0.00346207,\n",
      "        0.00600357,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.955800410162129, next_state=array([-0.0023263 ,  1.427548  , -0.05545593,  0.18274893,  0.00381067,\n",
      "        0.0069725 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0023263 ,  1.427548  , -0.05545593,  0.18274893,  0.00381067,\n",
      "        0.0069725 ,  0.        ,  0.        ], dtype=float32), action=1, reward=1.6230792224211836, next_state=array([-0.00294218,  1.43107   , -0.06359132,  0.1565207 ,  0.00578914,\n",
      "        0.0395732 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00294218,  1.43107   , -0.06359132,  0.1565207 ,  0.00578914,\n",
      "        0.0395732 ,  0.        ,  0.        ], dtype=float32), action=3, reward=2.5439724845092555, next_state=array([-0.00347624,  1.4339913 , -0.05332392,  0.12984249,  0.00570671,\n",
      "       -0.00164869,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00347624,  1.4339913 , -0.05332392,  0.12984249,  0.00570671,\n",
      "       -0.00164869,  0.        ,  0.        ], dtype=float32), action=0, reward=2.1984809805393013, next_state=array([-0.0040102 ,  1.4363128 , -0.05332317,  0.10317435,  0.00562555,\n",
      "       -0.00162331,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0040102 ,  1.4363128 , -0.05332317,  0.10317435,  0.00562555,\n",
      "       -0.00162331,  0.        ,  0.        ], dtype=float32), action=3, reward=2.8546140743183073, next_state=array([-0.00445776,  1.4380424 , -0.04245557,  0.07687943,  0.0033644 ,\n",
      "       -0.04522736,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00445776,  1.4380424 , -0.04245557,  0.07687943,  0.0033644 ,\n",
      "       -0.04522736,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2374330861828764, next_state=array([-0.0049983 ,  1.4391751 , -0.05414044,  0.05034422,  0.0034483 ,\n",
      "        0.00167829,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0049983 ,  1.4391751 , -0.05414044,  0.05034422,  0.0034483 ,\n",
      "        0.00167829,  0.        ,  0.        ], dtype=float32), action=0, reward=1.4221766066440011, next_state=array([-0.00553884,  1.4397078 , -0.05414133,  0.02367577,  0.00353073,\n",
      "        0.0016484 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00553884,  1.4397078 , -0.05414133,  0.02367577,  0.00353073,\n",
      "        0.0016484 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.061873777462455, next_state=array([-0.00594501,  1.4408318 , -0.04136525,  0.04994656,  0.00426387,\n",
      "        0.01466437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00594501,  1.4408318 , -0.04136525,  0.04994656,  0.00426387,\n",
      "        0.01466437,  0.        ,  0.        ], dtype=float32), action=0, reward=1.6131302885326022, next_state=array([-0.00635128,  1.4413553 , -0.04136757,  0.02326844,  0.0049964 ,\n",
      "        0.01465207,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00635128,  1.4413553 , -0.04136757,  0.02326844,  0.0049964 ,\n",
      "        0.01465207,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7426772576006602, next_state=array([-0.00684032,  1.4412845 , -0.05174892, -0.0031608 ,  0.00780895,\n",
      "        0.05625622,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00684032,  1.4412845 , -0.05174892, -0.0031608 ,  0.00780895,\n",
      "        0.05625622,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1605116752531033, next_state=array([-0.00741234,  1.4406146 , -0.06214529, -0.0298085 ,  0.01270203,\n",
      "        0.09787034,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00741234,  1.4406146 , -0.06214529, -0.0298085 ,  0.01270203,\n",
      "        0.09787034,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6372828107318866, next_state=array([-0.00789604,  1.440737  , -0.05379366,  0.00538648,  0.01806599,\n",
      "        0.1072889 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00789604,  1.440737  , -0.05379366,  0.00538648,  0.01806599,\n",
      "        0.1072889 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8695591493727477, next_state=array([-0.00837984,  1.4402597 , -0.05380892, -0.02129546,  0.02342922,\n",
      "        0.10727397,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00837984,  1.4402597 , -0.05380892, -0.02129546,  0.02342922,\n",
      "        0.10727397,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7453379187722635, next_state=array([-0.0087676 ,  1.4391942 , -0.04172831, -0.04740144,  0.02636358,\n",
      "        0.05869238,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0087676 ,  1.4391942 , -0.04172831, -0.04740144,  0.02636358,\n",
      "        0.05869238,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.556607169067546, next_state=array([-0.00906305,  1.4375404 , -0.03016194, -0.07351171,  0.0269745 ,\n",
      "        0.01221944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00906305,  1.4375404 , -0.03016194, -0.07351171,  0.0269745 ,\n",
      "        0.01221944,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.928473041316663, next_state=array([-0.00944166,  1.43529   , -0.04059751, -0.10007009,  0.02967454,\n",
      "        0.05400585,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00944166,  1.43529   , -0.04059751, -0.10007009,  0.02967454,\n",
      "        0.05400585,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4944605975057073, next_state=array([-0.00982046,  1.4324397 , -0.04060589, -0.12673964,  0.03237282,\n",
      "        0.05397085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00982046,  1.4324397 , -0.04060589, -0.12673964,  0.03237282,\n",
      "        0.05397085,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9302541721845885, next_state=array([-0.0102663 ,  1.4289877 , -0.04900834, -0.15352353,  0.03675358,\n",
      "        0.08762298,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0102663 ,  1.4289877 , -0.04900834, -0.15352353,  0.03675358,\n",
      "        0.08762298,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2992411463264204, next_state=array([-0.0107584 ,  1.4259855 , -0.05354378, -0.13354391,  0.04103769,\n",
      "        0.08568993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0107584 ,  1.4259855 , -0.05354378, -0.13354391,  0.04103769,\n",
      "        0.08568993,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.57438356333887, next_state=array([-0.01125069,  1.4223833 , -0.05355516, -0.16022268,  0.04532163,\n",
      "        0.08568641,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01125069,  1.4223833 , -0.05355516, -0.16022268,  0.04532163,\n",
      "        0.08568641,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.209239837288662, next_state=array([-0.01167326,  1.4181753 , -0.044825  , -0.18710104,  0.04785911,\n",
      "        0.05075436,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01167326,  1.4181753 , -0.044825  , -0.18710104,  0.04785911,\n",
      "        0.05075436,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.855157676082199, next_state=array([-0.01216822,  1.413354  , -0.05390466, -0.21442737,  0.05222414,\n",
      "        0.08730841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01216822,  1.413354  , -0.05390466, -0.21442737,  0.05222414,\n",
      "        0.08730841,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1234481722258465, next_state=array([-0.01281815,  1.4089541 , -0.06885266, -0.19568634,  0.05603681,\n",
      "        0.07625341,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01281815,  1.4089541 , -0.06885266, -0.19568634,  0.05603681,\n",
      "        0.07625341,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4143968298484992, next_state=array([-0.01346817,  1.4039546 , -0.06885256, -0.22235425,  0.05984949,\n",
      "        0.07625348,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01346817,  1.4039546 , -0.06885256, -0.22235425,  0.05984949,\n",
      "        0.07625348,  0.        ,  0.        ], dtype=float32), action=2, reward=0.851830362144949, next_state=array([-0.01412287,  1.3992133 , -0.06946401, -0.21089214,  0.06379856,\n",
      "        0.07898145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01412287,  1.3992133 , -0.06946401, -0.21089214,  0.06379856,\n",
      "        0.07898145,  0.        ,  0.        ], dtype=float32), action=2, reward=1.675569150074051, next_state=array([-0.01481371,  1.3949678 , -0.07311346, -0.18886371,  0.06779687,\n",
      "        0.07996593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01481371,  1.3949678 , -0.07311346, -0.18886371,  0.06779687,\n",
      "        0.07996593,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8602751878239008, next_state=array([-0.01541576,  1.3901291 , -0.06199534, -0.21513526,  0.0695636 ,\n",
      "        0.03533449,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01541576,  1.3901291 , -0.06199534, -0.21513526,  0.0695636 ,\n",
      "        0.03533449,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7127857949344034, next_state=array([-0.0160943 ,  1.3846858 , -0.07157088, -0.24210793,  0.07325136,\n",
      "        0.07375509,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0160943 ,  1.3846858 , -0.07157088, -0.24210793,  0.07325136,\n",
      "        0.07375509,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.857881888476895, next_state=array([-0.01684437,  1.3786283 , -0.08056552, -0.26950315,  0.07875577,\n",
      "        0.11008827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01684437,  1.3786283 , -0.08056552, -0.26950315,  0.07875577,\n",
      "        0.11008827,  0.        ,  0.        ], dtype=float32), action=2, reward=1.401488263744011, next_state=array([-0.01750116,  1.3729253 , -0.07191144, -0.2538108 ,  0.08492153,\n",
      "        0.12331504,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01750116,  1.3729253 , -0.07191144, -0.2538108 ,  0.08492153,\n",
      "        0.12331504,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.12637324242928, next_state=array([-0.01824513,  1.3666196 , -0.08282278, -0.28074712,  0.09327311,\n",
      "        0.16703178,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01824513,  1.3666196 , -0.08282278, -0.28074712,  0.09327311,\n",
      "        0.16703178,  0.        ,  0.        ], dtype=float32), action=2, reward=0.1208912913669849, next_state=array([-0.01907902,  1.3605261 , -0.09162569, -0.2713594 ,  0.10144374,\n",
      "        0.16341218,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01907902,  1.3605261 , -0.09162569, -0.2713594 ,  0.10144374,\n",
      "        0.16341218,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.3009985973397975, next_state=array([-0.01999092,  1.3538167 , -0.10142078, -0.29892316,  0.11160018,\n",
      "        0.20312865,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01999092,  1.3538167 , -0.10142078, -0.29892316,  0.11160018,\n",
      "        0.20312865,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.218599692787278, next_state=array([-0.02081976,  1.3465345 , -0.0909544 , -0.3242829 ,  0.1196183 ,\n",
      "        0.16036281,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02081976,  1.3465345 , -0.0909544 , -0.3242829 ,  0.1196183 ,\n",
      "        0.16036281,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1534347230007413, next_state=array([-0.02158079,  1.3386703 , -0.08240335, -0.35003716,  0.12589492,\n",
      "        0.1255321 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02158079,  1.3386703 , -0.08240335, -0.35003716,  0.12589492,\n",
      "        0.1255321 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.008082224952061, next_state=array([-0.02242746,  1.3301806 , -0.09320121, -0.378056  ,  0.13438106,\n",
      "        0.16972283,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02242746,  1.3301806 , -0.09320121, -0.378056  ,  0.13438106,\n",
      "        0.16972283,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9896465142137163, next_state=array([-0.02319088,  1.3211197 , -0.08269187, -0.40329948,  0.1407092 ,\n",
      "        0.12656334,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02319088,  1.3211197 , -0.08269187, -0.40329948,  0.1407092 ,\n",
      "        0.12656334,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9397751301415826, next_state=array([-0.02388811,  1.3114686 , -0.07438356, -0.42937958,  0.14535888,\n",
      "        0.09299304,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02388811,  1.3114686 , -0.07438356, -0.42937958,  0.14535888,\n",
      "        0.09299304,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6454446960987628, next_state=array([-0.02449675,  1.3012282 , -0.06328823, -0.45536587,  0.14777279,\n",
      "        0.04827841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02449675,  1.3012282 , -0.06328823, -0.45536587,  0.14777279,\n",
      "        0.04827841,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8014403434061705, next_state=array([-0.02510548,  1.2903879 , -0.06328813, -0.48203307,  0.15018669,\n",
      "        0.04827838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02510548,  1.2903879 , -0.06328813, -0.48203307,  0.15018669,\n",
      "        0.04827838,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2888208673040527, next_state=array([-0.02562704,  1.2789739 , -0.05232022, -0.5073055 ,  0.15034993,\n",
      "        0.00326474,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02562704,  1.2789739 , -0.05232022, -0.5073055 ,  0.15034993,\n",
      "        0.00326474,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8521998314954817, next_state=array([-0.02621965,  1.2669466 , -0.06124875, -0.53475946,  0.15232557,\n",
      "        0.03951278,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02621965,  1.2669466 , -0.06124875, -0.53475946,  0.15232557,\n",
      "        0.03951278,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4639648140652184, next_state=array([-0.02705174,  1.2551514 , -0.08448076, -0.52435845,  0.15359613,\n",
      "        0.02541147,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02705174,  1.2551514 , -0.08448076, -0.52435845,  0.15359613,\n",
      "        0.02541147,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5240248910427, next_state=array([-0.02788372,  1.2427562 , -0.08448073, -0.55102533,  0.1548667 ,\n",
      "        0.02541142,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02788372,  1.2427562 , -0.08448073, -0.55102533,  0.1548667 ,\n",
      "        0.02541142,  0.        ,  0.        ], dtype=float32), action=2, reward=3.0464141523039077, next_state=array([-0.02869873,  1.2308942 , -0.08339254, -0.5274002 ,  0.15675423,\n",
      "        0.03775087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02869873,  1.2308942 , -0.08339254, -0.5274002 ,  0.15675423,\n",
      "        0.03775087,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3265419992822956, next_state=array([-0.02958431,  1.2189711 , -0.09038109, -0.5301114 ,  0.15857899,\n",
      "        0.03649531,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02958431,  1.2189711 , -0.09038109, -0.5301114 ,  0.15857899,\n",
      "        0.03649531,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2497254862172997, next_state=array([-0.03040533,  1.206457  , -0.08229382, -0.55620193,  0.15877019,\n",
      "        0.00382396,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03040533,  1.206457  , -0.08229382, -0.55620193,  0.15877019,\n",
      "        0.00382396,  0.        ,  0.        ], dtype=float32), action=2, reward=2.9680276919243456, next_state=array([-0.03143682,  1.1944898 , -0.10294414, -0.53185344,  0.1585589 ,\n",
      "       -0.00422578,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03143682,  1.1944898 , -0.10294414, -0.53185344,  0.1585589 ,\n",
      "       -0.00422578,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3457168931792012, next_state=array([-0.03246832,  1.1819227 , -0.10294414, -0.55852014,  0.15834762,\n",
      "       -0.00422576,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03246832,  1.1819227 , -0.10294414, -0.55852014,  0.15834762,\n",
      "       -0.00422576,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8105585652452294, next_state=array([-0.03342056,  1.1687825 , -0.09294151, -0.58376384,  0.15607332,\n",
      "       -0.04548616,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03342056,  1.1687825 , -0.09294151, -0.58376384,  0.15607332,\n",
      "       -0.04548616,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7084948336900243, next_state=array([-0.03430405,  1.1550523 , -0.08433365, -0.6098095 ,  0.15205972,\n",
      "       -0.08027202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03430405,  1.1550523 , -0.08433365, -0.6098095 ,  0.15205972,\n",
      "       -0.08027202,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2136354588515974, next_state=array([-0.03525076,  1.1407032 , -0.09228972, -0.637498  ,  0.14967962,\n",
      "       -0.04760241,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03525076,  1.1407032 , -0.09228972, -0.637498  ,  0.14967962,\n",
      "       -0.04760241,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.911105698452559, next_state=array([-0.03619747,  1.1257541 , -0.09228961, -0.6641652 ,  0.14729951,\n",
      "       -0.04760236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03619747,  1.1257541 , -0.09228961, -0.6641652 ,  0.14729951,\n",
      "       -0.04760236,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.34095343828639, next_state=array([-0.03722706,  1.1101866 , -0.10269265, -0.69186383,  0.14703743,\n",
      "       -0.00524166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03722706,  1.1101866 , -0.10269265, -0.69186383,  0.14703743,\n",
      "       -0.00524166,  0.        ,  0.        ], dtype=float32), action=2, reward=4.8359963602450025, next_state=array([-0.03826819,  1.0954694 , -0.10445948, -0.65412843,  0.14737742,\n",
      "        0.00679993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03826819,  1.0954694 , -0.10445948, -0.65412843,  0.14737742,\n",
      "        0.00679993,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1415613005542298, next_state=array([-0.03930931,  1.0801523 , -0.10445948, -0.6807951 ,  0.14771743,\n",
      "        0.00679991,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03930931,  1.0801523 , -0.10445948, -0.6807951 ,  0.14771743,\n",
      "        0.00679991,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0842076754662457, next_state=array([-0.04035053,  1.0642352 , -0.10445948, -0.7074617 ,  0.14805743,\n",
      "        0.00679993,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04035053,  1.0642352 , -0.10445948, -0.7074617 ,  0.14805743,\n",
      "        0.00679993,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5942712504318297, next_state=array([-0.04131594,  1.0477453 , -0.09491332, -0.7327226 ,  0.14642806,\n",
      "       -0.03258703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04131594,  1.0477453 , -0.09491332, -0.7327226 ,  0.14642806,\n",
      "       -0.03258703,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7786816790926423, next_state=array([-0.04228134,  1.0306554 , -0.09491327, -0.7593895 ,  0.1447987 ,\n",
      "       -0.03258702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04228134,  1.0306554 , -0.09491327, -0.7593895 ,  0.1447987 ,\n",
      "       -0.03258702,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7204642087635307, next_state=array([-0.04324675,  1.0129657 , -0.09491322, -0.78605634,  0.14316934,\n",
      "       -0.032587  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04324675,  1.0129657 , -0.09491322, -0.78605634,  0.14316934,\n",
      "       -0.032587  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.34134850023877905, next_state=array([-0.04414244,  0.9946893 , -0.08614312, -0.8119518 ,  0.13976006,\n",
      "       -0.06818584,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04414244,  0.9946893 , -0.08614312, -0.8119518 ,  0.13976006,\n",
      "       -0.06818584,  0.        ,  0.        ], dtype=float32), action=3, reward=0.04042538917929164, next_state=array([-0.04494648,  0.9758437 , -0.07460701, -0.83705556,  0.1339806 ,\n",
      "       -0.11558904,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04494648,  0.9758437 , -0.07460701, -0.83705556,  0.1339806 ,\n",
      "       -0.11558904,  0.        ,  0.        ], dtype=float32), action=3, reward=0.0998152586926733, next_state=array([-0.04568348,  0.9564028 , -0.06620663, -0.86338943,  0.1265172 ,\n",
      "       -0.14926764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04568348,  0.9564028 , -0.06620663, -0.86338943,  0.1265172 ,\n",
      "       -0.14926764,  0.        ,  0.        ], dtype=float32), action=3, reward=0.33621706590813116, next_state=array([-0.04635582,  0.93637335, -0.05807623, -0.8894487 ,  0.11740967,\n",
      "       -0.18215123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04635582,  0.93637335, -0.05807623, -0.8894487 ,  0.11740967,\n",
      "       -0.18215123,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.07792142668043198, next_state=array([-0.04711752,  0.9157371 , -0.06926504, -0.91663945,  0.11055051,\n",
      "       -0.13718286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04711752,  0.9157371 , -0.06926504, -0.91663945,  0.11055051,\n",
      "       -0.13718286,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4070385515177124, next_state=array([-0.04774122,  0.8950935 , -0.05630661, -0.9170612 ,  0.1045273 ,\n",
      "       -0.12046399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04774122,  0.8950935 , -0.05630661, -0.9170612 ,  0.1045273 ,\n",
      "       -0.12046399,  0.        ,  0.        ], dtype=float32), action=2, reward=5.877654487165256, next_state=array([-0.04842768,  0.8752758 , -0.06274566, -0.88038266,  0.09867446,\n",
      "       -0.11705653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04842768,  0.8752758 , -0.06274566, -0.88038266,  0.09867446,\n",
      "       -0.11705653,  0.        ,  0.        ], dtype=float32), action=3, reward=0.27332354532043834, next_state=array([-0.04904079,  0.85487837, -0.05351966, -0.9060622 ,  0.09094615,\n",
      "       -0.15456632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04904079,  0.85487837, -0.05351966, -0.9060622 ,  0.09094615,\n",
      "       -0.15456632,  0.        ,  0.        ], dtype=float32), action=2, reward=6.371759088602642, next_state=array([-0.04974337,  0.8353874 , -0.06246825, -0.8658084 ,  0.08322778,\n",
      "       -0.15436736,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04974337,  0.8353874 , -0.06246825, -0.8658084 ,  0.08322778,\n",
      "       -0.15436736,  0.        ,  0.        ], dtype=float32), action=2, reward=6.208335653312145, next_state=array([-0.05051909,  0.8167883 , -0.06982104, -0.8262217 ,  0.07555477,\n",
      "       -0.15346026,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05051909,  0.8167883 , -0.06982104, -0.8262217 ,  0.07555477,\n",
      "       -0.15346026,  0.        ,  0.        ], dtype=float32), action=0, reward=0.02049036214168609, next_state=array([-0.0512948 ,  0.7975897 , -0.06982045, -0.8528933 ,  0.06788179,\n",
      "       -0.15345964,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0512948 ,  0.7975897 , -0.06982045, -0.8528933 ,  0.06788179,\n",
      "       -0.15345964,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.31650852687226805, next_state=array([-0.05216932,  0.777792  , -0.08220866, -0.8796713 ,  0.06268681,\n",
      "       -0.10389932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05216932,  0.777792  , -0.08220866, -0.8796713 ,  0.06268681,\n",
      "       -0.10389932,  0.        ,  0.        ], dtype=float32), action=3, reward=0.25641670779418857, next_state=array([-0.05295944,  0.7574132 , -0.07158142, -0.9054327 ,  0.05534628,\n",
      "       -0.14681081,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05295944,  0.7574132 , -0.07158142, -0.9054327 ,  0.05534628,\n",
      "       -0.14681081,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.25468210064891994, next_state=array([-0.05384493,  0.7364265 , -0.08356033, -0.93257403,  0.05041095,\n",
      "       -0.09870633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05384493,  0.7364265 , -0.08356033, -0.93257403,  0.05041095,\n",
      "       -0.09870633,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3197296296469847, next_state=array([-0.05480747,  0.71484345, -0.09321558, -0.9591453 ,  0.04740494,\n",
      "       -0.06012022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05480747,  0.71484345, -0.09321558, -0.9591453 ,  0.04740494,\n",
      "       -0.06012022,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5765755844716398, next_state=array([-0.05586433,  0.6926531 , -0.10504746, -0.98622227,  0.04677312,\n",
      "       -0.01263614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05586433,  0.6926531 , -0.10504746, -0.98622227,  0.04677312,\n",
      "       -0.01263614,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.009749891380549797, next_state=array([-0.05683498,  0.6698665 , -0.09423603, -1.0126511 ,  0.04397433,\n",
      "       -0.05597589,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05683498,  0.6698665 , -0.09423603, -1.0126511 ,  0.04397433,\n",
      "       -0.05597589,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.05426987189554211, next_state=array([-0.05780564,  0.64648   , -0.09423597, -1.0393183 ,  0.04117552,\n",
      "       -0.05597581,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05780564,  0.64648   , -0.09423597, -1.0393183 ,  0.04117552,\n",
      "       -0.05597581,  0.        ,  0.        ], dtype=float32), action=2, reward=6.300752647321173, next_state=array([-0.05868416,  0.62401515, -0.08564143, -0.99837804,  0.0389961 ,\n",
      "       -0.04358847,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05868416,  0.62401515, -0.08564143, -0.99837804,  0.0389961 ,\n",
      "       -0.04358847,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.52470932806517, next_state=array([-5.9650518e-02,  6.0094637e-01, -9.6675657e-02, -1.0252806e+00,\n",
      "        3.9028246e-02,  6.4283662e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-5.9650518e-02,  6.0094637e-01, -9.6675657e-02, -1.0252806e+00,\n",
      "        3.9028246e-02,  6.4283662e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-0.035769758158720605, next_state=array([-0.06053619,  0.5772801 , -0.08654343, -1.0517834 ,  0.03703039,\n",
      "       -0.03995716,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06053619,  0.5772801 , -0.08654343, -1.0517834 ,  0.03703039,\n",
      "       -0.03995716,  0.        ,  0.        ], dtype=float32), action=3, reward=0.16201333406400067, next_state=array([-0.06135263,  0.55301446, -0.07786046, -1.0783855 ,  0.03329387,\n",
      "       -0.07473036,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06135263,  0.55301446, -0.07786046, -1.0783855 ,  0.03329387,\n",
      "       -0.07473036,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.11162796607410883, next_state=array([-0.0622509 ,  0.528156  , -0.08811703, -1.1047827 ,  0.03160683,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0622509 ,  0.528156  , -0.08811703, -1.1047827 ,  0.03160683,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), action=0, reward=0.026587817226527477, next_state=array([-0.06314917,  0.50269765, -0.08811702, -1.1314498 ,  0.0299198 ,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06314917,  0.50269765, -0.08811702, -1.1314498 ,  0.0299198 ,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), action=0, reward=0.08243540716682674, next_state=array([-0.06404743,  0.4766392 , -0.08811701, -1.1581166 ,  0.02823277,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06404743,  0.4766392 , -0.08811701, -1.1581166 ,  0.02823277,\n",
      "       -0.03374068,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2053968966213917, next_state=array([-0.06506844,  0.45053744, -0.09985915, -1.1600368 ,  0.02602691,\n",
      "       -0.04411729,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06506844,  0.45053744, -0.09985915, -1.1600368 ,  0.02602691,\n",
      "       -0.04411729,  0.        ,  0.        ], dtype=float32), action=3, reward=0.5036491580519862, next_state=array([-0.06599531,  0.42383817, -0.08806039, -1.1865631 ,  0.02145761,\n",
      "       -0.09138638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06599531,  0.42383817, -0.08806039, -1.1865631 ,  0.02145761,\n",
      "       -0.09138638,  0.        ,  0.        ], dtype=float32), action=3, reward=0.7951630363571109, next_state=array([-0.06682758,  0.39654508, -0.07618443, -1.2129426 ,  0.01450817,\n",
      "       -0.13898891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06682758,  0.39654508, -0.07618443, -1.2129426 ,  0.01450817,\n",
      "       -0.13898891,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9608050186449202, next_state=array([-0.06757917,  0.36864397, -0.06606847, -1.2399886 ,  0.00553519,\n",
      "       -0.17945984,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06757917,  0.36864397, -0.06606847, -1.2399886 ,  0.00553519,\n",
      "       -0.17945984,  0.        ,  0.        ], dtype=float32), action=3, reward=0.17430793644010237, next_state=array([-0.06825686,  0.3401468 , -0.05680118, -1.2665318 , -0.0052939 ,\n",
      "       -0.21658166,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06825686,  0.3401468 , -0.05680118, -1.2665318 , -0.0052939 ,\n",
      "       -0.21658166,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4156023192999614, next_state=array([-0.0690321 ,  0.31190917, -0.06608137, -1.2550871 , -0.01658802,\n",
      "       -0.22588253,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0690321 ,  0.31190917, -0.06608137, -1.2550871 , -0.01658802,\n",
      "       -0.22588253,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9541824710618971, next_state=array([-0.06987181,  0.28306404, -0.07416748, -1.2821435 , -0.02626533,\n",
      "       -0.19354619,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06987181,  0.28306404, -0.07416748, -1.2821435 , -0.02626533,\n",
      "       -0.19354619,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3184422523555783, next_state=array([-0.07080593,  0.25443363, -0.08310149, -1.2726704 , -0.03644517,\n",
      "       -0.20359686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07080593,  0.25443363, -0.08310149, -1.2726704 , -0.03644517,\n",
      "       -0.20359686,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8059519181619226, next_state=array([-0.07183018,  0.22519928, -0.09441521, -1.2995216 , -0.04436324,\n",
      "       -0.15836123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07183018,  0.22519928, -0.09441521, -1.2995216 , -0.04436324,\n",
      "       -0.15836123,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6651726360435646, next_state=array([-0.07285442,  0.19536582, -0.09441553, -1.3261933 , -0.05228127,\n",
      "       -0.15836051,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07285442,  0.19536582, -0.09441553, -1.3261933 , -0.05228127,\n",
      "       -0.15836051,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0251445610782186, next_state=array([-0.07400227,  0.16566175, -0.10606425, -1.320509  , -0.06088696,\n",
      "       -0.1721139 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07400227,  0.16566175, -0.10606425, -1.320509  , -0.06088696,\n",
      "       -0.1721139 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.985104560181594, next_state=array([-0.07503309,  0.13674475, -0.09465915, -1.2855656 , -0.06921302,\n",
      "       -0.16652158,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07503309,  0.13674475, -0.09465915, -1.2855656 , -0.06921302,\n",
      "       -0.16652158,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8791834471222433, next_state=array([-0.07615604,  0.10723823, -0.1062416 , -1.3116934 , -0.07521094,\n",
      "       -0.11995821,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07615604,  0.10723823, -0.1062416 , -1.3116934 , -0.07521094,\n",
      "       -0.11995821,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2116486315965733, next_state=array([-0.07720079,  0.07712546, -0.09642726, -1.3387713 , -0.08318039,\n",
      "       -0.15938896,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07720079,  0.07712546, -0.09642726, -1.3387713 , -0.08318039,\n",
      "       -0.15938896,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5621068559096887, next_state=array([-0.07831917,  0.04641117, -0.1056446 , -1.3654372 , -0.08931028,\n",
      "       -0.12259804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07831917,  0.04641117, -0.1056446 , -1.3654372 , -0.08931028,\n",
      "       -0.12259804,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.05406920228837747, next_state=array([-0.07929488,  0.01562606, -0.09191019, -1.3685752 , -0.09492901,\n",
      "       -0.11237459,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07929488,  0.01562606, -0.09191019, -1.3685752 , -0.09492901,\n",
      "       -0.11237459,  0.        ,  0.        ], dtype=float32), action=3, reward=6.44453761219046, next_state=array([-0.08018322, -0.01576873, -0.08095068, -1.3958429 , -0.10275415,\n",
      "       -0.15650262,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08018322, -0.01576873, -0.08095068, -1.3958429 , -0.10275415,\n",
      "       -0.15650262,  1.        ,  0.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.08060551, -0.04053629, -0.17126217, -0.76707596, -0.02508423,\n",
      "        4.414012  ,  1.        ,  1.        ], dtype=float32), done=True), Experience(state=array([-1.3608932e-03,  1.4127568e+00, -1.3784936e-01,  8.1634067e-02,\n",
      "        1.5836337e-03,  3.1224888e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=0.8804472837502999, next_state=array([-0.00272188,  1.4140158 , -0.13766286,  0.05595305,  0.0031266 ,\n",
      "        0.03086291,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00272188,  1.4140158 , -0.13766286,  0.05595305,  0.0031266 ,\n",
      "        0.03086291,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8394649119210158, next_state=array([-0.00414076,  1.4156754 , -0.14317974,  0.07374901,  0.00440076,\n",
      "        0.02548601,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00414076,  1.4156754 , -0.14317974,  0.07374901,  0.00440076,\n",
      "        0.02548601,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7997307890948662, next_state=array([-0.00555964,  1.4167343 , -0.14318337,  0.04706926,  0.00567503,\n",
      "        0.02548791,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00555964,  1.4167343 , -0.14318337,  0.04706926,  0.00567503,\n",
      "        0.02548791,  0.        ,  0.        ], dtype=float32), action=3, reward=1.7386119662123474, next_state=array([-0.00688944,  1.4171898 , -0.13199988,  0.0202431 ,  0.0047061 ,\n",
      "       -0.01938038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00688944,  1.4171898 , -0.13199988,  0.0202431 ,  0.0047061 ,\n",
      "       -0.01938038,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6941807053792275, next_state=array([-0.0083765 ,  1.4176956 , -0.14696985,  0.02249053,  0.0029964 ,\n",
      "       -0.03419744,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0083765 ,  1.4176956 , -0.14696985,  0.02249053,  0.0029964 ,\n",
      "       -0.03419744,  0.        ,  0.        ], dtype=float32), action=0, reward=0.3450276413861957, next_state=array([-9.8633766e-03,  1.4176016e+00, -1.4696482e-01, -4.1832970e-03,\n",
      "        1.2870749e-03, -3.4189560e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.8633766e-03,  1.4176016e+00, -1.4696482e-01, -4.1832970e-03,\n",
      "        1.2870749e-03, -3.4189560e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-1.208963622187922, next_state=array([-0.01142454,  1.4169003 , -0.15626863, -0.03116716,  0.00144416,\n",
      "        0.00314182,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01142454,  1.4169003 , -0.15626863, -0.03116716,  0.00144416,\n",
      "        0.00314182,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4169139192853788, next_state=array([-1.2903595e-02,  1.4155904e+00, -1.4597453e-01, -5.8217123e-02,\n",
      "       -4.6325586e-04, -3.8151883e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-1.2903595e-02,  1.4155904e+00, -1.4597453e-01, -5.8217123e-02,\n",
      "       -4.6325586e-04, -3.8151883e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-1.1710929653371522, next_state=array([-0.01438265,  1.4136806 , -0.14596835, -0.08488569, -0.00236907,\n",
      "       -0.03812015,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01438265,  1.4136806 , -0.14596835, -0.08488569, -0.00236907,\n",
      "       -0.03812015,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4266517761581667, next_state=array([-0.01586151,  1.4111707 , -0.1459627 , -0.1115544 , -0.00427505,\n",
      "       -0.0381231 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01586151,  1.4111707 , -0.1459627 , -0.1115544 , -0.00427505,\n",
      "       -0.0381231 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.713471068168485, next_state=array([-0.01719398,  1.4085883 , -0.13200574, -0.11477114, -0.00549462,\n",
      "       -0.02439362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01719398,  1.4085883 , -0.13200574, -0.11477114, -0.00549462,\n",
      "       -0.02439362,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.660318920209221, next_state=array([-0.01852627,  1.405406  , -0.13200232, -0.14144407, -0.00671457,\n",
      "       -0.0244011 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01852627,  1.405406  , -0.13200232, -0.14144407, -0.00671457,\n",
      "       -0.0244011 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1800876806547478, next_state=array([-0.01982365,  1.4025599 , -0.12864819, -0.12650083, -0.00778888,\n",
      "       -0.02148848,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01982365,  1.4025599 , -0.12864819, -0.12650083, -0.00778888,\n",
      "       -0.02148848,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.281832985854065, next_state=array([-0.02120667,  1.3991026 , -0.13939098, -0.1536505 , -0.00671106,\n",
      "        0.0215584 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02120667,  1.3991026 , -0.13939098, -0.1536505 , -0.00671106,\n",
      "        0.0215584 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.079146120733667, next_state=array([-0.02249308,  1.3950478 , -0.12728088, -0.18021663, -0.00806154,\n",
      "       -0.02701179,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02249308,  1.3950478 , -0.12728088, -0.18021663, -0.00806154,\n",
      "       -0.02701179,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8108697480443368, next_state=array([-0.02374763,  1.3911783 , -0.12421487, -0.17198667, -0.00928031,\n",
      "       -0.02437764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02374763,  1.3911783 , -0.12421487, -0.17198667, -0.00928031,\n",
      "       -0.02437764,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.206701141955675, next_state=array([-0.02507114,  1.3867118 , -0.13287902, -0.19851176, -0.00876231,\n",
      "        0.01036096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02507114,  1.3867118 , -0.13287902, -0.19851176, -0.00876231,\n",
      "        0.01036096,  0.        ,  0.        ], dtype=float32), action=2, reward=2.1624601823351783, next_state=array([-0.02640066,  1.382816  , -0.1334209 , -0.17313986, -0.00830535,\n",
      "        0.00914019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02640066,  1.382816  , -0.1334209 , -0.17313986, -0.00830535,\n",
      "        0.00914019,  0.        ,  0.        ], dtype=float32), action=2, reward=0.767006060159116, next_state=array([-0.02758217,  1.3788456 , -0.1192909 , -0.17645629, -0.00716923,\n",
      "        0.02272432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02758217,  1.3788456 , -0.1192909 , -0.17645629, -0.00716923,\n",
      "        0.02272432,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6888742046004666, next_state=array([-0.02876358,  1.3742752 , -0.11929452, -0.20312469, -0.00603393,\n",
      "        0.02270836,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02876358,  1.3742752 , -0.11929452, -0.20312469, -0.00603393,\n",
      "        0.02270836,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4943637592479024, next_state=array([-0.02985582,  1.3690974 , -0.10809966, -0.2301286 , -0.00714258,\n",
      "       -0.02217486,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02985582,  1.3690974 , -0.10809966, -0.2301286 , -0.00714258,\n",
      "       -0.02217486,  0.        ,  0.        ], dtype=float32), action=2, reward=2.490494461506626, next_state=array([-0.03094959,  1.3645378 , -0.10822552, -0.20265166, -0.00828491,\n",
      "       -0.02284886,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03094959,  1.3645378 , -0.10822552, -0.20265166, -0.00828491,\n",
      "       -0.02284886,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3179377681652498, next_state=array([-0.03213148,  1.3593692 , -0.11926538, -0.22971167, -0.00721674,\n",
      "        0.02136524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03213148,  1.3593692 , -0.11926538, -0.22971167, -0.00721674,\n",
      "        0.02136524,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.957240964894935, next_state=array([-0.03337965,  1.3535955 , -0.12759626, -0.25660294, -0.0044824 ,\n",
      "        0.05469207,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03337965,  1.3535955 , -0.12759626, -0.25660294, -0.0044824 ,\n",
      "        0.05469207,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4905285155162165, next_state=array([-0.03455668,  1.347188  , -0.11865561, -0.28476566, -0.00354222,\n",
      "        0.01880379,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03455668,  1.347188  , -0.11865561, -0.28476566, -0.00354222,\n",
      "        0.01880379,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9215851918258398, next_state=array([-3.5818674e-02,  1.3401747e+00, -1.2930945e-01, -3.1170723e-01,\n",
      "       -4.6879938e-04,  6.1468035e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.5818674e-02,  1.3401747e+00, -1.2930945e-01, -3.1170723e-01,\n",
      "       -4.6879938e-04,  6.1468035e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-2.486617307454479, next_state=array([-0.03715897,  1.3325706 , -0.13913868, -0.33797073,  0.00457314,\n",
      "        0.10083866,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03715897,  1.3325706 , -0.13913868, -0.33797073,  0.00457314,\n",
      "        0.10083866,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7007261003575693, next_state=array([-0.03856754,  1.3243625 , -0.14770946, -0.3648373 ,  0.0113318 ,\n",
      "        0.13517353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03856754,  1.3243625 , -0.14770946, -0.3648373 ,  0.0113318 ,\n",
      "        0.13517353,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2837824892648086, next_state=array([-0.03997612,  1.315555  , -0.1477094 , -0.39150774,  0.01809044,\n",
      "        0.135173  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03997612,  1.315555  , -0.1477094 , -0.39150774,  0.01809044,\n",
      "        0.135173  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7821331434393515, next_state=array([-0.04145718,  1.3061455 , -0.15679829, -0.4183255 ,  0.02666998,\n",
      "        0.17159095,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04145718,  1.3061455 , -0.15679829, -0.4183255 ,  0.02666998,\n",
      "        0.17159095,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.919422478247553, next_state=array([-0.04300737,  1.2961255 , -0.16545847, -0.44555584,  0.03698888,\n",
      "        0.20637801,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04300737,  1.2961255 , -0.16545847, -0.44555584,  0.03698888,\n",
      "        0.20637801,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4851951782137007, next_state=array([-0.04455747,  1.285507  , -0.16545804, -0.47223142,  0.04730771,\n",
      "        0.20637664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04455747,  1.285507  , -0.16545804, -0.47223142,  0.04730771,\n",
      "        0.20637664,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.441230706099759, next_state=array([-0.04610767,  1.2742897 , -0.16545746, -0.498907  ,  0.05762647,\n",
      "        0.20637515,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04610767,  1.2742897 , -0.16545746, -0.498907  ,  0.05762647,\n",
      "        0.20637515,  0.        ,  0.        ], dtype=float32), action=2, reward=2.793266549892974, next_state=array([-0.04784441,  1.2639493 , -0.18351068, -0.45999104,  0.06734521,\n",
      "        0.19437495,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04784441,  1.2639493 , -0.18351068, -0.45999104,  0.06734521,\n",
      "        0.19437495,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3724065948742066, next_state=array([-0.04958134,  1.2530099 , -0.18350995, -0.48666564,  0.0770639 ,\n",
      "        0.1943737 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04958134,  1.2530099 , -0.18350995, -0.48666564,  0.0770639 ,\n",
      "        0.1943737 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.671906485520606, next_state=array([-0.05128889,  1.2427678 , -0.18101549, -0.45576763,  0.08722573,\n",
      "        0.20323646,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05128889,  1.2427678 , -0.18101549, -0.45576763,  0.08722573,\n",
      "        0.20323646,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.1186579204285736, next_state=array([-0.05307923,  1.2319114 , -0.19140562, -0.4832702 ,  0.09948783,\n",
      "        0.24524228,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05307923,  1.2319114 , -0.19140562, -0.4832702 ,  0.09948783,\n",
      "        0.24524228,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5789979486300467, next_state=array([-0.05486975,  1.2204571 , -0.19140387, -0.50994945,  0.11174982,\n",
      "        0.24523978,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05486975,  1.2204571 , -0.19140387, -0.50994945,  0.11174982,\n",
      "        0.24523978,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.15185693951805773, next_state=array([-0.05654297,  1.2089906 , -0.18040755, -0.51064885,  0.12475282,\n",
      "        0.26006007,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05654297,  1.2089906 , -0.18040755, -0.51064885,  0.12475282,\n",
      "        0.26006007,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2146522958918227, next_state=array([-0.05815029,  1.1969273 , -0.17212541, -0.5371463 ,  0.13610195,\n",
      "        0.22698233,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05815029,  1.1969273 , -0.17212541, -0.5371463 ,  0.13610195,\n",
      "        0.22698233,  0.        ,  0.        ], dtype=float32), action=2, reward=1.992343197656038, next_state=array([-0.05988465,  1.1855069 , -0.18475832, -0.50864536,  0.14738831,\n",
      "        0.22572735,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05988465,  1.1855069 , -0.18475832, -0.50864536,  0.14738831,\n",
      "        0.22572735,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8108450653348303, next_state=array([-0.06152544,  1.1734977 , -0.17301346, -0.53465915,  0.15631177,\n",
      "        0.17846921,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06152544,  1.1734977 , -0.17301346, -0.53465915,  0.15631177,\n",
      "        0.17846921,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7486203092024926, next_state=array([-0.06309891,  1.1608977 , -0.16456904, -0.56077033,  0.16353199,\n",
      "        0.1444048 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06309891,  1.1608977 , -0.16456904, -0.56077033,  0.16353199,\n",
      "        0.1444048 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9765787105720847, next_state=array([-0.06467237,  1.1476985 , -0.16456798, -0.5874413 ,  0.1707522 ,\n",
      "        0.14440428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06467237,  1.1476985 , -0.16456798, -0.5874413 ,  0.1707522 ,\n",
      "        0.14440428,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6775018582272423, next_state=array([-0.06637602,  1.1346755 , -0.17738387, -0.5796168 ,  0.17778601,\n",
      "        0.14067653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06637602,  1.1346755 , -0.17738387, -0.5796168 ,  0.17778601,\n",
      "        0.14067653,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6186757486202326, next_state=array([-0.06817627,  1.1210397 , -0.1894528 , -0.60720044,  0.18725975,\n",
      "        0.18947458,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06817627,  1.1210397 , -0.1894528 , -0.60720044,  0.18725975,\n",
      "        0.18947458,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6585591066260847, next_state=array([-0.07004309,  1.1067811 , -0.1978317 , -0.63516164,  0.19847311,\n",
      "        0.22426745,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07004309,  1.1067811 , -0.1978317 , -0.63516164,  0.19847311,\n",
      "        0.22426745,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.8789918321359367, next_state=array([-0.07198725,  1.0918927 , -0.20755522, -0.6635261 ,  0.2117219 ,\n",
      "        0.2649759 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07198725,  1.0918927 , -0.20755522, -0.6635261 ,  0.2117219 ,\n",
      "        0.2649759 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.1937691310516927, next_state=array([-0.07403421,  1.0779157 , -0.21830125, -0.62320995,  0.22548524,\n",
      "        0.2752668 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07403421,  1.0779157 , -0.21830125, -0.62320995,  0.22548524,\n",
      "        0.2752668 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.115890512354183, next_state=array([-0.07615795,  1.0633204 , -0.22789903, -0.6511345 ,  0.2412277 ,\n",
      "        0.31484944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07615795,  1.0633204 , -0.22789903, -0.6511345 ,  0.2412277 ,\n",
      "        0.31484944,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5986119851124556, next_state=array([-0.07828216,  1.0481281 , -0.22789183, -0.67782134,  0.2569699 ,\n",
      "        0.31484404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07828216,  1.0481281 , -0.22789183, -0.67782134,  0.2569699 ,\n",
      "        0.31484404,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.1790717422585417, next_state=array([-0.08047972,  1.032317  , -0.23699272, -0.7058369 ,  0.27460352,\n",
      "        0.35267305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08047972,  1.032317  , -0.23699272, -0.7058369 ,  0.27460352,\n",
      "        0.35267305,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.67998105178566, next_state=array([-0.08267794,  1.0159099 , -0.23698243, -0.7325286 ,  0.2922368 ,\n",
      "        0.35266548,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08267794,  1.0159099 , -0.23698243, -0.7325286 ,  0.2922368 ,\n",
      "        0.35266548,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.63053679007686, next_state=array([-0.08487701,  0.99890673, -0.2369715 , -0.75922024,  0.3098697 ,\n",
      "        0.35265797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08487701,  0.99890673, -0.2369715 , -0.75922024,  0.3098697 ,\n",
      "        0.35265797,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5804106418847823, next_state=array([-0.08707704,  0.98130757, -0.23695993, -0.78591174,  0.32750222,\n",
      "        0.35265043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08707704,  0.98130757, -0.23695993, -0.78591174,  0.32750222,\n",
      "        0.35265043,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.841877726529275, next_state=array([-0.08919907,  0.963155  , -0.2270017 , -0.8102086 ,  0.3429573 ,\n",
      "        0.30910152,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08919907,  0.963155  , -0.2270017 , -0.8102086 ,  0.3429573 ,\n",
      "        0.30910152,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5816302108271418, next_state=array([-0.09124422,  0.9444523 , -0.21713781, -0.83429205,  0.35622287,\n",
      "        0.26531154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09124422,  0.9444523 , -0.21713781, -0.83429205,  0.35622287,\n",
      "        0.26531154,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.010318440787728, next_state=array([-0.09328995,  0.9251518 , -0.21713026, -0.8609725 ,  0.3694883 ,\n",
      "        0.26530832,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09328995,  0.9251518 , -0.21713026, -0.8609725 ,  0.3694883 ,\n",
      "        0.26530832,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5352230115034318, next_state=array([-0.0953969 ,  0.90521806, -0.22480866, -0.88965636,  0.38446233,\n",
      "        0.29948044,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0953969 ,  0.90521806, -0.22480866, -0.88965636,  0.38446233,\n",
      "        0.29948044,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4346458903735584, next_state=array([-0.09743385,  0.88473386, -0.21581697, -0.9137366 ,  0.39739963,\n",
      "        0.25874704,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09743385,  0.88473386, -0.21581697, -0.9137366 ,  0.39739963,\n",
      "        0.25874704,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8198247870729176, next_state=array([-0.09947147,  0.8636516 , -0.21580896, -0.94041616,  0.41033682,\n",
      "        0.25874406,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09947147,  0.8636516 , -0.21580896, -0.94041616,  0.41033682,\n",
      "        0.25874406,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7664060882480328, next_state=array([-0.10150957,  0.84197134, -0.21580069, -0.9670956 ,  0.42327386,\n",
      "        0.25874108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10150957,  0.84197134, -0.21580069, -0.9670956 ,  0.42327386,\n",
      "        0.25874108,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7130139461123406, next_state=array([-0.10354833,  0.81969327, -0.21579218, -0.99377507,  0.43621075,\n",
      "        0.2587381 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10354833,  0.81969327, -0.21579218, -0.99377507,  0.43621075,\n",
      "        0.2587381 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2561019459068903, next_state=array([-0.10564518,  0.7967726 , -0.22311072, -1.0229445 ,  0.4508751 ,\n",
      "        0.29328722,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10564518,  0.7967726 , -0.22311072, -1.0229445 ,  0.4508751 ,\n",
      "        0.29328722,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.138772380254976, next_state=array([-0.10767327,  0.77330476, -0.21425824, -1.04676   ,  0.46347362,\n",
      "        0.25197056,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10767327,  0.77330476, -0.21425824, -1.04676   ,  0.46347362,\n",
      "        0.25197056,  0.        ,  0.        ], dtype=float32), action=2, reward=3.309446255025546, next_state=array([-0.10998688,  0.7506189 , -0.24339482, -1.0123286 ,  0.47679543,\n",
      "        0.266436  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10998688,  0.7506189 , -0.24339482, -1.0123286 ,  0.47679543,\n",
      "        0.266436  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8745426358382236, next_state=array([-0.11221504,  0.7273924 , -0.23251176, -1.035672  ,  0.4876043 ,\n",
      "        0.21617647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11221504,  0.7273924 , -0.23251176, -1.035672  ,  0.4876043 ,\n",
      "        0.21617647,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2930168159972311, next_state=array([-0.11460362,  0.70412034, -0.24863282, -1.0378104 ,  0.49855834,\n",
      "        0.21908095,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11460362,  0.70412034, -0.24863282, -1.0378104 ,  0.49855834,\n",
      "        0.21908095,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0628176223051584, next_state=array([-0.11725416,  0.68130815, -0.27521196, -1.0175996 ,  0.510011  ,\n",
      "        0.22905377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11725416,  0.68130815, -0.27521196, -1.0175996 ,  0.510011  ,\n",
      "        0.22905377,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.750792428988716, next_state=array([-0.11983462,  0.6579529 , -0.26625162, -1.0411047 ,  0.5193142 ,\n",
      "        0.18606424,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11983462,  0.6579529 , -0.26625162, -1.0411047 ,  0.5193142 ,\n",
      "        0.18606424,  0.        ,  0.        ], dtype=float32), action=2, reward=0.14393198057133533, next_state=array([-0.12276936,  0.6345951 , -0.3012024 , -1.0410974 ,  0.5281084 ,\n",
      "        0.17588326,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12276936,  0.6345951 , -0.3012024 , -1.0410974 ,  0.5281084 ,\n",
      "        0.17588326,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3799400922663938, next_state=array([-0.12563734,  0.61070424, -0.29256764, -1.0640742 ,  0.53470606,\n",
      "        0.13195257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12563734,  0.61070424, -0.29256764, -1.0640742 ,  0.53470606,\n",
      "        0.13195257,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5783467116105487, next_state=array([-0.12856397,  0.5861637 , -0.29999217, -1.093613  ,  0.5431357 ,\n",
      "        0.1685929 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12856397,  0.5861637 , -0.29999217, -1.093613  ,  0.5431357 ,\n",
      "        0.1685929 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7568734483905633, next_state=array([-0.13155603,  0.5609732 , -0.30823094, -1.1232423 ,  0.5535557 ,\n",
      "        0.2084001 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13155603,  0.5609732 , -0.30823094, -1.1232423 ,  0.5535557 ,\n",
      "        0.2084001 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9342217530345056, next_state=array([-0.13460931,  0.5351242 , -0.31597665, -1.1532925 ,  0.5659669 ,\n",
      "        0.24822357,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13460931,  0.5351242 , -0.31597665, -1.1532925 ,  0.5659669 ,\n",
      "        0.24822357,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2501412055655805, next_state=array([-0.13831672,  0.509802  , -0.38072386, -1.1297061 ,  0.5776872 ,\n",
      "        0.23440583,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13831672,  0.509802  , -0.38072386, -1.1297061 ,  0.5776872 ,\n",
      "        0.23440583,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3390178756656155, next_state=array([-0.14240055,  0.48492074, -0.4185428 , -1.1102983 ,  0.58970135,\n",
      "        0.24028209,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14240055,  0.48492074, -0.4185428 , -1.1102983 ,  0.58970135,\n",
      "        0.24028209,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6741443617794516, next_state=array([-0.1469945 ,  0.46076167, -0.4697245 , -1.0784007 ,  0.6020217 ,\n",
      "        0.24640629,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1469945 ,  0.46076167, -0.4697245 , -1.0784007 ,  0.6020217 ,\n",
      "        0.24640629,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6232045457522577, next_state=array([-0.1515216 ,  0.43606734, -0.4611496 , -1.1014243 ,  0.612147  ,\n",
      "        0.20250592,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1515216 ,  0.43606734, -0.4611496 , -1.1014243 ,  0.612147  ,\n",
      "        0.20250592,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9776256242634236, next_state=array([-0.15610008,  0.4107216 , -0.46762878, -1.1311047 ,  0.6239879 ,\n",
      "        0.23681843,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15610008,  0.4107216 , -0.46762878, -1.1311047 ,  0.6239879 ,\n",
      "        0.23681843,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1937824332933062, next_state=array([-0.16073266,  0.38471842, -0.47445002, -1.1611505 ,  0.6376827 ,\n",
      "        0.27389574,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16073266,  0.38471842, -0.47445002, -1.1611505 ,  0.6376827 ,\n",
      "        0.27389574,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5759408924290583, next_state=array([-0.16543627,  0.35804558, -0.48336992, -1.1919831 ,  0.6537485 ,\n",
      "        0.32131678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16543627,  0.35804558, -0.48336992, -1.1919831 ,  0.6537485 ,\n",
      "        0.32131678,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8374761833962907, next_state=array([-0.17014122,  0.33077538, -0.48335046, -1.2186671 ,  0.66981405,\n",
      "        0.32131106,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17014122,  0.33077538, -0.48335046, -1.2186671 ,  0.66981405,\n",
      "        0.32131106,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8061146775476573, next_state=array([-0.17534065,  0.3034379 , -0.5320219 , -1.2214684 ,  0.68510616,\n",
      "        0.30584174,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17534065,  0.3034379 , -0.5320219 , -1.2214684 ,  0.68510616,\n",
      "        0.30584174,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9708854490030092, next_state=array([-0.18118992,  0.27648354, -0.5965327 , -1.2043834 ,  0.6999889 ,\n",
      "        0.29765433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18118992,  0.27648354, -0.5965327 , -1.2043834 ,  0.6999889 ,\n",
      "        0.29765433,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7398882993019513, next_state=array([-0.18708554,  0.2488696 , -0.60237014, -1.234586  ,  0.7166252 ,\n",
      "        0.33272642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18708554,  0.2488696 , -0.60237014, -1.234586  ,  0.7166252 ,\n",
      "        0.33272642,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.099381139630583, next_state=array([-0.19341794,  0.22126658, -0.6456525 , -1.2341143 ,  0.7329749 ,\n",
      "        0.32699397,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19341794,  0.22126658, -0.6456525 , -1.2341143 ,  0.7329749 ,\n",
      "        0.32699397,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2907454391819317, next_state=array([-0.19968557,  0.19316055, -0.6370281 , -1.2553959 ,  0.7466788 ,\n",
      "        0.27407986,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19968557,  0.19316055, -0.6370281 , -1.2553959 ,  0.7466788 ,\n",
      "        0.27407986,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.637594247622302, next_state=array([-0.20591135,  0.16451533, -0.63147277, -1.2786658 ,  0.7586941 ,\n",
      "        0.24030738,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20591135,  0.16451533, -0.63147277, -1.2786658 ,  0.7586941 ,\n",
      "        0.24030738,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.168502819951658, next_state=array([-0.21259956,  0.13623255, -0.6779618 , -1.2628578 ,  0.7711991 ,\n",
      "        0.25009972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21259956,  0.13623255, -0.6779618 , -1.2628578 ,  0.7711991 ,\n",
      "        0.25009972,  0.        ,  0.        ], dtype=float32), action=1, reward=6.311228779449295, next_state=array([-0.21934457,  0.10728415, -0.68501604, -1.2934947 ,  0.785761  ,\n",
      "        0.29123777,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.21934457,  0.10728415, -0.68501604, -1.2934947 ,  0.785761  ,\n",
      "        0.29123777,  0.        ,  1.        ], dtype=float32), action=1, reward=57.16515463075456, next_state=array([-0.22147508,  0.09506236, -0.3295383 , -0.6459341 ,  0.95551753,\n",
      "        3.3083255 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.22147508,  0.09506236, -0.3295383 , -0.6459341 ,  0.95551753,\n",
      "        3.3083255 ,  0.        ,  1.        ], dtype=float32), action=1, reward=-17.691877165748025, next_state=array([-0.22368208,  0.08305179, -0.31566367, -0.6464536 ,  1.1402805 ,\n",
      "        3.6726303 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.22368208,  0.08305179, -0.31566367, -0.6464536 ,  1.1402805 ,\n",
      "        3.6726303 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-21.983811302423295, next_state=array([-0.22655849,  0.07063266, -0.35125226, -0.6679424 ,  1.3231454 ,\n",
      "        3.6534646 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.22655849,  0.07063266, -0.35125226, -0.6679424 ,  1.3231454 ,\n",
      "        3.6534646 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-32.74946857927439, next_state=array([-0.23030195,  0.05792199, -0.40490213, -0.6862168 ,  1.5053805 ,\n",
      "        3.6447353 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23030195,  0.05792199, -0.40490213, -0.6862168 ,  1.5053805 ,\n",
      "        3.6447353 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-100, next_state=array([-0.23227724,  0.05069154,  0.0393999 ,  0.00669114,  1.6171637 ,\n",
      "        0.3306281 ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 5.6934357e-04,  1.4198161e+00,  5.7649262e-02,  3.9537886e-01,\n",
      "       -6.5288943e-04, -1.3058451e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=1.205761130058819, next_state=array([ 1.2277603e-03,  1.4281331e+00,  6.8780176e-02,  3.6964694e-01,\n",
      "       -3.5460184e-03, -5.7866864e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.2277603e-03,  1.4281331e+00,  6.8780176e-02,  3.6964694e-01,\n",
      "       -3.5460184e-03, -5.7866864e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=2.034044767912151, next_state=array([ 0.00178938,  1.4358406 ,  0.0566075 ,  0.34254792, -0.00399524,\n",
      "       -0.00898527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00178938,  1.4358406 ,  0.0566075 ,  0.34254792, -0.00399524,\n",
      "       -0.00898527,  0.        ,  0.        ], dtype=float32), action=0, reward=1.8726276513716584, next_state=array([ 0.0023509 ,  1.4429477 ,  0.05660822,  0.31587642, -0.00444597,\n",
      "       -0.00901554,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0023509 ,  1.4429477 ,  0.05660822,  0.31587642, -0.00444597,\n",
      "       -0.00901554,  0.        ,  0.        ], dtype=float32), action=0, reward=1.9254653006045146, next_state=array([ 0.00291243,  1.4494549 ,  0.05660978,  0.28920746, -0.0048961 ,\n",
      "       -0.00900345,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00291243,  1.4494549 ,  0.05660978,  0.28920746, -0.0048961 ,\n",
      "       -0.00900345,  0.        ,  0.        ], dtype=float32), action=3, reward=1.5061592550894443, next_state=array([ 0.00355835,  1.4553589 ,  0.06719324,  0.26238978, -0.00746823,\n",
      "       -0.05144738,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00355835,  1.4553589 ,  0.06719324,  0.26238978, -0.00746823,\n",
      "       -0.05144738,  0.        ,  0.        ], dtype=float32), action=1, reward=2.285544977665013, next_state=array([ 0.0041091 ,  1.4606651 ,  0.05525662,  0.23583092, -0.00764391,\n",
      "       -0.00351394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0041091 ,  1.4606651 ,  0.05525662,  0.23583092, -0.00764391,\n",
      "       -0.00351394,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.8280146629126535, next_state=array([ 0.00454817,  1.4660037 ,  0.04464037,  0.23727073, -0.00836861,\n",
      "       -0.01449539,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00454817,  1.4660037 ,  0.04464037,  0.23727073, -0.00836861,\n",
      "       -0.01449539,  0.        ,  0.        ], dtype=float32), action=0, reward=2.0693049199112465, next_state=array([ 0.00498724,  1.4707422 ,  0.04464284,  0.21059719, -0.00909221,\n",
      "       -0.01447353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00498724,  1.4707422 ,  0.04464284,  0.21059719, -0.00909221,\n",
      "       -0.01447353,  0.        ,  0.        ], dtype=float32), action=1, reward=2.47611707887245, next_state=array([ 0.00534058,  1.4748914 ,  0.0338711 ,  0.18441834, -0.00765457,\n",
      "        0.02875542,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00534058,  1.4748914 ,  0.0338711 ,  0.18441834, -0.00765457,\n",
      "        0.02875542,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5159102107176239, next_state=array([ 0.00568972,  1.4792523 ,  0.03350631,  0.19382308, -0.00625658,\n",
      "        0.02796214,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00568972,  1.4792523 ,  0.03350631,  0.19382308, -0.00625658,\n",
      "        0.02796214,  0.        ,  0.        ], dtype=float32), action=3, reward=1.9270898341814313, next_state=array([ 0.00612087,  1.4830112 ,  0.04378298,  0.1670618 , -0.00691915,\n",
      "       -0.0132527 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00612087,  1.4830112 ,  0.04378298,  0.1670618 , -0.00691915,\n",
      "       -0.0132527 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.8663852038536843, next_state=array([ 0.00650854,  1.4874907 ,  0.03967374,  0.19907607, -0.00781497,\n",
      "       -0.01791812,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00650854,  1.4874907 ,  0.03967374,  0.19907607, -0.00781497,\n",
      "       -0.01791812,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.7590005516142524, next_state=array([ 0.00700254,  1.4923648 ,  0.04983396,  0.21662824, -0.00823311,\n",
      "       -0.00836402,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00700254,  1.4923648 ,  0.04983396,  0.21662824, -0.00823311,\n",
      "       -0.00836402,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.2470319257071365, next_state=array([ 0.00750828,  1.4975537 ,  0.05096516,  0.23061344, -0.00862057,\n",
      "       -0.00774987,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00750828,  1.4975537 ,  0.05096516,  0.23061344, -0.00862057,\n",
      "       -0.00774987,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9352705062242874, next_state=array([ 0.00785952,  1.5032487 ,  0.03627411,  0.25310367, -0.00976464,\n",
      "       -0.02288356,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00785952,  1.5032487 ,  0.03627411,  0.25310367, -0.00976464,\n",
      "       -0.02288356,  0.        ,  0.        ], dtype=float32), action=3, reward=1.6063235594187415, next_state=array([ 0.00828161,  1.5083532 ,  0.04516467,  0.22684503, -0.01268708,\n",
      "       -0.05845416,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00828161,  1.5083532 ,  0.04516467,  0.22684503, -0.01268708,\n",
      "       -0.05845416,  0.        ,  0.        ], dtype=float32), action=3, reward=1.4149659787250937, next_state=array([ 0.00877638,  1.5128629 ,  0.05426128,  0.20037694, -0.01742862,\n",
      "       -0.09483909,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00877638,  1.5128629 ,  0.05426128,  0.20037694, -0.01742862,\n",
      "       -0.09483909,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.340527878895773, next_state=array([ 0.00920486,  1.5181009 ,  0.04802982,  0.23273139, -0.02255155,\n",
      "       -0.10246804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00920486,  1.5181009 ,  0.04802982,  0.23273139, -0.02255155,\n",
      "       -0.10246804,  0.        ,  0.        ], dtype=float32), action=1, reward=2.035057962475635, next_state=array([ 0.00955057,  1.5227345 ,  0.03763794,  0.20589858, -0.0255906 ,\n",
      "       -0.06078617,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00955057,  1.5227345 ,  0.03763794,  0.20589858, -0.0255906 ,\n",
      "       -0.06078617,  0.        ,  0.        ], dtype=float32), action=3, reward=1.371487810935322, next_state=array([ 0.00999088,  1.5267673 ,  0.04950731,  0.17912832, -0.0310068 ,\n",
      "       -0.10833399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00999088,  1.5267673 ,  0.04950731,  0.17912832, -0.0310068 ,\n",
      "       -0.10833399,  0.        ,  0.        ], dtype=float32), action=0, reward=1.6695361268618, next_state=array([ 0.01043138,  1.5302002 ,  0.04952343,  0.15245683, -0.0364208 ,\n",
      "       -0.1082897 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01043138,  1.5302002 ,  0.04952343,  0.15245683, -0.0364208 ,\n",
      "       -0.1082897 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.9272448334682235, next_state=array([ 0.01097021,  1.5330311 ,  0.06185294,  0.1256069 , -0.0443022 ,\n",
      "       -0.15764183,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01097021,  1.5330311 ,  0.06185294,  0.1256069 , -0.0443022 ,\n",
      "       -0.15764183,  0.        ,  0.        ], dtype=float32), action=3, reward=0.667437351087558, next_state=array([ 0.01157274,  1.5352707 ,  0.06981133,  0.09923351, -0.05376437,\n",
      "       -0.18926059,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01157274,  1.5352707 ,  0.06981133,  0.09923351, -0.05376437,\n",
      "       -0.18926059,  0.        ,  0.        ], dtype=float32), action=1, reward=1.8652490397588803, next_state=array([ 0.01208372,  1.5369238 ,  0.05830341,  0.07319752, -0.06090492,\n",
      "       -0.14282356,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01208372,  1.5369238 ,  0.05830341,  0.07319752, -0.06090492,\n",
      "       -0.14282356,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6160176948243816, next_state=array([ 0.01272516,  1.5384717 ,  0.07084813,  0.0685106 , -0.06753638,\n",
      "       -0.13262925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01272516,  1.5384717 ,  0.07084813,  0.0685106 , -0.06753638,\n",
      "       -0.13262925,  0.        ,  0.        ], dtype=float32), action=1, reward=1.842251798403994, next_state=array([ 0.01328821,  1.5394278 ,  0.06100259,  0.04227442, -0.07218961,\n",
      "       -0.09306427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01328821,  1.5394278 ,  0.06100259,  0.04227442, -0.07218961,\n",
      "       -0.09306427,  0.        ,  0.        ], dtype=float32), action=0, reward=0.6237273548933899, next_state=array([ 0.01385126,  1.5397842 ,  0.0610024 ,  0.01560594, -0.07684283,\n",
      "       -0.09306412,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01385126,  1.5397842 ,  0.0610024 ,  0.01560594, -0.07684283,\n",
      "       -0.09306412,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5026707898887526, next_state=array([ 0.01448908,  1.5395246 ,  0.07039576, -0.01189865, -0.08339599,\n",
      "       -0.13106337,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01448908,  1.5395246 ,  0.07039576, -0.01189865, -0.08339599,\n",
      "       -0.13106337,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4574580814581282, next_state=array([ 0.0151269 ,  1.5386654 ,  0.07039533, -0.0385689 , -0.08994914,\n",
      "       -0.13106313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0151269 ,  1.5386654 ,  0.07039533, -0.0385689 , -0.08994914,\n",
      "       -0.13106313,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.2960865440665246, next_state=array([ 0.01585932,  1.537194  ,  0.08226316, -0.06597061, -0.09889433,\n",
      "       -0.17890362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01585932,  1.537194  ,  0.08226316, -0.06597061, -0.09889433,\n",
      "       -0.17890362,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.746831813117143, next_state=array([ 0.01685104,  1.5364535 ,  0.10739163, -0.03348236, -0.10705082,\n",
      "       -0.16312966,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01685104,  1.5364535 ,  0.10739163, -0.03348236, -0.10705082,\n",
      "       -0.16312966,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0571863889597624, next_state=array([ 0.01793308,  1.5350913 ,  0.11874659, -0.06132482, -0.11751574,\n",
      "       -0.2092988 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01793308,  1.5350913 ,  0.11874659, -0.06132482, -0.11751574,\n",
      "       -0.2092988 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0767508559148655, next_state=array([ 0.01891975,  1.5331393 ,  0.10677776, -0.08741428, -0.1255746 ,\n",
      "       -0.1611773 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01891975,  1.5331393 ,  0.10677776, -0.08741428, -0.1255746 ,\n",
      "       -0.1611773 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3784353324201106, next_state=array([ 0.01990662,  1.5305884 ,  0.10677677, -0.11408635, -0.13363342,\n",
      "       -0.16117653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01990662,  1.5305884 ,  0.10677677, -0.11408635, -0.13363342,\n",
      "       -0.16117653,  0.        ,  0.        ], dtype=float32), action=2, reward=0.55491768832577, next_state=array([ 0.02091866,  1.5286024 ,  0.10966048, -0.08904624, -0.14205492,\n",
      "       -0.16842997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02091866,  1.5286024 ,  0.10966048, -0.08904624, -0.14205492,\n",
      "       -0.16842997,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4549013554068029, next_state=array([ 0.02185202,  1.5260451 ,  0.09972705, -0.11428414, -0.14843044,\n",
      "       -0.12751046,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02185202,  1.5260451 ,  0.09972705, -0.11428414, -0.14843044,\n",
      "       -0.12751046,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3016421695543443, next_state=array([ 0.02295694,  1.5236511 ,  0.11643485, -0.10700046, -0.15436937,\n",
      "       -0.11877854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02295694,  1.5236511 ,  0.11643485, -0.10700046, -0.15436937,\n",
      "       -0.11877854,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9190364919989691, next_state=array([ 0.02435121,  1.5220997 ,  0.14472653, -0.06950957, -0.15966943,\n",
      "       -0.1060012 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02435121,  1.5220997 ,  0.14472653, -0.06950957, -0.15966943,\n",
      "       -0.1060012 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3574900205682525, next_state=array([ 0.02586613,  1.5207951 ,  0.1566601 , -0.05855062, -0.16483302,\n",
      "       -0.10327236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02586613,  1.5207951 ,  0.1566601 , -0.05855062, -0.16483302,\n",
      "       -0.10327236,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4380371389783875, next_state=array([ 0.02738113,  1.5188906 ,  0.15665956, -0.0852195 , -0.16999663,\n",
      "       -0.10327216,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02738113,  1.5188906 ,  0.15665956, -0.0852195 , -0.16999663,\n",
      "       -0.10327216,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8548043459271626, next_state=array([ 0.0289793 ,  1.5163649 ,  0.16709916, -0.11310615, -0.17729875,\n",
      "       -0.1460425 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0289793 ,  1.5163649 ,  0.16709916, -0.11310615, -0.17729875,\n",
      "       -0.1460425 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1822138964132862, next_state=array([ 0.03066463,  1.5132252 ,  0.17800096, -0.140702  , -0.1868116 ,\n",
      "       -0.19025722,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03066463,  1.5132252 ,  0.17800096, -0.140702  , -0.1868116 ,\n",
      "       -0.19025722,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3247638023144646, next_state=array([ 0.03235006,  1.5094867 ,  0.17799893, -0.1673761 , -0.1963244 ,\n",
      "       -0.190256  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03235006,  1.5094867 ,  0.17799893, -0.1673761 , -0.1963244 ,\n",
      "       -0.190256  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5917691809102326, next_state=array([ 0.03396416,  1.5051675 ,  0.16903912, -0.19299597, -0.20400001,\n",
      "       -0.1535128 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03396416,  1.5051675 ,  0.16903912, -0.19299597, -0.20400001,\n",
      "       -0.1535128 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5454377900929603, next_state=array([ 0.03550854,  1.5002754 ,  0.16021399, -0.21823587, -0.20983553,\n",
      "       -0.11671007,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03550854,  1.5002754 ,  0.16021399, -0.21823587, -0.20983553,\n",
      "       -0.11671007,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.553976481351724, next_state=array([ 0.03699169,  1.4948127 ,  0.15247193, -0.24338141, -0.21403462,\n",
      "       -0.08398174,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03699169,  1.4948127 ,  0.15247193, -0.24338141, -0.21403462,\n",
      "       -0.08398174,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7368840623352184, next_state=array([ 0.03853454,  1.4900062 ,  0.15898651, -0.21430849, -0.21878652,\n",
      "       -0.09503835,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03853454,  1.4900062 ,  0.15898651, -0.21430849, -0.21878652,\n",
      "       -0.09503835,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.124398445445621, next_state=array([ 0.0400774 ,  1.4846001 ,  0.1589859 , -0.240977  , -0.22353843,\n",
      "       -0.09503822,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0400774 ,  1.4846001 ,  0.1589859 , -0.240977  , -0.22353843,\n",
      "       -0.09503822,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.118940970927723, next_state=array([ 0.04170523,  1.4785578 ,  0.16969994, -0.2696123 , -0.2305476 ,\n",
      "       -0.14018378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04170523,  1.4785578 ,  0.16969994, -0.2696123 , -0.2305476 ,\n",
      "       -0.14018378,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.13826906628985397, next_state=array([ 0.04344378,  1.4727639 ,  0.18086174, -0.2586223 , -0.23765573,\n",
      "       -0.14216217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04344378,  1.4727639 ,  0.18086174, -0.2586223 , -0.23765573,\n",
      "       -0.14216217,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.2914714929959232, next_state=array([ 0.04526396,  1.4663287 ,  0.19117425, -0.28751072, -0.24696879,\n",
      "       -0.18626177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04526396,  1.4663287 ,  0.19117425, -0.28751072, -0.24696879,\n",
      "       -0.18626177,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6575855213377906, next_state=array([ 0.04716015,  1.4603972 ,  0.19923744, -0.26526797, -0.2567727 ,\n",
      "       -0.19607824,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04716015,  1.4603972 ,  0.19923744, -0.26526797, -0.2567727 ,\n",
      "       -0.19607824,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8055203796376407, next_state=array([ 0.04898892,  1.453883  ,  0.19076844, -0.29092753, -0.26483953,\n",
      "       -0.16133633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04898892,  1.453883  ,  0.19076844, -0.29092753, -0.26483953,\n",
      "       -0.16133633,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6231242650137847, next_state=array([ 0.05075111,  1.4468043 ,  0.18232565, -0.3157276 , -0.27108955,\n",
      "       -0.12500073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05075111,  1.4468043 ,  0.18232565, -0.3157276 , -0.27108955,\n",
      "       -0.12500073,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8376828733727266, next_state=array([ 0.05257053,  1.4391023 ,  0.18952617, -0.34373733, -0.27886474,\n",
      "       -0.15550405,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05257053,  1.4391023 ,  0.18952617, -0.34373733, -0.27886474,\n",
      "       -0.15550405,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3102484291541714, next_state=array([ 0.05439014,  1.4308012 ,  0.1895241 , -0.3704089 , -0.2866399 ,\n",
      "       -0.15550338,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05439014,  1.4308012 ,  0.1895241 , -0.3704089 , -0.2866399 ,\n",
      "       -0.15550338,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.087095614923497, next_state=array([ 0.056283  ,  1.4218664 ,  0.1987483 , -0.39899254, -0.2963917 ,\n",
      "       -0.19503576,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.056283  ,  1.4218664 ,  0.1987483 , -0.39899254, -0.2963917 ,\n",
      "       -0.19503576,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6725488565987063, next_state=array([ 0.0583312 ,  1.4134141 ,  0.21454108, -0.3776683 , -0.30643064,\n",
      "       -0.20077972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0583312 ,  1.4134141 ,  0.21454108, -0.3776683 , -0.30643064,\n",
      "       -0.20077972,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4463789390075306, next_state=array([ 0.06037979,  1.4043632 ,  0.21453734, -0.40434304, -0.31646958,\n",
      "       -0.20077834,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06037979,  1.4043632 ,  0.21453734, -0.40434304, -0.31646958,\n",
      "       -0.20077834,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2337560982536047, next_state=array([ 0.06253519,  1.3959179 ,  0.22584698, -0.3776286 , -0.32719615,\n",
      "       -0.21453115,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06253519,  1.3959179 ,  0.22584698, -0.3776286 , -0.32719615,\n",
      "       -0.21453115,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.488458077165035, next_state=array([ 0.06469087,  1.386874  ,  0.22584243, -0.4043044 , -0.33792263,\n",
      "       -0.21452944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06469087,  1.386874  ,  0.22584243, -0.4043044 , -0.33792263,\n",
      "       -0.21452944,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.4925211609384506, next_state=array([ 0.06694088,  1.3771951 ,  0.23760402, -0.4331816 , -0.35114756,\n",
      "       -0.26449856,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06694088,  1.3771951 ,  0.23760402, -0.4331816 , -0.35114756,\n",
      "       -0.26449856,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.662046875587265, next_state=array([ 0.06919136,  1.3669186 ,  0.23759659, -0.45986208, -0.36437234,\n",
      "       -0.26449537,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06919136,  1.3669186 ,  0.23759659, -0.45986208, -0.36437234,\n",
      "       -0.26449537,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.631923469497508, next_state=array([ 0.07144241,  1.3560439 ,  0.23758888, -0.48654243, -0.37759694,\n",
      "       -0.26449218,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07144241,  1.3560439 ,  0.23758888, -0.48654243, -0.37759694,\n",
      "       -0.26449218,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.3134569940031313, next_state=array([ 0.07375393,  1.3445333 ,  0.24518602, -0.51536787, -0.392536  ,\n",
      "       -0.29878163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07375393,  1.3445333 ,  0.24518602, -0.51536787, -0.392536  ,\n",
      "       -0.29878163,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0203790818472087, next_state=array([ 0.07600097,  1.3324656 ,  0.23691013, -0.5397641 , -0.40561485,\n",
      "       -0.26157698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07600097,  1.3324656 ,  0.23691013, -0.5397641 , -0.40561485,\n",
      "       -0.26157698,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6243978242434014, next_state=array([ 0.07816134,  1.319848  ,  0.22591622, -0.56365204, -0.41625607,\n",
      "       -0.21282437,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07816134,  1.319848  ,  0.22591622, -0.56365204, -0.41625607,\n",
      "       -0.21282437,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.485244456172693, next_state=array([ 0.08025531,  1.306688  ,  0.21737134, -0.5872572 , -0.42486376,\n",
      "       -0.1721535 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08025531,  1.306688  ,  0.21737134, -0.5872572 , -0.42486376,\n",
      "       -0.1721535 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5677542639682429, next_state=array([ 0.08266716,  1.2936275 ,  0.24869916, -0.5827499 , -0.43302146,\n",
      "       -0.16315386,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08266716,  1.2936275 ,  0.24869916, -0.5827499 , -0.43302146,\n",
      "       -0.16315386,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5942967565993613, next_state=array([ 0.08513546,  1.2799296 ,  0.25583693, -0.6115968 , -0.44282207,\n",
      "       -0.19601232,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08513546,  1.2799296 ,  0.25583693, -0.6115968 , -0.44282207,\n",
      "       -0.19601232,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6606278079697006, next_state=array([ 0.08793803,  1.2670085 ,  0.28959486, -0.5772531 , -0.4530453 ,\n",
      "       -0.20446464,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08793803,  1.2670085 ,  0.28959486, -0.5772531 , -0.4530453 ,\n",
      "       -0.20446464,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1005930668393364, next_state=array([ 0.09065218,  1.2535441 ,  0.27840108, -0.6007128 , -0.4607226 ,\n",
      "       -0.15354584,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09065218,  1.2535441 ,  0.27840108, -0.6007128 , -0.4607226 ,\n",
      "       -0.15354584,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2015793777254362, next_state=array([ 0.09331417,  1.2395226 ,  0.27170023, -0.62501395, -0.46680024,\n",
      "       -0.12155314,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09331417,  1.2395226 ,  0.27170023, -0.62501395, -0.46680024,\n",
      "       -0.12155314,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6240950645265286, next_state=array([ 0.09597626,  1.2249014 ,  0.27169818, -0.6516833 , -0.4728779 ,\n",
      "       -0.12155282,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09597626,  1.2249014 ,  0.27169818, -0.6516833 , -0.4728779 ,\n",
      "       -0.12155282,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5804555962768632, next_state=array([ 0.09863844,  1.2096808 ,  0.27169603, -0.6783527 , -0.4789555 ,\n",
      "       -0.12155257,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09863844,  1.2096808 ,  0.27169603, -0.6783527 , -0.4789555 ,\n",
      "       -0.12155257,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8112146112995038, next_state=array([ 0.10123301,  1.1939076 ,  0.26311576, -0.70230615, -0.48303586,\n",
      "       -0.08160723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10123301,  1.1939076 ,  0.26311576, -0.70230615, -0.48303586,\n",
      "       -0.08160723,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.302079679298032, next_state=array([ 0.10382767,  1.1775347 ,  0.26311478, -0.72897404, -0.48711622,\n",
      "       -0.08160713,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10382767,  1.1775347 ,  0.26311478, -0.72897404, -0.48711622,\n",
      "       -0.08160713,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.12395738582218313, next_state=array([ 0.10669603,  1.161138  ,  0.29023075, -0.7299421 , -0.49090922,\n",
      "       -0.07586026,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10669603,  1.161138  ,  0.29023075, -0.7299421 , -0.49090922,\n",
      "       -0.07586026,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0310760182217664, next_state=array([ 0.10962763,  1.144081  ,  0.29835945, -0.7599497 , -0.49673313,\n",
      "       -0.11647876,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10962763,  1.144081  ,  0.29835945, -0.7599497 , -0.49673313,\n",
      "       -0.11647876,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0467900703468715, next_state=array([ 0.11261034,  1.1263705 ,  0.30494455, -0.78956735, -0.504248  ,\n",
      "       -0.15029827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11261034,  1.1263705 ,  0.30494455, -0.78956735, -0.504248  ,\n",
      "       -0.15029827,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4534368783552907, next_state=array([ 0.11559315,  1.1080607 ,  0.30494112, -0.81623816, -0.5117629 ,\n",
      "       -0.15029779,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11559315,  1.1080607 ,  0.30494112, -0.81623816, -0.5117629 ,\n",
      "       -0.15029779,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3620871892500304, next_state=array([ 0.11881237,  1.0901427 ,  0.32901722, -0.799048  , -0.5198225 ,\n",
      "       -0.16119102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11881237,  1.0901427 ,  0.32901722, -0.799048  , -0.5198225 ,\n",
      "       -0.16119102,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5513679139472163, next_state=array([ 0.12195835,  1.0716971 ,  0.31957382, -0.8217108 , -0.52548885,\n",
      "       -0.1133273 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12195835,  1.0716971 ,  0.31957382, -0.8217108 , -0.52548885,\n",
      "       -0.1133273 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.0610874200296494, next_state=array([ 0.12517348,  1.0525945 ,  0.3283432 , -0.85167015, -0.53329825,\n",
      "       -0.15618797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12517348,  1.0525945 ,  0.3283432 , -0.85167015, -0.53329825,\n",
      "       -0.15618797,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.428192562428562, next_state=array([ 0.12846784,  1.0328109 ,  0.33852622, -0.8828795 , -0.54373634,\n",
      "       -0.20876154,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12846784,  1.0328109 ,  0.33852622, -0.8828795 , -0.54373634,\n",
      "       -0.20876154,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5585562331967253, next_state=array([ 0.1317627 ,  1.0124286 ,  0.3385192 , -0.90955406, -0.55417436,\n",
      "       -0.20875995,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1317627 ,  1.0124286 ,  0.3385192 , -0.90955406, -0.55417436,\n",
      "       -0.20875995,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5115639986011047, next_state=array([ 0.13505812,  0.9914476 ,  0.33851206, -0.93622845, -0.56461227,\n",
      "       -0.20875838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13505812,  0.9914476 ,  0.33851206, -0.93622845, -0.56461227,\n",
      "       -0.20875838,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4533238749990844, next_state=array([ 0.13843536,  0.96980083,  0.348769  , -0.9668056 , -0.57757515,\n",
      "       -0.25925803,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13843536,  0.96980083,  0.348769  , -0.9668056 , -0.57757515,\n",
      "       -0.25925803,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6570965953464452, next_state=array([ 0.14181337,  0.9475558 ,  0.3487576 , -0.99348414, -0.5905379 ,\n",
      "       -0.25925502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14181337,  0.9475558 ,  0.3487576 , -0.99348414, -0.5905379 ,\n",
      "       -0.25925502,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9518924475945869, next_state=array([ 0.14513674,  0.92476505,  0.3416955 , -1.0171483 , -0.6016938 ,\n",
      "       -0.22311838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14513674,  0.92476505,  0.3416955 , -1.0171483 , -0.6016938 ,\n",
      "       -0.22311838,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5846377586298945, next_state=array([ 0.14839411,  0.9014414 ,  0.3332015 , -1.0400472 , -0.6106414 ,\n",
      "       -0.17895271,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14839411,  0.9014414 ,  0.3332015 , -1.0400472 , -0.6106414 ,\n",
      "       -0.17895271,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3643965524817918, next_state=array([ 0.15159282,  0.8775872 ,  0.32555094, -1.0628554 , -0.6174976 ,\n",
      "       -0.13712364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15159282,  0.8775872 ,  0.32555094, -1.0628554 , -0.6174976 ,\n",
      "       -0.13712364,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8861056893612158, next_state=array([ 0.15479183,  0.85313344,  0.32554755, -1.0895253 , -0.62435377,\n",
      "       -0.1371226 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15479183,  0.85313344,  0.32554755, -1.0895253 , -0.62435377,\n",
      "       -0.1371226 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.6644391518612567, next_state=array([ 0.15835428,  0.8292977 ,  0.36254543, -1.0624156 , -0.63204145,\n",
      "       -0.15375356,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15835428,  0.8292977 ,  0.36254543, -1.0624156 , -0.63204145,\n",
      "       -0.15375356,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9666858655324404, next_state=array([ 0.16191702,  0.8048627 ,  0.36254105, -1.0890864 , -0.63972914,\n",
      "       -0.15375338,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16191702,  0.8048627 ,  0.36254105, -1.0890864 , -0.63972914,\n",
      "       -0.15375338,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.29598173381887594, next_state=array([ 0.16543245,  0.7798841 ,  0.35639447, -1.1125811 , -0.6457138 ,\n",
      "       -0.11969288,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16543245,  0.7798841 ,  0.35639447, -1.1125811 , -0.6457138 ,\n",
      "       -0.11969288,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6766397906675639, next_state=array([ 0.16902399,  0.7542349 ,  0.36597985, -1.1434226 , -0.6541799 ,\n",
      "       -0.16932122,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16902399,  0.7542349 ,  0.36597985, -1.1434226 , -0.6541799 ,\n",
      "       -0.16932122,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.19729027935923568, next_state=array([ 0.1725544 ,  0.72804326,  0.35822934, -1.1667457 , -0.66064596,\n",
      "       -0.12932125,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1725544 ,  0.72804326,  0.35822934, -1.1667457 , -0.66064596,\n",
      "       -0.12932125,  0.        ,  0.        ], dtype=float32), action=1, reward=0.2944509199024037, next_state=array([ 0.17601022,  0.70133746,  0.34861362, -1.1885024 , -0.6644535 ,\n",
      "       -0.07615145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17601022,  0.70133746,  0.34861362, -1.1885024 , -0.6644535 ,\n",
      "       -0.07615145,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5906444550790024, next_state=array([ 0.1793909 ,  0.6741191 ,  0.33896226, -1.2101778 , -0.66557705,\n",
      "       -0.022471  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1793909 ,  0.6741191 ,  0.33896226, -1.2101778 , -0.66557705,\n",
      "       -0.022471  ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6283373362761335, next_state=array([ 0.18271522,  0.64636606,  0.3317229 , -1.2331032 , -0.6646877 ,\n",
      "        0.01778675,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18271522,  0.64636606,  0.3317229 , -1.2331032 , -0.6646877 ,\n",
      "        0.01778675,  0.        ,  0.        ], dtype=float32), action=1, reward=0.702352578556231, next_state=array([ 0.18599014,  0.61806077,  0.32546803, -1.2569526 , -0.6621565 ,\n",
      "        0.05062469,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18599014,  0.61806077,  0.32546803, -1.2569526 , -0.6621565 ,\n",
      "        0.05062469,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2468347358899063, next_state=array([ 0.18920031,  0.5892465 ,  0.31697366, -1.2785462 , -0.6571051 ,\n",
      "        0.10102879,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18920031,  0.5892465 ,  0.31697366, -1.2785462 , -0.6571051 ,\n",
      "        0.10102879,  0.        ,  0.        ], dtype=float32), action=2, reward=4.0887634949901726, next_state=array([ 0.19291162,  0.561065  ,  0.36747232, -1.2506331 , -0.6525401 ,\n",
      "        0.09130014,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19291162,  0.561065  ,  0.36747232, -1.2506331 , -0.6525401 ,\n",
      "        0.09130014,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3662324947339062, next_state=array([ 0.19668055,  0.5322095 ,  0.3749349 , -1.2814758 , -0.6501204 ,\n",
      "        0.04839312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19668055,  0.5322095 ,  0.3749349 , -1.2814758 , -0.6501204 ,\n",
      "        0.04839312,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4149013517131539, next_state=array([ 0.20050593,  0.5027009 ,  0.38208246, -1.3112599 , -0.6495524 ,\n",
      "        0.0113591 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20050593,  0.5027009 ,  0.38208246, -1.3112599 , -0.6495524 ,\n",
      "        0.0113591 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.7228969490219026, next_state=array([ 0.2042841 ,  0.4726461 ,  0.37601775, -1.3348583 , -0.64731634,\n",
      "        0.04472088,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2042841 ,  0.4726461 ,  0.37601775, -1.3348583 , -0.64731634,\n",
      "        0.04472088,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2144237539380367, next_state=array([ 0.20799676,  0.44208014,  0.36742586, -1.3565623 , -0.6425769 ,\n",
      "        0.09478967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20799676,  0.44208014,  0.36742586, -1.3565623 , -0.6425769 ,\n",
      "        0.09478967,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8798988988903147, next_state=array([ 0.21220665,  0.41162124,  0.4167048 , -1.3516026 , -0.63730234,\n",
      "        0.1054908 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21220665,  0.41162124,  0.4167048 , -1.3516026 , -0.63730234,\n",
      "        0.1054908 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.43532171144141674, next_state=array([ 0.2164816 ,  0.38048196,  0.42512497, -1.3828049 , -0.6344027 ,\n",
      "        0.05799351,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2164816 ,  0.38048196,  0.42512497, -1.3828049 , -0.6344027 ,\n",
      "        0.05799351,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8506007970235612, next_state=array([ 0.22070856,  0.3487972 ,  0.41894883, -1.4063817 , -0.62981504,\n",
      "        0.09175302,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22070856,  0.3487972 ,  0.41894883, -1.4063817 , -0.62981504,\n",
      "        0.09175302,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6758170602039388, next_state=array([ 0.22500734,  0.316425  ,  0.42824936, -1.4379771 , -0.6278294 ,\n",
      "        0.03971304,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22500734,  0.316425  ,  0.42824936, -1.4379771 , -0.6278294 ,\n",
      "        0.03971304,  0.        ,  0.        ], dtype=float32), action=2, reward=2.4609847063874044, next_state=array([ 0.22947578,  0.2842641 ,  0.44590187, -1.4289166 , -0.62667805,\n",
      "        0.02302652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22947578,  0.2842641 ,  0.44590187, -1.4289166 , -0.62667805,\n",
      "        0.02302652,  0.        ,  0.        ], dtype=float32), action=1, reward=0.46483280104360003, next_state=array([ 0.23389348,  0.25157082,  0.4392496 , -1.4518226 , -0.62361425,\n",
      "        0.06127577,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23389348,  0.25157082,  0.4392496 , -1.4518226 , -0.62361425,\n",
      "        0.06127577,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9338056515836957, next_state=array([ 0.23837033,  0.21822682,  0.44670883, -1.481487  , -0.6224239 ,\n",
      "        0.02380713,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23837033,  0.21822682,  0.44670883, -1.481487  , -0.6224239 ,\n",
      "        0.02380713,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5251249310707624, next_state=array([ 0.24291773,  0.18421105,  0.45571452, -1.5122782 , -0.6236069 ,\n",
      "       -0.02366029,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24291773,  0.18421105,  0.45571452, -1.5122782 , -0.6236069 ,\n",
      "       -0.02366029,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2542298107693728, next_state=array([ 0.24739036,  0.1496612 ,  0.44626755, -1.5350732 , -0.6224007 ,\n",
      "        0.02412433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24739036,  0.1496612 ,  0.44626755, -1.5350732 , -0.6224007 ,\n",
      "        0.02412433,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.011080649597192849, next_state=array([ 0.2521971 ,  0.11508916,  0.47949904, -1.535976  , -0.62097746,\n",
      "        0.0284651 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2521971 ,  0.11508916,  0.47949904, -1.535976  , -0.62097746,\n",
      "        0.0284651 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.2945358790512216, next_state=array([ 0.25732452,  0.08094293,  0.5120929 , -1.5173    , -0.6201882 ,\n",
      "        0.01578606,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25732452,  0.08094293,  0.5120929 , -1.5173    , -0.6201882 ,\n",
      "        0.01578606,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1225294140320716, next_state=array([ 0.26237002,  0.04627477,  0.5016731 , -1.5394461 , -0.61670876,\n",
      "        0.06958831,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26237002,  0.04627477,  0.5016731 , -1.5394461 , -0.61670876,\n",
      "        0.06958831,  0.        ,  0.        ], dtype=float32), action=0, reward=7.6881339905583275, next_state=array([ 0.26741543,  0.01100665,  0.50167227, -1.5661138 , -0.61322933,\n",
      "        0.06958798,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26741543,  0.01100665,  0.50167227, -1.5661138 , -0.61322933,\n",
      "        0.06958798,  1.        ,  0.        ], dtype=float32), action=3, reward=7.623535751385391, next_state=array([ 0.2724143 , -0.02292547,  0.48461646, -1.5011532 , -0.5980217 ,\n",
      "        0.30033174,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2724143 , -0.02292547,  0.48461646, -1.5011532 , -0.5980217 ,\n",
      "        0.30033174,  1.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([ 0.279564  , -0.04976952,  0.64524835, -0.7800628 , -0.44762653,\n",
      "        5.156993  ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00652771,  1.4072183 , -0.6611923 , -0.16453747,  0.00757069,\n",
      "        0.14976999,  0.        ,  0.        ], dtype=float32), action=3, reward=0.40563777409627844, next_state=array([-0.01296444,  1.4029397 , -0.64883274, -0.19019155,  0.0126719 ,\n",
      "        0.10203432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01296444,  1.4029397 , -0.64883274, -0.19019155,  0.0126719 ,\n",
      "        0.10203432,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1506493324077212, next_state=array([-0.01930122,  1.3992968 , -0.6393715 , -0.16197005,  0.01830063,\n",
      "        0.11258508,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01930122,  1.3992968 , -0.6393715 , -0.16197005,  0.01830063,\n",
      "        0.11258508,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4988295556308174, next_state=array([-0.02561579,  1.3966262 , -0.63735086, -0.11877055,  0.02412635,\n",
      "        0.1165252 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02561579,  1.3966262 , -0.63735086, -0.11877055,  0.02412635,\n",
      "        0.1165252 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.0717303864466328, next_state=array([-0.03186855,  1.3933526 , -0.6295756 , -0.14556931,  0.02839034,\n",
      "        0.08528759,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03186855,  1.3933526 , -0.6295756 , -0.14556931,  0.02839034,\n",
      "        0.08528759,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7083997935960724, next_state=array([-0.03812132,  1.3894793 , -0.62958723, -0.17223254,  0.0326544 ,\n",
      "        0.08528914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03812132,  1.3894793 , -0.62958723, -0.17223254,  0.0326544 ,\n",
      "        0.08528914,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7528378408902086, next_state=array([-0.04437418,  1.3850062 , -0.62959987, -0.19890189,  0.03691745,\n",
      "        0.08526896,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04437418,  1.3850062 , -0.62959987, -0.19890189,  0.03691745,\n",
      "        0.08526896,  0.        ,  0.        ], dtype=float32), action=3, reward=0.22095140894916313, next_state=array([-0.05055437,  1.3799338 , -0.62048095, -0.22550015,  0.03934924,\n",
      "        0.04864024,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05055437,  1.3799338 , -0.62048095, -0.22550015,  0.03934924,\n",
      "        0.04864024,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0330037167897046, next_state=array([-0.05663357,  1.3750432 , -0.61095273, -0.21745278,  0.0423595 ,\n",
      "        0.06021085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05663357,  1.3750432 , -0.61095273, -0.21745278,  0.0423595 ,\n",
      "        0.06021085,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7262814189382982, next_state=array([-0.06278048,  1.3695445 , -0.6194556 , -0.24452144,  0.04707607,\n",
      "        0.09433988,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06278048,  1.3695445 , -0.6194556 , -0.24452144,  0.04707607,\n",
      "        0.09433988,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9180248713534809, next_state=array([-0.06892757,  1.3634464 , -0.6194705 , -0.27118868,  0.0517914 ,\n",
      "        0.09431521,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06892757,  1.3634464 , -0.6194705 , -0.27118868,  0.0517914 ,\n",
      "        0.09431521,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9905974619978621, next_state=array([-0.07503472,  1.3578988 , -0.61585784, -0.24674755,  0.05688306,\n",
      "        0.10184248,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07503472,  1.3578988 , -0.61585784, -0.24674755,  0.05688306,\n",
      "        0.10184248,  0.        ,  0.        ], dtype=float32), action=3, reward=0.01936275608238816, next_state=array([-0.08106852,  1.3517461 , -0.60666513, -0.2735823 ,  0.06013476,\n",
      "        0.06503991,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08106852,  1.3517461 , -0.60666513, -0.2735823 ,  0.06013476,\n",
      "        0.06503991,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8294324859650999, next_state=array([-0.08710241,  1.3449935 , -0.6066738 , -0.30024728,  0.06338689,\n",
      "        0.06504855,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08710241,  1.3449935 , -0.6066738 , -0.30024728,  0.06338689,\n",
      "        0.06504855,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7238536461993987, next_state=array([-0.09312582,  1.3386059 , -0.6058625 , -0.28405052,  0.06687955,\n",
      "        0.06985968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09312582,  1.3386059 , -0.6058625 , -0.28405052,  0.06687955,\n",
      "        0.06985968,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.09233858360226918, next_state=array([-0.09908915,  1.3316121 , -0.5983568 , -0.3109301 ,  0.06887412,\n",
      "        0.03989498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09908915,  1.3316121 , -0.5983568 , -0.3109301 ,  0.06887412,\n",
      "        0.03989498,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0358980209213768, next_state=array([-0.10509777,  1.3253179 , -0.60293853, -0.27983877,  0.07093716,\n",
      "        0.0412645 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10509777,  1.3253179 , -0.60293853, -0.27983877,  0.07093716,\n",
      "        0.0412645 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.02853206339774489, next_state=array([-0.11118831,  1.3194172 , -0.6109759 , -0.2623352 ,  0.07283574,\n",
      "        0.0379753 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11118831,  1.3194172 , -0.6109759 , -0.2623352 ,  0.07283574,\n",
      "        0.0379753 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.05137245029770271, next_state=array([-0.11734953,  1.3139181 , -0.6179411 , -0.24449375,  0.07463115,\n",
      "        0.03591163,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11734953,  1.3139181 , -0.6179411 , -0.24449375,  0.07463115,\n",
      "        0.03591163,  0.        ,  0.        ], dtype=float32), action=3, reward=0.1816979592726409, next_state=array([-0.12345114,  1.3078338 , -0.61044   , -0.27043122,  0.07490597,\n",
      "        0.0054969 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12345114,  1.3078338 , -0.61044   , -0.27043122,  0.07490597,\n",
      "        0.0054969 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.924899759624725, next_state=array([-0.12972507,  1.3019423 , -0.62704206, -0.26182228,  0.07456406,\n",
      "       -0.00683866,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12972507,  1.3019423 , -0.62704206, -0.26182228,  0.07456406,\n",
      "       -0.00683866,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4040456195359912, next_state=array([-0.13606425,  1.2954478 , -0.6352337 , -0.2887082 ,  0.07586533,\n",
      "        0.02602752,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13606425,  1.2954478 , -0.6352337 , -0.2887082 ,  0.07586533,\n",
      "        0.02602752,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6379514599621814, next_state=array([-0.14240351,  1.2883536 , -0.6352388 , -0.3153742 ,  0.07716544,\n",
      "        0.02600455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14240351,  1.2883536 , -0.6352388 , -0.3153742 ,  0.07716544,\n",
      "        0.02600455,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5146677240737005, next_state=array([-0.14884233,  1.2819195 , -0.64503217, -0.28601387,  0.07830489,\n",
      "        0.02279096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14884233,  1.2819195 , -0.64503217, -0.28601387,  0.07830489,\n",
      "        0.02279096,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.45521866555175733, next_state=array([-0.15548925,  1.2762389 , -0.66519356, -0.2524944 ,  0.07880941,\n",
      "        0.01009098,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15548925,  1.2762389 , -0.66519356, -0.2524944 ,  0.07880941,\n",
      "        0.01009098,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5232204516659635, next_state=array([-0.16213493,  1.2699372 , -0.6650788 , -0.28011456,  0.07931428,\n",
      "        0.01009714,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16213493,  1.2699372 , -0.6650788 , -0.28011456,  0.07931428,\n",
      "        0.01009714,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5285060843548024, next_state=array([-0.16878071,  1.263035  , -0.6650788 , -0.30678126,  0.07981914,\n",
      "        0.0100971 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16878071,  1.263035  , -0.6650788 , -0.30678126,  0.07981914,\n",
      "        0.0100971 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.17121148852465923, next_state=array([-0.17541695,  1.2560627 , -0.6643067 , -0.3099171 ,  0.08049754,\n",
      "        0.01356804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17541695,  1.2560627 , -0.6643067 , -0.3099171 ,  0.08049754,\n",
      "        0.01356804,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5786189052626582, next_state=array([-0.18205318,  1.2484905 , -0.66430664, -0.33658382,  0.08117595,\n",
      "        0.01356802,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18205318,  1.2484905 , -0.66430664, -0.33658382,  0.08117595,\n",
      "        0.01356802,  0.        ,  0.        ], dtype=float32), action=3, reward=0.19128035156643478, next_state=array([-0.1886302 ,  1.2403257 , -0.6568731 , -0.36283597,  0.08035788,\n",
      "       -0.01636135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1886302 ,  1.2403257 , -0.6568731 , -0.36283597,  0.08035788,\n",
      "       -0.01636135,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5939017354896794, next_state=array([-0.19528513,  1.2315438 , -0.66666925, -0.390372  ,  0.08152173,\n",
      "        0.02327717,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19528513,  1.2315438 , -0.66666925, -0.390372  ,  0.08152173,\n",
      "        0.02327717,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.977071529321505, next_state=array([-0.20203319,  1.222148  , -0.6783639 , -0.4177934 ,  0.08504311,\n",
      "        0.07042735,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20203319,  1.222148  , -0.6783639 , -0.4177934 ,  0.08504311,\n",
      "        0.07042735,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7527188080738767, next_state=array([-0.20877647,  1.2135012 , -0.67826414, -0.38452494,  0.08893891,\n",
      "        0.07791609,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20877647,  1.2135012 , -0.67826414, -0.38452494,  0.08893891,\n",
      "        0.07791609,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4639715488438128, next_state=array([-0.21547718,  1.2049114 , -0.6743818 , -0.38202846,  0.0932105 ,\n",
      "        0.08543172,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21547718,  1.2049114 , -0.6743818 , -0.38202846,  0.0932105 ,\n",
      "        0.08543172,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.04598311253664519, next_state=array([-0.22210808,  1.19574   , -0.66559607, -0.40777922,  0.09569795,\n",
      "        0.04974885,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22210808,  1.19574   , -0.66559607, -0.40777922,  0.09569795,\n",
      "        0.04974885,  0.        ,  0.        ], dtype=float32), action=3, reward=0.19459086277123674, next_state=array([-0.22865768,  1.1859679 , -0.6554109 , -0.43433315,  0.09615102,\n",
      "        0.00906161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22865768,  1.1859679 , -0.6554109 , -0.43433315,  0.09615102,\n",
      "        0.00906161,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6835415584382065, next_state=array([-0.23528099,  1.1755801 , -0.6646881 , -0.46183118,  0.09848363,\n",
      "        0.04665213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23528099,  1.1755801 , -0.6646881 , -0.46183118,  0.09848363,\n",
      "        0.04665213,  0.        ,  0.        ], dtype=float32), action=3, reward=0.36581000407278563, next_state=array([-2.4181286e-01,  1.1646180e+00, -6.5317690e-01, -4.8720822e-01,\n",
      "        9.8474085e-02, -1.9101005e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.4181286e-01,  1.1646180e+00, -6.5317690e-01, -4.8720822e-01,\n",
      "        9.8474085e-02, -1.9101005e-04,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=0.13095689547270808, next_state=array([-0.24828258,  1.1530597 , -0.64538264, -0.51359564,  0.09690086,\n",
      "       -0.03146451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24828258,  1.1530597 , -0.64538264, -0.51359564,  0.09690086,\n",
      "       -0.03146451,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6685872705075429, next_state=array([-0.2548415 ,  1.1408807 , -0.65659773, -0.54133433,  0.09760238,\n",
      "        0.01403019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2548415 ,  1.1408807 , -0.65659773, -0.54133433,  0.09760238,\n",
      "        0.01403019,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5877411355614413, next_state=array([-0.2615827 ,  1.1291691 , -0.674304  , -0.5205286 ,  0.09778461,\n",
      "        0.00364446,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2615827 ,  1.1291691 , -0.674304  , -0.5205286 ,  0.09778461,\n",
      "        0.00364446,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.08191312936252187, next_state=array([-0.26842982,  1.1174722 , -0.6845839 , -0.51985323,  0.09766416,\n",
      "       -0.00240906,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26842982,  1.1174722 , -0.6845839 , -0.51985323,  0.09766416,\n",
      "       -0.00240906,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7859654868524604, next_state=array([-0.27536565,  1.1051567 , -0.69574153, -0.5474953 ,  0.09980351,\n",
      "        0.04278701,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27536565,  1.1051567 , -0.69574153, -0.5474953 ,  0.09980351,\n",
      "        0.04278701,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6440442695447064, next_state=array([-0.28236538,  1.0922344 , -0.70375323, -0.5745794 ,  0.10355503,\n",
      "        0.07503035,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28236538,  1.0922344 , -0.70375323, -0.5745794 ,  0.10355503,\n",
      "        0.07503035,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9977468570260999, next_state=array([-0.28944722,  1.0787086 , -0.7140401 , -0.6015567 ,  0.10936765,\n",
      "        0.1162523 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28944722,  1.0787086 , -0.7140401 , -0.6015567 ,  0.10936765,\n",
      "        0.1162523 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.011757515189374318, next_state=array([-0.29643232,  1.0645909 , -0.7019087 , -0.6277076 ,  0.11274405,\n",
      "        0.06752808,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.29643232,  1.0645909 , -0.7019087 , -0.6277076 ,  0.11274405,\n",
      "        0.06752808,  0.        ,  0.        ], dtype=float32), action=3, reward=0.24863323232585913, next_state=array([-0.30332175,  1.0498917 , -0.68988717, -0.65336984,  0.11368552,\n",
      "        0.01882925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30332175,  1.0498917 , -0.68988717, -0.65336984,  0.11368552,\n",
      "        0.01882925,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6740541960313351, next_state=array([-0.31021112,  1.0345925 , -0.68988717, -0.68003654,  0.11462699,\n",
      "        0.01882925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31021112,  1.0345925 , -0.68988717, -0.68003654,  0.11462699,\n",
      "        0.01882925,  0.        ,  0.        ], dtype=float32), action=3, reward=0.30040841321127343, next_state=array([-0.3170154 ,  1.0187011 , -0.6792172 , -0.7061904 ,  0.11342356,\n",
      "       -0.02406853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3170154 ,  1.0187011 , -0.6792172 , -0.7061904 ,  0.11342356,\n",
      "       -0.02406853,  0.        ,  0.        ], dtype=float32), action=2, reward=1.4139280046697251, next_state=array([-0.32402906,  1.0033549 , -0.6995891 , -0.6819188 ,  0.11165661,\n",
      "       -0.03533911,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32402906,  1.0033549 , -0.6995891 , -0.6819188 ,  0.11165661,\n",
      "       -0.03533911,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2252556945205118, next_state=array([-0.33110532,  0.9873888 , -0.70746934, -0.7095935 ,  0.11150049,\n",
      "       -0.00312219,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33110532,  0.9873888 , -0.70746934, -0.7095935 ,  0.11150049,\n",
      "       -0.00312219,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5514978859986286, next_state=array([-0.33818159,  0.97082275, -0.70746934, -0.7362602 ,  0.11134437,\n",
      "       -0.00312223,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33818159,  0.97082275, -0.70746934, -0.7362602 ,  0.11134437,\n",
      "       -0.00312223,  0.        ,  0.        ], dtype=float32), action=3, reward=0.318511871605325, next_state=array([-0.34518513,  0.9536791 , -0.6983159 , -0.7617903 ,  0.10931867,\n",
      "       -0.04051414,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34518513,  0.9536791 , -0.6983159 , -0.7617903 ,  0.10931867,\n",
      "       -0.04051414,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4215704441337482, next_state=array([-0.35227433,  0.93590987, -0.70909435, -0.7897588 ,  0.10949241,\n",
      "        0.00347466,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35227433,  0.93590987, -0.70909435, -0.7897588 ,  0.10949241,\n",
      "        0.00347466,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5555412674178797, next_state=array([-0.3593635 ,  0.9175405 , -0.70909435, -0.8164255 ,  0.10966614,\n",
      "        0.00347472,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3593635 ,  0.9175405 , -0.70909435, -0.8164255 ,  0.10966614,\n",
      "        0.00347472,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5462202559577349, next_state=array([-0.36645275,  0.8985712 , -0.70909435, -0.84309214,  0.10983987,\n",
      "        0.00347473,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36645275,  0.8985712 , -0.70909435, -0.84309214,  0.10983987,\n",
      "        0.00347473,  0.        ,  0.        ], dtype=float32), action=3, reward=0.21830897712291744, next_state=array([-0.37347117,  0.8790121 , -0.70021576, -0.86917347,  0.10822202,\n",
      "       -0.03235691,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37347117,  0.8790121 , -0.70021576, -0.86917347,  0.10822202,\n",
      "       -0.03235691,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0913060530969279, next_state=array([-0.38055038,  0.8588343 , -0.7078649 , -0.8967904 ,  0.10816596,\n",
      "       -0.00112123,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38055038,  0.8588343 , -0.7078649 , -0.8967904 ,  0.10816596,\n",
      "       -0.00112123,  0.        ,  0.        ], dtype=float32), action=3, reward=0.40194245724453137, next_state=array([-0.38754606,  0.83807534, -0.6973578 , -0.9224653 ,  0.10597749,\n",
      "       -0.0437696 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38754606,  0.83807534, -0.6973578 , -0.9224653 ,  0.10597749,\n",
      "       -0.0437696 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.103041770686059, next_state=array([-0.39455596,  0.8178233 , -0.6990803 , -0.89995646,  0.10408376,\n",
      "       -0.03787493,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39455596,  0.8178233 , -0.6990803 , -0.89995646,  0.10408376,\n",
      "       -0.03787493,  0.        ,  0.        ], dtype=float32), action=2, reward=3.5660287038400726, next_state=array([-0.40162134,  0.79832286, -0.7048112 , -0.8665668 ,  0.10236663,\n",
      "       -0.03434268,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40162134,  0.79832286, -0.7048112 , -0.8665668 ,  0.10236663,\n",
      "       -0.03434268,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.243085965056962, next_state=array([-0.4087565 ,  0.77821213, -0.71356225, -0.8938122 ,  0.10241517,\n",
      "        0.00097089,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4087565 ,  0.77821213, -0.71356225, -0.8938122 ,  0.10241517,\n",
      "        0.00097089,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6466926379788436, next_state=array([-0.41598612,  0.75749606, -0.7254043 , -0.92088807,  0.10483856,\n",
      "        0.04846784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41598612,  0.75749606, -0.7254043 , -0.92088807,  0.10483856,\n",
      "        0.04846784,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2142799460030574, next_state=array([-0.42330518,  0.7367283 , -0.73411167, -0.9231668 ,  0.10702705,\n",
      "        0.04376997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42330518,  0.7367283 , -0.73411167, -0.9231668 ,  0.10702705,\n",
      "        0.04376997,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8467308991096729, next_state=array([-0.43062425,  0.7153606 , -0.7341115 , -0.9498338 ,  0.10921556,\n",
      "        0.04376995,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43062425,  0.7153606 , -0.7341115 , -0.9498338 ,  0.10921556,\n",
      "        0.04376995,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8539777910297914, next_state=array([-0.43794328,  0.69339293, -0.7341114 , -0.97650087,  0.11140405,\n",
      "        0.04376992,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43794328,  0.69339293, -0.7341114 , -0.97650087,  0.11140405,\n",
      "        0.04376992,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6780339013539265, next_state=array([-0.44533515,  0.6708135 , -0.74324685, -1.0038459 ,  0.11543921,\n",
      "        0.08070326,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44533515,  0.6708135 , -0.74324685, -1.0038459 ,  0.11543921,\n",
      "        0.08070326,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0997020431665576, next_state=array([-0.4528225 ,  0.64762115, -0.75522625, -1.0312823 ,  0.1218909 ,\n",
      "        0.12903377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4528225 ,  0.64762115, -0.75522625, -1.0312823 ,  0.1218909 ,\n",
      "        0.12903377,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3108432840439548, next_state=array([-0.4603099 ,  0.6238293 , -0.7552256 , -1.0579524 ,  0.12834257,\n",
      "        0.12903343,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4603099 ,  0.6238293 , -0.7552256 , -1.0579524 ,  0.12834257,\n",
      "        0.12903343,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5873571326538183, next_state=array([-0.46806607,  0.600777  , -0.7813925 , -1.0250576 ,  0.13408864,\n",
      "        0.11492135,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46806607,  0.600777  , -0.7813925 , -1.0250576 ,  0.13408864,\n",
      "        0.11492135,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2015525590863647, next_state=array([-0.4759007 ,  0.5771187 , -0.7912052 , -1.0521948 ,  0.14180581,\n",
      "        0.1543435 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4759007 ,  0.5771187 , -0.7912052 , -1.0521948 ,  0.14180581,\n",
      "        0.1543435 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.541608917381352, next_state=array([-0.48381695,  0.55283356, -0.8014778 , -1.0803051 ,  0.15163662,\n",
      "        0.19661628,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48381695,  0.55283356, -0.8014778 , -1.0803051 ,  0.15163662,\n",
      "        0.19661628,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6258385323881144, next_state=array([-0.49180013,  0.5279246 , -0.80989504, -1.1082885 ,  0.16320887,\n",
      "        0.2314448 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49180013,  0.5279246 , -0.80989504, -1.1082885 ,  0.16320887,\n",
      "        0.2314448 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.035767630385891, next_state=array([-0.49978346,  0.5024173 , -0.80989236, -1.1349663 ,  0.17478101,\n",
      "        0.23144262,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49978346,  0.5024173 , -0.80989236, -1.1349663 ,  0.17478101,\n",
      "        0.23144262,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1232391561200064, next_state=array([-0.50767237,  0.47632614, -0.7980286 , -1.160712  ,  0.18395282,\n",
      "        0.18343642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.50767237,  0.47632614, -0.7980286 , -1.160712  ,  0.18395282,\n",
      "        0.18343642,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3016831690896982, next_state=array([-0.5154995 ,  0.44964612, -0.79028076, -1.1867367 ,  0.19155477,\n",
      "        0.15203872,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5154995 ,  0.44964612, -0.79028076, -1.1867367 ,  0.19155477,\n",
      "        0.15203872,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7745436545511084, next_state=array([-0.52341044,  0.42234287, -0.8007947 , -1.2147624 ,  0.20132144,\n",
      "        0.19533318,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.52341044,  0.42234287, -0.8007947 , -1.2147624 ,  0.20132144,\n",
      "        0.19533318,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1725198294574273, next_state=array([-0.53122604,  0.39445776, -0.788838  , -1.24035   ,  0.20866044,\n",
      "        0.14678009,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.53122604,  0.39445776, -0.788838  , -1.24035   ,  0.20866044,\n",
      "        0.14678009,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.8409887259013815, next_state=array([-0.53911525,  0.36594224, -0.7981197 , -1.268679  ,  0.2179481 ,\n",
      "        0.1857532 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.53911525,  0.36594224, -0.7981197 , -1.268679  ,  0.2179481 ,\n",
      "        0.1857532 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4410216546126253, next_state=array([-0.5469235 ,  0.33685106, -0.7879254 , -1.2940079 ,  0.2251331 ,\n",
      "        0.14369997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5469235 ,  0.33685106, -0.7879254 , -1.2940079 ,  0.2251331 ,\n",
      "        0.14369997,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5891352182440357, next_state=array([-0.5550014 ,  0.30863228, -0.81468123, -1.2552367 ,  0.23211463,\n",
      "        0.13963054,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5550014 ,  0.30863228, -0.81468123, -1.2552367 ,  0.23211463,\n",
      "        0.13963054,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.315042172119661, next_state=array([-0.5630795 ,  0.27981412, -0.8146799 , -1.2819073 ,  0.23909613,\n",
      "        0.13963014,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5630795 ,  0.27981412, -0.8146799 , -1.2819073 ,  0.23909613,\n",
      "        0.13963014,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.465337021813325, next_state=array([-0.57106745,  0.2504313 , -0.8033263 , -1.3066467 ,  0.24369599,\n",
      "        0.09199695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.57106745,  0.2504313 , -0.8033263 , -1.3066467 ,  0.24369599,\n",
      "        0.09199695,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3413984067942977, next_state=array([-0.57905555,  0.22044869, -0.8033258 , -1.333315  ,  0.24829584,\n",
      "        0.0919968 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.57905555,  0.22044869, -0.8033258 , -1.333315  ,  0.24829584,\n",
      "        0.0919968 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.3005378282702111, next_state=array([-0.5872764 ,  0.19084118, -0.826301  , -1.3166078 ,  0.25259   ,\n",
      "        0.08588399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5872764 ,  0.19084118, -0.826301  , -1.3166078 ,  0.25259   ,\n",
      "        0.08588399,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8796994016347515, next_state=array([-0.5954251 ,  0.1606546 , -0.81724054, -1.3420365 ,  0.25501052,\n",
      "        0.04841034,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5954251 ,  0.1606546 , -0.81724054, -1.3420365 ,  0.25501052,\n",
      "        0.04841034,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5223881720310417, next_state=array([-0.60365665,  0.12984003, -0.8276526 , -1.3703245 ,  0.2596032 ,\n",
      "        0.09185368,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.60365665,  0.12984003, -0.8276526 , -1.3703245 ,  0.2596032 ,\n",
      "        0.09185368,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.05578038117656, next_state=array([-0.61198246,  0.0983883 , -0.8395294 , -1.3991048 ,  0.26669967,\n",
      "        0.14192969,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.61198246,  0.0983883 , -0.8395294 , -1.3991048 ,  0.26669967,\n",
      "        0.14192969,  0.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([-0.6209201 ,  0.07273601, -1.1527942 , -0.32486305,  0.31076515,\n",
      "        3.0915058 ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([-0.00358248,  1.409108  , -0.36288893, -0.08054332,  0.00415806,\n",
      "        0.08219971,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6274054249612846, next_state=array([-0.00732126,  1.4075978 , -0.37723967, -0.06713106,  0.00748138,\n",
      "        0.06647347,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00732126,  1.4075978 , -0.37723967, -0.06713106,  0.00748138,\n",
      "        0.06647347,  0.        ,  0.        ], dtype=float32), action=3, reward=0.18168322728203748, next_state=array([-0.01099939,  1.4054868 , -0.36962134, -0.09382813,  0.00927326,\n",
      "        0.0358409 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01099939,  1.4054868 , -0.36962134, -0.09382813,  0.00927326,\n",
      "        0.0358409 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7769978099289279, next_state=array([-0.01475258,  1.4027697 , -0.37903476, -0.12079424,  0.01295305,\n",
      "        0.07360236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01475258,  1.4027697 , -0.37903476, -0.12079424,  0.01295305,\n",
      "        0.07360236,  0.        ,  0.        ], dtype=float32), action=2, reward=1.099532793970934, next_state=array([-0.01840305,  1.4005967 , -0.3693063 , -0.09661167,  0.01717049,\n",
      "        0.08435631,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01840305,  1.4005967 , -0.3693063 , -0.09661167,  0.01717049,\n",
      "        0.08435631,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.649039130207558, next_state=array([-0.02214661,  1.399301  , -0.37824634, -0.05764069,  0.0210234 ,\n",
      "        0.07706522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02214661,  1.399301  , -0.37824634, -0.05764069,  0.0210234 ,\n",
      "        0.07706522,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1019210769488823, next_state=array([-0.02598276,  1.3973958 , -0.38987568, -0.08477326,  0.02720886,\n",
      "        0.12372062,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02598276,  1.3973958 , -0.38987568, -0.08477326,  0.02720886,\n",
      "        0.12372062,  0.        ,  0.        ], dtype=float32), action=3, reward=0.2762155390690577, next_state=array([-0.02972775,  1.3948915 , -0.3784182 , -0.11138301,  0.03109163,\n",
      "        0.07766245,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02972775,  1.3948915 , -0.3784182 , -0.11138301,  0.03109163,\n",
      "        0.07766245,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.10209838508238817, next_state=array([-0.0334383 ,  1.3924394 , -0.37521428, -0.10907437,  0.03520317,\n",
      "        0.08223857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0334383 ,  1.3924394 , -0.37521428, -0.10907437,  0.03520317,\n",
      "        0.08223857,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2289740870991737, next_state=array([-0.03723726,  1.3893938 , -0.38628128, -0.13551582,  0.04152507,\n",
      "        0.1264495 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03723726,  1.3893938 , -0.38628128, -0.13551582,  0.04152507,\n",
      "        0.1264495 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.11393095505789688, next_state=array([-0.04093885,  1.3857536 , -0.3740585 , -0.16190465,  0.04538891,\n",
      "        0.07728385,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04093885,  1.3857536 , -0.3740585 , -0.16190465,  0.04538891,\n",
      "        0.07728385,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1059724204823453, next_state=array([-0.04464054,  1.3815136 , -0.3740687 , -0.18857442,  0.0492537 ,\n",
      "        0.07730252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04464054,  1.3815136 , -0.3740687 , -0.18857442,  0.0492537 ,\n",
      "        0.07730252,  0.        ,  0.        ], dtype=float32), action=2, reward=0.061157132773314526, next_state=array([-0.04828768,  1.3772295 , -0.36895454, -0.19054273,  0.05346184,\n",
      "        0.08417015,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04828768,  1.3772295 , -0.36895454, -0.19054273,  0.05346184,\n",
      "        0.08417015,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.529960732236218, next_state=array([-0.05202799,  1.3723398 , -0.38065562, -0.21757187,  0.06001565,\n",
      "        0.13108817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05202799,  1.3723398 , -0.38065562, -0.21757187,  0.06001565,\n",
      "        0.13108817,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0541861926645424, next_state=array([-0.05567436,  1.367856  , -0.37188613, -0.19958465,  0.06719998,\n",
      "        0.14369997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05567436,  1.367856  , -0.37188613, -0.19958465,  0.06719998,\n",
      "        0.14369997,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5526997740387287, next_state=array([-0.05932093,  1.3627727 , -0.37190574, -0.22626585,  0.0743832 ,\n",
      "        0.14367726,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05932093,  1.3627727 , -0.37190574, -0.22626585,  0.0743832 ,\n",
      "        0.14367726,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.612579886405797, next_state=array([-0.06296768,  1.3570904 , -0.37192613, -0.25293577,  0.08156558,\n",
      "        0.14366052,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06296768,  1.3570904 , -0.37192613, -0.25293577,  0.08156558,\n",
      "        0.14366052,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5371092882216544, next_state=array([-0.06667852,  1.3520889 , -0.3783522 , -0.22268817,  0.08877455,\n",
      "        0.1441927 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06667852,  1.3520889 , -0.3783522 , -0.22268817,  0.08877455,\n",
      "        0.1441927 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1833118161591074, next_state=array([-0.07063808,  1.3477956 , -0.4024109 , -0.19121526,  0.09518557,\n",
      "        0.12823173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07063808,  1.3477956 , -0.4024109 , -0.19121526,  0.09518557,\n",
      "        0.12823173,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.383764410285437, next_state=array([-0.07459784,  1.3429024 , -0.40242752, -0.21789376,  0.10159637,\n",
      "        0.1282272 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07459784,  1.3429024 , -0.40242752, -0.21789376,  0.10159637,\n",
      "        0.1282272 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4449894055655363, next_state=array([-0.07855787,  1.3374101 , -0.4024461 , -0.2445621 ,  0.10800583,\n",
      "        0.12820072,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07855787,  1.3374101 , -0.4024461 , -0.2445621 ,  0.10800583,\n",
      "        0.12820072,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.496753912105703, next_state=array([-0.082518  ,  1.3313178 , -0.4024636 , -0.27123466,  0.1144143 ,\n",
      "        0.1281815 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.082518  ,  1.3313178 , -0.4024636 , -0.27123466,  0.1144143 ,\n",
      "        0.1281815 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5098838301298259, next_state=array([-0.08666001,  1.325338  , -0.42004862, -0.26623183,  0.12023459,\n",
      "        0.11641638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08666001,  1.325338  , -0.42004862, -0.26623183,  0.12023459,\n",
      "        0.11641638,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4592249792657583, next_state=array([-0.0908638 ,  1.3195273 , -0.42621312, -0.2587354 ,  0.12605634,\n",
      "        0.11644524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0908638 ,  1.3195273 , -0.42621312, -0.2587354 ,  0.12605634,\n",
      "        0.11644524,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6264774395454082, next_state=array([-0.09499483,  1.314421  , -0.41978726, -0.22751209,  0.13271825,\n",
      "        0.13324998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09499483,  1.314421  , -0.41978726, -0.22751209,  0.13271825,\n",
      "        0.13324998,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.1384985217911378, next_state=array([-0.09920073,  1.3098595 , -0.4274032 , -0.20335475,  0.13950309,\n",
      "        0.13569707,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09920073,  1.3098595 , -0.4274032 , -0.20335475,  0.13950309,\n",
      "        0.13569707,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.22127869264673336, next_state=array([-0.1033227 ,  1.3047247 , -0.4168194 , -0.22865008,  0.14411674,\n",
      "        0.09227265,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1033227 ,  1.3047247 , -0.4168194 , -0.22865008,  0.14411674,\n",
      "        0.09227265,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2615729081951201, next_state=array([-0.10744467,  1.2989902 , -0.41681895, -0.25531846,  0.14873038,\n",
      "        0.09227248,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10744467,  1.2989902 , -0.41681895, -0.25531846,  0.14873038,\n",
      "        0.09227248,  0.        ,  0.        ], dtype=float32), action=2, reward=0.09934847797704266, next_state=array([-0.11161566,  1.2936213 , -0.42192942, -0.23911569,  0.15356079,\n",
      "        0.09660804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11161566,  1.2936213 , -0.42192942, -0.23911569,  0.15356079,\n",
      "        0.09660804,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.217467922834031, next_state=array([-0.11585055,  1.287636  , -0.4299728 , -0.2666913 ,  0.16003558,\n",
      "        0.12949593,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11585055,  1.287636  , -0.4299728 , -0.2666913 ,  0.16003558,\n",
      "        0.12949593,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.460129082581402, next_state=array([-0.12015676,  1.281045  , -0.43887982, -0.29385164,  0.16830088,\n",
      "        0.16530563,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12015676,  1.281045  , -0.43887982, -0.29385164,  0.16830088,\n",
      "        0.16530563,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.3951768178294685, next_state=array([-0.12465258,  1.2752147 , -0.4576715 , -0.2600539 ,  0.17640382,\n",
      "        0.16205868,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12465258,  1.2752147 , -0.4576715 , -0.2600539 ,  0.17640382,\n",
      "        0.16205868,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5825490328262788, next_state=array([-0.12914848,  1.2687856 , -0.45767006, -0.286726  ,  0.1845067 ,\n",
      "        0.16205797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12914848,  1.2687856 , -0.45767006, -0.286726  ,  0.1845067 ,\n",
      "        0.16205797,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6196360947930373, next_state=array([-0.13364458,  1.2617571 , -0.4576686 , -0.31339806,  0.19260955,\n",
      "        0.16205712,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13364458,  1.2617571 , -0.4576686 , -0.31339806,  0.19260955,\n",
      "        0.16205712,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.934378330376137, next_state=array([-0.13835278,  1.2548083 , -0.47831258, -0.30983287,  0.20014997,\n",
      "        0.15080851,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13835278,  1.2548083 , -0.47831258, -0.30983287,  0.20014997,\n",
      "        0.15080851,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6194117066732745, next_state=array([-0.14313717,  1.2472422 , -0.48786512, -0.3375846 ,  0.20964657,\n",
      "        0.18993202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14313717,  1.2472422 , -0.48786512, -0.3375846 ,  0.20964657,\n",
      "        0.18993202,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.751445347998441, next_state=array([-0.14792185,  1.239077  , -0.48786277, -0.3642587 ,  0.21914311,\n",
      "        0.18993083,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14792185,  1.239077  , -0.48786277, -0.3642587 ,  0.21914311,\n",
      "        0.18993083,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.386516440203013, next_state=array([-0.15300341,  1.2310598 , -0.5167165 , -0.3576169 ,  0.22779953,\n",
      "        0.1731286 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15300341,  1.2310598 , -0.5167165 , -0.3576169 ,  0.22779953,\n",
      "        0.1731286 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1152602204242215, next_state=array([-0.15835647,  1.2237065 , -0.5434984 , -0.3281112 ,  0.23611268,\n",
      "        0.1662632 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15835647,  1.2237065 , -0.5434984 , -0.3281112 ,  0.23611268,\n",
      "        0.1662632 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6418789851388724, next_state=array([-0.16378374,  1.2157204 , -0.5528669 , -0.3565884 ,  0.24640998,\n",
      "        0.20594606,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16378374,  1.2157204 , -0.5528669 , -0.3565884 ,  0.24640998,\n",
      "        0.20594606,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4574899707775433, next_state=array([-0.16912127,  1.2071795 , -0.5414709 , -0.38091153,  0.25427756,\n",
      "        0.15735157,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.16912127,  1.2071795 , -0.5414709 , -0.38091153,  0.25427756,\n",
      "        0.15735157,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.549820198486428, next_state=array([-0.17453137,  1.1980183 , -0.55056906, -0.40886155,  0.26403028,\n",
      "        0.19505455,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17453137,  1.1980183 , -0.55056906, -0.40886155,  0.26403028,\n",
      "        0.19505455,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4206310045345731, next_state=array([-0.17993966,  1.1889014 , -0.5508605 , -0.4070398 ,  0.2743103 ,\n",
      "        0.20560023,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17993966,  1.1889014 , -0.5508605 , -0.4070398 ,  0.2743103 ,\n",
      "        0.20560023,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0600161738697964, next_state=array([-0.18543549,  1.1791396 , -0.56191945, -0.43622622,  0.2869801 ,\n",
      "        0.25339538,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18543549,  1.1791396 , -0.56191945, -0.43622622,  0.2869801 ,\n",
      "        0.25339538,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9824364609571308, next_state=array([-0.1908598 ,  1.1688217 , -0.5527766 , -0.46064287,  0.29765242,\n",
      "        0.21344657,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1908598 ,  1.1688217 , -0.5527766 , -0.46064287,  0.29765242,\n",
      "        0.21344657,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8405965824906219, next_state=array([-0.19647494,  1.1585132 , -0.5715537 , -0.4602455 ,  0.30803102,\n",
      "        0.2075716 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19647494,  1.1585132 , -0.5715537 , -0.4602455 ,  0.30803102,\n",
      "        0.2075716 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9747618685947816, next_state=array([-0.20202918,  1.1476243 , -0.56388754, -0.48576963,  0.31681567,\n",
      "        0.17569335,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20202918,  1.1476243 , -0.56388754, -0.48576963,  0.31681567,\n",
      "        0.17569335,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5023696288009318, next_state=array([-0.20772418,  1.1374388 , -0.5785527 , -0.4547028 ,  0.32623288,\n",
      "        0.18834426,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20772418,  1.1374388 , -0.5785527 , -0.4547028 ,  0.32623288,\n",
      "        0.18834426,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6628020419213385, next_state=array([-0.21341944,  1.1266543 , -0.5785492 , -0.4813765 ,  0.33565003,\n",
      "        0.18834312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21341944,  1.1266543 , -0.5785492 , -0.4813765 ,  0.33565003,\n",
      "        0.18834312,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6649693956409806, next_state=array([-0.21911497,  1.115271  , -0.5785456 , -0.5080502 ,  0.3450671 ,\n",
      "        0.18834195,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.21911497,  1.115271  , -0.5785456 , -0.5080502 ,  0.3450671 ,\n",
      "        0.18834195,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.884874117989908, next_state=array([-0.22489329,  1.1032377 , -0.58901316, -0.5375318 ,  0.35681662,\n",
      "        0.23499012,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22489329,  1.1032377 , -0.58901316, -0.5375318 ,  0.35681662,\n",
      "        0.23499012,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.673835031817947, next_state=array([-0.23105583,  1.0913739 , -0.626596  , -0.52988017,  0.36772922,\n",
      "        0.2182521 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23105583,  1.0913739 , -0.626596  , -0.52988017,  0.36772922,\n",
      "        0.2182521 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6726623780635623, next_state=array([-0.23713946,  1.0789499 , -0.61661285, -0.5543266 ,  0.3764745 ,\n",
      "        0.17490551,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23713946,  1.0789499 , -0.61661285, -0.5543266 ,  0.3764745 ,\n",
      "        0.17490551,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2044981378757484, next_state=array([-0.24351068,  1.0668985 , -0.64522094, -0.5377819 ,  0.38508463,\n",
      "        0.17220251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24351068,  1.0668985 , -0.64522094, -0.5377819 ,  0.38508463,\n",
      "        0.17220251,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7417529073533047, next_state=array([-0.24995604,  1.0548606 , -0.6529709 , -0.5373282 ,  0.39408752,\n",
      "        0.18005809,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.24995604,  1.0548606 , -0.6529709 , -0.5373282 ,  0.39408752,\n",
      "        0.18005809,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.8284677138600385, next_state=array([-0.25673413,  1.0427492 , -0.68547213, -0.5404346 ,  0.40229225,\n",
      "        0.16409428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25673413,  1.0427492 , -0.68547213, -0.5404346 ,  0.40229225,\n",
      "        0.16409428,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.428414377691297, next_state=array([-0.26351246,  1.0300386 , -0.68546885, -0.56710637,  0.41049695,\n",
      "        0.16409375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.26351246,  1.0300386 , -0.68546885, -0.56710637,  0.41049695,\n",
      "        0.16409375,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5290130675763283, next_state=array([-0.27022848,  1.0167698 , -0.6775406 , -0.591465  ,  0.41689757,\n",
      "        0.1280128 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27022848,  1.0167698 , -0.6775406 , -0.591465  ,  0.41689757,\n",
      "        0.1280128 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.39239669253304327, next_state=array([-0.27728444,  1.0042778 , -0.7117772 , -0.55704397,  0.42357913,\n",
      "        0.13363138,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27728444,  1.0042778 , -0.7117772 , -0.55704397,  0.42357913,\n",
      "        0.13363138,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5762451103137665, next_state=array([-0.28473783,  0.99239403, -0.751372  , -0.5299923 ,  0.4301157 ,\n",
      "        0.13073221,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28473783,  0.99239403, -0.751372  , -0.5299923 ,  0.4301157 ,\n",
      "        0.13073221,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.10180350767717414, next_state=array([-0.2921186 ,  0.9799693 , -0.7420698 , -0.55343556,  0.43445083,\n",
      "        0.08670359,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2921186 ,  0.9799693 , -0.7420698 , -0.55343556,  0.43445083,\n",
      "        0.08670359,  0.        ,  0.        ], dtype=float32), action=3, reward=0.28279877652553975, next_state=array([-0.2994145 ,  0.96701163, -0.7312223 , -0.576409  ,  0.4362279 ,\n",
      "        0.0355418 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2994145 ,  0.96701163, -0.7312223 , -0.576409  ,  0.4362279 ,\n",
      "        0.0355418 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.28124852172854387, next_state=array([-0.30664116,  0.9535106 , -0.7223609 , -0.59994733,  0.43589693,\n",
      "       -0.00661922,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30664116,  0.9535106 , -0.7223609 , -0.59994733,  0.43589693,\n",
      "       -0.00661922,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5778621178391745, next_state=array([-0.3138678 ,  0.9394096 , -0.72236097, -0.6266139 ,  0.43556598,\n",
      "       -0.00661903,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3138678 ,  0.9394096 , -0.72236097, -0.6266139 ,  0.43556598,\n",
      "       -0.00661903,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5765741383542604, next_state=array([-0.32109442,  0.92470866, -0.72236097, -0.65328056,  0.43523502,\n",
      "       -0.00661897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32109442,  0.92470866, -0.72236097, -0.65328056,  0.43523502,\n",
      "       -0.00661897,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.7816016605727032, next_state=array([-0.32840014,  0.9093518 , -0.732397  , -0.6830952 ,  0.43722805,\n",
      "        0.03985987,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32840014,  0.9093518 , -0.732397  , -0.6830952 ,  0.43722805,\n",
      "        0.03985987,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7920371638596748, next_state=array([-0.33570582,  0.89339507, -0.7323967 , -0.70976216,  0.43922108,\n",
      "        0.0398599 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33570582,  0.89339507, -0.7323967 , -0.70976216,  0.43922108,\n",
      "        0.0398599 ,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4798524198103007, next_state=array([-0.34292498,  0.87690526, -0.7213606 , -0.7326994 ,  0.4386144 ,\n",
      "       -0.01213401,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.34292498,  0.87690526, -0.7213606 , -0.7326994 ,  0.4386144 ,\n",
      "       -0.01213401,  0.        ,  0.        ], dtype=float32), action=3, reward=0.44214704242753666, next_state=array([-0.35007057,  0.8598551 , -0.71212405, -0.75702417,  0.43595767,\n",
      "       -0.05313427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35007057,  0.8598551 , -0.71212405, -0.75702417,  0.43595767,\n",
      "       -0.05313427,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5069261753327339, next_state=array([-0.35748953,  0.8435432 , -0.74000347, -0.72438645,  0.43389702,\n",
      "       -0.04121322,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35748953,  0.8435432 , -0.74000347, -0.72438645,  0.43389702,\n",
      "       -0.04121322,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8283292628502477, next_state=array([-0.3648196 ,  0.826689  , -0.7287459 , -0.7477721 ,  0.4292698 ,\n",
      "       -0.09254453,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3648196 ,  0.826689  , -0.7287459 , -0.7477721 ,  0.4292698 ,\n",
      "       -0.09254453,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3983155767191693, next_state=array([-0.37223488,  0.8091837 , -0.7394992 , -0.7773984 ,  0.4270658 ,\n",
      "       -0.04407975,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37223488,  0.8091837 , -0.7394992 , -0.7773984 ,  0.4270658 ,\n",
      "       -0.04407975,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6526332589174035, next_state=array([-0.37973857,  0.7910281 , -0.7506336 , -0.8069898 ,  0.4273487 ,\n",
      "        0.0056585 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37973857,  0.7910281 , -0.7506336 , -0.8069898 ,  0.4273487 ,\n",
      "        0.0056585 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3146938932553838, next_state=array([-0.3875565 ,  0.7727992 , -0.781455  , -0.8100723 ,  0.42698166,\n",
      "       -0.00734102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3875565 ,  0.7727992 , -0.781455  , -0.8100723 ,  0.42698166,\n",
      "       -0.00734102,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8820902509877147, next_state=array([-0.39545947,  0.7539017 , -0.7923265 , -0.8405021 ,  0.4291854 ,\n",
      "        0.0440746 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.39545947,  0.7539017 , -0.7923265 , -0.8405021 ,  0.4291854 ,\n",
      "        0.0440746 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.78188176399584, next_state=array([-0.40342537,  0.73435724, -0.8003355 , -0.86979604,  0.43326074,\n",
      "        0.08150692,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.40342537,  0.73435724, -0.8003355 , -0.86979604,  0.43326074,\n",
      "        0.08150692,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6428802607301407, next_state=array([-0.41167006,  0.7150201 , -0.82809687, -0.8605497 ,  0.4372105 ,\n",
      "        0.07899538,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41167006,  0.7150201 , -0.82809687, -0.8605497 ,  0.4372105 ,\n",
      "        0.07899538,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0321666301337302, next_state=array([-0.41991478,  0.69508326, -0.8280959 , -0.8872175 ,  0.44116026,\n",
      "        0.07899529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41991478,  0.69508326, -0.8280959 , -0.8872175 ,  0.44116026,\n",
      "        0.07899529,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.065992475636959, next_state=array([-0.42822972,  0.6745016 , -0.83695734, -0.9164739 ,  0.44713232,\n",
      "        0.11944138,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42822972,  0.6745016 , -0.83695734, -0.9164739 ,  0.44713232,\n",
      "        0.11944138,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2581798793782184, next_state=array([-0.43654475,  0.6533203 , -0.8369554 , -0.9431432 ,  0.45310438,\n",
      "        0.11944111,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43654475,  0.6533203 , -0.8369554 , -0.9431432 ,  0.45310438,\n",
      "        0.11944111,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5039597474558934, next_state=array([-0.44480664,  0.631586  , -0.8301145 , -0.96725726,  0.4574222 ,\n",
      "        0.08635632,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.44480664,  0.631586  , -0.8301145 , -0.96725726,  0.4574222 ,\n",
      "        0.08635632,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6144253606618519, next_state=array([-0.45316687,  0.61011416, -0.8406395 , -0.9558218 ,  0.4625064 ,\n",
      "        0.10168408,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45316687,  0.61011416, -0.8406395 , -0.9558218 ,  0.4625064 ,\n",
      "        0.10168408,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4240676412335618, next_state=array([-0.46160427,  0.58798474, -0.8504287 , -0.9857742 ,  0.46989888,\n",
      "        0.14784916,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46160427,  0.58798474, -0.8504287 , -0.9857742 ,  0.46989888,\n",
      "        0.14784916,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.532267485008731, next_state=array([-0.47004184,  0.5652558 , -0.8504256 , -1.0124449 ,  0.47729132,\n",
      "        0.14784856,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47004184,  0.5652558 , -0.8504256 , -1.0124449 ,  0.47729132,\n",
      "        0.14784856,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.20279995095130515, next_state=array([-0.4785816 ,  0.5426596 , -0.8611727 , -1.0067785 ,  0.4853014 ,\n",
      "        0.16020243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4785816 ,  0.5426596 , -0.8611727 , -1.0067785 ,  0.4853014 ,\n",
      "        0.16020243,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5247764405083786, next_state=array([-0.48752016,  0.5207377 , -0.90119505, -0.97690773,  0.49351278,\n",
      "        0.16422771,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48752016,  0.5207377 , -0.90119505, -0.97690773,  0.49351278,\n",
      "        0.16422771,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7297019288452191, next_state=array([-0.49688268,  0.49924493, -0.94336605, -0.9578059 ,  0.5014996 ,\n",
      "        0.15973677,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49688268,  0.49924493, -0.94336605, -0.9578059 ,  0.5014996 ,\n",
      "        0.15973677,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.841608063180587, next_state=array([-0.5062455 ,  0.47715282, -0.94336224, -0.9844772 ,  0.5094864 ,\n",
      "        0.15973608,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5062455 ,  0.47715282, -0.94336224, -0.9844772 ,  0.5094864 ,\n",
      "        0.15973608,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6370744464100424, next_state=array([-0.5159684 ,  0.45509827, -0.9789035 , -0.98268396,  0.5169775 ,\n",
      "        0.14982252,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5159684 ,  0.45509827, -0.9789035 , -0.98268396,  0.5169775 ,\n",
      "        0.14982252,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1119255829597978, next_state=array([-0.52563405,  0.4324836 , -0.97166777, -1.007042  ,  0.52277803,\n",
      "        0.11601107,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.52563405,  0.4324836 , -0.97166777, -1.007042  ,  0.52277803,\n",
      "        0.11601107,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.4210281701170288, next_state=array([-0.535541  ,  0.41040847, -0.99647295, -0.9833504 ,  0.5293654 ,\n",
      "        0.13174832,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.535541  ,  0.41040847, -0.99647295, -0.9833504 ,  0.5293654 ,\n",
      "        0.13174832,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.8457523292560425, next_state=array([-0.5455009 ,  0.38768843, -1.003163  , -1.0126041 ,  0.53760266,\n",
      "        0.16474342,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5455009 ,  0.38768843, -1.003163  , -1.0126041 ,  0.53760266,\n",
      "        0.16474342,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5044209437683365, next_state=array([-0.55554175,  0.36430386, -1.0134035 , -1.0430567 ,  0.5483332 ,\n",
      "        0.21461177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.55554175,  0.36430386, -1.0134035 , -1.0430567 ,  0.5483332 ,\n",
      "        0.21461177,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6988387056640475, next_state=array([-0.565894  ,  0.34107837, -1.0444677 , -1.0360461 ,  0.5590548 ,\n",
      "        0.21443084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.565894  ,  0.34107837, -1.0444677 , -1.0360461 ,  0.5590548 ,\n",
      "        0.21443084,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.621193606581005, next_state=array([-0.5766133 ,  0.31824526, -1.0812719 , -1.0187429 ,  0.5699593 ,\n",
      "        0.21808973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5766133 ,  0.31824526, -1.0812719 , -1.0187429 ,  0.5699593 ,\n",
      "        0.21808973,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.539365921972194, next_state=array([-0.5875546 ,  0.29556364, -1.1037247 , -1.0122181 ,  0.5812498 ,\n",
      "        0.22580934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5875546 ,  0.29556364, -1.1037247 , -1.0122181 ,  0.5812498 ,\n",
      "        0.22580934,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9257358780172353, next_state=array([-0.59849644,  0.27228335, -1.1037159 , -1.0388938 ,  0.59254014,\n",
      "        0.22580734,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.59849644,  0.27228335, -1.1037159 , -1.0388938 ,  0.59254014,\n",
      "        0.22580734,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.806888187183772, next_state=array([-0.6093638 ,  0.24848121, -1.0940819 , -1.0611988 ,  0.6013095 ,\n",
      "        0.17538656,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6093638 ,  0.24848121, -1.0940819 , -1.0611988 ,  0.6013095 ,\n",
      "        0.17538656,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.048609276941106, next_state=array([-0.6201799 ,  0.22413434, -1.0874559 , -1.0847774 ,  0.60832435,\n",
      "        0.14029703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6201799 ,  0.22413434, -1.0874559 , -1.0847774 ,  0.60832435,\n",
      "        0.14029703,  0.        ,  0.        ], dtype=float32), action=2, reward=5.740311285465805, next_state=array([-0.63164365,  0.20032527, -1.1518192 , -1.06072   ,  0.6148856 ,\n",
      "        0.13122532,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.63164365,  0.20032527, -1.1518192 , -1.06072   ,  0.6148856 ,\n",
      "        0.13122532,  0.        ,  1.        ], dtype=float32), action=0, reward=85.79691527927241, next_state=array([-0.636537  ,  0.19819644, -0.58562005, -0.17538133,  0.7073956 ,\n",
      "        1.7734482 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.636537  ,  0.19819644, -0.58562005, -0.17538133,  0.7073956 ,\n",
      "        1.7734482 ,  0.        ,  1.        ], dtype=float32), action=0, reward=0.8408007057220459, next_state=array([-0.64023983,  0.20209916, -0.46583396,  0.0958755 ,  0.8300067 ,\n",
      "        2.4194007 ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.64023983,  0.20209916, -0.46583396,  0.0958755 ,  0.8300067 ,\n",
      "        2.4194007 ,  0.        ,  1.        ], dtype=float32), action=3, reward=-11.352378881797078, next_state=array([-0.6440649 ,  0.20515838, -0.45960444,  0.07137004,  0.9491448 ,\n",
      "        2.377972  ,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.6440649 ,  0.20515838, -0.45960444,  0.07137004,  0.9491448 ,\n",
      "        2.377972  ,  0.        ,  1.        ], dtype=float32), action=1, reward=-22.787758424792855, next_state=array([-0.6480575 ,  0.2075635 , -0.46527308,  0.03786265,  1.0704889 ,\n",
      "        2.4270234 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6480575 ,  0.2075635 , -0.46527308,  0.03786265,  1.0704889 ,\n",
      "        2.4270234 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-18.625760390193637, next_state=array([-0.6527496 ,  0.21001811, -0.52223855,  0.03519373,  1.1919168 ,\n",
      "        2.4286985 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6527496 ,  0.21001811, -0.52223855,  0.03519373,  1.1919168 ,\n",
      "        2.4286985 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-21.009982663159906, next_state=array([-0.6583653 ,  0.21268095, -0.6009643 ,  0.0403107 ,  1.313963  ,\n",
      "        2.441064  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6583653 ,  0.21268095, -0.6009643 ,  0.0403107 ,  1.313963  ,\n",
      "        2.441064  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-12.46540163661956, next_state=array([-0.66410077,  0.21479689, -0.5984036 ,  0.01314443,  1.4362757 ,\n",
      "        2.446281  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.66410077,  0.21479689, -0.5984036 ,  0.01314443,  1.4362757 ,\n",
      "        2.446281  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-12.296913785868325, next_state=array([-0.66995645,  0.21644627, -0.5953774 , -0.00725325,  1.555992  ,\n",
      "        2.3943508 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.66995645,  0.21644627, -0.5953774 , -0.00725325,  1.555992  ,\n",
      "        2.3943508 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-12.818326458701646, next_state=array([-0.6759454 ,  0.21739084, -0.59398496, -0.04029294,  1.6779569 ,\n",
      "        2.439328  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6759454 ,  0.21739084, -0.59398496, -0.04029294,  1.6779569 ,\n",
      "        2.439328  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-20.761405082348336, next_state=array([-0.6828152 ,  0.21736501, -0.66726863, -0.08187859,  1.7991124 ,\n",
      "        2.4231381 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6828152 ,  0.21736501, -0.66726863, -0.08187859,  1.7991124 ,\n",
      "        2.4231381 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-17.209406482518023, next_state=array([-0.6902113 ,  0.21683301, -0.70516956, -0.10265616,  1.9209859 ,\n",
      "        2.4374998 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6902113 ,  0.21683301, -0.70516956, -0.10265616,  1.9209859 ,\n",
      "        2.4374998 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-18.33849139787201, next_state=array([-0.6981964 ,  0.21520479, -0.75020003, -0.14762148,  2.0422463 ,\n",
      "        2.4252434 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6981964 ,  0.21520479, -0.75020003, -0.14762148,  2.0422463 ,\n",
      "        2.4252434 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-13.367221256089776, next_state=array([-0.7063394 ,  0.21300739, -0.7543565 , -0.16676845,  2.160486  ,\n",
      "        2.3648267 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7063394 ,  0.21300739, -0.7543565 , -0.16676845,  2.160486  ,\n",
      "        2.3648267 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-22.95043447853566, next_state=array([-0.7154893 ,  0.20936638, -0.8430315 , -0.22590095,  2.2790534 ,\n",
      "        2.3713846 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7154893 ,  0.20936638, -0.8430315 , -0.22590095,  2.2790534 ,\n",
      "        2.3713846 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-13.060229926046956, next_state=array([-0.7246988 ,  0.20492585, -0.8368489 , -0.25611037,  2.3993442 ,\n",
      "        2.405847  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7246988 ,  0.20492585, -0.8368489 , -0.25611037,  2.3993442 ,\n",
      "        2.405847  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-19.263694499409826, next_state=array([-0.73447603,  0.19910397, -0.8835124 , -0.3104225 ,  2.5198147 ,\n",
      "        2.409845  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.73447603,  0.19910397, -0.8835124 , -0.3104225 ,  2.5198147 ,\n",
      "        2.409845  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-13.994277753784699, next_state=array([-0.7443782 ,  0.1925716 , -0.8891076 , -0.33348426,  2.6384258 ,\n",
      "        2.3737247 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7443782 ,  0.1925716 , -0.8891076 , -0.33348426,  2.6384258 ,\n",
      "        2.3737247 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-100, next_state=array([-0.7520113 ,  0.19243248, -0.44650427,  0.21653952,  2.7417889 ,\n",
      "        0.8194396 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00187349,  1.4018564 , -0.1897819 , -0.40283415,  0.00217772,\n",
      "        0.0429885 ,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5805857890927768, next_state=array([-0.0036417 ,  1.3929976 , -0.17948641, -0.3937319 ,  0.00481516,\n",
      "        0.05275441,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0036417 ,  1.3929976 , -0.17948641, -0.3937319 ,  0.00481516,\n",
      "        0.05275441,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7627221543416851, next_state=array([-0.00529718,  1.3841546 , -0.16876309, -0.39303508,  0.00800272,\n",
      "        0.06375678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00529718,  1.3841546 , -0.16876309, -0.39303508,  0.00800272,\n",
      "        0.06375678,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6821963643702817, next_state=array([-0.00678244,  1.3760312 , -0.15260369, -0.361069  ,  0.01203979,\n",
      "        0.08074854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00678244,  1.3760312 , -0.15260369, -0.361069  ,  0.01203979,\n",
      "        0.08074854,  0.        ,  0.        ], dtype=float32), action=2, reward=2.480250213283381, next_state=array([-0.00845423,  1.3686846 , -0.17040059, -0.3265448 ,  0.01523647,\n",
      "        0.06393933,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00845423,  1.3686846 , -0.17040059, -0.3265448 ,  0.01523647,\n",
      "        0.06393933,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4850417314414404, next_state=array([-0.01006613,  1.3607339 , -0.16290256, -0.35338852,  0.01692961,\n",
      "        0.03386585,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01006613,  1.3607339 , -0.16290256, -0.35338852,  0.01692961,\n",
      "        0.03386585,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1826375879620332, next_state=array([-0.01160412,  1.3521967 , -0.15362476, -0.3794306 ,  0.01675783,\n",
      "       -0.00343578,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01160412,  1.3521967 , -0.15362476, -0.3794306 ,  0.01675783,\n",
      "       -0.00343578,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.082987438007193, next_state=array([-0.01307478,  1.3430686 , -0.14518107, -0.40566492,  0.01489139,\n",
      "       -0.03733222,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01307478,  1.3430686 , -0.14518107, -0.40566492,  0.01489139,\n",
      "       -0.03733222,  0.        ,  0.        ], dtype=float32), action=2, reward=4.355835133210047, next_state=array([-0.0145772 ,  1.3348439 , -0.14827149, -0.3655307 ,  0.01294521,\n",
      "       -0.038927  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0145772 ,  1.3348439 , -0.14827149, -0.3655307 ,  0.01294521,\n",
      "       -0.038927  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8558879317952506, next_state=array([-0.01613884,  1.3260192 , -0.1557082 , -0.39219865,  0.0124909 ,\n",
      "       -0.00908681,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01613884,  1.3260192 , -0.1557082 , -0.39219865,  0.0124909 ,\n",
      "       -0.00908681,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.503008847068969, next_state=array([-0.01770048,  1.3165947 , -0.15570742, -0.41886088,  0.01203598,\n",
      "       -0.00909936,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01770048,  1.3165947 , -0.15570742, -0.41886088,  0.01203598,\n",
      "       -0.00909936,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8585645094221934, next_state=array([-0.01916542,  1.3065711 , -0.1435782 , -0.44547275,  0.00915049,\n",
      "       -0.05771529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01916542,  1.3065711 , -0.1435782 , -0.44547275,  0.00915049,\n",
      "       -0.05771529,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1939852549723866, next_state=array([-0.02049742,  1.2965231 , -0.13093035, -0.44656706,  0.00691107,\n",
      "       -0.04479243,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02049742,  1.2965231 , -0.13093035, -0.44656706,  0.00691107,\n",
      "       -0.04479243,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7853460754971138, next_state=array([-0.02172031,  1.2866257 , -0.12056353, -0.43987435,  0.00520132,\n",
      "       -0.03419841,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02172031,  1.2866257 , -0.12056353, -0.43987435,  0.00520132,\n",
      "       -0.03419841,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3589902903459006, next_state=array([-0.02294321,  1.2761284 , -0.12055866, -0.4665468 ,  0.00349164,\n",
      "       -0.03419664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02294321,  1.2761284 , -0.12055866, -0.4665468 ,  0.00349164,\n",
      "       -0.03419664,  0.        ,  0.        ], dtype=float32), action=2, reward=4.175968018900574, next_state=array([-0.02413721,  1.2663944 , -0.11781571, -0.43262547,  0.00193309,\n",
      "       -0.03117406,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02413721,  1.2663944 , -0.11781571, -0.43262547,  0.00193309,\n",
      "       -0.03117406,  0.        ,  0.        ], dtype=float32), action=2, reward=4.640194002264349, next_state=array([-2.5325298e-02,  1.2575712e+00, -1.1727162e-01, -3.9213955e-01,\n",
      "        4.1060880e-04, -3.0452272e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-2.5325298e-02,  1.2575712e+00, -1.1727162e-01, -3.9213955e-01,\n",
      "        4.1060880e-04, -3.0452272e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-1.6648284935500886, next_state=array([-0.02645149,  1.2481505 , -0.10951219, -0.41870376, -0.0026655 ,\n",
      "       -0.061528  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02645149,  1.2481505 , -0.10951219, -0.41870376, -0.0026655 ,\n",
      "       -0.061528  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8924610689187773, next_state=array([-0.02757759,  1.2381299 , -0.10950295, -0.44536743, -0.00574054,\n",
      "       -0.06150614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02757759,  1.2381299 , -0.10950295, -0.44536743, -0.00574054,\n",
      "       -0.06150614,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8744913773396934, next_state=array([-0.02860613,  1.2275053 , -0.09726488, -0.47223684, -0.01126606,\n",
      "       -0.11052018,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02860613,  1.2275053 , -0.09726488, -0.47223684, -0.01126606,\n",
      "       -0.11052018,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0050404782445923, next_state=array([-0.02945394,  1.2169739 , -0.0800247 , -0.4681104 , -0.01597208,\n",
      "       -0.09412875,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02945394,  1.2169739 , -0.0800247 , -0.4681104 , -0.01597208,\n",
      "       -0.09412875,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9911859145484243, next_state=array([-0.03030157,  1.2058425 , -0.08001199, -0.49478617, -0.0206786 ,\n",
      "       -0.09413891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03030157,  1.2058425 , -0.08001199, -0.49478617, -0.0206786 ,\n",
      "       -0.09413891,  0.        ,  0.        ], dtype=float32), action=2, reward=2.580276782889098, next_state=array([-0.03121338,  1.1952677 , -0.08603992, -0.47007146, -0.02575678,\n",
      "       -0.1015726 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03121338,  1.1952677 , -0.08603992, -0.47007146, -0.02575678,\n",
      "       -0.1015726 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.43210753171184707, next_state=array([-0.03203306,  1.1846923 , -0.07722332, -0.47011068, -0.03045543,\n",
      "       -0.09398116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03203306,  1.1846923 , -0.07722332, -0.47011068, -0.03045543,\n",
      "       -0.09398116,  0.        ,  0.        ], dtype=float32), action=2, reward=2.2012535195468788, next_state=array([-0.03289652,  1.1745882 , -0.08128686, -0.4491764 , -0.03545801,\n",
      "       -0.10006049,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03289652,  1.1745882 , -0.08128686, -0.4491764 , -0.03545801,\n",
      "       -0.10006049,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5829410517569726, next_state=array([-0.03360472,  1.1645005 , -0.06641762, -0.4484627 , -0.03981028,\n",
      "       -0.08704527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03360472,  1.1645005 , -0.06641762, -0.4484627 , -0.03981028,\n",
      "       -0.08704527,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.967327058522726, next_state=array([-0.03439035,  1.1538162 , -0.07613022, -0.47491542, -0.04221577,\n",
      "       -0.04810973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03439035,  1.1538162 , -0.07613022, -0.47491542, -0.04221577,\n",
      "       -0.04810973,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6996726326781288, next_state=array([-0.03526478,  1.1425393 , -0.08727492, -0.50120926, -0.0423854 ,\n",
      "       -0.00339251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03526478,  1.1425393 , -0.08727492, -0.50120926, -0.0423854 ,\n",
      "       -0.00339251,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4186343310177552, next_state=array([-0.0362278 ,  1.1306707 , -0.09839471, -0.5274327 , -0.04032301,\n",
      "        0.04124782,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0362278 ,  1.1306707 , -0.09839471, -0.5274327 , -0.04032301,\n",
      "        0.04124782,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1743137489203832, next_state=array([-0.03719082,  1.1182022 , -0.09839474, -0.5540997 , -0.03826062,\n",
      "        0.04124786,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03719082,  1.1182022 , -0.09839474, -0.5540997 , -0.03826062,\n",
      "        0.04124786,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1184014306438428, next_state=array([-0.03815384,  1.1051338 , -0.09839475, -0.5807667 , -0.03619823,\n",
      "        0.04124782,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03815384,  1.1051338 , -0.09839475, -0.5807667 , -0.03619823,\n",
      "        0.04124782,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.13363248192769, next_state=array([-0.03903913,  1.0914676 , -0.08863756, -0.6073826 , -0.03608786,\n",
      "        0.00220737,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03903913,  1.0914676 , -0.08863756, -0.6073826 , -0.03608786,\n",
      "        0.00220737,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1279456734916369, next_state=array([-0.04000177,  1.0772132 , -0.09835189, -0.6334784 , -0.03402552,\n",
      "        0.04124696,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04000177,  1.0772132 , -0.09835189, -0.6334784 , -0.03402552,\n",
      "        0.04124696,  0.        ,  0.        ], dtype=float32), action=2, reward=4.949017595805498, next_state=array([-0.04080791,  1.0637369 , -0.08329561, -0.5988899 , -0.03138485,\n",
      "        0.05281332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04080791,  1.0637369 , -0.08329561, -0.5988899 , -0.03138485,\n",
      "        0.05281332,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6548980399618187, next_state=array([-0.04147692,  1.0502888 , -0.07015587, -0.59762794, -0.02817071,\n",
      "        0.06428309,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04147692,  1.0502888 , -0.07015587, -0.59762794, -0.02817071,\n",
      "        0.06428309,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8460527510163149, next_state=array([-0.0422245 ,  1.0362474 , -0.08001404, -0.62397414, -0.02297968,\n",
      "        0.10382074,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0422245 ,  1.0362474 , -0.08001404, -0.62397414, -0.02297968,\n",
      "        0.10382074,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8083400553311708, next_state=array([-0.04288559,  1.0216027 , -0.06917275, -0.6508248 , -0.01996081,\n",
      "        0.06037756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04288559,  1.0216027 , -0.06917275, -0.6508248 , -0.01996081,\n",
      "        0.06037756,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9502289084574318, next_state=array([-0.04345798,  1.0063654 , -0.05803648, -0.67720103, -0.01916947,\n",
      "        0.01582636,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04345798,  1.0063654 , -0.05803648, -0.67720103, -0.01916947,\n",
      "        0.01582636,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9211840316697522, next_state=array([-0.04412098,  0.9905235 , -0.06939513, -0.7040454 , -0.01610514,\n",
      "        0.06128677,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04412098,  0.9905235 , -0.06939513, -0.7040454 , -0.01610514,\n",
      "        0.06128677,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.708438308453708, next_state=array([-0.04478388,  0.97408193, -0.06939515, -0.7307129 , -0.0130408 ,\n",
      "        0.06128671,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04478388,  0.97408193, -0.06939515, -0.7307129 , -0.0130408 ,\n",
      "        0.06128671,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8296791349707451, next_state=array([-0.04537201,  0.9570308 , -0.06000804, -0.75781286, -0.01185836,\n",
      "        0.02364879,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04537201,  0.9570308 , -0.06000804, -0.75781286, -0.01185836,\n",
      "        0.02364879,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6500794194866433, next_state=array([-0.04603023,  0.93939245, -0.06881738, -0.7839063 , -0.00890926,\n",
      "        0.05898198,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04603023,  0.93939245, -0.06881738, -0.7839063 , -0.00890926,\n",
      "        0.05898198,  0.        ,  0.        ], dtype=float32), action=2, reward=3.258276826154412, next_state=array([-0.046698  ,  0.92210543, -0.06968691, -0.7682962 , -0.00602991,\n",
      "        0.05758695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.046698  ,  0.92210543, -0.06968691, -0.7682962 , -0.00602991,\n",
      "        0.05758695,  0.        ,  0.        ], dtype=float32), action=2, reward=5.038444431916401, next_state=array([-0.04748659,  0.9056286 , -0.08118582, -0.7322869 , -0.00373641,\n",
      "        0.04587019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04748659,  0.9056286 , -0.08118582, -0.7322869 , -0.00373641,\n",
      "        0.04587019,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.720671680524049, next_state=array([-0.04827518,  0.8885522 , -0.08118582, -0.758954  , -0.00144291,\n",
      "        0.0458702 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04827518,  0.8885522 , -0.08118582, -0.758954  , -0.00144291,\n",
      "        0.0458702 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7689151247688233, next_state=array([-0.04897556,  0.87088454, -0.0701098 , -0.785227  , -0.00136732,\n",
      "        0.00151173,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04897556,  0.87088454, -0.0701098 , -0.785227  , -0.00136732,\n",
      "        0.00151173,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.8291086177502507, next_state=array([-0.04967594,  0.8526169 , -0.07010979, -0.81189364, -0.00129172,\n",
      "        0.00151172,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04967594,  0.8526169 , -0.07010979, -0.81189364, -0.00129172,\n",
      "        0.00151172,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.903431300344862, next_state=array([-0.05028801,  0.83375686, -0.05903653, -0.8382219 , -0.00343355,\n",
      "       -0.04283666,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05028801,  0.83375686, -0.05903653, -0.8382219 , -0.00343355,\n",
      "       -0.04283666,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9359330581675067, next_state=array([-0.05089998,  0.8142971 , -0.05903653, -0.864889  , -0.0055754 ,\n",
      "       -0.04283664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05089998,  0.8142971 , -0.05903653, -0.864889  , -0.0055754 ,\n",
      "       -0.04283664,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.876846437141694, next_state=array([-0.05151205,  0.7942373 , -0.05903654, -0.891556  , -0.00771724,\n",
      "       -0.04283664,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05151205,  0.7942373 , -0.05903654, -0.891556  , -0.00771724,\n",
      "       -0.04283664,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7145280608550866, next_state=array([-0.0521884 ,  0.7735836 , -0.06710287, -0.9179428 , -0.00824289,\n",
      "       -0.01051313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0521884 ,  0.7735836 , -0.06710287, -0.9179428 , -0.00824289,\n",
      "       -0.01051313,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8426841311968178, next_state=array([-0.05276613,  0.75231916, -0.05473285, -0.94510573, -0.01124729,\n",
      "       -0.06008805,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05276613,  0.75231916, -0.05473285, -0.94510573, -0.01124729,\n",
      "       -0.06008805,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6246944348531815, next_state=array([-0.05342569,  0.73046595, -0.06498883, -0.97126615, -0.01219574,\n",
      "       -0.01896926,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05342569,  0.73046595, -0.06498883, -0.97126615, -0.01219574,\n",
      "       -0.01896926,  0.        ,  0.        ], dtype=float32), action=2, reward=5.282411195558905, next_state=array([-0.05403977,  0.70941025, -0.06060946, -0.93581337, -0.01298712,\n",
      "       -0.01582737,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05403977,  0.70941025, -0.06060946, -0.93581337, -0.01298712,\n",
      "       -0.01582737,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5861105365902972, next_state=array([-0.05465383,  0.6877546 , -0.06060946, -0.9624801 , -0.0137785 ,\n",
      "       -0.01582736,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05465383,  0.6877546 , -0.06060946, -0.9624801 , -0.0137785 ,\n",
      "       -0.01582736,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4080908154682834, next_state=array([-0.05534401,  0.66550344, -0.07016031, -0.9889262 , -0.01265619,\n",
      "        0.02244611,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05534401,  0.66550344, -0.07016031, -0.9889262 , -0.01265619,\n",
      "        0.02244611,  0.        ,  0.        ], dtype=float32), action=2, reward=5.56195560479996, next_state=array([-0.05609512,  0.6440871 , -0.07590663, -0.9518303 , -0.01187172,\n",
      "        0.01568942,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05609512,  0.6440871 , -0.07590663, -0.9518303 , -0.01187172,\n",
      "        0.01568942,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5803720910041352, next_state=array([-0.0567812 ,  0.6220588 , -0.06773639, -0.9790418 , -0.01272579,\n",
      "       -0.01708151,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0567812 ,  0.6220588 , -0.06773639, -0.9790418 , -0.01272579,\n",
      "       -0.01708151,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.49929643825200287, next_state=array([-0.05746727,  0.5994306 , -0.06773639, -1.0057085 , -0.01357987,\n",
      "       -0.01708161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05746727,  0.5994306 , -0.06773639, -1.0057085 , -0.01357987,\n",
      "       -0.01708161,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.44125689153162284, next_state=array([-0.05815325,  0.5762024 , -0.0677364 , -1.0323752 , -0.01443394,\n",
      "       -0.0170816 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05815325,  0.5762024 , -0.0677364 , -1.0323752 , -0.01443394,\n",
      "       -0.0170816 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3834464322015094, next_state=array([-0.05883932,  0.55237406, -0.0677364 , -1.0590419 , -0.01528802,\n",
      "       -0.01708161,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05883932,  0.55237406, -0.0677364 , -1.0590419 , -0.01528802,\n",
      "       -0.01708161,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4502761252996652, next_state=array([-0.05945215,  0.52795446, -0.05856572, -1.085349  , -0.01797637,\n",
      "       -0.05376686,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05945215,  0.52795446, -0.05856572, -1.085349  , -0.01797637,\n",
      "       -0.05376686,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5704278491407411, next_state=array([-0.06000242,  0.5029425 , -0.05070297, -1.1116983 , -0.02223691,\n",
      "       -0.08521099,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06000242,  0.5029425 , -0.05070297, -1.1116983 , -0.02223691,\n",
      "       -0.08521099,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5548835209072251, next_state=array([-0.0605526 ,  0.47733086, -0.05070301, -1.1383665 , -0.02649745,\n",
      "       -0.0852109 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0605526 ,  0.47733086, -0.05070301, -1.1383665 , -0.02649745,\n",
      "       -0.0852109 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4985363601745121, next_state=array([-0.06110287,  0.45111945, -0.05070307, -1.1650347 , -0.03075798,\n",
      "       -0.0852108 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06110287,  0.45111945, -0.05070307, -1.1650347 , -0.03075798,\n",
      "       -0.0852108 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4429372744115483, next_state=array([-0.06165304,  0.4243083 , -0.05070313, -1.1917027 , -0.03501851,\n",
      "       -0.08521068,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06165304,  0.4243083 , -0.05070313, -1.1917027 , -0.03501851,\n",
      "       -0.08521068,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.21961989969193382, next_state=array([-0.0622942 ,  0.39690158, -0.0621258 , -1.2181264 , -0.03698967,\n",
      "       -0.03942301,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0622942 ,  0.39690158, -0.0621258 , -1.2181264 , -0.03698967,\n",
      "       -0.03942301,  0.        ,  0.        ], dtype=float32), action=2, reward=3.144310336961934, next_state=array([-0.06297998,  0.36972544, -0.06627317, -1.2078873 , -0.03926144,\n",
      "       -0.04543544,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06297998,  0.36972544, -0.06627317, -1.2078873 , -0.03926144,\n",
      "       -0.04543544,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.16741478055709536, next_state=array([-0.06366567,  0.3419494 , -0.0662732 , -1.2345543 , -0.04153322,\n",
      "       -0.04543535,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06366567,  0.3419494 , -0.0662732 , -1.2345543 , -0.04153322,\n",
      "       -0.04543535,  0.        ,  0.        ], dtype=float32), action=2, reward=5.899393932988187, next_state=array([-0.06425228,  0.3150108 , -0.05663767, -1.1973301 , -0.04353115,\n",
      "       -0.03995851,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06425228,  0.3150108 , -0.05663767, -1.1973301 , -0.04353115,\n",
      "       -0.03995851,  0.        ,  0.        ], dtype=float32), action=2, reward=3.191229084392046, next_state=array([-0.06486187,  0.28832617, -0.05871592, -1.18605   , -0.0457502 ,\n",
      "       -0.04438112,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06486187,  0.28832617, -0.05871592, -1.18605   , -0.0457502 ,\n",
      "       -0.04438112,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2449185490852983, next_state=array([-0.06547155,  0.2610416 , -0.05871595, -1.212717  , -0.04796925,\n",
      "       -0.04438109,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06547155,  0.2610416 , -0.05871595, -1.212717  , -0.04796925,\n",
      "       -0.04438109,  0.        ,  0.        ], dtype=float32), action=2, reward=4.240884713818429, next_state=array([-0.0659338 ,  0.23422273, -0.04450706, -1.1920031 , -0.0496651 ,\n",
      "       -0.03391712,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0659338 ,  0.23422273, -0.04450706, -1.1920031 , -0.0496651 ,\n",
      "       -0.03391712,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.04034208310832696, next_state=array([-0.06648016,  0.20681277, -0.05506346, -1.2182084 , -0.04924083,\n",
      "        0.00848553,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06648016,  0.20681277, -0.05506346, -1.2182084 , -0.04924083,\n",
      "        0.00848553,  0.        ,  0.        ], dtype=float32), action=0, reward=0.006648288124438295, next_state=array([-0.06702652,  0.17880279, -0.05506346, -1.2448752 , -0.04881655,\n",
      "        0.00848551,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06702652,  0.17880279, -0.05506346, -1.2448752 , -0.04881655,\n",
      "        0.00848551,  0.        ,  0.        ], dtype=float32), action=2, reward=4.77585991836217, next_state=array([-0.06739111,  0.15132609, -0.03756994, -1.2211481 , -0.04772352,\n",
      "        0.02186079,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06739111,  0.15132609, -0.03756994, -1.2211481 , -0.04772352,\n",
      "        0.02186079,  0.        ,  0.        ], dtype=float32), action=2, reward=2.6686340583106984, next_state=array([-0.0677764 ,  0.12395018, -0.03943845, -1.2166783 , -0.04682933,\n",
      "        0.0178841 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0677764 ,  0.12395018, -0.03943845, -1.2166783 , -0.04682933,\n",
      "        0.0178841 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.0014978102702809803, next_state=array([-0.06824847,  0.09599048, -0.05033769, -1.2425622 , -0.04374089,\n",
      "        0.06176873,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06824847,  0.09599048, -0.05033769, -1.2425622 , -0.04374089,\n",
      "        0.06176873,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2056008864144303, next_state=array([-0.06872053,  0.06743082, -0.05033775, -1.2692298 , -0.04065246,\n",
      "        0.06176867,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06872053,  0.06743082, -0.05033775, -1.2692298 , -0.04065246,\n",
      "        0.06176867,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8373626507391225, next_state=array([-0.06910896,  0.03827127, -0.03983604, -1.2959548 , -0.03966629,\n",
      "        0.01972337,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06910896,  0.03827127, -0.03983604, -1.2959548 , -0.03966629,\n",
      "        0.01972337,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5294345984295876, next_state=array([-0.06955709,  0.00852185, -0.04733627, -1.3221297 , -0.03717187,\n",
      "        0.04988817,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06955709,  0.00852185, -0.04733627, -1.3221297 , -0.03717187,\n",
      "        0.04988817,  0.        ,  0.        ], dtype=float32), action=2, reward=20.699710493142373, next_state=array([-0.0700594 , -0.02097737, -0.05240799, -1.3110234 , -0.0350258 ,\n",
      "        0.04292162,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.0700594 , -0.02097737, -0.05240799, -1.3110234 , -0.0350258 ,\n",
      "        0.04292162,  1.        ,  1.        ], dtype=float32), action=3, reward=-100, next_state=array([-7.0179269e-02, -4.2792488e-02,  4.3544496e-08,  7.0838084e-08,\n",
      "        2.3281362e-04, -4.7393914e-07,  1.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([ 0.00460091,  1.417705  ,  0.46601763,  0.3015483 , -0.00532465,\n",
      "       -0.10556003,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.308451831725125, next_state=array([ 0.00923843,  1.4254748 ,  0.4688726 ,  0.3452929 , -0.01039196,\n",
      "       -0.10135503,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00923843,  1.4254748 ,  0.4688726 ,  0.3452929 , -0.01039196,\n",
      "       -0.10135503,  0.        ,  0.        ], dtype=float32), action=0, reward=0.3108829082248121, next_state=array([ 0.01387615,  1.4326453 ,  0.46888834,  0.31864756, -0.0154564 ,\n",
      "       -0.10129799,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01387615,  1.4326453 ,  0.46888834,  0.31864756, -0.0154564 ,\n",
      "       -0.10129799,  0.        ,  0.        ], dtype=float32), action=1, reward=1.4653894663819085, next_state=array([ 0.01842308,  1.439209  ,  0.4574961 ,  0.2916813 , -0.01823452,\n",
      "       -0.0555675 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01842308,  1.439209  ,  0.4574961 ,  0.2916813 , -0.01823452,\n",
      "       -0.0555675 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5045274927176138, next_state=array([ 0.02297001,  1.4451727 ,  0.45750338,  0.26501247, -0.02101323,\n",
      "       -0.05557898,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02297001,  1.4451727 ,  0.45750338,  0.26501247, -0.02101323,\n",
      "       -0.05557898,  0.        ,  0.        ], dtype=float32), action=1, reward=1.445422345925324, next_state=array([ 0.0274437 ,  1.4505292 ,  0.4483087 ,  0.23805544, -0.0219483 ,\n",
      "       -0.01870315,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0274437 ,  1.4505292 ,  0.4483087 ,  0.23805544, -0.0219483 ,\n",
      "       -0.01870315,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7300274475666402, next_state=array([ 0.0320137 ,  1.4552749 ,  0.46040076,  0.2108646 , -0.02531189,\n",
      "       -0.06727795,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0320137 ,  1.4552749 ,  0.46040076,  0.2108646 , -0.02531189,\n",
      "       -0.06727795,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9501342208845915, next_state=array([ 0.03667087,  1.4594069 ,  0.47132295,  0.18353847, -0.03086658,\n",
      "       -0.11110421,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03667087,  1.4594069 ,  0.47132295,  0.18353847, -0.03086658,\n",
      "       -0.11110421,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.863554018041003, next_state=array([ 0.04148149,  1.4642478 ,  0.486072  ,  0.2150384 , -0.03581804,\n",
      "       -0.09903819,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04148149,  1.4642478 ,  0.486072  ,  0.2150384 , -0.03581804,\n",
      "       -0.09903819,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2981997474040827, next_state=array([ 0.04638901,  1.4684765 ,  0.4982285 ,  0.18774976, -0.04321069,\n",
      "       -0.14786637,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04638901,  1.4684765 ,  0.4982285 ,  0.18774976, -0.04321069,\n",
      "       -0.14786637,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.7041935937823665, next_state=array([ 0.05148144,  1.4730852 ,  0.51595306,  0.20462054, -0.04986011,\n",
      "       -0.13300057,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05148144,  1.4730852 ,  0.51595306,  0.20462054, -0.04986011,\n",
      "       -0.13300057,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5311385924192666, next_state=array([ 0.05666905,  1.4770769 ,  0.5279138 ,  0.17708345, -0.05891668,\n",
      "       -0.18114789,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05666905,  1.4770769 ,  0.5279138 ,  0.17708345, -0.05891668,\n",
      "       -0.18114789,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5178155442546586, next_state=array([ 0.06192665,  1.4804684 ,  0.5366591 ,  0.15026797, -0.06971798,\n",
      "       -0.21604562,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06192665,  1.4804684 ,  0.5366591 ,  0.15026797, -0.06971798,\n",
      "       -0.21604562,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5867839351152953, next_state=array([ 0.0670598 ,  1.4844773 ,  0.5250691 ,  0.1775855 , -0.08137076,\n",
      "       -0.23307689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0670598 ,  1.4844773 ,  0.5250691 ,  0.1775855 , -0.08137076,\n",
      "       -0.23307689,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9037891835384062, next_state=array([ 0.0722723 ,  1.487879  ,  0.53500533,  0.15037991, -0.09501555,\n",
      "       -0.27292052,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0722723 ,  1.487879  ,  0.53500533,  0.15037991, -0.09501555,\n",
      "       -0.27292052,  0.        ,  0.        ], dtype=float32), action=1, reward=0.33165106199422323, next_state=array([ 0.07739067,  1.4907033 ,  0.52314115,  0.12477265, -0.10624453,\n",
      "       -0.22459984,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07739067,  1.4907033 ,  0.52314115,  0.12477265, -0.10624453,\n",
      "       -0.22459984,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8209477969672025, next_state=array([ 0.0825756 ,  1.4929173 ,  0.53147155,  0.09742007, -0.11915419,\n",
      "       -0.25821692,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0825756 ,  1.4929173 ,  0.53147155,  0.09742007, -0.11915419,\n",
      "       -0.25821692,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9861781480439786, next_state=array([ 0.08798647,  1.4952235 ,  0.5532325 ,  0.1014823 , -0.13126837,\n",
      "       -0.24230532,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08798647,  1.4952235 ,  0.5532325 ,  0.1014823 , -0.13126837,\n",
      "       -0.24230532,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9978073592202463, next_state=array([ 0.09339771,  1.4969314 ,  0.5532631 ,  0.07479383, -0.14338163,\n",
      "       -0.24228665,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09339771,  1.4969314 ,  0.5532631 ,  0.07479383, -0.14338163,\n",
      "       -0.24228665,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.174465198742399, next_state=array([ 0.09911404,  1.4993935 ,  0.5829383 ,  0.10829953, -0.15468559,\n",
      "       -0.22609957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09911404,  1.4993935 ,  0.5829383 ,  0.10829953, -0.15468559,\n",
      "       -0.22609957,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.9286200462733802, next_state=array([ 0.10483084,  1.501257  ,  0.58296525,  0.08160691, -0.16598843,\n",
      "       -0.22607699,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10483084,  1.501257  ,  0.58296525,  0.08160691, -0.16598843,\n",
      "       -0.22607699,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.03889042089275449, next_state=array([ 0.1104825 ,  1.5025468 ,  0.57471955,  0.05623165, -0.17557241,\n",
      "       -0.19169647,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1104825 ,  1.5025468 ,  0.57471955,  0.05623165, -0.17557241,\n",
      "       -0.19169647,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9051604019211072, next_state=array([ 0.11620092,  1.5032114 ,  0.58311635,  0.02816472, -0.18689899,\n",
      "       -0.2265521 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11620092,  1.5032114 ,  0.58311635,  0.02816472, -0.18689899,\n",
      "       -0.2265521 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1192968310154185, next_state=array([ 1.2192001e-01,  1.5032774e+00,  5.8314598e-01,  1.4816897e-03,\n",
      "       -1.9822277e-01, -2.2649547e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.2192001e-01,  1.5032774e+00,  5.8314598e-01,  1.4816897e-03,\n",
      "       -1.9822277e-01, -2.2649547e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=0.17339820296220523, next_state=array([ 0.12754813,  1.5027704 ,  0.5717007 , -0.02373928, -0.20718311,\n",
      "       -0.17922266,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12754813,  1.5027704 ,  0.5717007 , -0.02373928, -0.20718311,\n",
      "       -0.17922266,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.071973925265381, next_state=array([ 0.13324337,  1.501628  ,  0.58015954, -0.0523055 , -0.21792918,\n",
      "       -0.21492186,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13324337,  1.501628  ,  0.58015954, -0.0523055 , -0.21792918,\n",
      "       -0.21492186,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5483485088109306, next_state=array([ 0.13902168,  1.499862  ,  0.59057987, -0.08042563, -0.2308312 ,\n",
      "       -0.25804028,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13902168,  1.499862  ,  0.59057987, -0.08042563, -0.2308312 ,\n",
      "       -0.25804028,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8795950330485867, next_state=array([ 0.14488582,  1.497461  ,  0.6013636 , -0.1091247 , -0.24601097,\n",
      "       -0.30359545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14488582,  1.497461  ,  0.6013636 , -0.1091247 , -0.24601097,\n",
      "       -0.30359545,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.238047886070659, next_state=array([ 0.15084104,  1.4944237 ,  0.6127646 , -0.13797712, -0.26360583,\n",
      "       -0.3518974 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15084104,  1.4944237 ,  0.6127646 , -0.13797712, -0.26360583,\n",
      "       -0.3518974 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0979445383276243, next_state=array([ 0.15679693,  1.4907905 ,  0.61275476, -0.16466886, -0.28120032,\n",
      "       -0.35189003,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15679693,  1.4907905 ,  0.61275476, -0.16466886, -0.28120032,\n",
      "       -0.35189003,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1459559055843442, next_state=array([ 0.16275358,  1.4865612 ,  0.6127442 , -0.19136047, -0.29879448,\n",
      "       -0.35188264,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16275358,  1.4865612 ,  0.6127442 , -0.19136047, -0.29879448,\n",
      "       -0.35188264,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.667072012325973, next_state=array([ 0.16880608,  1.4816996 ,  0.62467325, -0.22018854, -0.31891096,\n",
      "       -0.4023294 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16880608,  1.4816996 ,  0.62467325, -0.22018854, -0.31891096,\n",
      "       -0.4023294 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.677480336457988, next_state=array([ 0.17493467,  1.4762006 ,  0.63414943, -0.24924667, -0.34111145,\n",
      "       -0.4440108 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17493467,  1.4762006 ,  0.63414943, -0.24924667, -0.34111145,\n",
      "       -0.4440108 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.609430923012694, next_state=array([ 0.18111964,  1.4700717 ,  0.64109546, -0.27792546, -0.3648755 ,\n",
      "       -0.47528118,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18111964,  1.4700717 ,  0.64109546, -0.27792546, -0.3648755 ,\n",
      "       -0.47528118,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.8889988215275935, next_state=array([ 0.1873064 ,  1.4633498 ,  0.6410709 , -0.30463648, -0.38863862,\n",
      "       -0.4752627 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1873064 ,  1.4633498 ,  0.6410709 , -0.30463648, -0.38863862,\n",
      "       -0.4752627 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6521406854679117, next_state=array([ 0.1934124 ,  1.456086  ,  0.63058805, -0.32844448, -0.41004732,\n",
      "       -0.42817393,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1934124 ,  1.456086  ,  0.63058805, -0.32844448, -0.41004732,\n",
      "       -0.42817393,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8592996276252325, next_state=array([ 0.1994606 ,  1.4482542 ,  0.6231504 , -0.3535114 , -0.42984754,\n",
      "       -0.39600414,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1994606 ,  1.4482542 ,  0.6231504 , -0.3535114 , -0.42984754,\n",
      "       -0.39600414,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5412712428191344, next_state=array([ 0.20544071,  1.439869  ,  0.61435026, -0.37777627, -0.44766617,\n",
      "       -0.35637265,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20544071,  1.439869  ,  0.61435026, -0.37777627, -0.44766617,\n",
      "       -0.35637265,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2984208930219256, next_state=array([ 0.21135092,  1.4309448 ,  0.6052761 , -0.4012805 , -0.46332806,\n",
      "       -0.31323746,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21135092,  1.4309448 ,  0.6052761 , -0.4012805 , -0.46332806,\n",
      "       -0.31323746,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.095019297307913, next_state=array([ 0.21718922,  1.4214795 ,  0.5960008 , -0.42478922, -0.47679406,\n",
      "       -0.26931986,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21718922,  1.4214795 ,  0.5960008 , -0.42478922, -0.47679406,\n",
      "       -0.26931986,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0211443856923097, next_state=array([ 0.22302838,  1.4114164 ,  0.59599054, -0.4514694 , -0.4902599 ,\n",
      "       -0.2693165 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22302838,  1.4114164 ,  0.59599054, -0.4514694 , -0.4902599 ,\n",
      "       -0.2693165 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.410181321852792, next_state=array([ 0.2291873 ,  1.4012771 ,  0.62740296, -0.45478633, -0.50318056,\n",
      "       -0.2584132 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2291873 ,  1.4012771 ,  0.62740296, -0.45478633, -0.50318056,\n",
      "       -0.2584132 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.2627083256034255, next_state=array([ 0.2354289 ,  1.3904736 ,  0.63781047, -0.4852515 , -0.51861846,\n",
      "       -0.3087575 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2354289 ,  1.3904736 ,  0.63781047, -0.4852515 , -0.51861846,\n",
      "       -0.3087575 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1685497124784934, next_state=array([ 0.24161005,  1.3791345 ,  0.6298757 , -0.50849617, -0.5320342 ,\n",
      "       -0.26831502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24161005,  1.3791345 ,  0.6298757 , -0.50849617, -0.5320342 ,\n",
      "       -0.26831502,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0574795225980143, next_state=array([ 0.24772882,  1.3672395 ,  0.6219372 , -0.53265876, -0.5435998 ,\n",
      "       -0.23131165,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24772882,  1.3672395 ,  0.6219372 , -0.53265876, -0.5435998 ,\n",
      "       -0.23131165,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7979559192158376, next_state=array([ 0.25384817,  1.3547461 ,  0.62192863, -0.559335  , -0.55516523,\n",
      "       -0.2313095 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25384817,  1.3547461 ,  0.62192863, -0.559335  , -0.55516523,\n",
      "       -0.2313095 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.791256563826721, next_state=array([ 0.2599682 ,  1.3416541 ,  0.6219199 , -0.5860111 , -0.5667306 ,\n",
      "       -0.23130734,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2599682 ,  1.3416541 ,  0.6219199 , -0.5860111 , -0.5667306 ,\n",
      "       -0.23130734,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.6954985651196806, next_state=array([ 0.2665782 ,  1.3289888 ,  0.6706675 , -0.56705683, -0.57808214,\n",
      "       -0.22703096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2665782 ,  1.3289888 ,  0.6706675 , -0.56705683, -0.57808214,\n",
      "       -0.22703096,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6378260238033977, next_state=array([ 0.27311897,  1.3157842 ,  0.66183555, -0.5902681 , -0.5872389 ,\n",
      "       -0.1831365 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27311897,  1.3157842 ,  0.66183555, -0.5902681 , -0.5872389 ,\n",
      "       -0.1831365 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.8308299176127023, next_state=array([ 0.27974185,  1.3019072 ,  0.6721767 , -0.621194  , -0.5990106 ,\n",
      "       -0.23543358,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27974185,  1.3019072 ,  0.6721767 , -0.621194  , -0.5990106 ,\n",
      "       -0.23543358,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9240092308291876, next_state=array([ 0.2868759 ,  1.2884367 ,  0.7230444 , -0.6031231 , -0.6105788 ,\n",
      "       -0.23136428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2868759 ,  1.2884367 ,  0.7230444 , -0.6031231 , -0.6105788 ,\n",
      "       -0.23136428,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6723276984084237, next_state=array([ 0.29401064,  1.2743677 ,  0.72303474, -0.62979895, -0.6221469 ,\n",
      "       -0.23136213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29401064,  1.2743677 ,  0.72303474, -0.62979895, -0.6221469 ,\n",
      "       -0.23136213,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.3635220293545443, next_state=array([ 0.3015523 ,  1.260263  ,  0.76323545, -0.6312484 , -0.6331988 ,\n",
      "       -0.22103831,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3015523 ,  1.260263  ,  0.76323545, -0.6312484 , -0.6331988 ,\n",
      "       -0.22103831,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.471721984653725, next_state=array([ 0.3091486 ,  1.2455126 ,  0.7700194 , -0.66071874, -0.6459716 ,\n",
      "       -0.25545642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3091486 ,  1.2455126 ,  0.7700194 , -0.66071874, -0.6459716 ,\n",
      "       -0.25545642,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.731610290843605, next_state=array([ 0.31674585,  1.2301639 ,  0.77000713, -0.68739635, -0.6587443 ,\n",
      "       -0.25545353,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31674585,  1.2301639 ,  0.77000713, -0.68739635, -0.6587443 ,\n",
      "       -0.25545353,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.865611521772307, next_state=array([ 0.32440624,  1.2141395 ,  0.7780456 , -0.71847886, -0.67381036,\n",
      "       -0.3013217 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32440624,  1.2141395 ,  0.7780456 , -0.71847886, -0.67381036,\n",
      "       -0.3013217 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7337621970119972, next_state=array([ 0.33199683,  1.1975985 ,  0.7689376 , -0.7404751 , -0.68634963,\n",
      "       -0.25078404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33199683,  1.1975985 ,  0.7689376 , -0.7404751 , -0.68634963,\n",
      "       -0.25078404,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.396187233569292, next_state=array([ 0.33951387,  1.1805499 ,  0.75937164, -0.76192814, -0.69615847,\n",
      "       -0.19617565,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.33951387,  1.1805499 ,  0.75937164, -0.76192814, -0.69615847,\n",
      "       -0.19617565,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4035527829281023, next_state=array([ 0.3470315 ,  1.1629024 ,  0.75936395, -0.7886009 , -0.7059672 ,\n",
      "       -0.1961741 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3470315 ,  1.1629024 ,  0.75936395, -0.7886009 , -0.7059672 ,\n",
      "       -0.1961741 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.9712871931663356, next_state=array([ 0.35494882,  1.1451128 ,  0.79889506, -0.7947531 , -0.71528435,\n",
      "       -0.18634267,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.35494882,  1.1451128 ,  0.79889506, -0.7947531 , -0.71528435,\n",
      "       -0.18634267,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.3460011747716747, next_state=array([ 0.36351642,  1.1276995 ,  0.8636408 , -0.77792436, -0.72430515,\n",
      "       -0.1804156 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36351642,  1.1276995 ,  0.8636408 , -0.77792436, -0.72430515,\n",
      "       -0.1804156 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1006493204504566, next_state=array([ 0.3721282 ,  1.109628  ,  0.8692848 , -0.80799544, -0.7350242 ,\n",
      "       -0.21438006,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3721282 ,  1.109628  ,  0.8692848 , -0.80799544, -0.7350242 ,\n",
      "       -0.21438006,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9295169025787005, next_state=array([ 0.38119403,  1.092102  ,  0.9152173 , -0.78417784, -0.74655324,\n",
      "       -0.23058113,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38119403,  1.092102  ,  0.9152173 , -0.78417784, -0.74655324,\n",
      "       -0.23058113,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5116366935087331, next_state=array([ 0.39020395,  1.0740476 ,  0.90797603, -0.80675334, -0.75596833,\n",
      "       -0.18830174,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39020395,  1.0740476 ,  0.90797603, -0.80675334, -0.75596833,\n",
      "       -0.18830174,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.390422933182917, next_state=array([ 0.39926758,  1.0553081 ,  0.91494817, -0.83831966, -0.76766866,\n",
      "       -0.23400633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39926758,  1.0553081 ,  0.91494817, -0.83831966, -0.76766866,\n",
      "       -0.23400633,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.26805274253802, next_state=array([ 0.40895367,  1.0366987 ,  0.97673255, -0.8323593 , -0.7788601 ,\n",
      "       -0.22382887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40895367,  1.0366987 ,  0.97673255, -0.8323593 , -0.7788601 ,\n",
      "       -0.22382887,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.373487065324666, next_state=array([ 0.41869134,  1.0174301 ,  0.98312217, -0.8626048 , -0.79191065,\n",
      "       -0.26101094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41869134,  1.0174301 ,  0.98312217, -0.8626048 , -0.79191065,\n",
      "       -0.26101094,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6245285157870626, next_state=array([ 0.42843   ,  0.9975632 ,  0.983107  , -0.88928145, -0.804961  ,\n",
      "       -0.26100788,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42843   ,  0.9975632 ,  0.983107  , -0.88928145, -0.804961  ,\n",
      "       -0.26100788,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.49741931317478705, next_state=array([ 0.438111 ,  0.9771887,  0.9754842, -0.9106974, -0.8155234,\n",
      "       -0.2112476,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.438111 ,  0.9771887,  0.9754842, -0.9106974, -0.8155234,\n",
      "       -0.2112476,  0.       ,  0.       ], dtype=float32), action=1, reward=-0.3017377605816296, next_state=array([ 0.4477358 ,  0.95630234,  0.9681269 , -0.93231165, -0.82368636,\n",
      "       -0.16325906,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4477358 ,  0.95630234,  0.9681269 , -0.93231165, -0.82368636,\n",
      "       -0.16325906,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.012957470366575, next_state=array([ 0.45770445,  0.935494  ,  1.0027722 , -0.9290965 , -0.83230215,\n",
      "       -0.17231631,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45770445,  0.935494  ,  1.0027722 , -0.9290965 , -0.83230215,\n",
      "       -0.17231631,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.17043594575775842, next_state=array([ 0.46762162,  0.9141761 ,  0.9959709 , -0.95059854, -0.8385585 ,\n",
      "       -0.1251271 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46762162,  0.9141761 ,  0.9959709 , -0.95059854, -0.8385585 ,\n",
      "       -0.1251271 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.838696698110623, next_state=array([ 0.4775795 ,  0.89219326,  1.0011973 , -0.98105174, -0.8465777 ,\n",
      "       -0.16038421,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4775795 ,  0.89219326,  1.0011973 , -0.98105174, -0.8465777 ,\n",
      "       -0.16038421,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.353116248455392, next_state=array([ 0.4875926 ,  0.86951524,  1.008353  , -1.0132662 , -0.8571152 ,\n",
      "       -0.21075043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4875926 ,  0.86951524,  1.008353  , -1.0132662 , -0.8571152 ,\n",
      "       -0.21075043,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4359842696464398, next_state=array([ 0.49760646,  0.8462381 ,  1.0083425 , -1.0399389 , -0.86765265,\n",
      "       -0.21074882,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49760646,  0.8462381 ,  1.0083425 , -1.0399389 , -0.86765265,\n",
      "       -0.21074882,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3233932447681966, next_state=array([ 0.5076642 ,  0.8222958 ,  1.0138347 , -1.0705149 , -0.8800265 ,\n",
      "       -0.24747732,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5076642 ,  0.8222958 ,  1.0138347 , -1.0705149 , -0.8800265 ,\n",
      "       -0.24747732,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6487908659894401, next_state=array([ 0.5177231 ,  0.79775465,  1.0138198 , -1.0971897 , -0.8924002 ,\n",
      "       -0.24747422,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5177231 ,  0.79775465,  1.0138198 , -1.0971897 , -0.8924002 ,\n",
      "       -0.24747422,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7463107686464514, next_state=array([ 0.527743  ,  0.77270424,  1.0084307 , -1.118726  , -0.9025874 ,\n",
      "       -0.20374417,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.527743  ,  0.77270424,  1.0084307 , -1.118726  , -0.9025874 ,\n",
      "       -0.20374417,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.257841520384761, next_state=array([ 0.53847295,  0.74816537,  1.0797721 , -1.0963801 , -0.9134291 ,\n",
      "       -0.21683374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.53847295,  0.74816537,  1.0797721 , -1.0963801 , -0.9134291 ,\n",
      "       -0.21683374,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5553458755224756, next_state=array([ 0.54915315,  0.7231207 ,  1.073201  , -1.117602  , -0.921839  ,\n",
      "       -0.1681985 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.54915315,  0.7231207 ,  1.073201  , -1.117602  , -0.921839  ,\n",
      "       -0.1681985 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4110323631500705, next_state=array([ 0.5598339 ,  0.6974766 ,  1.0731938 , -1.1442722 , -0.93024886,\n",
      "       -0.16819772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5598339 ,  0.6974766 ,  1.0731938 , -1.1442722 , -0.93024886,\n",
      "       -0.16819772,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3562689475856176, next_state=array([ 0.5705555 ,  0.67115754,  1.0784031 , -1.1753799 , -0.9406261 ,\n",
      "       -0.20754497,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5705555 ,  0.67115754,  1.0784031 , -1.1753799 , -0.9406261 ,\n",
      "       -0.20754497,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6937528028751103, next_state=array([ 0.58127785,  0.6442391 ,  1.0783923 , -1.2020519 , -0.95100325,\n",
      "       -0.20754346,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.58127785,  0.6442391 ,  1.0783923 , -1.2020519 , -0.95100325,\n",
      "       -0.20754346,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.685602400007144, next_state=array([ 0.5928467 ,  0.6173577 ,  1.1625473 , -1.2000738 , -0.9607046 ,\n",
      "       -0.19402742,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5928467 ,  0.6173577 ,  1.1625473 , -1.2000738 , -0.9607046 ,\n",
      "       -0.19402742,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.944587998276943, next_state=array([ 0.6043848 ,  0.5899616 ,  1.1582515 , -1.2218773 , -0.96840745,\n",
      "       -0.154057  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6043848 ,  0.5899616 ,  1.1582515 , -1.2218773 , -0.96840745,\n",
      "       -0.154057  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.622014655200462, next_state=array([ 0.61680734,  0.56277114,  1.2465099 , -1.21261   , -0.9758378 ,\n",
      "       -0.14860746,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.61680734,  0.56277114,  1.2465099 , -1.21261   , -0.9758378 ,\n",
      "       -0.14860746,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.48660668634297966, next_state=array([ 0.6291822 ,  0.53510356,  1.240017  , -1.2321783 , -0.98031956,\n",
      "       -0.08963524,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6291822 ,  0.53510356,  1.240017  , -1.2321783 , -0.98031956,\n",
      "       -0.08963524,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.8688033098807635, next_state=array([ 0.64187086,  0.5072327 ,  1.2714994 , -1.2413404 , -0.98500884,\n",
      "       -0.09378511,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.64187086,  0.5072327 ,  1.2714994 , -1.2413404 , -0.98500884,\n",
      "       -0.09378511,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6284112262612211, next_state=array([ 0.65455973,  0.47876203,  1.271497  , -1.268008  , -0.98969805,\n",
      "       -0.09378481,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.65455973,  0.47876203,  1.271497  , -1.268008  , -0.98969805,\n",
      "       -0.09378481,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7292164635866811, next_state=array([ 0.6672487 ,  0.44969144,  1.2714947 , -1.2946757 , -0.9943873 ,\n",
      "       -0.09378402,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6672487 ,  0.44969144,  1.2714947 , -1.2946757 , -0.9943873 ,\n",
      "       -0.09378402,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.751319691868473, next_state=array([ 0.67988986,  0.42012277,  1.2652888 , -1.3153654 , -0.9965075 ,\n",
      "       -0.04240432,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.67988986,  0.42012277,  1.2652888 , -1.3153654 , -0.9965075 ,\n",
      "       -0.04240432,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.798651749347725, next_state=array([ 0.692572  ,  0.389849  ,  1.2707493 , -1.3481388 , -1.0011575 ,\n",
      "       -0.09300066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.692572  ,  0.389849  ,  1.2707493 , -1.3481388 , -1.0011575 ,\n",
      "       -0.09300066,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.767626640009939, next_state=array([ 0.7055481,  0.3595331,  1.3005192, -1.350432 , -1.006522 ,\n",
      "       -0.1072906,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.7055481,  0.3595331,  1.3005192, -1.350432 , -1.006522 ,\n",
      "       -0.1072906,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.2894263980670644, next_state=array([ 0.71852416,  0.32861733,  1.3005161 , -1.3771001 , -1.0118866 ,\n",
      "       -0.10729017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.71852416,  0.32861733,  1.3005161 , -1.3771001 , -1.0118866 ,\n",
      "       -0.10729017,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4422793158986156, next_state=array([ 0.7314631 ,  0.29720265,  1.2954681 , -1.3979005 , -1.0148371 ,\n",
      "       -0.05901079,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7314631 ,  0.29720265,  1.2954681 , -1.3979005 , -1.0148371 ,\n",
      "       -0.05901079,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.3925763472760466, next_state=array([ 0.74444216,  0.26508802,  1.3007828 , -1.4304119 , -1.0202235 ,\n",
      "       -0.10772804,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.74444216,  0.26508802,  1.3007828 , -1.4304119 , -1.0202235 ,\n",
      "       -0.10772804,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.723060444727878, next_state=array([ 0.7574215 ,  0.23237358,  1.3007797 , -1.4570796 , -1.0256099 ,\n",
      "       -0.10772779,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7574215 ,  0.23237358,  1.3007797 , -1.4570796 , -1.0256099 ,\n",
      "       -0.10772779,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1049195275004124, next_state=array([ 0.77036935,  0.19913644,  1.2966154 , -1.4792264 , -1.0291048 ,\n",
      "       -0.06989885,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.77036935,  0.19913644,  1.2966154 , -1.4792264 , -1.0291048 ,\n",
      "       -0.06989885,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.83700689052486, next_state=array([ 0.783358  ,  0.16521178,  1.3018368 , -1.5110711 , -1.0348136 ,\n",
      "       -0.11417538,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.783358  ,  0.16521178,  1.3018368 , -1.5110711 , -1.0348136 ,\n",
      "       -0.11417538,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.089893420447054, next_state=array([ 0.79637796,  0.130607  ,  1.305928  , -1.542448  , -1.0424695 ,\n",
      "       -0.15311678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.79637796,  0.130607  ,  1.305928  , -1.542448  , -1.0424695 ,\n",
      "       -0.15311678,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.418098176611152, next_state=array([ 0.8094231 ,  0.09531971,  1.3093553 , -1.5739219 , -1.0520389 ,\n",
      "       -0.1913875 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8094231 ,  0.09531971,  1.3093553 , -1.5739219 , -1.0520389 ,\n",
      "       -0.1913875 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.9733527598574483, next_state=array([ 0.82246876,  0.05943297,  1.3093452 , -1.6005924 , -1.0616082 ,\n",
      "       -0.19138667,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.82246876,  0.05943297,  1.3093452 , -1.6005924 , -1.0616082 ,\n",
      "       -0.19138667,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.969377012138948, next_state=array([ 0.8355404 ,  0.02286345,  1.3127834 , -1.6321162 , -1.073114  ,\n",
      "       -0.23011689,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8355404 ,  0.02286345,  1.3127834 , -1.6321162 , -1.073114  ,\n",
      "       -0.23011689,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.4651732021435167, next_state=array([ 0.8485758 , -0.01419399,  1.3077875 , -1.6522747 , -1.081983  ,\n",
      "       -0.17737848,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8485758 , -0.01419399,  1.3077875 , -1.6522747 , -1.081983  ,\n",
      "       -0.17737848,  0.        ,  0.        ], dtype=float32), action=1, reward=6.554651636470141, next_state=array([ 0.8615738 , -0.05175082,  1.3028543 , -1.6730369 , -1.08842   ,\n",
      "       -0.12874152,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8615738 , -0.05175082,  1.3028543 , -1.6730369 , -1.08842   ,\n",
      "       -0.12874152,  1.        ,  0.        ], dtype=float32), action=1, reward=-2.9132340549869853, next_state=array([ 0.87454474, -0.08924942,  1.2974308 , -1.6806927 , -1.098565  ,\n",
      "       -0.18137701,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.87454474, -0.08924942,  1.2974308 , -1.6806927 , -1.098565  ,\n",
      "       -0.18137701,  1.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.88687897, -0.10510939,  1.2795533 , -0.77077043, -1.3891855 ,\n",
      "       -6.690727  ,  1.        ,  0.        ], dtype=float32), done=True), Experience(state=array([ 3.3683778e-04,  1.4061077e+00,  3.4109481e-02, -2.1388969e-01,\n",
      "       -3.8359876e-04, -7.7263257e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-2.0352848037031777, next_state=array([ 6.7367556e-04,  1.4007180e+00,  3.4063555e-02, -2.3954314e-01,\n",
      "       -7.6547044e-04, -7.6374561e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 6.7367556e-04,  1.4007180e+00,  3.4063555e-02, -2.3954314e-01,\n",
      "       -7.6547044e-04, -7.6374561e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=1.184069555687256, next_state=array([ 1.1812210e-03,  1.3956070e+00,  5.0316066e-02, -2.2715361e-01,\n",
      "       -3.2877349e-04,  8.7346928e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.1812210e-03,  1.3956070e+00,  5.0316066e-02, -2.2715361e-01,\n",
      "       -3.2877349e-04,  8.7346928e-03,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.9924662151061738, next_state=array([ 1.7139434e-03,  1.3906912e+00,  5.2710187e-02, -2.1848343e-01,\n",
      "        2.2712430e-04,  1.1119049e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([ 1.7139434e-03,  1.3906912e+00,  5.2710187e-02, -2.1848343e-01,\n",
      "        2.2712430e-04,  1.1119049e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-2.540768871624634, next_state=array([ 0.00234423,  1.3851676 ,  0.06494187, -0.24549507, -0.00166982,\n",
      "       -0.0379421 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00234423,  1.3851676 ,  0.06494187, -0.24549507, -0.00166982,\n",
      "       -0.0379421 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.712889058835968, next_state=array([ 0.00306263,  1.379039  ,  0.07599881, -0.27238023, -0.00578122,\n",
      "       -0.08223613,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00306263,  1.379039  ,  0.07599881, -0.27238023, -0.00578122,\n",
      "       -0.08223613,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.955142559297427, next_state=array([ 0.00387678,  1.3722991 ,  0.08800291, -0.29960012, -0.0122971 ,\n",
      "       -0.13032934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00387678,  1.3722991 ,  0.08800291, -0.29960012, -0.0122971 ,\n",
      "       -0.13032934,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.485609422004501, next_state=array([ 0.00469112,  1.3649596 ,  0.08802238, -0.32627133, -0.01881139,\n",
      "       -0.13029763,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00469112,  1.3649596 ,  0.08802238, -0.32627133, -0.01881139,\n",
      "       -0.13029763,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.439961813889255, next_state=array([ 0.00550566,  1.3570205 ,  0.08804138, -0.35294282, -0.02532515,\n",
      "       -0.13028723,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00550566,  1.3570205 ,  0.08804138, -0.35294282, -0.02532515,\n",
      "       -0.13028723,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.928101663378895, next_state=array([ 0.00640955,  1.3484796 ,  0.09924807, -0.37976506, -0.03408136,\n",
      "       -0.17514014,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00640955,  1.3484796 ,  0.09924807, -0.37976506, -0.03408136,\n",
      "       -0.17514014,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7415140807486693, next_state=array([ 0.00735245,  1.3404557 ,  0.1030724 , -0.3568449 , -0.04277233,\n",
      "       -0.17383552,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00735245,  1.3404557 ,  0.1030724 , -0.3568449 , -0.04277233,\n",
      "       -0.17383552,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.143894797594099, next_state=array([ 0.00838842,  1.3318377 ,  0.11472307, -0.3833702 , -0.05378808,\n",
      "       -0.22033508,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00838842,  1.3318377 ,  0.11472307, -0.3833702 , -0.05378808,\n",
      "       -0.22033508,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.743539471911106, next_state=array([ 0.00942478,  1.3226216 ,  0.11475523, -0.4100438 , -0.06480106,\n",
      "       -0.2202796 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00942478,  1.3226216 ,  0.11475523, -0.4100438 , -0.06480106,\n",
      "       -0.2202796 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9681011633777643, next_state=array([ 0.0104042 ,  1.3137316 ,  0.10950904, -0.39565477, -0.07627131,\n",
      "       -0.22942586,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0104042 ,  1.3137316 ,  0.10950904, -0.39565477, -0.07627131,\n",
      "       -0.22942586,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7773822040303457, next_state=array([ 0.01138401,  1.3042428 ,  0.10954063, -0.42234182, -0.0877393 ,\n",
      "       -0.22938065,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01138401,  1.3042428 ,  0.10954063, -0.42234182, -0.0877393 ,\n",
      "       -0.22938065,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6311516500135383, next_state=array([ 0.01239023,  1.2947419 ,  0.11221113, -0.42298242, -0.09924484,\n",
      "       -0.23013167,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01239023,  1.2947419 ,  0.11221113, -0.42298242, -0.09924484,\n",
      "       -0.23013167,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7265939243158925, next_state=array([ 0.01339683,  1.2846427 ,  0.11224218, -0.44966754, -0.11074851,\n",
      "       -0.23009415,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01339683,  1.2846427 ,  0.11224218, -0.44966754, -0.11074851,\n",
      "       -0.23009415,  0.        ,  0.        ], dtype=float32), action=2, reward=2.3328817210197146, next_state=array([ 0.01440287,  1.275219  ,  0.11260287, -0.41975948, -0.12269589,\n",
      "       -0.23896918,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01440287,  1.275219  ,  0.11260287, -0.41975948, -0.12269589,\n",
      "       -0.23896918,  0.        ,  0.        ], dtype=float32), action=2, reward=0.28539082427773793, next_state=array([ 0.0154254 ,  1.2660161 ,  0.11447595, -0.41007468, -0.13487914,\n",
      "       -0.243687  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0154254 ,  1.2660161 ,  0.11447595, -0.41007468, -0.13487914,\n",
      "       -0.243687  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.320841590164973, next_state=array([ 0.0165144 ,  1.2561975 ,  0.12278583, -0.43769705, -0.1487517 ,\n",
      "       -0.27747625,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0165144 ,  1.2561975 ,  0.12278583, -0.43769705, -0.1487517 ,\n",
      "       -0.27747625,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.473971549105953, next_state=array([ 0.01753588,  1.2457987 ,  0.11425535, -0.4634216 , -0.16087018,\n",
      "       -0.24239092,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01753588,  1.2457987 ,  0.11425535, -0.4634216 , -0.16087018,\n",
      "       -0.24239092,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7092156909126572, next_state=array([ 0.01855784,  1.2348018 ,  0.11428586, -0.49010533, -0.1729878 ,\n",
      "       -0.24237435,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01855784,  1.2348018 ,  0.11428586, -0.49010533, -0.1729878 ,\n",
      "       -0.24237435,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2368449446130385, next_state=array([ 0.01950569,  1.2232169 ,  0.10496493, -0.5161002 , -0.18321297,\n",
      "       -0.20452139,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01950569,  1.2232169 ,  0.10496493, -0.5161002 , -0.18321297,\n",
      "       -0.20452139,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0211292160604146, next_state=array([ 0.02053375,  1.2110022 ,  0.11503904, -0.54443467, -0.19553056,\n",
      "       -0.24637382,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02053375,  1.2110022 ,  0.11503904, -0.54443467, -0.19553056,\n",
      "       -0.24637382,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1099209602418056, next_state=array([ 0.02183361,  1.199258  ,  0.14160502, -0.523541  , -0.20725341,\n",
      "       -0.23447773,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02183361,  1.199258  ,  0.14160502, -0.523541  , -0.20725341,\n",
      "       -0.23447773,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.996321142402677, next_state=array([ 0.02304945,  1.1869284 ,  0.13105464, -0.54933906, -0.21681905,\n",
      "       -0.19131236,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02304945,  1.1869284 ,  0.13105464, -0.54933906, -0.21681905,\n",
      "       -0.19131236,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9216304786609144, next_state=array([ 0.02435141,  1.1739714 ,  0.14186536, -0.57762265, -0.22863023,\n",
      "       -0.23622377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02435141,  1.1739714 ,  0.14186536, -0.57762265, -0.22863023,\n",
      "       -0.23622377,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9675500849322975, next_state=array([ 0.02558212,  1.1604337 ,  0.13289286, -0.6032372 , -0.238601  ,\n",
      "       -0.19941545,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02558212,  1.1604337 ,  0.13289286, -0.6032372 , -0.238601  ,\n",
      "       -0.19941545,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5195904964576357, next_state=array([ 0.02692909,  1.1470709 ,  0.14454833, -0.5955307 , -0.2486134 ,\n",
      "       -0.20024784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02692909,  1.1470709 ,  0.14454833, -0.5955307 , -0.2486134 ,\n",
      "       -0.20024784,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.20400780760491, next_state=array([ 0.02827644,  1.1331096 ,  0.1445453 , -0.6222055 , -0.25862572,\n",
      "       -0.20024645,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02827644,  1.1331096 ,  0.1445453 , -0.6222055 , -0.25862572,\n",
      "       -0.20024645,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5133320844203968, next_state=array([ 0.02953796,  1.1185887 ,  0.13368827, -0.64671654, -0.26632738,\n",
      "       -0.15403327,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02953796,  1.1185887 ,  0.13368827, -0.64671654, -0.26632738,\n",
      "       -0.15403327,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9827043838897225, next_state=array([ 0.03082962,  1.1042417 ,  0.13716772, -0.63912076, -0.27452248,\n",
      "       -0.1639018 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03082962,  1.1042417 ,  0.13716772, -0.63912076, -0.27452248,\n",
      "       -0.1639018 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9393187858459555, next_state=array([ 0.03212147,  1.0892957 ,  0.13716546, -0.6657929 , -0.28271753,\n",
      "       -0.16390076,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03212147,  1.0892957 ,  0.13716546, -0.6657929 , -0.28271753,\n",
      "       -0.16390076,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7104275857136144, next_state=array([ 0.03373947,  1.074826  ,  0.16925336, -0.64456135, -0.2903897 ,\n",
      "       -0.15344295,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03373947,  1.074826  ,  0.16925336, -0.64456135, -0.2903897 ,\n",
      "       -0.15344295,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3084210066705555, next_state=array([ 0.03528776,  1.0597892 ,  0.16043574, -0.6694335 , -0.2961756 ,\n",
      "       -0.11571838,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03528776,  1.0597892 ,  0.16043574, -0.6694335 , -0.2961756 ,\n",
      "       -0.11571838,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6173468800260196, next_state=array([ 0.03683605,  1.0441527 ,  0.16043451, -0.6961028 , -0.3019615 ,\n",
      "       -0.11571814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03683605,  1.0441527 ,  0.16043451, -0.6961028 , -0.3019615 ,\n",
      "       -0.11571814,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7905891840656636, next_state=array([ 0.03849363,  1.0288539 ,  0.17170456, -0.68120414, -0.308125  ,\n",
      "       -0.12326956,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03849363,  1.0288539 ,  0.17170456, -0.68120414, -0.308125  ,\n",
      "       -0.12326956,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0321439839072457, next_state=array([ 0.04007435,  1.0129905 ,  0.16202305, -0.70587933, -0.31221265,\n",
      "       -0.08175331,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04007435,  1.0129905 ,  0.16202305, -0.70587933, -0.31221265,\n",
      "       -0.08175331,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3717935200532736, next_state=array([ 0.04165516,  0.9965274 ,  0.16202241, -0.73254734, -0.31630027,\n",
      "       -0.0817532 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04165516,  0.9965274 ,  0.16202241, -0.73254734, -0.31630027,\n",
      "       -0.0817532 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3168307181381635, next_state=array([ 0.04323607,  0.9794645 ,  0.16202177, -0.7592153 , -0.32038793,\n",
      "       -0.08175311,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04323607,  0.9794645 ,  0.16202177, -0.7592153 , -0.32038793,\n",
      "       -0.08175311,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6427605848828353, next_state=array([ 0.04472828,  0.96183586,  0.15088405, -0.7838616 , -0.3221184 ,\n",
      "       -0.03460953,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04472828,  0.96183586,  0.15088405, -0.7838616 , -0.3221184 ,\n",
      "       -0.03460953,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.49200195050928985, next_state=array([ 0.04615068,  0.9436385 ,  0.14209844, -0.8087434 , -0.32196653,\n",
      "        0.00303758,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04615068,  0.9436385 ,  0.14209844, -0.8087434 , -0.32196653,\n",
      "        0.00303758,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.3327519326959976, next_state=array([ 0.04765196,  0.9248098 ,  0.15201075, -0.83725065, -0.32391757,\n",
      "       -0.0390211 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04765196,  0.9248098 ,  0.15201075, -0.83725065, -0.32391757,\n",
      "       -0.0390211 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.6163505689742397, next_state=array([ 0.04924221,  0.9053344 ,  0.16324422, -0.8665257 , -0.32831502,\n",
      "       -0.08794899,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04924221,  0.9053344 ,  0.16324422, -0.8665257 , -0.32831502,\n",
      "       -0.08794899,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0662752841504641, next_state=array([ 0.05083246,  0.88525915,  0.16324344, -0.89319396, -0.33271244,\n",
      "       -0.08794888,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05083246,  0.88525915,  0.16324344, -0.89319396, -0.33271244,\n",
      "       -0.08794888,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5642267584238414, next_state=array([ 0.05236225,  0.86461705,  0.15558165, -0.91803545, -0.33543435,\n",
      "       -0.05443798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05236225,  0.86461705,  0.15558165, -0.91803545, -0.33543435,\n",
      "       -0.05443798,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7918446163988051, next_state=array([ 0.05389204,  0.8433749 ,  0.15558134, -0.9447027 , -0.33815625,\n",
      "       -0.05443798,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05389204,  0.8433749 ,  0.15558134, -0.9447027 , -0.33815625,\n",
      "       -0.05443798,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0394270816615403, next_state=array([ 0.05560474,  0.82208246,  0.1736488 , -0.94689137, -0.34064206,\n",
      "       -0.04971624,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05560474,  0.82208246,  0.1736488 , -0.94689137, -0.34064206,\n",
      "       -0.04971624,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7006528068693569, next_state=array([ 0.05731745,  0.8001899 ,  0.17364857, -0.97355855, -0.34312788,\n",
      "       -0.04971617,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05731745,  0.8001899 ,  0.17364857, -0.97355855, -0.34312788,\n",
      "       -0.04971617,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.07629339277497024, next_state=array([ 0.05894842,  0.7777339 ,  0.1633504 , -0.9981086 , -0.34340268,\n",
      "       -0.0054962 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05894842,  0.7777339 ,  0.1633504 , -0.9981086 , -0.34340268,\n",
      "       -0.0054962 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3160108083442321, next_state=array([ 0.06048794,  0.7547314 ,  0.15178019, -1.0218132 , -0.34111872,\n",
      "        0.04567891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06048794,  0.7547314 ,  0.15178019, -1.0218132 , -0.34111872,\n",
      "        0.04567891,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.07049754656594587, next_state=array([ 0.06202755,  0.7311291 ,  0.15177996, -1.0484802 , -0.33883476,\n",
      "        0.04567897,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06202755,  0.7311291 ,  0.15177996, -1.0484802 , -0.33883476,\n",
      "        0.04567897,  0.        ,  0.        ], dtype=float32), action=2, reward=3.520622336355257, next_state=array([ 0.06366005,  0.707869  ,  0.16159876, -1.0333972 , -0.33711147,\n",
      "        0.03446518,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06366005,  0.707869  ,  0.16159876, -1.0333972 , -0.33711147,\n",
      "        0.03446518,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.10235514655474276, next_state=array([ 0.06529246,  0.6840088 ,  0.16159862, -1.0600641 , -0.3353882 ,\n",
      "        0.0344652 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06529246,  0.6840088 ,  0.16159862, -1.0600641 , -0.3353882 ,\n",
      "        0.0344652 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.618126227194183, next_state=array([ 0.06683874,  0.65960443,  0.15063438, -1.083718  , -0.33121654,\n",
      "        0.08343264,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06683874,  0.65960443,  0.15063438, -1.083718  , -0.33121654,\n",
      "        0.08343264,  0.        ,  0.        ], dtype=float32), action=2, reward=5.3090311164632285, next_state=array([ 0.06853304,  0.6359196 ,  0.16607054, -1.0518936 , -0.3277211 ,\n",
      "        0.06990974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06853304,  0.6359196 ,  0.16607054, -1.0518936 , -0.3277211 ,\n",
      "        0.06990974,  0.        ,  0.        ], dtype=float32), action=0, reward=0.10945041589192783, next_state=array([ 0.07022724,  0.6116349 ,  0.16607001, -1.0785614 , -0.3242256 ,\n",
      "        0.06990972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07022724,  0.6116349 ,  0.16607001, -1.0785614 , -0.3242256 ,\n",
      "        0.06990972,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5388461292320994, next_state=array([ 0.07185793,  0.58677083,  0.15810914, -1.1039749 , -0.31906834,\n",
      "        0.10314529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07185793,  0.58677083,  0.15810914, -1.1039749 , -0.31906834,\n",
      "        0.10314529,  0.        ,  0.        ], dtype=float32), action=0, reward=0.3808922972810649, next_state=array([ 0.07348871,  0.56130695,  0.1581081 , -1.1306437 , -0.31391108,\n",
      "        0.10314526,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07348871,  0.56130695,  0.1581081 , -1.1306437 , -0.31391108,\n",
      "        0.10314526,  0.        ,  0.        ], dtype=float32), action=0, reward=0.43480271206269094, next_state=array([ 0.0751195 ,  0.5352434 ,  0.15810706, -1.1573124 , -0.30875385,\n",
      "        0.10314499,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0751195 ,  0.5352434 ,  0.15810706, -1.1573124 , -0.30875385,\n",
      "        0.10314499,  0.        ,  0.        ], dtype=float32), action=0, reward=0.4878827673143178, next_state=array([ 0.07675047,  0.50858027,  0.15810603, -1.1839811 , -0.30359665,\n",
      "        0.10314482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07675047,  0.50858027,  0.15810603, -1.1839811 , -0.30359665,\n",
      "        0.10314482,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5399384290897444, next_state=array([ 0.07838144,  0.4813174 ,  0.15810503, -1.2106497 , -0.29843938,\n",
      "        0.10314459,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07838144,  0.4813174 ,  0.15810503, -1.2106497 , -0.29843938,\n",
      "        0.10314459,  0.        ,  0.        ], dtype=float32), action=2, reward=6.198303108628079, next_state=array([ 0.08031769,  0.45493078,  0.18862239, -1.1717223 , -0.29327044,\n",
      "        0.10337903,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08031769,  0.45493078,  0.18862239, -1.1717223 , -0.29327044,\n",
      "        0.10337903,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.030252958050765527, next_state=array([ 0.08232622,  0.4279147 ,  0.1977041 , -1.2000811 , -0.29002732,\n",
      "        0.06486277,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08232622,  0.4279147 ,  0.1977041 , -1.2000811 , -0.29002732,\n",
      "        0.06486277,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.27401599553976896, next_state=array([ 0.08441982,  0.40026248,  0.2084266 , -1.2288036 , -0.28906393,\n",
      "        0.01926756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08441982,  0.40026248,  0.2084266 , -1.2288036 , -0.28906393,\n",
      "        0.01926756,  0.        ,  0.        ], dtype=float32), action=1, reward=0.6852634458694535, next_state=array([ 0.08644581,  0.37205052,  0.19983295, -1.2533225 , -0.2862194 ,\n",
      "        0.05689103,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08644581,  0.37205052,  0.19983295, -1.2533225 , -0.2862194 ,\n",
      "        0.05689103,  0.        ,  0.        ], dtype=float32), action=1, reward=1.0004144576352598, next_state=array([ 0.08838835,  0.34328428,  0.1892534 , -1.2775277 , -0.28107956,\n",
      "        0.10279695,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08838835,  0.34328428,  0.1892534 , -1.2775277 , -0.28107956,\n",
      "        0.10279695,  0.        ,  0.        ], dtype=float32), action=1, reward=1.255230723446432, next_state=array([ 0.09024124,  0.3139603 ,  0.17792207, -1.3018867 , -0.27351755,\n",
      "        0.15124044,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09024124,  0.3139603 ,  0.17792207, -1.3018867 , -0.27351755,\n",
      "        0.15124044,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4383480778146247, next_state=array([ 0.09216614,  0.28401262,  0.1869462 , -1.3299851 , -0.26784152,\n",
      "        0.11352066,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09216614,  0.28401262,  0.1869462 , -1.3299851 , -0.26784152,\n",
      "        0.11352066,  0.        ,  0.        ], dtype=float32), action=0, reward=0.7488421884791876, next_state=array([ 0.09409113,  0.25346527,  0.18694513, -1.3566545 , -0.2621655 ,\n",
      "        0.11352038,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09409113,  0.25346527,  0.18694513, -1.3566545 , -0.2621655 ,\n",
      "        0.11352038,  0.        ,  0.        ], dtype=float32), action=1, reward=1.3437660019122302, next_state=array([ 0.09592762,  0.22236408,  0.17572966, -1.3808776 , -0.2540806 ,\n",
      "        0.16169764,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09592762,  0.22236408,  0.17572966, -1.3808776 , -0.2540806 ,\n",
      "        0.16169764,  0.        ,  0.        ], dtype=float32), action=2, reward=5.355984810830489, next_state=array([ 0.09797277,  0.19181915,  0.19654135, -1.3561921 , -0.24595769,\n",
      "        0.16245845,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09797277,  0.19181915,  0.19654135, -1.3561921 , -0.24595769,\n",
      "        0.16245845,  0.        ,  0.        ], dtype=float32), action=2, reward=4.10781157430709, next_state=array([ 0.10031681,  0.16160674,  0.22579256, -1.3413545 , -0.23719345,\n",
      "        0.17528433,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10031681,  0.16160674,  0.22579256, -1.3413545 , -0.23719345,\n",
      "        0.17528433,  0.        ,  0.        ], dtype=float32), action=1, reward=1.084154045650423, next_state=array([ 0.10259886,  0.13082995,  0.21788804, -1.3662301 , -0.22673123,\n",
      "        0.2092443 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10259886,  0.13082995,  0.21788804, -1.3662301 , -0.22673123,\n",
      "        0.2092443 ,  0.        ,  0.        ], dtype=float32), action=2, reward=4.893944652159928, next_state=array([ 0.10508785,  0.10060123,  0.23843133, -1.3419212 , -0.21613167,\n",
      "        0.21199122,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10508785,  0.10060123,  0.23843133, -1.3419212 , -0.21613167,\n",
      "        0.21199122,  0.        ,  0.        ], dtype=float32), action=0, reward=0.15828774331325235, next_state=array([ 0.10757713,  0.06977406,  0.23842824, -1.3685971 , -0.2055322 ,\n",
      "        0.21198957,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10757713,  0.06977406,  0.23842824, -1.3685971 , -0.2055322 ,\n",
      "        0.21198957,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.40200056888417635, next_state=array([ 0.1100667 ,  0.0383483 ,  0.23842525, -1.3952731 , -0.1949328 ,\n",
      "        0.21198793,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1100667 ,  0.0383483 ,  0.23842525, -1.3952731 , -0.1949328 ,\n",
      "        0.21198793,  0.        ,  0.        ], dtype=float32), action=0, reward=8.812007799089201, next_state=array([ 0.11255626,  0.00632405,  0.23842247, -1.421949  , -0.18433349,\n",
      "        0.2119863 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11255626,  0.00632405,  0.23842247, -1.421949  , -0.18433349,\n",
      "        0.2119863 ,  1.        ,  0.        ], dtype=float32), action=1, reward=16.193885939915873, next_state=array([ 0.11486168, -0.02505794,  0.19536725, -1.3906457 , -0.15476225,\n",
      "        0.584276  ,  1.        ,  1.        ], dtype=float32), done=False), Experience(state=array([ 0.11486168, -0.02505794,  0.19536725, -1.3906457 , -0.15476225,\n",
      "        0.584276  ,  1.        ,  1.        ], dtype=float32), action=1, reward=-100, next_state=array([ 1.17612265e-01, -4.26609889e-02,  1.08026541e-07,  6.35782840e-08,\n",
      "        1.33491924e-03, -4.81842392e-07,  1.00000000e+00,  1.00000000e+00],\n",
      "      dtype=float32), done=True), Experience(state=array([ 0.00777378,  1.4220576 ,  0.7873846 ,  0.49497327, -0.00900108,\n",
      "       -0.17835422,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8271013192901921, next_state=array([ 0.0156455 ,  1.432613  ,  0.79857206,  0.46902058, -0.02027209,\n",
      "       -0.22543971,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0156455 ,  1.432613  ,  0.79857206,  0.46902058, -0.02027209,\n",
      "       -0.22543971,  0.        ,  0.        ], dtype=float32), action=1, reward=0.3978968783860364, next_state=array([ 0.02342405,  1.4425771 ,  0.7868761 ,  0.44270244, -0.02918216,\n",
      "       -0.17821784,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02342405,  1.4425771 ,  0.7868761 ,  0.44270244, -0.02918216,\n",
      "       -0.17821784,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.465658592885659, next_state=array([ 0.03126755,  1.4519386 ,  0.7949883 ,  0.41583624, -0.03971581,\n",
      "       -0.21069269,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03126755,  1.4519386 ,  0.7949883 ,  0.41583624, -0.03971581,\n",
      "       -0.21069269,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7796083421401636, next_state=array([ 0.03918324,  1.4607096 ,  0.8040323 ,  0.38943616, -0.05204855,\n",
      "       -0.24667755,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03918324,  1.4607096 ,  0.8040323 ,  0.38943616, -0.05204855,\n",
      "       -0.24667755,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9215803590624307, next_state=array([ 0.04716701,  1.4688864 ,  0.81252116,  0.3628684 , -0.0660688 ,\n",
      "       -0.28043094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04716701,  1.4688864 ,  0.81252116,  0.3628684 , -0.0660688 ,\n",
      "       -0.28043094,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.3998349040900266, next_state=array([ 0.05523977,  1.4764582 ,  0.82367545,  0.33571818, -0.0823219 ,\n",
      "       -0.32509202,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05523977,  1.4764582 ,  0.82367545,  0.33571818, -0.0823219 ,\n",
      "       -0.32509202,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.739589636918906, next_state=array([ 0.06340704,  1.4834282 ,  0.83547354,  0.3086378 , -0.10093231,\n",
      "       -0.3722424 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06340704,  1.4834282 ,  0.83547354,  0.3086378 , -0.10093231,\n",
      "       -0.3722424 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.326205816924516, next_state=array([ 0.07170658,  1.4905659 ,  0.8482787 ,  0.31588697, -0.11916052,\n",
      "       -0.36459816,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07170658,  1.4905659 ,  0.8482787 ,  0.31588697, -0.11916052,\n",
      "       -0.36459816,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.62576678343612, next_state=array([ 0.08000708,  1.4971077 ,  0.84832746,  0.28918582, -0.13738632,\n",
      "       -0.36454925,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08000708,  1.4971077 ,  0.84832746,  0.28918582, -0.13738632,\n",
      "       -0.36454925,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.801010670201008, next_state=array([ 0.08824711,  1.5030639 ,  0.8406943 ,  0.26309142, -0.15405205,\n",
      "       -0.33334512,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08824711,  1.5030639 ,  0.8406943 ,  0.26309142, -0.15405205,\n",
      "       -0.33334512,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.3922503057506104, next_state=array([ 0.09644756,  1.5096968 ,  0.8374878 ,  0.2929042 , -0.1715209 ,\n",
      "       -0.34940967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09644756,  1.5096968 ,  0.8374878 ,  0.2929042 , -0.1715209 ,\n",
      "       -0.34940967,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.5609379428769214, next_state=array([ 0.10458393,  1.5165057 ,  0.8317305 ,  0.30042306, -0.1897037 ,\n",
      "       -0.3636892 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10458393,  1.5165057 ,  0.8317305 ,  0.30042306, -0.1897037 ,\n",
      "       -0.3636892 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4076112419027982, next_state=array([ 0.11263218,  1.5227388 ,  0.8205857 ,  0.27493456, -0.2055942 ,\n",
      "       -0.31783873,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11263218,  1.5227388 ,  0.8205857 ,  0.27493456, -0.2055942 ,\n",
      "       -0.31783873,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4435274863778591, next_state=array([ 0.12061109,  1.5283899 ,  0.81184167,  0.24915957, -0.21968985,\n",
      "       -0.28193852,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12061109,  1.5283899 ,  0.81184167,  0.24915957, -0.21968985,\n",
      "       -0.28193852,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5641731098299645, next_state=array([ 0.12868214,  1.533408  ,  0.8233777 ,  0.22052044, -0.23619415,\n",
      "       -0.3301166 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12868214,  1.533408  ,  0.8233777 ,  0.22052044, -0.23619415,\n",
      "       -0.3301166 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5342990281850166, next_state=array([ 0.13668403,  1.5378643 ,  0.8145304 ,  0.19569172, -0.25079706,\n",
      "       -0.29208428,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13668403,  1.5378643 ,  0.8145304 ,  0.19569172, -0.25079706,\n",
      "       -0.29208428,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.470387424758587, next_state=array([ 0.14496794,  1.5427879 ,  0.8422491 ,  0.21640281, -0.2649463 ,\n",
      "       -0.28301102,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14496794,  1.5427879 ,  0.8422491 ,  0.21640281, -0.2649463 ,\n",
      "       -0.28301102,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.789794737630404, next_state=array([ 0.1535286 ,  1.5476923 ,  0.86909306,  0.21555366, -0.27832004,\n",
      "       -0.26749894,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1535286 ,  1.5476923 ,  0.86909306,  0.21555366, -0.27832004,\n",
      "       -0.26749894,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.603676584299619, next_state=array([ 0.16218157,  1.5519664 ,  0.88062   ,  0.18696904, -0.29410347,\n",
      "       -0.31569722,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16218157,  1.5519664 ,  0.88062   ,  0.18696904, -0.29410347,\n",
      "       -0.31569722,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6947016696909984, next_state=array([ 0.17091389,  1.5556078 ,  0.8905037 ,  0.15825179, -0.31199273,\n",
      "       -0.357817  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17091389,  1.5556078 ,  0.8905037 ,  0.15825179, -0.31199273,\n",
      "       -0.357817  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7638958435977656, next_state=array([ 0.17964754,  1.558653  ,  0.8905425 ,  0.13154846, -0.32987857,\n",
      "       -0.3577488 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17964754,  1.558653  ,  0.8905425 ,  0.13154846, -0.32987857,\n",
      "       -0.3577488 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.5365426672471745, next_state=array([ 0.18829688,  1.561151  ,  0.87973183,  0.10756794, -0.3453723 ,\n",
      "       -0.309902  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18829688,  1.561151  ,  0.87973183,  0.10756794, -0.3453723 ,\n",
      "       -0.309902  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5624789401423413, next_state=array([ 0.19694738,  1.5630518 ,  0.8797622 ,  0.08087096, -0.36086446,\n",
      "       -0.3098714 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19694738,  1.5630518 ,  0.8797622 ,  0.08087096, -0.36086446,\n",
      "       -0.3098714 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.587385199359744, next_state=array([ 0.20559902,  1.5643553 ,  0.8797924 ,  0.05417337, -0.37635365,\n",
      "       -0.30981153,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20559902,  1.5643553 ,  0.8797924 ,  0.05417337, -0.37635365,\n",
      "       -0.30981153,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.173170916745721, next_state=array([ 0.21423379,  1.5657278 ,  0.87915784,  0.05678259, -0.39304614,\n",
      "       -0.3338626 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21423379,  1.5657278 ,  0.87915784,  0.05678259, -0.39304614,\n",
      "       -0.3338626 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.41652650221479237, next_state=array([ 0.22278795,  1.56654   ,  0.8683735 ,  0.032444  , -0.40693533,\n",
      "       -0.2777839 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22278795,  1.56654   ,  0.8683735 ,  0.032444  , -0.40693533,\n",
      "       -0.2777839 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4731982510215857, next_state=array([ 0.23134279,  1.5667542 ,  0.86836404,  0.00576237, -0.42082435,\n",
      "       -0.27778023,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23134279,  1.5667542 ,  0.86836404,  0.00576237, -0.42082435,\n",
      "       -0.27778023,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.459684232535578, next_state=array([ 0.23995924,  1.5663433 ,  0.8759697 , -0.02262054, -0.43636733,\n",
      "       -0.3108599 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23995924,  1.5663433 ,  0.8759697 , -0.02262054, -0.43636733,\n",
      "       -0.3108599 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.442014042448522, next_state=array([ 0.2490221 ,  1.5666913 ,  0.92043275,  0.01099476, -0.45180935,\n",
      "       -0.30884022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2490221 ,  1.5666913 ,  0.92043275,  0.01099476, -0.45180935,\n",
      "       -0.30884022,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6698981743352306, next_state=array([ 0.25808603,  1.5664421 ,  0.9204198 , -0.01569004, -0.46725106,\n",
      "       -0.30883497,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.25808603,  1.5664421 ,  0.9204198 , -0.01569004, -0.46725106,\n",
      "       -0.30883497,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.197433795165284, next_state=array([ 0.26758766,  1.5663228 ,  0.9633752 , -0.00981677, -0.481899  ,\n",
      "       -0.29295945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.26758766,  1.5663228 ,  0.9633752 , -0.00981677, -0.481899  ,\n",
      "       -0.29295945,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7989516510084784, next_state=array([ 0.2771636 ,  1.5655553 ,  0.9726243 , -0.03944211, -0.49870515,\n",
      "       -0.3361234 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2771636 ,  1.5655553 ,  0.9726243 , -0.03944211, -0.49870515,\n",
      "       -0.3361234 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8590911101713345, next_state=array([ 0.28674078,  1.5641912 ,  0.9726075 , -0.06612976, -0.515511  ,\n",
      "       -0.3361168 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28674078,  1.5641912 ,  0.9726075 , -0.06612976, -0.515511  ,\n",
      "       -0.3361168 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8789805167790519, next_state=array([ 0.2963191 ,  1.5622302 ,  0.97259015, -0.09281722, -0.5323165 ,\n",
      "       -0.3361102 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2963191 ,  1.5622302 ,  0.97259015, -0.09281722, -0.5323165 ,\n",
      "       -0.3361102 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8986155305377679, next_state=array([ 0.30589876,  1.5596726 ,  0.9725723 , -0.11950448, -0.5491217 ,\n",
      "       -0.33610368,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.30589876,  1.5596726 ,  0.9725723 , -0.11950448, -0.5491217 ,\n",
      "       -0.33610368,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.9413989101302875, next_state=array([ 0.31554165,  1.5564721 ,  0.9803365 , -0.14891717, -0.5677929 ,\n",
      "       -0.37342462,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31554165,  1.5564721 ,  0.9803365 , -0.14891717, -0.5677929 ,\n",
      "       -0.37342462,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1820319461151303, next_state=array([ 0.32513037,  1.5527421 ,  0.9730608 , -0.17190062, -0.58448565,\n",
      "       -0.33385354,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32513037,  1.5527421 ,  0.9730608 , -0.17190062, -0.58448565,\n",
      "       -0.33385354,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7611752572234127, next_state=array([ 0.3346489 ,  1.5484871 ,  0.9638815 , -0.1945018 , -0.5987967 ,\n",
      "       -0.28622177,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3346489 ,  1.5484871 ,  0.9638815 , -0.1945018 , -0.5987967 ,\n",
      "       -0.28622177,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7221634830497692, next_state=array([ 0.34416837,  1.5436342 ,  0.96386707, -0.22118276, -0.6131077 ,\n",
      "       -0.28621772,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34416837,  1.5436342 ,  0.96386707, -0.22118276, -0.6131077 ,\n",
      "       -0.28621772,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.830801065105986, next_state=array([ 0.353753  ,  1.5381284 ,  0.9719264 , -0.25111172, -0.6294462 ,\n",
      "       -0.32677096,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.353753  ,  1.5381284 ,  0.9719264 , -0.25111172, -0.6294462 ,\n",
      "       -0.32677096,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9562179637632084, next_state=array([ 0.36333895,  1.5320255 ,  0.9719068 , -0.2777967 , -0.6457845 ,\n",
      "       -0.32676494,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36333895,  1.5320255 ,  0.9719068 , -0.2777967 , -0.6457845 ,\n",
      "       -0.32676494,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1380200080115785, next_state=array([ 0.37299356,  1.5252616 ,  0.980364  , -0.30823278, -0.6643305 ,\n",
      "       -0.37091976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.37299356,  1.5252616 ,  0.980364  , -0.30823278, -0.6643305 ,\n",
      "       -0.37091976,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.202230270483028, next_state=array([ 0.38265   ,  1.5179015 ,  0.98033744, -0.33492243, -0.68287605,\n",
      "       -0.37091094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38265   ,  1.5179015 ,  0.98033744, -0.33492243, -0.68287605,\n",
      "       -0.37091094,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0661768599757964, next_state=array([ 0.3923544 ,  1.5098913 ,  0.9862054 , -0.36471787, -0.7030771 ,\n",
      "       -0.40402085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3923544 ,  1.5098913 ,  0.9862054 , -0.36471787, -0.7030771 ,\n",
      "       -0.40402085,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5257636047872143, next_state=array([ 0.40201092,  1.5013423 ,  0.97978055, -0.3880733 , -0.7214863 ,\n",
      "       -0.36818498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40201092,  1.5013423 ,  0.97978055, -0.3880733 , -0.7214863 ,\n",
      "       -0.36818498,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1538706253536748, next_state=array([ 0.4116109 ,  1.4922765 ,  0.9721898 , -0.41017786, -0.7376146 ,\n",
      "       -0.32256582,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4116109 ,  1.4922765 ,  0.9721898 , -0.41017786, -0.7376146 ,\n",
      "       -0.32256582,  0.        ,  0.        ], dtype=float32), action=2, reward=-7.5205083057156115, next_state=array([ 0.42196313,  1.4836717 ,  1.0469667 , -0.38964543, -0.75336796,\n",
      "       -0.31506938,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42196313,  1.4836717 ,  1.0469667 , -0.38964543, -0.75336796,\n",
      "       -0.31506938,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6756407456734042, next_state=array([ 0.4322504 ,  1.474571  ,  1.0382773 , -0.41050965, -0.7663519 ,\n",
      "       -0.2596787 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4322504 ,  1.474571  ,  1.0382773 , -0.41050965, -0.7663519 ,\n",
      "       -0.2596787 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.808616640997427, next_state=array([ 0.44259852,  1.4647925 ,  1.0459076 , -0.44180998, -0.78164905,\n",
      "       -0.30594516,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44259852,  1.4647925 ,  1.0459076 , -0.44180998, -0.78164905,\n",
      "       -0.30594516,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6521714096268443, next_state=array([ 0.45288163,  1.4545143 ,  1.0372889 , -0.46282387, -0.7942167 ,\n",
      "       -0.2513519 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45288163,  1.4545143 ,  1.0372889 , -0.46282387, -0.7942167 ,\n",
      "       -0.2513519 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.572095697225761, next_state=array([ 0.4632125 ,  1.4435692 ,  1.0432963 , -0.49347797, -0.8087006 ,\n",
      "       -0.28967887,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4632125 ,  1.4435692 ,  1.0432963 , -0.49347797, -0.8087006 ,\n",
      "       -0.28967887,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9656985484176903, next_state=array([ 0.47349873,  1.4320956 ,  1.0373454 , -0.51610476, -0.82125753,\n",
      "       -0.25113642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.47349873,  1.4320956 ,  1.0373454 , -0.51610476, -0.82125753,\n",
      "       -0.25113642,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.395572739129409, next_state=array([ 0.48430794,  1.4206661 ,  1.0894115 , -0.5141147 , -0.83361995,\n",
      "       -0.24724889,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.48430794,  1.4206661 ,  1.0894115 , -0.5141147 , -0.83361995,\n",
      "       -0.24724889,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6143573973943717, next_state=array([ 0.49511823,  1.4086381 ,  1.0893973 , -0.54079   , -0.84598225,\n",
      "       -0.24724624,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49511823,  1.4086381 ,  1.0893973 , -0.54079   , -0.84598225,\n",
      "       -0.24724624,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6185278252108901, next_state=array([ 0.5059296 ,  1.3960114 ,  1.089383  , -0.56746536, -0.85834444,\n",
      "       -0.24724364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5059296 ,  1.3960114 ,  1.089383  , -0.56746536, -0.85834444,\n",
      "       -0.24724364,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5370241506454065, next_state=array([ 0.51678574,  1.3827144 ,  1.095018  , -0.5983276 , -0.8726422 ,\n",
      "       -0.28595638,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51678574,  1.3827144 ,  1.095018  , -0.5983276 , -0.8726422 ,\n",
      "       -0.28595638,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.07846975967871, next_state=array([ 0.52770126,  1.3687121 ,  1.1025584 , -0.6312115 , -0.889708  ,\n",
      "       -0.34131607,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.52770126,  1.3687121 ,  1.1025584 , -0.6312115 , -0.889708  ,\n",
      "       -0.34131607,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.070267949759993, next_state=array([ 0.5386591 ,  1.3540204 ,  1.1079513 , -0.6631552 , -0.90900064,\n",
      "       -0.38585362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5386591 ,  1.3540204 ,  1.1079513 , -0.6631552 , -0.90900064,\n",
      "       -0.38585362,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.309941706128882, next_state=array([ 0.5496195 ,  1.3387315 ,  1.1079144 , -0.6898414 , -0.9282928 ,\n",
      "       -0.38584375,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5496195 ,  1.3387315 ,  1.1079144 , -0.6898414 , -0.9282928 ,\n",
      "       -0.38584375,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.8676479001846245, next_state=array([ 0.5610339,  1.323608 ,  1.1533865, -0.6830008, -0.9482146,\n",
      "       -0.3984354,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.5610339,  1.323608 ,  1.1533865, -0.6830008, -0.9482146,\n",
      "       -0.3984354,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.3757966082021653, next_state=array([ 0.57245123,  1.3078876 ,  1.1533462 , -0.7096872 , -0.96813583,\n",
      "       -0.3984245 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.57245123,  1.3078876 ,  1.1533462 , -0.7096872 , -0.96813583,\n",
      "       -0.3984245 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6320865790205221, next_state=array([ 0.58383524,  1.2916381 ,  1.148697  , -0.73235434, -0.9862839 ,\n",
      "       -0.36296108,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.58383524,  1.2916381 ,  1.148697  , -0.73235434, -0.9862839 ,\n",
      "       -0.36296108,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.2091547347652067, next_state=array([ 0.59522164,  1.274791  ,  1.1486626 , -0.7590366 , -1.0044315 ,\n",
      "       -0.36295286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.59522164,  1.274791  ,  1.1486626 , -0.7590366 , -1.0044315 ,\n",
      "       -0.36295286,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.007801405088673, next_state=array([ 0.6072054 ,  1.2580085 ,  1.208247  , -0.75643134, -1.0228252 ,\n",
      "       -0.36787394,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6072054 ,  1.2580085 ,  1.208247  , -0.75643134, -1.0228252 ,\n",
      "       -0.36787394,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2230939951285495, next_state=array([ 0.6191511 ,  1.240736  ,  1.2028288 , -0.77682084, -1.0386295 ,\n",
      "       -0.31608474,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6191511 ,  1.240736  ,  1.2028288 , -0.77682084, -1.0386295 ,\n",
      "       -0.31608474,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9898974054972314, next_state=array([ 0.63109875,  1.222865  ,  1.2028017 , -0.8034982 , -1.0544335 ,\n",
      "       -0.31607932,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.63109875,  1.222865  ,  1.2028017 , -0.8034982 , -1.0544335 ,\n",
      "       -0.31607932,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.387332694448037, next_state=array([ 0.64366513,  1.2048304 ,  1.2643352 , -0.81070924, -1.0699947 ,\n",
      "       -0.3112255 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.64366513,  1.2048304 ,  1.2643352 , -0.81070924, -1.0699947 ,\n",
      "       -0.3112255 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.770194772849122, next_state=array([ 0.6562605 ,  1.1861135 ,  1.2679566 , -0.84228885, -1.08753   ,\n",
      "       -0.35070702,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6562605 ,  1.1861135 ,  1.2679566 , -0.84228885, -1.08753   ,\n",
      "       -0.35070702,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.2346544221174143, next_state=array([ 0.6688973 ,  1.1666915 ,  1.2729876 , -0.8752893 , -1.1076491 ,\n",
      "       -0.40238094,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6688973 ,  1.1666915 ,  1.2729876 , -0.8752893 , -1.1076491 ,\n",
      "       -0.40238094,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4437127924158517, next_state=array([ 0.68153745,  1.1466718 ,  1.2729421 , -0.9019715 , -1.1277676 ,\n",
      "       -0.40236974,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.68153745,  1.1466718 ,  1.2729421 , -0.9019715 , -1.1277676 ,\n",
      "       -0.40236974,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.456677267870816, next_state=array([ 0.6941805 ,  1.1260545 ,  1.272896  , -0.92865306, -1.1478854 ,\n",
      "       -0.40235853,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6941805 ,  1.1260545 ,  1.272896  , -0.92865306, -1.1478854 ,\n",
      "       -0.40235853,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5779061025902184, next_state=array([ 0.7068016 ,  1.1049509 ,  1.2692789 , -0.9488055 , -1.165462  ,\n",
      "       -0.35153213,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7068016 ,  1.1049509 ,  1.2692789 , -0.9488055 , -1.165462  ,\n",
      "       -0.35153213,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2147602659410655, next_state=array([ 0.7193926 ,  1.08337   ,  1.264909  , -0.9683352 , -1.180217  ,\n",
      "       -0.29509908,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7193926 ,  1.08337   ,  1.264909  , -0.9683352 , -1.180217  ,\n",
      "       -0.29509908,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9778189836513889, next_state=array([ 0.7319853 ,  1.0611901 ,  1.2648838 , -0.995009  , -1.1949718 ,\n",
      "       -0.29509467,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7319853 ,  1.0611901 ,  1.2648838 , -0.995009  , -1.1949718 ,\n",
      "       -0.29509467,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.917607000686689, next_state=array([ 0.7448786 ,  1.0387082 ,  1.2948643 , -1.0087036 , -1.2100706 ,\n",
      "       -0.30197302,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7448786 ,  1.0387082 ,  1.2948643 , -1.0087036 , -1.2100706 ,\n",
      "       -0.30197302,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.4172381949359645, next_state=array([ 0.7581873 ,  1.0156746 ,  1.3359846 , -1.0329366 , -1.224631  ,\n",
      "       -0.29120734,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7581873 ,  1.0156746 ,  1.3359846 , -1.0329366 , -1.224631  ,\n",
      "       -0.29120734,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1059687382668515, next_state=array([ 0.7715244 ,  0.9919128 ,  1.3396275 , -1.0672528 , -1.2421539 ,\n",
      "       -0.35045913,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7715244 ,  0.9919128 ,  1.3396275 , -1.0672528 , -1.2421539 ,\n",
      "       -0.35045913,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.4154413957368477, next_state=array([ 0.7848902,  0.967423 ,  1.3430722, -1.1015557, -1.2626262,\n",
      "       -0.4094453,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.7848902,  0.967423 ,  1.3430722, -1.1015557, -1.2626262,\n",
      "       -0.4094453,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.669088614248949, next_state=array([ 0.7982594 ,  0.942335  ,  1.3430218 , -1.1282336 , -1.2830979 ,\n",
      "       -0.40943345,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.7982594 ,  0.942335  ,  1.3430218 , -1.1282336 , -1.2830979 ,\n",
      "       -0.40943345,  0.        ,  0.        ], dtype=float32), action=2, reward=-8.9864905435109, next_state=array([ 0.8125591,  0.9171048,  1.4357212, -1.134722 , -1.303701 ,\n",
      "       -0.4120626,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.8125591,  0.9171048,  1.4357212, -1.134722 , -1.303701 ,\n",
      "       -0.4120626,  0.       ,  0.       ], dtype=float32), action=0, reward=-2.7694036329669984, next_state=array([ 0.8268625 ,  0.89127606,  1.4356694 , -1.1613985 , -1.3243036 ,\n",
      "       -0.41205058,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.8268625 ,  0.89127606,  1.4356694 , -1.1613985 , -1.3243036 ,\n",
      "       -0.41205058,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.8787349053649494, next_state=array([ 0.8411911,  0.864713 ,  1.4384553, -1.1961386, -1.3479953,\n",
      "       -0.4738354,  0.       ,  0.       ], dtype=float32), done=False), Experience(state=array([ 0.8411911,  0.864713 ,  1.4384553, -1.1961386, -1.3479953,\n",
      "       -0.4738354,  0.       ,  0.       ], dtype=float32), action=1, reward=-2.3048998137897727, next_state=array([ 0.85550195,  0.83766335,  1.4356197 , -1.2161467 , -1.3691093 ,\n",
      "       -0.42227998,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.85550195,  0.83766335,  1.4356197 , -1.2161467 , -1.3691093 ,\n",
      "       -0.42227998,  0.        ,  0.        ], dtype=float32), action=2, reward=-7.771766474828257, next_state=array([ 0.870458  ,  0.81016433,  1.4996505 , -1.2360798 , -1.3900807 ,\n",
      "       -0.41942778,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.870458  ,  0.81016433,  1.4996505 , -1.2360798 , -1.3900807 ,\n",
      "       -0.41942778,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.021054110809814, next_state=array([ 0.88541776,  0.7820665 ,  1.499596  , -1.2627534 , -1.4110514 ,\n",
      "       -0.419415  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.88541776,  0.7820665 ,  1.499596  , -1.2627534 , -1.4110514 ,\n",
      "       -0.419415  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0851995432442436, next_state=array([ 0.90038127,  0.75336945,  1.4995412 , -1.2894266 , -1.4320214 ,\n",
      "       -0.4194023 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.90038127,  0.75336945,  1.4995412 , -1.2894266 , -1.4320214 ,\n",
      "       -0.4194023 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.9404541459392406, next_state=array([ 0.9153532 ,  0.7239587 ,  1.5002348 , -1.3229141 , -1.4555585 ,\n",
      "       -0.47074658,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9153532 ,  0.7239587 ,  1.5002348 , -1.3229141 , -1.4555585 ,\n",
      "       -0.47074658,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7902951841089405, next_state=array([ 0.93032324,  0.69405454,  1.4992605 , -1.3432767 , -1.4767089 ,\n",
      "       -0.42300743,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.93032324,  0.69405454,  1.4992605 , -1.3432767 , -1.4767089 ,\n",
      "       -0.42300743,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6874385331142023, next_state=array([ 0.94529706,  0.66365665,  1.4990233 , -1.3636612 , -1.4954937 ,\n",
      "       -0.3756957 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.94529706,  0.66365665,  1.4990233 , -1.3636612 , -1.4954937 ,\n",
      "       -0.3756957 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.8249951005106184, next_state=array([ 0.9602808 ,  0.6325692 ,  1.4997665 , -1.3956885 , -1.5163059 ,\n",
      "       -0.41624427,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9602808 ,  0.6325692 ,  1.4997665 , -1.3956885 , -1.5163059 ,\n",
      "       -0.41624427,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.148915494285943, next_state=array([ 0.97527105,  0.6007825 ,  1.50007   , -1.4283001 , -1.5393603 ,\n",
      "       -0.46108884,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.97527105,  0.6007825 ,  1.50007   , -1.4283001 , -1.5393603 ,\n",
      "       -0.46108884,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.2098902916925725, next_state=array([ 0.9902611 ,  0.5684847 ,  1.4994853 , -1.4496729 , -1.5604135 ,\n",
      "       -0.42106295,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.9902611 ,  0.5684847 ,  1.4994853 , -1.4496729 , -1.5604135 ,\n",
      "       -0.42106295,  0.        ,  0.        ], dtype=float32), action=3, reward=-100, next_state=array([ 1.0052618 ,  0.5354771 ,  1.5000942 , -1.4828982 , -1.5839417 ,\n",
      "       -0.47056374,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.00180378,  1.4071648 , -0.18272051, -0.16690321,  0.00209695,\n",
      "        0.04138896,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.276199356424455, next_state=array([-0.00367041,  1.4028355 , -0.19031937, -0.1924222 ,  0.00571552,\n",
      "        0.07237891,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00367041,  1.4028355 , -0.19031937, -0.1924222 ,  0.00571552,\n",
      "        0.07237891,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0830650854024657, next_state=array([-0.00546198,  1.3978989 , -0.18090765, -0.21941458,  0.00744299,\n",
      "        0.03455255,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00546198,  1.3978989 , -0.18090765, -0.21941458,  0.00744299,\n",
      "        0.03455255,  0.        ,  0.        ], dtype=float32), action=2, reward=1.5364532032610725, next_state=array([-0.00730248,  1.393522  , -0.18558094, -0.19453762,  0.00896502,\n",
      "        0.03044325,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00730248,  1.393522  , -0.18558094, -0.19453762,  0.00896502,\n",
      "        0.03044325,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6449397321200934, next_state=array([-0.00914288,  1.388545  , -0.1855853 , -0.22121559,  0.01048659,\n",
      "        0.03043421,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00914288,  1.388545  , -0.1855853 , -0.22121559,  0.01048659,\n",
      "        0.03043421,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8521126996869544, next_state=array([-0.01089897,  1.3829757 , -0.1750007 , -0.24751736,  0.00988327,\n",
      "       -0.0120675 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01089897,  1.3829757 , -0.1750007 , -0.24751736,  0.00988327,\n",
      "       -0.0120675 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.911638682119144, next_state=array([-0.01256046,  1.3774438 , -0.16601445, -0.24586548,  0.00975243,\n",
      "       -0.00261737,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01256046,  1.3774438 , -0.16601445, -0.24586548,  0.00975243,\n",
      "       -0.00261737,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2322389723986746, next_state=array([-0.01428089,  1.3713005 , -0.17341468, -0.27304605,  0.01110625,\n",
      "        0.02707907,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01428089,  1.3713005 , -0.17341468, -0.27304605,  0.01110625,\n",
      "        0.02707907,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.743646268626378, next_state=array([-0.01600132,  1.3645571 , -0.173419  , -0.2997119 ,  0.0124594 ,\n",
      "        0.02706555,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01600132,  1.3645571 , -0.173419  , -0.2997119 ,  0.0124594 ,\n",
      "        0.02706555,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.038285505788848, next_state=array([-0.01762905,  1.3572037 , -0.16178378, -0.32680842,  0.01148166,\n",
      "       -0.01955646,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01762905,  1.3572037 , -0.16178378, -0.32680842,  0.01148166,\n",
      "       -0.01955646,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2524039467109547, next_state=array([-0.01935034,  1.3492591 , -0.17351681, -0.35310072,  0.01285588,\n",
      "        0.02748691,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01935034,  1.3492591 , -0.17351681, -0.35310072,  0.01285588,\n",
      "        0.02748691,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.332894204629922, next_state=array([-0.0211443 ,  1.3407053 , -0.18261525, -0.38020724,  0.01605314,\n",
      "        0.06395071,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0211443 ,  1.3407053 , -0.18261525, -0.38020724,  0.01605314,\n",
      "        0.06395071,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1371134216016958, next_state=array([-0.02284794,  1.331561  , -0.17130151, -0.4064251 ,  0.01697763,\n",
      "        0.01849159,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02284794,  1.331561  , -0.17130151, -0.4064251 ,  0.01697763,\n",
      "        0.01849159,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0587095371114958, next_state=array([-0.02446985,  1.3218135 , -0.16105878, -0.43321064,  0.01585118,\n",
      "       -0.02253116,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02446985,  1.3218135 , -0.16105878, -0.43321064,  0.01585118,\n",
      "       -0.02253116,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.364400622712509, next_state=array([-0.02609186,  1.3114659 , -0.1610553 , -0.45987925,  0.01472529,\n",
      "       -0.02251996,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02609186,  1.3114659 , -0.1610553 , -0.45987925,  0.01472529,\n",
      "       -0.02251996,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9454401301864255, next_state=array([-0.02780895,  1.3005267 , -0.17299978, -0.4861937 ,  0.01599116,\n",
      "        0.02531982,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02780895,  1.3005267 , -0.17299978, -0.4861937 ,  0.01599116,\n",
      "        0.02531982,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0457470572448517, next_state=array([-0.02945795,  1.2889973 , -0.16442893, -0.5124241 ,  0.01553507,\n",
      "       -0.00912279,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02945795,  1.2889973 , -0.16442893, -0.5124241 ,  0.01553507,\n",
      "       -0.00912279,  0.        ,  0.        ], dtype=float32), action=2, reward=3.58006510916199, next_state=array([-0.03122539,  1.2781999 , -0.17579082, -0.47987223,  0.01458872,\n",
      "       -0.01892846,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03122539,  1.2781999 , -0.17579082, -0.47987223,  0.01458872,\n",
      "       -0.01892846,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7074470959219912, next_state=array([-0.032903  ,  1.2668072 , -0.16453137, -0.5063194 ,  0.0113862 ,\n",
      "       -0.06405628,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.032903  ,  1.2668072 , -0.16453137, -0.5063194 ,  0.0113862 ,\n",
      "       -0.06405628,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0272245879494335, next_state=array([-0.03458061,  1.2548145 , -0.16452189, -0.5329837 ,  0.00818485,\n",
      "       -0.06403277,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03458061,  1.2548145 , -0.16452189, -0.5329837 ,  0.00818485,\n",
      "       -0.06403277,  0.        ,  0.        ], dtype=float32), action=2, reward=1.55782883658689, next_state=array([-0.03635674,  1.2429638 , -0.1739302 , -0.52668226,  0.0045421 ,\n",
      "       -0.07286156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03635674,  1.2429638 , -0.1739302 , -0.52668226,  0.0045421 ,\n",
      "       -0.07286156,  0.        ,  0.        ], dtype=float32), action=2, reward=3.8939025005133887, next_state=array([-3.8281154e-02,  1.2318612e+00, -1.8808150e-01, -4.9344376e-01,\n",
      "        2.2773503e-04, -8.6294815e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-3.8281154e-02,  1.2318612e+00, -1.8808150e-01, -4.9344376e-01,\n",
      "        2.2773503e-04, -8.6294815e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=0.3055459767388243, next_state=array([-0.0403677 ,  1.2208922 , -0.20353699, -0.48752007, -0.00483995,\n",
      "       -0.10136251,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0403677 ,  1.2208922 , -0.20353699, -0.48752007, -0.00483995,\n",
      "       -0.10136251,  0.        ,  0.        ], dtype=float32), action=2, reward=0.7865510960974802, next_state=array([-0.04231567,  1.2099099 , -0.19031459, -0.48812512, -0.00927241,\n",
      "       -0.08865678,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04231567,  1.2099099 , -0.19031459, -0.48812512, -0.00927241,\n",
      "       -0.08865678,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9843189344419148, next_state=array([-0.04432821,  1.1983165 , -0.198401  , -0.5152823 , -0.01208475,\n",
      "       -0.05625187,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04432821,  1.1983165 , -0.198401  , -0.5152823 , -0.01208475,\n",
      "       -0.05625187,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.654741673597215, next_state=array([-0.04634075,  1.1861019 , -0.19840966, -0.54290324, -0.01489694,\n",
      "       -0.05624399,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04634075,  1.1861019 , -0.19840966, -0.54290324, -0.01489694,\n",
      "       -0.05624399,  0.        ,  0.        ], dtype=float32), action=2, reward=1.7381532142849607, next_state=array([-0.04845018,  1.174253  , -0.20759642, -0.5266527 , -0.01820166,\n",
      "       -0.06609444,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04845018,  1.174253  , -0.20759642, -0.5266527 , -0.01820166,\n",
      "       -0.06609444,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.462380359306137, next_state=array([-0.05048189,  1.1618078 , -0.19783871, -0.55319303, -0.02345931,\n",
      "       -0.10515286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05048189,  1.1618078 , -0.19783871, -0.55319303, -0.02345931,\n",
      "       -0.10515286,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.645050092938958, next_state=array([-0.05242901,  1.1487668 , -0.18724184, -0.5797316 , -0.03083737,\n",
      "       -0.14756146,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05242901,  1.1487668 , -0.18724184, -0.5797316 , -0.03083737,\n",
      "       -0.14756146,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9276947069242283, next_state=array([-0.05437622,  1.1351266 , -0.18724203, -0.60640275, -0.03821541,\n",
      "       -0.14756086,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05437622,  1.1351266 , -0.18724203, -0.60640275, -0.03821541,\n",
      "       -0.14756086,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8782082906298285, next_state=array([-0.05632334,  1.1208872 , -0.18724225, -0.633074  , -0.04559341,\n",
      "       -0.14755997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05632334,  1.1208872 , -0.18724225, -0.633074  , -0.04559341,\n",
      "       -0.14755997,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9294268692731567, next_state=array([-0.05835523,  1.10605   , -0.19787462, -0.65960133, -0.05084188,\n",
      "       -0.1049697 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05835523,  1.10605   , -0.19787462, -0.65960133, -0.05084188,\n",
      "       -0.1049697 ,  0.        ,  0.        ], dtype=float32), action=2, reward=2.7845487145819563, next_state=array([-0.06046715,  1.0917971 , -0.20532826, -0.6336745 , -0.05664645,\n",
      "       -0.11609115,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06046715,  1.0917971 , -0.20532826, -0.6336745 , -0.05664645,\n",
      "       -0.11609115,  0.        ,  0.        ], dtype=float32), action=2, reward=3.600885286312132, next_state=array([-0.06268978,  1.0783935 , -0.21561618, -0.5959852 , -0.063215  ,\n",
      "       -0.13137089,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06268978,  1.0783935 , -0.21561618, -0.5959852 , -0.063215  ,\n",
      "       -0.13137089,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7864296289668573, next_state=array([-0.06491232,  1.0643904 , -0.2156165 , -0.62265545, -0.06978352,\n",
      "       -0.13137053,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06491232,  1.0643904 , -0.2156165 , -0.62265545, -0.06978352,\n",
      "       -0.13137053,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7385780320880986, next_state=array([-0.06705914,  1.0497729 , -0.20610046, -0.6500942 , -0.07827348,\n",
      "       -0.1697993 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06705914,  1.0497729 , -0.20610046, -0.6500942 , -0.07827348,\n",
      "       -0.1697993 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9383248618585742, next_state=array([-0.06913795,  1.0345374 , -0.19756287, -0.6777011 , -0.08849576,\n",
      "       -0.20444568,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06913795,  1.0345374 , -0.19756287, -0.6777011 , -0.08849576,\n",
      "       -0.20444568,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.083631239752036, next_state=array([-0.07130995,  1.0187138 , -0.20925172, -0.7037653 , -0.09636609,\n",
      "       -0.15740651,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07130995,  1.0187138 , -0.20925172, -0.7037653 , -0.09636609,\n",
      "       -0.15740651,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.7231149872926312, next_state=array([-0.07341232,  1.0022869 , -0.20053652, -0.7307454 , -0.10598493,\n",
      "       -0.19237709,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07341232,  1.0022869 , -0.20053652, -0.7307454 , -0.10598493,\n",
      "       -0.19237709,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.855308794814846, next_state=array([-0.07551451,  0.9852611 , -0.20053765, -0.7574197 , -0.11560374,\n",
      "       -0.19237587,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07551451,  0.9852611 , -0.20053765, -0.7574197 , -0.11560374,\n",
      "       -0.19237587,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.867301326815748, next_state=array([-0.07753267,  0.96762246, -0.19000354, -0.78489804, -0.12735331,\n",
      "       -0.23499134,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07753267,  0.96762246, -0.19000354, -0.78489804, -0.12735331,\n",
      "       -0.23499134,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.050097153144377, next_state=array([-0.07947588,  0.94937295, -0.1806182 , -0.8123115 , -0.14100277,\n",
      "       -0.2729896 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07947588,  0.94937295, -0.1806182 , -0.8123115 , -0.14100277,\n",
      "       -0.2729896 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.3833478394325427, next_state=array([-0.08137588,  0.9318785 , -0.17592928, -0.7789257 , -0.1550414 ,\n",
      "       -0.28077275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08137588,  0.9318785 , -0.17592928, -0.7789257 , -0.1550414 ,\n",
      "       -0.28077275,  0.        ,  0.        ], dtype=float32), action=2, reward=1.8213297662167462, next_state=array([-0.08306064,  0.91469264, -0.15498906, -0.765277  , -0.16852915,\n",
      "       -0.26975498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08306064,  0.91469264, -0.15498906, -0.765277  , -0.16852915,\n",
      "       -0.26975498,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.416267034038411, next_state=array([-0.08466434,  0.8968788 , -0.14479457, -0.79356253, -0.18413192,\n",
      "       -0.31205547,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08466434,  0.8968788 , -0.14479457, -0.79356253, -0.18413192,\n",
      "       -0.31205547,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.369852754119762, next_state=array([-0.08626757,  0.8784684 , -0.14479992, -0.82024926, -0.19973442,\n",
      "       -0.31205016,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08626757,  0.8784684 , -0.14479992, -0.82024926, -0.19973442,\n",
      "       -0.31205016,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4656207351060844, next_state=array([-0.08780117,  0.8594466 , -0.1361471 , -0.8478318 , -0.21710327,\n",
      "       -0.34737724,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08780117,  0.8594466 , -0.1361471 , -0.8478318 , -0.21710327,\n",
      "       -0.34737724,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.438038080774106, next_state=array([-0.0893342 ,  0.83982867, -0.13615489, -0.87452316, -0.23447177,\n",
      "       -0.34737003,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0893342 ,  0.83982867, -0.13615489, -0.87452316, -0.23447177,\n",
      "       -0.34737003,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.6188605772508127, next_state=array([-0.09080801,  0.81958455, -0.12873395, -0.90282536, -0.25342864,\n",
      "       -0.3791377 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09080801,  0.81958455, -0.12873395, -0.90282536, -0.25342864,\n",
      "       -0.3791377 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7245616059353197, next_state=array([-0.09221029,  0.79871964, -0.11985786, -0.930977  , -0.2742458 ,\n",
      "       -0.41634393,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09221029,  0.79871964, -0.11985786, -0.930977  , -0.2742458 ,\n",
      "       -0.41634393,  0.        ,  0.        ], dtype=float32), action=2, reward=0.22066414340964685, next_state=array([-0.09334192,  0.77789944, -0.09356757, -0.92914975, -0.29439604,\n",
      "       -0.40300503,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09334192,  0.77789944, -0.09356757, -0.92914975, -0.29439604,\n",
      "       -0.40300503,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6879262392453542, next_state=array([-0.09403124,  0.75789803, -0.05010747, -0.8928746 , -0.31385708,\n",
      "       -0.38922095,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09403124,  0.75789803, -0.05010747, -0.8928746 , -0.31385708,\n",
      "       -0.38922095,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.195207518925257, next_state=array([-0.09479503,  0.7373497 , -0.05974088, -0.91695535, -0.33117986,\n",
      "       -0.34645584,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09479503,  0.7373497 , -0.05974088, -0.91695535, -0.33117986,\n",
      "       -0.34645584,  0.        ,  0.        ], dtype=float32), action=2, reward=1.6019136046405833, next_state=array([-0.0951972 ,  0.7171187 , -0.02428959, -0.9029026 , -0.34783933,\n",
      "       -0.33318967,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0951972 ,  0.7171187 , -0.02428959, -0.9029026 , -0.34783933,\n",
      "       -0.33318967,  0.        ,  0.        ], dtype=float32), action=2, reward=4.018190951570472, next_state=array([-9.5361330e-02,  6.9781655e-01, -5.4167951e-05, -8.6192256e-01,\n",
      "       -3.6507162e-01, -3.4464592e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.5361330e-02,  6.9781655e-01, -5.4167951e-05, -8.6192256e-01,\n",
      "       -3.6507162e-01, -3.4464592e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=1, reward=-2.0000213614713958, next_state=array([-0.09560633,  0.6779596 , -0.01034602, -0.88621163, -0.380057  ,\n",
      "       -0.2997079 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09560633,  0.6779596 , -0.01034602, -0.88621163, -0.380057  ,\n",
      "       -0.2997079 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.737670671127175, next_state=array([-9.5765397e-02,  6.5744591e-01,  4.5695616e-04, -9.1617608e-01,\n",
      "       -3.9751315e-01, -3.4912330e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.5765397e-02,  6.5744591e-01,  4.5695616e-04, -9.1617608e-01,\n",
      "       -3.9751315e-01, -3.4912330e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=0, reward=-2.3287162086943454, next_state=array([-9.5923424e-02,  6.3633585e-01,  4.4246446e-04, -9.4286638e-01,\n",
      "       -4.1496891e-01, -3.4911597e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), done=False), Experience(state=array([-9.5923424e-02,  6.3633585e-01,  4.4246446e-04, -9.4286638e-01,\n",
      "       -4.1496891e-01, -3.4911597e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=3, reward=-2.854741658262695, next_state=array([-0.09599743,  0.6145745 ,  0.01094118, -0.972691  , -0.43482864,\n",
      "       -0.39719483,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09599743,  0.6145745 ,  0.01094118, -0.972691  , -0.43482864,\n",
      "       -0.39719483,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4486720816700824, next_state=array([-0.09607001,  0.5922178 ,  0.01092078, -0.99938774, -0.4546878 ,\n",
      "       -0.39718404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09607001,  0.5922178 ,  0.01092078, -0.99938774, -0.4546878 ,\n",
      "       -0.39718404,  0.        ,  0.        ], dtype=float32), action=2, reward=0.918304010598672, next_state=array([-0.09594297,  0.5701157 ,  0.03098258, -0.9884187 , -0.47487518,\n",
      "       -0.40374795,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09594297,  0.5701157 ,  0.03098258, -0.9884187 , -0.47487518,\n",
      "       -0.40374795,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2384129572383074, next_state=array([-0.09560728,  0.5481297 ,  0.05181688, -0.9835455 , -0.4952127 ,\n",
      "       -0.40675086,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09560728,  0.5481297 ,  0.05181688, -0.9835455 , -0.4952127 ,\n",
      "       -0.40675086,  0.        ,  0.        ], dtype=float32), action=2, reward=2.095702850883737, next_state=array([-0.09488525,  0.5267397 ,  0.09040126, -0.9573635 , -0.5157306 ,\n",
      "       -0.41035828,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09488525,  0.5267397 ,  0.09040126, -0.9573635 , -0.5157306 ,\n",
      "       -0.41035828,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5342248218798886, next_state=array([-0.09416132,  0.5047546 ,  0.09037567, -0.9840611 , -0.53624797,\n",
      "       -0.41034642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09416132,  0.5047546 ,  0.09037567, -0.9840611 , -0.53624797,\n",
      "       -0.41034642,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1905848178276686, next_state=array([-0.09335919,  0.48211133,  0.10002594, -1.0143985 , -0.559133  ,\n",
      "       -0.45770016,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09335919,  0.48211133,  0.10002594, -1.0143985 , -0.559133  ,\n",
      "       -0.45770016,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.4311699998121683, next_state=array([-0.09247217,  0.4588056 ,  0.11041045, -1.0450966 , -0.58458596,\n",
      "       -0.5090589 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09247217,  0.4588056 ,  0.11041045, -1.0450966 , -0.58458596,\n",
      "       -0.5090589 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.033529372634773, next_state=array([-0.09165774,  0.43499422,  0.10056214, -1.0669117 , -0.60737914,\n",
      "       -0.45586306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09165774,  0.43499422,  0.10056214, -1.0669117 , -0.60737914,\n",
      "       -0.45586306,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6010670420704856, next_state=array([-0.09037266,  0.41120297,  0.14676236, -1.0660292 , -0.6294752 ,\n",
      "       -0.44192022,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09037266,  0.41120297,  0.14676236, -1.0660292 , -0.6294752 ,\n",
      "       -0.44192022,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.5933274903009635, next_state=array([-0.08915959,  0.38690615,  0.13711378, -1.0876666 , -0.64888823,\n",
      "       -0.38826087,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08915959,  0.38690615,  0.13711378, -1.0876666 , -0.64888823,\n",
      "       -0.38826087,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.1392549999156927, next_state=array([-0.08794451,  0.36201334,  0.13708554, -1.1143585 , -0.6683008 ,\n",
      "       -0.38825148,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08794451,  0.36201334,  0.13708554, -1.1143585 , -0.6683008 ,\n",
      "       -0.38825148,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0883090983625436, next_state=array([-0.08672734,  0.33652455,  0.13705656, -1.1410502 , -0.68771285,\n",
      "       -0.38824084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08672734,  0.33652455,  0.13705656, -1.1410502 , -0.68771285,\n",
      "       -0.38824084,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.844366925848816, next_state=array([-0.08544502,  0.31036007,  0.14512116, -1.1723028 , -0.70947057,\n",
      "       -0.43515438,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08544502,  0.31036007,  0.14512116, -1.1723028 , -0.70947057,\n",
      "       -0.43515438,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5240056336039458, next_state=array([-0.08380308,  0.28443262,  0.18108071, -1.1621976 , -0.7316475 ,\n",
      "       -0.4435389 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08380308,  0.28443262,  0.18108071, -1.1621976 , -0.7316475 ,\n",
      "       -0.4435389 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.1785704334072578, next_state=array([-0.0820858 ,  0.2578267 ,  0.19021705, -1.1938069 , -0.75643   ,\n",
      "       -0.49564976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0820858 ,  0.2578267 ,  0.19021705, -1.1938069 , -0.75643   ,\n",
      "       -0.49564976,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5185329902180229, next_state=array([-0.07999516,  0.23130614,  0.22726354, -1.1904056 , -0.7814062 ,\n",
      "       -0.49952635,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07999516,  0.23130614,  0.22726354, -1.1904056 , -0.7814062 ,\n",
      "       -0.49952635,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.5004222429746505, next_state=array([-0.0779006 ,  0.2041915 ,  0.22720905, -1.2171098 , -0.8063815 ,\n",
      "       -0.49950486,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0779006 ,  0.2041915 ,  0.22720905, -1.2171098 , -0.8063815 ,\n",
      "       -0.49950486,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.8143410327948277, next_state=array([-0.07584953,  0.17655152,  0.22107998, -1.2397801 , -0.82941484,\n",
      "       -0.46066585,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07584953,  0.17655152,  0.22107998, -1.2397801 , -0.82941484,\n",
      "       -0.46066585,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2497588285768757, next_state=array([-0.07344303,  0.14877577,  0.25619155, -1.2460315 , -0.85239285,\n",
      "       -0.4595601 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07344303,  0.14877577,  0.25619155, -1.2460315 , -0.85239285,\n",
      "       -0.4595601 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.3669428710931, next_state=array([-0.07097473,  0.12029565,  0.26379073, -1.2790163 , -0.8781661 ,\n",
      "       -0.5154649 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07097473,  0.12029565,  0.26379073, -1.2790163 , -0.8781661 ,\n",
      "       -0.5154649 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.082261909386648, next_state=array([-0.06794386,  0.09193999,  0.31956652, -1.2738062 , -0.90399563,\n",
      "       -0.51659244,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06794386,  0.09193999,  0.31956652, -1.2738062 , -0.90399563,\n",
      "       -0.51659244,  0.        ,  0.        ], dtype=float32), action=1, reward=7.864068361514684, next_state=array([-0.06495257,  0.06305403,  0.31395853, -1.2966663 , -0.92799824,\n",
      "       -0.48005238,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06495257,  0.06305403,  0.31395853, -1.2966663 , -0.92799824,\n",
      "       -0.48005238,  1.        ,  0.        ], dtype=float32), action=1, reward=75.50640083598617, next_state=array([-0.06227789,  0.05953532,  0.35008258, -0.3214822 , -1.0358372 ,\n",
      "       -1.9689497 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06227789,  0.05953532,  0.35008258, -0.3214822 , -1.0358372 ,\n",
      "       -1.9689497 ,  1.        ,  0.        ], dtype=float32), action=1, reward=-7.54274292744381, next_state=array([-0.05843744,  0.06308077,  0.42961273,  0.00471478, -1.1567922 ,\n",
      "       -2.291217  ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05843744,  0.06308077,  0.42961273,  0.00471478, -1.1567922 ,\n",
      "       -2.291217  ,  1.        ,  0.        ], dtype=float32), action=3, reward=-12.253930622177249, next_state=array([-0.05438881,  0.06509672,  0.4320917 , -0.02966164, -1.2767229 ,\n",
      "       -2.3378806 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05438881,  0.06509672,  0.4320917 , -0.02966164, -1.2767229 ,\n",
      "       -2.3378806 ,  1.        ,  0.        ], dtype=float32), action=1, reward=-10.954743359311008, next_state=array([-0.05036678,  0.06584538,  0.42726555, -0.04916868, -1.3909211 ,\n",
      "       -2.2763946 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05036678,  0.06584538,  0.42726555, -0.04916868, -1.3909211 ,\n",
      "       -2.2763946 ,  1.        ,  0.        ], dtype=float32), action=1, reward=-20.922541934151525, next_state=array([-0.04624891,  0.06605731,  0.4240598 , -0.06916568, -1.5025303 ,\n",
      "       -2.2287629 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04624891,  0.06605731,  0.4240598 , -0.06916568, -1.5025303 ,\n",
      "       -2.2287629 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-20.863582487188143, next_state=array([-0.0410676 ,  0.06590474,  0.5202419 , -0.08205599, -1.6141415 ,\n",
      "       -2.2341332 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0410676 ,  0.06590474,  0.5202419 , -0.08205599, -1.6141415 ,\n",
      "       -2.2341332 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-11.425565296555645, next_state=array([-0.03577938,  0.06504937,  0.518029  , -0.11427995, -1.7276988 ,\n",
      "       -2.2728465 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03577938,  0.06504937,  0.518029  , -0.11427995, -1.7276988 ,\n",
      "       -2.2728465 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-11.732402941178945, next_state=array([-0.03038225,  0.0634718 ,  0.51556623, -0.14631417, -1.8431531 ,\n",
      "       -2.3108287 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03038225,  0.0634718 ,  0.51556623, -0.14631417, -1.8431531 ,\n",
      "       -2.3108287 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-18.817338943821017, next_state=array([-0.02417879,  0.0611086 ,  0.58305377, -0.1790889 , -1.9589646 ,\n",
      "       -2.3179746 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02417879,  0.0611086 ,  0.58305377, -0.1790889 , -1.9589646 ,\n",
      "       -2.3179746 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-16.16770565638051, next_state=array([-0.01744108,  0.05802628,  0.6236688 , -0.2079821 , -2.0752733 ,\n",
      "       -2.3278985 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01744108,  0.05802628,  0.6236688 , -0.2079821 , -2.0752733 ,\n",
      "       -2.3278985 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-11.80109276527608, next_state=array([-0.01064424,  0.05413321,  0.61598355, -0.2411812 , -2.1943226 ,\n",
      "       -2.3827844 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01064424,  0.05413321,  0.61598355, -0.2411812 , -2.1943226 ,\n",
      "       -2.3827844 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-12.18323986994585, next_state=array([-0.00374823,  0.04952661,  0.61430204, -0.26729524, -2.3132374 ,\n",
      "       -2.380104  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.00374823,  0.04952661,  0.61430204, -0.26729524, -2.3132374 ,\n",
      "       -2.380104  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-12.27836315403465, next_state=array([ 0.00323706,  0.04419037,  0.61272615, -0.29327342, -2.4320204 ,\n",
      "       -2.3774648 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00323706,  0.04419037,  0.61272615, -0.29327342, -2.4320204 ,\n",
      "       -2.3774648 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-12.691830584365247, next_state=array([ 0.0103528 ,  0.03817628,  0.61811787, -0.3154456 , -2.5487316 ,\n",
      "       -2.3359516 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0103528 ,  0.03817628,  0.61811787, -0.3154456 , -2.5487316 ,\n",
      "       -2.3359516 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-12.807136190947146, next_state=array([ 0.01760521,  0.03150044,  0.62579197, -0.33662122, -2.6633444 ,\n",
      "       -2.2938259 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01760521,  0.03150044,  0.62579197, -0.33662122, -2.6633444 ,\n",
      "       -2.2938259 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-12.075014215329217, next_state=array([ 0.02483702,  0.02401272,  0.6155823 , -0.36541417, -2.7800484 ,\n",
      "       -2.335701  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02483702,  0.02401272,  0.6155823 , -0.36541417, -2.7800484 ,\n",
      "       -2.335701  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-16.767624845417277, next_state=array([ 0.03224773,  0.01481839,  0.6290256 , -0.43260768, -2.8962233 ,\n",
      "       -2.3251157 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03224773,  0.01481839,  0.6290256 , -0.43260768, -2.8962233 ,\n",
      "       -2.3251157 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-18.94210974118737, next_state=array([ 0.03984118,  0.00339951,  0.64437914, -0.52260983, -3.0119102 ,\n",
      "       -2.315339  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03984118,  0.00339951,  0.64437914, -0.52260983, -3.0119102 ,\n",
      "       -2.315339  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([ 0.04762755, -0.00790682,  0.6574842 , -0.45855072, -3.1436408 ,\n",
      "       -2.9930425 ,  0.        ,  0.        ], dtype=float32), done=True), Experience(state=array([-0.0062356 ,  1.401477  , -0.6316074 , -0.41970825,  0.00723222,\n",
      "        0.14306852,  0.        ,  0.        ], dtype=float32), action=2, reward=1.9815483177117243, next_state=array([-0.01248446,  1.3929492 , -0.6320065 , -0.3790692 ,  0.01427397,\n",
      "        0.14084917,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01248446,  1.3929492 , -0.6320065 , -0.3790692 ,  0.01427397,\n",
      "        0.14084917,  0.        ,  0.        ], dtype=float32), action=2, reward=2.0859111337631875, next_state=array([-0.01858025,  1.3849198 , -0.6174973 , -0.35696074,  0.02209742,\n",
      "        0.15648362,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.01858025,  1.3849198 , -0.6174973 , -0.35696074,  0.02209742,\n",
      "        0.15648362,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.26718396638457764, next_state=array([-0.02459745,  1.3763018 , -0.60761213, -0.38311931,  0.02792835,\n",
      "        0.11662938,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.02459745,  1.3763018 , -0.60761213, -0.38311931,  0.02792835,\n",
      "        0.11662938,  0.        ,  0.        ], dtype=float32), action=2, reward=2.225016817614784, next_state=array([-0.03055868,  1.3685304 , -0.602429  , -0.34552684,  0.03415575,\n",
      "        0.12455968,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03055868,  1.3685304 , -0.602429  , -0.34552684,  0.03415575,\n",
      "        0.12455968,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1672502705620502, next_state=array([-0.03652029,  1.360159  , -0.6024469 , -0.37220964,  0.04038145,\n",
      "        0.12452552,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.03652029,  1.360159  , -0.6024469 , -0.37220964,  0.04038145,\n",
      "        0.12452552,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4955176418906604, next_state=array([-0.04267902,  1.351849  , -0.6212951 , -0.36949614,  0.04575175,\n",
      "        0.10741578,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04267902,  1.351849  , -0.6212951 , -0.36949614,  0.04575175,\n",
      "        0.10741578,  0.        ,  0.        ], dtype=float32), action=2, reward=0.1521424690859135, next_state=array([-0.04881573,  1.3435519 , -0.6192931 , -0.36894643,  0.05131587,\n",
      "        0.11129285,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.04881573,  1.3435519 , -0.6192931 , -0.36894643,  0.05131587,\n",
      "        0.11129285,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9694144161381348, next_state=array([-0.05501642,  1.334652  , -0.62730855, -0.39581233,  0.05848388,\n",
      "        0.14337324,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.05501642,  1.334652  , -0.62730855, -0.39581233,  0.05848388,\n",
      "        0.14337324,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.515171442566269, next_state=array([-0.06131067,  1.3251451 , -0.639025  , -0.42292377,  0.06800058,\n",
      "        0.19035098,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.06131067,  1.3251451 , -0.639025  , -0.42292377,  0.06800058,\n",
      "        0.19035098,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.479036221015349, next_state=array([-0.0676053 ,  1.3150396 , -0.6390533 , -0.44959965,  0.07751507,\n",
      "        0.19030756,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.0676053 ,  1.3150396 , -0.6390533 , -0.44959965,  0.07751507,\n",
      "        0.19030756,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7152569257358892, next_state=array([-0.07398806,  1.3050334 , -0.64762   , -0.44521654,  0.08678423,\n",
      "        0.18539988,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.07398806,  1.3050334 , -0.64762   , -0.44521654,  0.08678423,\n",
      "        0.18539988,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.05897441207308701, next_state=array([-0.08052091,  1.2956208 , -0.66225153, -0.41887963,  0.09567131,\n",
      "        0.17775814,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08052091,  1.2956208 , -0.66225153, -0.41887963,  0.09567131,\n",
      "        0.17775814,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3147710614888968, next_state=array([-0.08697214,  1.2856243 , -0.65196246, -0.4447473 ,  0.10247034,\n",
      "        0.13599291,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.08697214,  1.2856243 , -0.65196246, -0.4447473 ,  0.10247034,\n",
      "        0.13599291,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9222239739454892, next_state=array([-0.09332275,  1.2757318 , -0.64260393, -0.44019163,  0.10996699,\n",
      "        0.1499467 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09332275,  1.2757318 , -0.64260393, -0.44019163,  0.10996699,\n",
      "        0.1499467 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2912976171966761, next_state=array([-0.09967365,  1.2652402 , -0.64262426, -0.46687114,  0.11746145,\n",
      "        0.14990295,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.09967365,  1.2652402 , -0.64262426, -0.46687114,  0.11746145,\n",
      "        0.14990295,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.293708595867912, next_state=array([-0.10602484,  1.254149  , -0.642645  , -0.49354362,  0.12495507,\n",
      "        0.14988585,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.10602484,  1.254149  , -0.642645  , -0.49354362,  0.12495507,\n",
      "        0.14988585,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1309356568469853, next_state=array([-0.11244021,  1.2424537 , -0.6506734 , -0.52057964,  0.13405675,\n",
      "        0.18205021,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11244021,  1.2424537 , -0.6506734 , -0.52057964,  0.13405675,\n",
      "        0.18205021,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.1080618438476108, next_state=array([-0.11906872,  1.2313741 , -0.67149615, -0.4932191 ,  0.14267522,\n",
      "        0.17238533,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.11906872,  1.2313741 , -0.67149615, -0.4932191 ,  0.14267522,\n",
      "        0.17238533,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6366021144303204, next_state=array([-0.12573728,  1.2202247 , -0.6755378 , -0.4963809 ,  0.1513437 ,\n",
      "        0.17338529,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.12573728,  1.2202247 , -0.6755378 , -0.4963809 ,  0.1513437 ,\n",
      "        0.17338529,  0.        ,  0.        ], dtype=float32), action=2, reward=0.4564145493024057, next_state=array([-0.1324772 ,  1.2095585 , -0.68283504, -0.47497216,  0.16019022,\n",
      "        0.17694642,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1324772 ,  1.2095585 , -0.68283504, -0.47497216,  0.16019022,\n",
      "        0.17694642,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3294555925365603, next_state=array([-0.13913374,  1.1983032 , -0.6723763 , -0.5009653 ,  0.1669211 ,\n",
      "        0.13462958,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.13913374,  1.1983032 , -0.6723763 , -0.5009653 ,  0.1669211 ,\n",
      "        0.13462958,  0.        ,  0.        ], dtype=float32), action=2, reward=0.2135995425942781, next_state=array([-0.14584741,  1.1873026 , -0.6782565 , -0.48970395,  0.17383057,\n",
      "        0.1382021 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.14584741,  1.1873026 , -0.6782565 , -0.48970395,  0.17383057,\n",
      "        0.1382021 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2146378556528248, next_state=array([-0.15256138,  1.1757023 , -0.6782729 , -0.5163853 ,  0.18073845,\n",
      "        0.13816985,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15256138,  1.1757023 , -0.6782729 , -0.5163853 ,  0.18073845,\n",
      "        0.13816985,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.213235384195542, next_state=array([-0.15927562,  1.1635025 , -0.6782914 , -0.5430586 ,  0.18764538,\n",
      "        0.13815072,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.15927562,  1.1635025 , -0.6782914 , -0.5430586 ,  0.18764538,\n",
      "        0.13815072,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.27024574856989, next_state=array([-0.1660616 ,  1.150659  , -0.6873952 , -0.5719722 ,  0.1964846 ,\n",
      "        0.17678444,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1660616 ,  1.150659  , -0.6873952 , -0.5719722 ,  0.1964846 ,\n",
      "        0.17678444,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3825771314624546, next_state=array([-0.17284766,  1.1372161 , -0.68739337, -0.5986453 ,  0.20532374,\n",
      "        0.1767833 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.17284766,  1.1372161 , -0.68739337, -0.5986453 ,  0.20532374,\n",
      "        0.1767833 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4022726606967795, next_state=array([-0.1797081 ,  1.1231439 , -0.69674724, -0.62695545,  0.21612339,\n",
      "        0.21599312,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.1797081 ,  1.1231439 , -0.69674724, -0.62695545,  0.21612339,\n",
      "        0.21599312,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8059104068248064, next_state=array([-0.18651095,  1.1084974 , -0.68944514, -0.65233314,  0.2253899 ,\n",
      "        0.18533027,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.18651095,  1.1084974 , -0.68944514, -0.65233314,  0.2253899 ,\n",
      "        0.18533027,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.243534041745049, next_state=array([-0.19337901,  1.0932345 , -0.69759446, -0.6800309 ,  0.23633394,\n",
      "        0.21888085,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.19337901,  1.0932345 , -0.69759446, -0.6800309 ,  0.23633394,\n",
      "        0.21888085,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.353067797454058, next_state=array([-0.20030637,  1.077346  , -0.70505404, -0.7081774 ,  0.24886112,\n",
      "        0.25054377,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20030637,  1.077346  , -0.70505404, -0.7081774 ,  0.24886112,\n",
      "        0.25054377,  0.        ,  0.        ], dtype=float32), action=2, reward=1.1452885230696495, next_state=array([-0.20744029,  1.0624002 , -0.72591233, -0.6664251 ,  0.26163274,\n",
      "        0.25543216,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.20744029,  1.0624002 , -0.72591233, -0.6664251 ,  0.26163274,\n",
      "        0.25543216,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8456956744083175, next_state=array([-0.2145061 ,  1.0468817 , -0.71730214, -0.69166005,  0.27259842,\n",
      "        0.21931347,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2145061 ,  1.0468817 , -0.71730214, -0.69166005,  0.27259842,\n",
      "        0.21931347,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5339412620408268, next_state=array([-0.2215722 ,  1.0307646 , -0.71729815, -0.71833634,  0.283564  ,\n",
      "        0.21931167,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2215722 ,  1.0307646 , -0.71729815, -0.71833634,  0.283564  ,\n",
      "        0.21931167,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7628847266390992, next_state=array([-0.22873072,  1.01401   , -0.7288932 , -0.7472441 ,  0.29699552,\n",
      "        0.26863018,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.22873072,  1.01401   , -0.7288932 , -0.7472441 ,  0.29699552,\n",
      "        0.26863018,  0.        ,  0.        ], dtype=float32), action=2, reward=0.5459210423372383, next_state=array([-0.23593621,  0.99764013, -0.73419344, -0.7303957 ,  0.31110722,\n",
      "        0.2822346 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.23593621,  0.99764013, -0.73419344, -0.7303957 ,  0.31110722,\n",
      "        0.2822346 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.5310106325188599, next_state=array([-0.2431941 ,  0.9813399 , -0.7397543 , -0.7275212 ,  0.32561967,\n",
      "        0.29024914,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2431941 ,  0.9813399 , -0.7397543 , -0.7275212 ,  0.32561967,\n",
      "        0.29024914,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7096626092592533, next_state=array([-0.25036198,  0.9644809 , -0.7283553 , -0.7519341 ,  0.33769637,\n",
      "        0.24153431,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25036198,  0.9644809 , -0.7283553 , -0.7519341 ,  0.33769637,\n",
      "        0.24153431,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6886125388084452, next_state=array([-0.25778455,  0.9476501 , -0.7533347 , -0.7506724 ,  0.34930226,\n",
      "        0.23211758,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.25778455,  0.9476501 , -0.7533347 , -0.7506724 ,  0.34930226,\n",
      "        0.23211758,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7639001969415335, next_state=array([-0.2651453 ,  0.9302525 , -0.74547106, -0.77553856,  0.3591953 ,\n",
      "        0.19786073,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2651453 ,  0.9302525 , -0.74547106, -0.77553856,  0.3591953 ,\n",
      "        0.19786073,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4063273454605962, next_state=array([-0.27250633,  0.9122562 , -0.7454668 , -0.80221283,  0.36908826,\n",
      "        0.19785939,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27250633,  0.9122562 , -0.7454668 , -0.80221283,  0.36908826,\n",
      "        0.19785939,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.352601666290694, next_state=array([-0.27993304,  0.8936164 , -0.7537865 , -0.83135265,  0.3808722 ,\n",
      "        0.23567858,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.27993304,  0.8936164 , -0.7537865 , -0.83135265,  0.3808722 ,\n",
      "        0.23567858,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.563462868590591, next_state=array([-0.28736025,  0.87437814, -0.75378007, -0.85803014,  0.392656  ,\n",
      "        0.23567633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.28736025,  0.87437814, -0.75378007, -0.85803014,  0.392656  ,\n",
      "        0.23567633,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1955017631763554, next_state=array([-0.2949931 ,  0.85515404, -0.7741476 , -0.85744417,  0.4042851 ,\n",
      "        0.23258238,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.2949931 ,  0.85515404, -0.7741476 , -0.85744417,  0.4042851 ,\n",
      "        0.23258238,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.40349235242623993, next_state=array([-0.30254072,  0.8353818 , -0.763321  , -0.88123876,  0.4134937 ,\n",
      "        0.18417168,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.30254072,  0.8353818 , -0.763321  , -0.88123876,  0.4134937 ,\n",
      "        0.18417168,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.473056949150066, next_state=array([-0.31058234,  0.81602615, -0.81192017, -0.8625449 ,  0.42186838,\n",
      "        0.16749397,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31058234,  0.81602615, -0.81192017, -0.8625449 ,  0.42186838,\n",
      "        0.16749397,  0.        ,  0.        ], dtype=float32), action=2, reward=0.53015805799144, next_state=array([-0.31894392,  0.79747814, -0.8442731 , -0.8268172 ,  0.43066934,\n",
      "        0.17601934,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.31894392,  0.79747814, -0.8442731 , -0.8268172 ,  0.43066934,\n",
      "        0.17601934,  0.        ,  0.        ], dtype=float32), action=2, reward=0.6450112270894521, next_state=array([-0.32753268,  0.7796834 , -0.8676831 , -0.79360205,  0.44025677,\n",
      "        0.19174856,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.32753268,  0.7796834 , -0.8676831 , -0.79360205,  0.44025677,\n",
      "        0.19174856,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8814058926625308, next_state=array([-0.33641538,  0.7619648 , -0.8967258 , -0.7901838 ,  0.44950184,\n",
      "        0.18490185,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.33641538,  0.7619648 , -0.8967258 , -0.7901838 ,  0.44950184,\n",
      "        0.18490185,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8166816264855357, next_state=array([-0.3455461 ,  0.74424577, -0.921278  , -0.79017985,  0.45851684,\n",
      "        0.18030001,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3455461 ,  0.74424577, -0.921278  , -0.79017985,  0.45851684,\n",
      "        0.18030001,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.596983905710799, next_state=array([-0.35475025,  0.725861  , -0.93067056, -0.8205145 ,  0.469832  ,\n",
      "        0.22630349,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.35475025,  0.725861  , -0.93067056, -0.8205145 ,  0.469832  ,\n",
      "        0.22630349,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6270174603450585, next_state=array([-0.36395493,  0.70687765, -0.9306634 , -0.84719074,  0.48114708,\n",
      "        0.2263015 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.36395493,  0.70687765, -0.9306634 , -0.84719074,  0.48114708,\n",
      "        0.2263015 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.9221373322996442, next_state=array([-0.37353525,  0.6886647 , -0.9685376 , -0.81316537,  0.49287635,\n",
      "        0.2345852 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.37353525,  0.6886647 , -0.9685376 , -0.81316537,  0.49287635,\n",
      "        0.2345852 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.951049550667277, next_state=array([-0.38319272,  0.66979283, -0.9782578 , -0.8433029 ,  0.50694036,\n",
      "        0.2812808 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.38319272,  0.66979283, -0.9782578 , -0.8433029 ,  0.50694036,\n",
      "        0.2812808 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3778272162634722, next_state=array([-0.3931532 ,  0.65151274, -1.0089443 , -0.817296  ,  0.521563  ,\n",
      "        0.29245305,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.3931532 ,  0.65151274, -1.0089443 , -0.817296  ,  0.521563  ,\n",
      "        0.29245305,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2516255519825268, next_state=array([-0.4030613 ,  0.6326818 , -1.0021489 , -0.841334  ,  0.53451014,\n",
      "        0.25894246,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4030613 ,  0.6326818 , -1.0021489 , -0.841334  ,  0.53451014,\n",
      "        0.25894246,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.942689739643015, next_state=array([-0.41297024,  0.6132526 , -1.0021383 , -0.8680127 ,  0.5474571 ,\n",
      "        0.25893945,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.41297024,  0.6132526 , -1.0021383 , -0.8680127 ,  0.5474571 ,\n",
      "        0.25893945,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9738780425612958, next_state=array([-0.42287987,  0.5932253 , -1.0021273 , -0.8946914 ,  0.56040394,\n",
      "        0.25893643,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.42287987,  0.5932253 , -1.0021273 , -0.8946914 ,  0.56040394,\n",
      "        0.25893643,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.008922197869765, next_state=array([-0.43279037,  0.5726    , -1.0021162 , -0.9213699 ,  0.5733506 ,\n",
      "        0.2589334 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.43279037,  0.5726    , -1.0021162 , -0.9213699 ,  0.5733506 ,\n",
      "        0.2589334 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.143137182687126, next_state=array([-0.4426442 ,  0.5514315 , -0.9947755 , -0.94490546,  0.5844201 ,\n",
      "        0.22138944,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.4426442 ,  0.5514315 , -0.9947755 , -0.94490546,  0.5844201 ,\n",
      "        0.22138944,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.8145789931305556, next_state=array([-0.45305222,  0.5308443 , -1.0500134 , -0.9190944 ,  0.5953603 ,\n",
      "        0.21880396,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.45305222,  0.5308443 , -1.0500134 , -0.9190944 ,  0.5953603 ,\n",
      "        0.21880396,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9628724579139885, next_state=array([-0.46346083,  0.5096584 , -1.0500051 , -0.94576937,  0.6063004 ,\n",
      "        0.21880217,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.46346083,  0.5096584 , -1.0500051 , -0.94576937,  0.6063004 ,\n",
      "        0.21880217,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0177093504366894, next_state=array([-0.47386998,  0.4878738 , -1.0499966 , -0.97244436,  0.6172404 ,\n",
      "        0.2188004 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.47386998,  0.4878738 , -1.0499966 , -0.97244436,  0.6172404 ,\n",
      "        0.2188004 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.8893630972663573, next_state=array([-0.48460174,  0.46651384, -1.0826802 , -0.95387685,  0.6287919 ,\n",
      "        0.23103008,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.48460174,  0.46651384, -1.0826802 , -0.95387685,  0.6287919 ,\n",
      "        0.23103008,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4241364704228932, next_state=array([-0.49528533,  0.44460684, -1.0764285 , -0.9775911 ,  0.63867456,\n",
      "        0.1976521 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.49528533,  0.44460684, -1.0764285 , -0.9775911 ,  0.63867456,\n",
      "        0.1976521 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.069693431229182, next_state=array([-0.5059085 ,  0.42217627, -1.0685308 , -1.0000105 ,  0.64633036,\n",
      "        0.15311566,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5059085 ,  0.42217627, -1.0685308 , -1.0000105 ,  0.64633036,\n",
      "        0.15311566,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8196336440223877, next_state=array([-0.51646525,  0.39922988, -1.0598723 , -1.0219595 ,  0.6515283 ,\n",
      "        0.10395827,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.51646525,  0.39922988, -1.0598723 , -1.0219595 ,  0.6515283 ,\n",
      "        0.10395827,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.896280051020567, next_state=array([-0.5270862 ,  0.37562314, -1.0679739 , -1.0521916 ,  0.6588324 ,\n",
      "        0.1460817 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5270862 ,  0.37562314, -1.0679739 , -1.0521916 ,  0.6588324 ,\n",
      "        0.1460817 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0133690799055148, next_state=array([-0.53764427,  0.35149848, -1.0597548 , -1.0742533 ,  0.6637698 ,\n",
      "        0.0987478 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.53764427,  0.35149848, -1.0597548 , -1.0742533 ,  0.6637698 ,\n",
      "        0.0987478 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2152389327451647, next_state=array([-0.5481548 ,  0.32682574, -1.0536635 , -1.0979375 ,  0.66705245,\n",
      "        0.06565303,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5481548 ,  0.32682574, -1.0536635 , -1.0979375 ,  0.66705245,\n",
      "        0.06565303,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.1261029182704645, next_state=array([-0.5592767 ,  0.30265132, -1.1146965 , -1.0757377 ,  0.6702078 ,\n",
      "        0.0631066 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5592767 ,  0.30265132, -1.1146965 , -1.0757377 ,  0.6702078 ,\n",
      "        0.0631066 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.993797440838107, next_state=array([-0.57033515,  0.27794474, -1.1066135 , -1.0984787 ,  0.6711738 ,\n",
      "        0.01932019,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.57033515,  0.27794474, -1.1066135 , -1.0984787 ,  0.6711738 ,\n",
      "        0.01932019,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9924708135034053, next_state=array([-0.581617  ,  0.25325677, -1.1292446 , -1.0978084 ,  0.6725168 ,\n",
      "        0.02686   ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.581617  ,  0.25325677, -1.1292446 , -1.0978084 ,  0.6725168 ,\n",
      "        0.02686   ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0897632709273353, next_state=array([-0.5928988 ,  0.22796875, -1.1292444 , -1.1244751 ,  0.67385983,\n",
      "        0.02686043,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.5928988 ,  0.22796875, -1.1292444 , -1.1244751 ,  0.67385983,\n",
      "        0.02686043,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.213442002728357, next_state=array([-0.6041806 ,  0.20208086, -1.1292443 , -1.1511419 ,  0.67520285,\n",
      "        0.02685976,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6041806 ,  0.20208086, -1.1292443 , -1.1511419 ,  0.67520285,\n",
      "        0.02685976,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.342725079605316, next_state=array([-0.6154624 ,  0.17559285, -1.1292442 , -1.1778086 ,  0.67654586,\n",
      "        0.02686033,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6154624 ,  0.17559285, -1.1292442 , -1.1778086 ,  0.67654586,\n",
      "        0.02686033,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4772011251951653, next_state=array([-0.6267443 ,  0.14850499, -1.1292442 , -1.2044754 ,  0.6778889 ,\n",
      "        0.02685983,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6267443 ,  0.14850499, -1.1292442 , -1.2044754 ,  0.6778889 ,\n",
      "        0.02685983,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5894812782862846, next_state=array([-0.63796836,  0.12089468, -1.1217258 , -1.2267545 ,  0.67701954,\n",
      "       -0.0173871 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.63796836,  0.12089468, -1.1217258 , -1.2267545 ,  0.67701954,\n",
      "       -0.0173871 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7810896259943434, next_state=array([-0.64936405,  0.09341105, -1.1394998 , -1.2214589 ,  0.6769349 ,\n",
      "       -0.00169328,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.64936405,  0.09341105, -1.1394998 , -1.2214589 ,  0.6769349 ,\n",
      "       -0.00169328,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.960933364961106, next_state=array([-0.6608318 ,  0.06525372, -1.1486397 , -1.2524395 ,  0.67929715,\n",
      "        0.04724498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.6608318 ,  0.06525372, -1.1486397 , -1.2524395 ,  0.67929715,\n",
      "        0.04724498,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.916224096152905, next_state=array([-0.67277   ,  0.03770014, -1.1961861 , -1.225879  ,  0.68229747,\n",
      "        0.06000693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.67277   ,  0.03770014, -1.1961861 , -1.225879  ,  0.68229747,\n",
      "        0.06000693,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.6338752985923746, next_state=array([-0.68520945,  0.01070596, -1.2466552 , -1.201215  ,  0.6857521 ,\n",
      "        0.06909286,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.68520945,  0.01070596, -1.2466552 , -1.201215  ,  0.6857521 ,\n",
      "        0.06909286,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.4623100926309576, next_state=array([-0.69764894, -0.01688811, -1.2466543 , -1.2278824 ,  0.6892067 ,\n",
      "        0.06909306,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.69764894, -0.01688811, -1.2466543 , -1.2278824 ,  0.6892067 ,\n",
      "        0.06909306,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.5934006420881133, next_state=array([-0.7100885 , -0.04508202, -1.2466533 , -1.2545497 ,  0.6926614 ,\n",
      "        0.06909339,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7100885 , -0.04508202, -1.2466533 , -1.2545497 ,  0.6926614 ,\n",
      "        0.06909339,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.971316349644012, next_state=array([-0.7225932 , -0.07396566, -1.2551262 , -1.2863076 ,  0.69865   ,\n",
      "        0.11977191,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.7225932 , -0.07396566, -1.2551262 , -1.2863076 ,  0.69865   ,\n",
      "        0.11977191,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.114223069969398, next_state=array([-0.73509806, -0.1034489 , -1.2551234 , -1.3129765 ,  0.70463854,\n",
      "        0.119771  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([-0.73509806, -0.1034489 , -1.2551234 , -1.3129765 ,  0.70463854,\n",
      "        0.119771  ,  0.        ,  0.        ], dtype=float32), action=3, reward=6.95228575589178, next_state=array([-0.7475345 , -0.13344596, -1.2462928 , -1.3347083 ,  0.70807254,\n",
      "        0.06868009,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.7475345 , -0.13344596, -1.2462928 , -1.3347083 ,  0.70807254,\n",
      "        0.06868009,  0.        ,  1.        ], dtype=float32), action=1, reward=1.566693437072588, next_state=array([-0.76012266, -0.1626181 , -1.2539338 , -1.29484   ,  0.6977613 ,\n",
      "       -0.21253558,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.76012266, -0.1626181 , -1.2539338 , -1.29484   ,  0.6977613 ,\n",
      "       -0.21253558,  0.        ,  1.        ], dtype=float32), action=1, reward=-3.092617097814325, next_state=array([-0.77298343, -0.19180104, -1.2731459 , -1.3081313 ,  0.68636775,\n",
      "       -0.24928236,  0.        ,  1.        ], dtype=float32), done=False), Experience(state=array([-0.77298343, -0.19180104, -1.2731459 , -1.3081313 ,  0.68636775,\n",
      "       -0.24928236,  0.        ,  1.        ], dtype=float32), action=1, reward=-100, next_state=array([-0.7818128 , -0.18732773, -1.0236079 , -0.01667886,  0.8036876 ,\n",
      "        1.7223635 ,  0.        ,  1.        ], dtype=float32), done=True), Experience(state=array([ 1.3128280e-03,  1.3983423e+00,  1.3295624e-01, -5.5902034e-01,\n",
      "       -1.5144291e-03, -3.0116593e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), action=2, reward=2.512618616418462, next_state=array([ 0.00269451,  1.3861973 ,  0.1393436 , -0.5397734 , -0.00267575,\n",
      "       -0.02322799,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00269451,  1.3861973 ,  0.1393436 , -0.5397734 , -0.00267575,\n",
      "       -0.02322799,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8601619925995283, next_state=array([ 0.0041503 ,  1.3734556 ,  0.14863122, -0.56630695, -0.00569791,\n",
      "       -0.06044884,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0041503 ,  1.3734556 ,  0.14863122, -0.56630695, -0.00569791,\n",
      "       -0.06044884,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.551932324939969, next_state=array([ 0.00560617,  1.3601141 ,  0.14864066, -0.59297556, -0.00871871,\n",
      "       -0.0604213 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00560617,  1.3601141 ,  0.14864066, -0.59297556, -0.00871871,\n",
      "       -0.0604213 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.952871913273184, next_state=array([ 0.00713644,  1.34617   ,  0.15797481, -0.6197799 , -0.01360972,\n",
      "       -0.09782928,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00713644,  1.34617   ,  0.15797481, -0.6197799 , -0.01360972,\n",
      "       -0.09782928,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6234743316218783, next_state=array([ 0.0086669 ,  1.3316259 ,  0.15798958, -0.64645016, -0.01849912,\n",
      "       -0.09779742,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0086669 ,  1.3316259 ,  0.15798958, -0.64645016, -0.01849912,\n",
      "       -0.09779742,  0.        ,  0.        ], dtype=float32), action=2, reward=0.880300163790747, next_state=array([ 0.01020088,  1.3171363 ,  0.15837017, -0.644055  , -0.02341016,\n",
      "       -0.09822997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01020088,  1.3171363 ,  0.15837017, -0.644055  , -0.02341016,\n",
      "       -0.09822997,  0.        ,  0.        ], dtype=float32), action=2, reward=2.5973849760194243, next_state=array([ 0.01158361,  1.3030472 ,  0.14404264, -0.62628675, -0.02911608,\n",
      "       -0.1141289 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01158361,  1.3030472 ,  0.14404264, -0.62628675, -0.02911608,\n",
      "       -0.1141289 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.5879298212643507, next_state=array([ 0.01289911,  1.2896569 ,  0.1377551 , -0.59525895, -0.03526114,\n",
      "       -0.12291221,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01289911,  1.2896569 ,  0.1377551 , -0.59525895, -0.03526114,\n",
      "       -0.12291221,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.4608790396483176, next_state=array([ 0.0141469 ,  1.2756746 ,  0.12925196, -0.6215392 , -0.03969279,\n",
      "       -0.08864097,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0141469 ,  1.2756746 ,  0.12925196, -0.6215392 , -0.03969279,\n",
      "       -0.08864097,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.1438378131894342, next_state=array([ 0.01529608,  1.261093  ,  0.11690476, -0.6481279 , -0.04164791,\n",
      "       -0.0391059 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01529608,  1.261093  ,  0.11690476, -0.6481279 , -0.04164791,\n",
      "       -0.0391059 ,  0.        ,  0.        ], dtype=float32), action=2, reward=3.940733324995233, next_state=array([ 0.01666479,  1.247289  ,  0.13798346, -0.61354154, -0.04274664,\n",
      "       -0.02197652,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01666479,  1.247289  ,  0.13798346, -0.61354154, -0.04274664,\n",
      "       -0.02197652,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2771897008653355, next_state=array([ 0.0180336 ,  1.2328848 ,  0.13798586, -0.6402219 , -0.04384535,\n",
      "       -0.02197601,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0180336 ,  1.2328848 ,  0.13798586, -0.6402219 , -0.04384535,\n",
      "       -0.02197601,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7730849775585671, next_state=array([ 0.01930447,  1.2178774 ,  0.12571213, -0.6669549 , -0.04248649,\n",
      "        0.02717982,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01930447,  1.2178774 ,  0.12571213, -0.6669549 , -0.04248649,\n",
      "        0.02717982,  0.        ,  0.        ], dtype=float32), action=2, reward=1.632476424173842, next_state=array([ 0.0206111 ,  1.2029535 ,  0.12921068, -0.6632407 , -0.0410514 ,\n",
      "        0.02870453,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0206111 ,  1.2029535 ,  0.12921068, -0.6632407 , -0.0410514 ,\n",
      "        0.02870453,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6271161515234087, next_state=array([ 0.02184629,  1.1874263 ,  0.12026168, -0.69000655, -0.03782653,\n",
      "        0.06450301,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02184629,  1.1874263 ,  0.12026168, -0.69000655, -0.03782653,\n",
      "        0.06450301,  0.        ,  0.        ], dtype=float32), action=2, reward=5.201443412026191, next_state=array([ 0.02323036,  1.1728005 ,  0.13462879, -0.6499391 , -0.03408105,\n",
      "        0.07491649,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00396252,  1.4200824 ,  0.40133458,  0.40720975, -0.00458469,\n",
      "       -0.09090825,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.1986320657174643, next_state=array([ 0.00796814,  1.4296405 ,  0.4049139 ,  0.4247871 , -0.00888301,\n",
      "       -0.08597364,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.00796814,  1.4296405 ,  0.4049139 ,  0.4247871 , -0.00888301,\n",
      "       -0.08597364,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.21251884472419988, next_state=array([ 0.01203852,  1.438603  ,  0.413016  ,  0.39828724, -0.01480053,\n",
      "       -0.11836141,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01203852,  1.438603  ,  0.413016  ,  0.39828724, -0.01480053,\n",
      "       -0.11836141,  0.        ,  0.        ], dtype=float32), action=0, reward=0.38486804586125345, next_state=array([ 0.01610899,  1.446966  ,  0.41303474,  0.37161788, -0.02071648,\n",
      "       -0.11832972,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.01610899,  1.446966  ,  0.41303474,  0.37161788, -0.02071648,\n",
      "       -0.11832972,  0.        ,  0.        ], dtype=float32), action=1, reward=1.1850604370131077, next_state=array([ 0.02010679,  1.4547428 ,  0.40389457,  0.3455712 , -0.02479088,\n",
      "       -0.08149569,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02010679,  1.4547428 ,  0.40389457,  0.3455712 , -0.02479088,\n",
      "       -0.08149569,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5619044079309674, next_state=array([ 0.02410469,  1.4619198 ,  0.40390563,  0.3189017 , -0.02886545,\n",
      "       -0.08149902,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02410469,  1.4619198 ,  0.40390563,  0.3189017 , -0.02886545,\n",
      "       -0.08149902,  0.        ,  0.        ], dtype=float32), action=1, reward=1.371937937657209, next_state=array([ 0.02803383,  1.4684973 ,  0.39528817,  0.2922887 , -0.0312088 ,\n",
      "       -0.04687126,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.02803383,  1.4684973 ,  0.39528817,  0.2922887 , -0.0312088 ,\n",
      "       -0.04687126,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.3089580964517211, next_state=array([ 0.03199244,  1.4750334 ,  0.39815208,  0.29044244, -0.03346751,\n",
      "       -0.04517857,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03199244,  1.4750334 ,  0.39815208,  0.29044244, -0.03346751,\n",
      "       -0.04517857,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5629512750629704, next_state=array([ 0.03604641,  1.4809664 ,  0.41008538,  0.26357487, -0.03811765,\n",
      "       -0.0930116 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.03604641,  1.4809664 ,  0.41008538,  0.26357487, -0.03811765,\n",
      "       -0.0930116 ,  0.        ,  0.        ], dtype=float32), action=1, reward=1.1857515735039226, next_state=array([ 0.04003735,  1.4863013 ,  0.402186  ,  0.23701786, -0.04117903,\n",
      "       -0.0612335 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04003735,  1.4863013 ,  0.402186  ,  0.23701786, -0.04117903,\n",
      "       -0.0612335 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.2607058488974188, next_state=array([ 0.04415178,  1.4921083 ,  0.41409698,  0.25801376, -0.04379499,\n",
      "       -0.0523238 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04415178,  1.4921083 ,  0.41409698,  0.25801376, -0.04379499,\n",
      "       -0.0523238 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7731050233747101, next_state=array([ 0.04836292,  1.4973173 ,  0.42620984,  0.23135976, -0.04883439,\n",
      "       -0.10079739,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.04836292,  1.4973173 ,  0.42620984,  0.23135976, -0.04883439,\n",
      "       -0.10079739,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9744105046888647, next_state=array([ 0.05274811,  1.5030718 ,  0.4429562 ,  0.25559464, -0.05322687,\n",
      "       -0.08785771,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05274811,  1.5030718 ,  0.4429562 ,  0.25559464, -0.05322687,\n",
      "       -0.08785771,  0.        ,  0.        ], dtype=float32), action=1, reward=1.2216489015954732, next_state=array([ 0.05706396,  1.5082266 ,  0.43425232,  0.22900605, -0.05587365,\n",
      "       -0.05294017,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.05706396,  1.5082266 ,  0.43425232,  0.22900605, -0.05587365,\n",
      "       -0.05294017,  0.        ,  0.        ], dtype=float32), action=1, reward=1.388554828104817, next_state=array([ 0.06130876,  1.5127879 ,  0.42534685,  0.20268758, -0.05672968,\n",
      "       -0.01712235,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06130876,  1.5127879 ,  0.42534685,  0.20268758, -0.05672968,\n",
      "       -0.01712235,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5334017544667222, next_state=array([ 0.06563149,  1.516744  ,  0.43511385,  0.17571594, -0.05954631,\n",
      "       -0.05633815,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.06563149,  1.516744  ,  0.43511385,  0.17571594, -0.05954631,\n",
      "       -0.05633815,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7523674067853949, next_state=array([ 0.07002668,  1.5200839 ,  0.44421086,  0.14824551, -0.06419732,\n",
      "       -0.09302825,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07002668,  1.5200839 ,  0.44421086,  0.14824551, -0.06419732,\n",
      "       -0.09302825,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0317607053318898, next_state=array([ 0.0744916 ,  1.522826  ,  0.4529361 ,  0.12157943, -0.07058918,\n",
      "       -0.12784863,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.0744916 ,  1.522826  ,  0.4529361 ,  0.12157943, -0.07058918,\n",
      "       -0.12784863,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8028505780469868, next_state=array([ 0.07888212,  1.5249791 ,  0.4436058 ,  0.0954731 , -0.07509594,\n",
      "       -0.09014384,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.07888212,  1.5249791 ,  0.4436058 ,  0.0954731 , -0.07509594,\n",
      "       -0.09014384,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.144872735591548, next_state=array([ 0.08327293,  1.5265325 ,  0.44361696,  0.06880223, -0.07960322,\n",
      "       -0.09015324,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08327293,  1.5265325 ,  0.44361696,  0.06880223, -0.07960322,\n",
      "       -0.09015324,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.0562720745503384, next_state=array([ 0.08762884,  1.5285261 ,  0.44055662,  0.08832886, -0.08452878,\n",
      "       -0.09851999,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.08762884,  1.5285261 ,  0.44055662,  0.08832886, -0.08452878,\n",
      "       -0.09851999,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2108834978350842, next_state=array([ 0.09198494,  1.5299197 ,  0.4405695 ,  0.06164934, -0.08945319,\n",
      "       -0.09849693,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09198494,  1.5299197 ,  0.4405695 ,  0.06164934, -0.08945319,\n",
      "       -0.09849693,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.30919059995559905, next_state=array([ 0.09634123,  1.5307137 ,  0.44058338,  0.03498161, -0.0943771 ,\n",
      "       -0.09848653,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.09634123,  1.5307137 ,  0.44058338,  0.03498161, -0.0943771 ,\n",
      "       -0.09848653,  0.        ,  0.        ], dtype=float32), action=1, reward=0.8999360010426198, next_state=array([ 0.10060863,  1.5309198 ,  0.42942572,  0.00898446, -0.09704832,\n",
      "       -0.05342865,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10060863,  1.5309198 ,  0.42942572,  0.00898446, -0.09704832,\n",
      "       -0.05342865,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.491510801248238, next_state=array([ 0.10495396,  1.5305109 ,  0.43921226, -0.01848057, -0.10169902,\n",
      "       -0.09302277,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10495396,  1.5305109 ,  0.43921226, -0.01848057, -0.10169902,\n",
      "       -0.09302277,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5816336012668728, next_state=array([ 0.10929795,  1.5294809 ,  0.439078  , -0.04610093, -0.10634876,\n",
      "       -0.09299423,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.10929795,  1.5294809 ,  0.439078  , -0.04610093, -0.10634876,\n",
      "       -0.09299423,  0.        ,  0.        ], dtype=float32), action=1, reward=0.5954204792306836, next_state=array([ 0.11355457,  1.5278677 ,  0.42811352, -0.07188201, -0.1087795 ,\n",
      "       -0.04861473,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11355457,  1.5278677 ,  0.42811352, -0.07188201, -0.1087795 ,\n",
      "       -0.04861473,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4004853225202283, next_state=array([ 0.11794786,  1.526956  ,  0.44158038, -0.04068267, -0.11101717,\n",
      "       -0.04475313,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.11794786,  1.526956  ,  0.44158038, -0.04068267, -0.11101717,\n",
      "       -0.04475313,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.642181911161315, next_state=array([ 0.12241936,  1.52543   ,  0.45140275, -0.06814096, -0.11524293,\n",
      "       -0.08451541,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12241936,  1.52543   ,  0.45140275, -0.06814096, -0.11524293,\n",
      "       -0.08451541,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.720638864598385, next_state=array([ 0.12689085,  1.5233043 ,  0.45140252, -0.09480911, -0.1194687 ,\n",
      "       -0.08451523,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.12689085,  1.5233043 ,  0.45140252, -0.09480911, -0.1194687 ,\n",
      "       -0.08451523,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6913107662553444, next_state=array([ 0.13141164,  1.5217261 ,  0.45652276, -0.07050015, -0.12388945,\n",
      "       -0.08841474,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13141164,  1.5217261 ,  0.45652276, -0.07050015, -0.12388945,\n",
      "       -0.08841474,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4536607394651242, next_state=array([ 0.13604517,  1.5207919 ,  0.4677468 , -0.04189283, -0.12826622,\n",
      "       -0.08753522,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.13604517,  1.5207919 ,  0.4677468 , -0.04189283, -0.12826622,\n",
      "       -0.08753522,  0.        ,  0.        ], dtype=float32), action=1, reward=0.803668907099053, next_state=array([ 0.14058152,  1.5192809 ,  0.45553666, -0.06732206, -0.13015792,\n",
      "       -0.03783403,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14058152,  1.5192809 ,  0.45553666, -0.06732206, -0.13015792,\n",
      "       -0.03783403,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.48623798936964135, next_state=array([ 0.14511776,  1.51717   ,  0.4555366 , -0.09398902, -0.13204962,\n",
      "       -0.03783391,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14511776,  1.51717   ,  0.4555366 , -0.09398902, -0.13204962,\n",
      "       -0.03783391,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.12430379846562117, next_state=array([ 0.14967756,  1.5159032 ,  0.4583539 , -0.05650882, -0.13441992,\n",
      "       -0.0474062 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.14967756,  1.5159032 ,  0.4583539 , -0.05650882, -0.13441992,\n",
      "       -0.0474062 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4983507713839117, next_state=array([ 0.15423727,  1.5140368 ,  0.45835382, -0.08317595, -0.1367902 ,\n",
      "       -0.04740604,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15423727,  1.5140368 ,  0.45835382, -0.08317595, -0.1367902 ,\n",
      "       -0.04740604,  0.        ,  0.        ], dtype=float32), action=1, reward=0.33093836875795657, next_state=array([ 0.15873441,  1.5115885 ,  0.45047283, -0.10888483, -0.1375475 ,\n",
      "       -0.01514616,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.15873441,  1.5115885 ,  0.45047283, -0.10888483, -0.1375475 ,\n",
      "       -0.01514616,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.9598857080051164, next_state=array([ 0.16332626,  1.5085213 ,  0.4623731 , -0.13661742, -0.14072073,\n",
      "       -0.0634646 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16332626,  1.5085213 ,  0.4623731 , -0.13661742, -0.14072073,\n",
      "       -0.0634646 ,  0.        ,  0.        ], dtype=float32), action=1, reward=0.4039332726891314, next_state=array([ 0.16783448,  1.5048836 ,  0.45182985, -0.1617686 , -0.14172289,\n",
      "       -0.02004332,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.16783448,  1.5048836 ,  0.45182985, -0.1617686 , -0.14172289,\n",
      "       -0.02004332,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6931371126004251, next_state=array([ 0.17234278,  1.500646  ,  0.45182982, -0.18843536, -0.14272504,\n",
      "       -0.02004319,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17234278,  1.500646  ,  0.45182982, -0.18843536, -0.14272504,\n",
      "       -0.02004319,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.7588973599409599, next_state=array([ 0.17685108,  1.4958084 ,  0.45182985, -0.21510212, -0.14372721,\n",
      "       -0.02004319,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.17685108,  1.4958084 ,  0.45182985, -0.21510212, -0.14372721,\n",
      "       -0.02004319,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8595852143160403, next_state=array([ 0.18142986,  1.4903517 ,  0.46071   , -0.24279064, -0.14654478,\n",
      "       -0.05635145,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.18142986,  1.4903517 ,  0.46071   , -0.24279064, -0.14654478,\n",
      "       -0.05635145,  0.        ,  0.        ], dtype=float32), action=1, reward=0.18145052488580518, next_state=array([ 0.1859192 ,  1.4843116 ,  0.44946742, -0.2685066 , -0.14708258,\n",
      "       -0.010756  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.1859192 ,  1.4843116 ,  0.44946742, -0.2685066 , -0.14708258,\n",
      "       -0.010756  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.878616719001626, next_state=array([ 0.19048233,  1.477667  ,  0.45870486, -0.29555294, -0.14947122,\n",
      "       -0.04777269,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19048233,  1.477667  ,  0.45870486, -0.29555294, -0.14947122,\n",
      "       -0.04777269,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.1837585829732393, next_state=array([ 0.19497833,  1.47044   ,  0.45026818, -0.32126826, -0.15013556,\n",
      "       -0.01328676,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19497833,  1.47044   ,  0.45026818, -0.32126826, -0.15013556,\n",
      "       -0.01328676,  0.        ,  0.        ], dtype=float32), action=2, reward=1.804686893066031, next_state=array([ 0.19950466,  1.4639947 ,  0.45379576, -0.28657264, -0.15129815,\n",
      "       -0.02325144,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.19950466,  1.4639947 ,  0.45379576, -0.28657264, -0.15129815,\n",
      "       -0.02325144,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1774839906010173, next_state=array([ 0.20412083,  1.4569387 ,  0.46505094, -0.3139582 , -0.15472981,\n",
      "       -0.06863333,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20412083,  1.4569387 ,  0.46505094, -0.3139582 , -0.15472981,\n",
      "       -0.06863333,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1846267985017676, next_state=array([ 0.20873699,  1.4492828 ,  0.4650508 , -0.34062585, -0.15816148,\n",
      "       -0.06863327,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.20873699,  1.4492828 ,  0.4650508 , -0.34062585, -0.15816148,\n",
      "       -0.06863327,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.24549969769585117, next_state=array([ 0.21349545,  1.441966  ,  0.47909063, -0.32553336, -0.1613985 ,\n",
      "       -0.06474084,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21349545,  1.441966  ,  0.47909063, -0.32553336, -0.1613985 ,\n",
      "       -0.06474084,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6763964908668243, next_state=array([ 0.21852168,  1.4352831 ,  0.50524247, -0.29730245, -0.1640243 ,\n",
      "       -0.05251598,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.21852168,  1.4352831 ,  0.50524247, -0.29730245, -0.1640243 ,\n",
      "       -0.05251598,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1750687329053435, next_state=array([ 0.22362748,  1.4279732 ,  0.515269  , -0.32541534, -0.16872044,\n",
      "       -0.09392302,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22362748,  1.4279732 ,  0.515269  , -0.32541534, -0.16872044,\n",
      "       -0.09392302,  0.        ,  0.        ], dtype=float32), action=2, reward=0.277728454173581, next_state=array([ 0.22873144,  1.4208729 ,  0.51550734, -0.31615883, -0.17384395,\n",
      "       -0.10247018,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.22873144,  1.4208729 ,  0.51550734, -0.31615883, -0.17384395,\n",
      "       -0.10247018,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2705928194173168, next_state=array([ 0.23383541,  1.413173  ,  0.5155068 , -0.34282768, -0.17896745,\n",
      "       -0.10246997,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23383541,  1.413173  ,  0.5155068 , -0.34282768, -0.17896745,\n",
      "       -0.10246997,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5962039533904033, next_state=array([ 0.23913078,  1.4054934 ,  0.53411907, -0.34187433, -0.18355954,\n",
      "       -0.09184209,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.23913078,  1.4054934 ,  0.53411907, -0.34187433, -0.18355954,\n",
      "       -0.09184209,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.209892083131848, next_state=array([ 0.24442625,  1.397214  ,  0.5341186 , -0.3685428 , -0.18815161,\n",
      "       -0.09184193,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24442625,  1.397214  ,  0.5341186 , -0.3685428 , -0.18815161,\n",
      "       -0.09184193,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.287264571249493, next_state=array([ 0.24979982,  1.3883241 ,  0.5438857 , -0.39595285, -0.19471753,\n",
      "       -0.13131839,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.24979982,  1.3883241 ,  0.5438857 , -0.39595285, -0.19471753,\n",
      "       -0.13131839,  0.        ,  0.        ], dtype=float32), action=2, reward=1.0865923228004248, next_state=array([ 0.2552825 ,  1.3803685 ,  0.5552105 , -0.35451278, -0.20170279,\n",
      "       -0.13970482,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2552825 ,  1.3803685 ,  0.5552105 , -0.35451278, -0.20170279,\n",
      "       -0.13970482,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.4530192523139065, next_state=array([ 0.2608389 ,  1.3718023 ,  0.5644264 , -0.3819475 , -0.2105541 ,\n",
      "       -0.17702633,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2608389 ,  1.3718023 ,  0.5644264 , -0.3819475 , -0.2105541 ,\n",
      "       -0.17702633,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.3672680033339748, next_state=array([ 0.2663006 ,  1.3626589 ,  0.552525  , -0.40728596, -0.21696968,\n",
      "       -0.12831208,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2663006 ,  1.3626589 ,  0.552525  , -0.40728596, -0.21696968,\n",
      "       -0.12831208,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4072281266462596, next_state=array([ 0.27176237,  1.3529162 ,  0.5525239 , -0.43395603, -0.22338527,\n",
      "       -0.12831172,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27176237,  1.3529162 ,  0.5525239 , -0.43395603, -0.22338527,\n",
      "       -0.12831172,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.2006267968832833, next_state=array([ 0.27713364,  1.3426114 ,  0.54108787, -0.45859727, -0.22739777,\n",
      "       -0.08024966,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.27713364,  1.3426114 ,  0.54108787, -0.45859727, -0.22739777,\n",
      "       -0.08024966,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.274036997639199, next_state=array([ 0.28258544,  1.3316852 ,  0.5511862 , -0.4865502 , -0.23348998,\n",
      "       -0.12184404,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.28258544,  1.3316852 ,  0.5511862 , -0.4865502 , -0.23348998,\n",
      "       -0.12184404,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.27248978787611, next_state=array([ 0.2880991 ,  1.3201276 ,  0.55901253, -0.5149009 , -0.24125433,\n",
      "       -0.15528698,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2880991 ,  1.3201276 ,  0.55901253, -0.5149009 , -0.24125433,\n",
      "       -0.15528698,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.576014267445571, next_state=array([ 0.2936921 ,  1.3079504 ,  0.5689303 , -0.5428246 , -0.25106055,\n",
      "       -0.19612461,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.2936921 ,  1.3079504 ,  0.5689303 , -0.5428246 , -0.25106055,\n",
      "       -0.19612461,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7234757363227402, next_state=array([ 0.29928523,  1.2951745 ,  0.5689274 , -0.56949914, -0.2608667 ,\n",
      "       -0.19612333,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.29928523,  1.2951745 ,  0.5689274 , -0.56949914, -0.2608667 ,\n",
      "       -0.19612333,  0.        ,  0.        ], dtype=float32), action=2, reward=0.49769493811966187, next_state=array([ 0.3050314 ,  1.2830079 ,  0.58447516, -0.5425273 , -0.27095026,\n",
      "       -0.20167124,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3050314 ,  1.2830079 ,  0.58447516, -0.5425273 , -0.27095026,\n",
      "       -0.20167124,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7400578221265164, next_state=array([ 0.31077784,  1.2702426 ,  0.5844718 , -0.5692022 , -0.28103372,\n",
      "       -0.20166984,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.31077784,  1.2702426 ,  0.5844718 , -0.5692022 , -0.28103372,\n",
      "       -0.20166984,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.7338813013548589, next_state=array([ 0.3166399 ,  1.2575879 ,  0.596092  , -0.5643646 , -0.29121104,\n",
      "       -0.20354614,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3166399 ,  1.2575879 ,  0.596092  , -0.5643646 , -0.29121104,\n",
      "       -0.20354614,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.35980425132074173, next_state=array([ 0.32262784,  1.2452239 ,  0.6088855 , -0.5515638 , -0.30161795,\n",
      "       -0.20813854,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32262784,  1.2452239 ,  0.6088855 , -0.5515638 , -0.30161795,\n",
      "       -0.20813854,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9605649074130327, next_state=array([ 0.32894582,  1.2331095 ,  0.64119506, -0.5404033 , -0.31134495,\n",
      "       -0.19454092,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.32894582,  1.2331095 ,  0.64119506, -0.5404033 , -0.31134495,\n",
      "       -0.19454092,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7896107646878634, next_state=array([ 0.3353446 ,  1.2203621 ,  0.6513188 , -0.569054  , -0.32323125,\n",
      "       -0.23772609,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3353446 ,  1.2203621 ,  0.6513188 , -0.569054  , -0.32323125,\n",
      "       -0.23772609,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8527675904229, next_state=array([ 0.34174386,  1.2070162 ,  0.6513132 , -0.59573185, -0.33511743,\n",
      "       -0.23772378,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.34174386,  1.2070162 ,  0.6513132 , -0.59573185, -0.33511743,\n",
      "       -0.23772378,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8469066653829884, next_state=array([ 0.3481435 ,  1.1930722 ,  0.65130746, -0.6224097 , -0.3470035 ,\n",
      "       -0.23772147,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3481435 ,  1.1930722 ,  0.65130746, -0.6224097 , -0.3470035 ,\n",
      "       -0.23772147,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.108009936274924, next_state=array([ 0.3546338 ,  1.1784848 ,  0.66269094, -0.651693  , -0.3613691 ,\n",
      "       -0.28731218,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3546338 ,  1.1784848 ,  0.66269094, -0.651693  , -0.3613691 ,\n",
      "       -0.28731218,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0634613063037364, next_state=array([ 0.3611249 ,  1.1632998 ,  0.66268194, -0.6783758 , -0.3757345 ,\n",
      "       -0.28730807,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3611249 ,  1.1632998 ,  0.66268194, -0.6783758 , -0.3757345 ,\n",
      "       -0.28730807,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.218700833866751, next_state=array([ 0.36805   ,  1.1488991 ,  0.7057258 , -0.6435741 , -0.38979766,\n",
      "       -0.28126258,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.36805   ,  1.1488991 ,  0.7057258 , -0.6435741 , -0.38979766,\n",
      "       -0.28126258,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.2643403104036566, next_state=array([ 0.3753256 ,  1.1351894 ,  0.7407127 , -0.6129905 , -0.40387294,\n",
      "       -0.28150636,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.3753256 ,  1.1351894 ,  0.7407127 , -0.6129905 , -0.40387294,\n",
      "       -0.28150636,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.2160072353339886, next_state=array([ 0.38268003,  1.120827  ,  0.7506463 , -0.64275396, -0.42023683,\n",
      "       -0.32727754,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.38268003,  1.120827  ,  0.7506463 , -0.64275396, -0.42023683,\n",
      "       -0.32727754,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.219449522741286, next_state=array([ 0.39003554,  1.1058677 ,  0.7506327 , -0.66944116, -0.4366004 ,\n",
      "       -0.3272715 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39003554,  1.1058677 ,  0.7506327 , -0.66944116, -0.4366004 ,\n",
      "       -0.3272715 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.214904350768336, next_state=array([ 0.39739197,  1.0903116 ,  0.7506187 , -0.69612813, -0.45296362,\n",
      "       -0.32726547,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.39739197,  1.0903116 ,  0.7506187 , -0.69612813, -0.45296362,\n",
      "       -0.32726547,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2962225684363762, next_state=array([ 0.40468732,  1.0742074 ,  0.74269533, -0.72009087, -0.46745193,\n",
      "       -0.2897665 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.40468732,  1.0742074 ,  0.74269533, -0.72009087, -0.46745193,\n",
      "       -0.2897665 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.2122163485107353, next_state=array([ 0.41192406,  1.0575405 ,  0.7352119 , -0.7446884 , -0.48024967,\n",
      "       -0.25595498,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.41192406,  1.0575405 ,  0.7352119 , -0.7446884 , -0.48024967,\n",
      "       -0.25595498,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.38316747250160005, next_state=array([ 0.4193243 ,  1.041277  ,  0.75215566, -0.72709733, -0.49380606,\n",
      "       -0.27112758,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4193243 ,  1.041277  ,  0.75215566, -0.72709733, -0.49380606,\n",
      "       -0.27112758,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.997270099979146, next_state=array([ 0.42666072,  1.0244671 ,  0.7439548 , -0.7508526 , -0.50539434,\n",
      "       -0.23176527,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.42666072,  1.0244671 ,  0.7439548 , -0.7508526 , -0.50539434,\n",
      "       -0.23176527,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.520383018408977, next_state=array([ 0.4339157 ,  1.0071294 ,  0.7334944 , -0.7735407 , -0.5144214 ,\n",
      "       -0.18054117,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4339157 ,  1.0071294 ,  0.7334944 , -0.7735407 , -0.5144214 ,\n",
      "       -0.18054117,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.685707200812685, next_state=array([ 0.44124365,  0.9891213 ,  0.74279386, -0.8041743 , -0.52580726,\n",
      "       -0.22771549,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44124365,  0.9891213 ,  0.74279386, -0.8041743 , -0.52580726,\n",
      "       -0.22771549,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7033723800963387, next_state=array([ 0.44863567,  0.9704636 ,  0.7508484 , -0.8338068 , -0.5391499 ,\n",
      "       -0.26685268,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.44863567,  0.9704636 ,  0.7508484 , -0.8338068 , -0.5391499 ,\n",
      "       -0.26685268,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8199257991031164, next_state=array([ 0.45595598,  0.9512724 ,  0.7415937 , -0.8567934 , -0.55018765,\n",
      "       -0.22075538,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.45595598,  0.9512724 ,  0.7415937 , -0.8567934 , -0.55018765,\n",
      "       -0.22075538,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6763111703317009, next_state=array([ 0.46327677,  0.93148273,  0.7415858 , -0.88346875, -0.5612253 ,\n",
      "       -0.22075352,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.46327677,  0.93148273,  0.7415858 , -0.88346875, -0.5612253 ,\n",
      "       -0.22075352,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.7660299792093952, next_state=array([ 0.4708457 ,  0.9116355 ,  0.7662723 , -0.8860637 , -0.57218087,\n",
      "       -0.21911156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4708457 ,  0.9116355 ,  0.7662723 , -0.8860637 , -0.57218087,\n",
      "       -0.21911156,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.669056500774218, next_state=array([ 0.4784153 ,  0.89118963,  0.7662642 , -0.91273874, -0.5831364 ,\n",
      "       -0.21910973,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4784153 ,  0.89118963,  0.7662642 , -0.91273874, -0.5831364 ,\n",
      "       -0.21910973,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.5157510961759315, next_state=array([ 0.4860363 ,  0.87009144,  0.7727765 , -0.9424507 , -0.5958135 ,\n",
      "       -0.25354442,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.4860363 ,  0.87009144,  0.7727765 , -0.9424507 , -0.5958135 ,\n",
      "       -0.25354442,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8341612889412318, next_state=array([ 0.49365807,  0.8483949 ,  0.7727652 , -0.9691286 , -0.6084906 ,\n",
      "       -0.25354156,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.49365807,  0.8483949 ,  0.7727652 , -0.9691286 , -0.6084906 ,\n",
      "       -0.25354156,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.8365718869721377, next_state=array([ 0.50128067,  0.82610023,  0.7727537 , -0.9958063 , -0.62116754,\n",
      "       -0.25353876,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.50128067,  0.82610023,  0.7727537 , -0.9958063 , -0.62116754,\n",
      "       -0.25353876,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8344143948272336, next_state=array([ 0.508838  ,  0.8032747 ,  0.76432306, -1.018603  , -0.6316203 ,\n",
      "       -0.20905451,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.508838  ,  0.8032747 ,  0.76432306, -1.018603  , -0.6316203 ,\n",
      "       -0.20905451,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6329765701979113, next_state=array([ 0.51639587,  0.7798502 ,  0.764315  , -1.045277  , -0.6420729 ,\n",
      "       -0.20905297,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.51639587,  0.7798502 ,  0.764315  , -1.045277  , -0.6420729 ,\n",
      "       -0.20905297,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.67853582806154, next_state=array([ 0.5240201 ,  0.7557627 ,  0.7726209 , -1.0757071 , -0.65470815,\n",
      "       -0.2527054 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5240201 ,  0.7557627 ,  0.7726209 , -1.0757071 , -0.65470815,\n",
      "       -0.2527054 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.7750324731335057, next_state=array([ 0.5317028 ,  0.73102087,  0.77989244, -1.1056696 , -0.66925555,\n",
      "       -0.29094833,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5317028 ,  0.73102087,  0.77989244, -1.1056696 , -0.66925555,\n",
      "       -0.29094833,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0439402511029516, next_state=array([ 0.53932446,  0.7057604 ,  0.7718338 , -1.1278397 , -0.6814825 ,\n",
      "       -0.244539  ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.53932446,  0.7057604 ,  0.7718338 , -1.1278397 , -0.6814825 ,\n",
      "       -0.244539  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.9245665908736942, next_state=array([ 0.5468936 ,  0.6799812 ,  0.7648226 , -1.1500478 , -0.6915571 ,\n",
      "       -0.20149192,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5468936 ,  0.6799812 ,  0.7648226 , -1.1500478 , -0.6915571 ,\n",
      "       -0.20149192,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.7749489624686408, next_state=array([ 0.5544019 ,  0.6536655 ,  0.75703996, -1.1730419 , -0.69954675,\n",
      "       -0.15979275,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5544019 ,  0.6536655 ,  0.75703996, -1.1730419 , -0.69954675,\n",
      "       -0.15979275,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.680851466707536, next_state=array([ 0.561862  ,  0.62681997,  0.7507039 , -1.1957784 , -0.7056093 ,\n",
      "       -0.12125063,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.561862  ,  0.62681997,  0.7507039 , -1.1957784 , -0.7056093 ,\n",
      "       -0.12125063,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.4901086574494957, next_state=array([ 0.56927   ,  0.5994458 ,  0.743912  , -1.218403  , -0.7096462 ,\n",
      "       -0.08073805,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.56927   ,  0.5994458 ,  0.743912  , -1.218403  , -0.7096462 ,\n",
      "       -0.08073805,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2054213923902921, next_state=array([ 0.5766783 ,  0.5714718 ,  0.7439107 , -1.2450708 , -0.7136831 ,\n",
      "       -0.08073849,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5766783 ,  0.5714718 ,  0.7439107 , -1.2450708 , -0.7136831 ,\n",
      "       -0.08073849,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.154353646069778, next_state=array([ 0.58414143,  0.5428348 ,  0.75091827, -1.2754226 , -0.7196917 ,\n",
      "       -0.12017147,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.58414143,  0.5428348 ,  0.75091827, -1.2754226 , -0.7196917 ,\n",
      "       -0.12017147,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.720103229688209, next_state=array([ 0.59187096,  0.5139789 ,  0.77739537, -1.2851009 , -0.7255488 ,\n",
      "       -0.11714278,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.59187096,  0.5139789 ,  0.77739537, -1.2851009 , -0.7255488 ,\n",
      "       -0.11714278,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5743293886438892, next_state=array([ 0.5996006 ,  0.48452333,  0.77739245, -1.3117696 , -0.731406  ,\n",
      "       -0.11714311,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.5996006 ,  0.48452333,  0.77739245, -1.3117696 , -0.731406  ,\n",
      "       -0.11714311,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6505656681987375, next_state=array([ 0.6073305 ,  0.45446813,  0.7773896 , -1.3384383 , -0.73726314,\n",
      "       -0.11714289,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6073305 ,  0.45446813,  0.7773896 , -1.3384383 , -0.73726314,\n",
      "       -0.11714289,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7366756364446587, next_state=array([ 0.6150606 ,  0.42381322,  0.7773867 , -1.365107  , -0.74312025,\n",
      "       -0.11714265,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6150606 ,  0.42381322,  0.7773867 , -1.365107  , -0.74312025,\n",
      "       -0.11714265,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.063331592357456, next_state=array([ 0.6227459 ,  0.3926252 ,  0.77153647, -1.3879776 , -0.74714446,\n",
      "       -0.08048374,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6227459 ,  0.3926252 ,  0.77153647, -1.3879776 , -0.74714446,\n",
      "       -0.08048374,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7593545895985585, next_state=array([ 0.63043153,  0.3608373 ,  0.77153504, -1.4146451 , -0.75116867,\n",
      "       -0.08048368,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.63043153,  0.3608373 ,  0.77153504, -1.4146451 , -0.75116867,\n",
      "       -0.08048368,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.0698375233623936, next_state=array([ 0.6381796 ,  0.32834867,  0.7797513 , -1.4470385 , -0.75787187,\n",
      "       -0.13406338,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6381796 ,  0.32834867,  0.7797513 , -1.4470385 , -0.75787187,\n",
      "       -0.13406338,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.429055126467999, next_state=array([ 0.6459907 ,  0.29516596,  0.7879501 , -1.479123  , -0.76717395,\n",
      "       -0.1860413 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6459907 ,  0.29516596,  0.7879501 , -1.479123  , -0.76717395,\n",
      "       -0.1860413 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.9010532776648277, next_state=array([ 0.653866  ,  0.26127923,  0.79626864, -1.5117633 , -0.77924114,\n",
      "       -0.24134502,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.653866  ,  0.26127923,  0.79626864, -1.5117633 , -0.77924114,\n",
      "       -0.24134502,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2016774891419275, next_state=array([ 0.6616877 ,  0.22687083,  0.7892543 , -1.5339788 , -0.7891273 ,\n",
      "       -0.1977212 ,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.6616877 ,  0.22687083,  0.7892543 , -1.5339788 , -0.7891273 ,\n",
      "       -0.1977212 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.1939239945730717, next_state=array([ 0.66993254,  0.19240895,  0.83137023, -1.5363109 , -0.7988302 ,\n",
      "       -0.19405797,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.66993254,  0.19240895,  0.83137023, -1.5363109 , -0.7988302 ,\n",
      "       -0.19405797,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.09289193511293, next_state=array([ 0.67822516,  0.15728074,  0.83743066, -1.5669004 , -0.81044054,\n",
      "       -0.23220703,  0.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.67822516,  0.15728074,  0.83743066, -1.5669004 , -0.81044054,\n",
      "       -0.23220703,  0.        ,  0.        ], dtype=float32), action=2, reward=6.052658276374655, next_state=array([ 0.68689287,  0.12200354,  0.874705  , -1.5734941 , -0.8218625 ,\n",
      "       -0.2284391 ,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.68689287,  0.12200354,  0.874705  , -1.5734941 , -0.8218625 ,\n",
      "       -0.2284391 ,  1.        ,  0.        ], dtype=float32), action=3, reward=-3.193240893604552, next_state=array([ 0.695591  ,  0.08690322,  0.8817436 , -1.5845193 , -0.83708364,\n",
      "       -0.27335364,  1.        ,  0.        ], dtype=float32), done=False), Experience(state=array([ 0.695591  ,  0.08690322,  0.8817436 , -1.5845193 , -0.83708364,\n",
      "       -0.27335364,  1.        ,  0.        ], dtype=float32), action=1, reward=-100, next_state=array([ 0.70106757,  0.08516157,  0.557536  ,  0.02780027, -0.9091605 ,\n",
      "       -1.5496347 ,  1.        ,  0.        ], dtype=float32), done=True)], maxlen=100000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) agent.qnetwork_target(next_states)\n",
      "*** NameError: name 'next_states' is not defined\n",
      "(Pdb) states\n",
      "*** NameError: name 'states' is not defined\n",
      "(Pdb) exps = agent.memory.sample()\n",
      "(Pdb) exps\n",
      "(tensor([[ 6.0966e-03,  1.3830e+00,  2.1713e-01, -4.1300e-01, -9.8569e-03,\n",
      "         -7.0632e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.3087e-02,  8.9639e-01, -1.8141e-01, -9.1193e-01,  3.1014e-01,\n",
      "          6.5574e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.6992e-01,  1.5441e+00, -4.7929e-01, -2.0485e-01,  2.4759e-01,\n",
      "          1.5405e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5873e-01,  1.5116e+00,  4.5047e-01, -1.0888e-01, -1.3755e-01,\n",
      "         -1.5146e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2511e-03,  6.5165e-01,  3.2420e-01, -9.8647e-01, -5.3010e-01,\n",
      "         -2.3200e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9436e-01,  1.2574e+00, -7.4399e-01, -4.3366e-01,  2.5142e-01,\n",
      "          1.7521e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6542e-01,  1.1775e+00,  7.6149e-01, -5.1593e-01, -1.3705e-01,\n",
      "         -1.5712e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8463e-01,  9.2171e-01,  5.2515e-01, -9.0506e-01, -1.9296e-01,\n",
      "         -8.0051e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4800e-01,  1.1683e+00,  6.0748e-01, -4.6594e-01,  6.2858e-02,\n",
      "          1.3179e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6310e-01,  7.9135e-01,  9.7690e-01, -1.1712e+00, -1.1493e+00,\n",
      "         -6.8299e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0412e-01,  1.4569e+00,  4.6505e-01, -3.1396e-01, -1.5473e-01,\n",
      "         -6.8633e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.6848e-02,  1.4259e+00, -2.1764e-01, -3.6407e-03,  2.6289e-02,\n",
      "          6.7064e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.4150e-01,  4.1150e-01, -1.1228e+00, -1.2278e+00,  7.2809e-01,\n",
      "          1.5617e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.3404e-02,  1.4915e+00, -2.9461e-01,  2.4831e-01, -4.1041e-03,\n",
      "         -5.1662e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.5682e-02,  1.2652e+00,  2.6642e-01, -5.3701e-01, -9.3669e-02,\n",
      "         -1.5457e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6525e-01, -4.9481e-03,  6.2342e-01, -1.5217e+00, -3.2421e-01,\n",
      "         -2.0857e-01,  1.0000e+00,  0.0000e+00],\n",
      "        [ 1.1383e-02,  1.4011e+00,  1.1335e-01, -9.3926e-02,  6.4951e-04,\n",
      "          6.7619e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.9764e-01,  4.5046e-02, -2.9541e-01, -1.3711e+00,  1.4598e-01,\n",
      "          2.7966e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4997e-01,  4.1086e-01, -4.9066e-01, -9.6503e-01,  6.1372e-01,\n",
      "          4.2491e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3049e-02,  1.1869e+00,  1.3105e-01, -5.4934e-01, -2.1682e-01,\n",
      "         -1.9131e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.8691e-01,  1.6598e-01, -2.6079e-01, -1.3202e+00,  9.8460e-02,\n",
      "          2.1576e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7576e-01,  1.5081e-01,  2.4193e-01, -1.1806e+00,  1.1221e-01,\n",
      "          1.3253e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8098e-02,  1.0455e-01, -4.4058e-02, -1.4413e+00,  5.3438e-01,\n",
      "          1.6680e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.0182e-01,  3.4003e-01, -9.5505e-01, -1.4529e+00,  9.4302e-01,\n",
      "          3.0405e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.4437e-02,  1.6723e-01, -2.1451e-01, -1.3059e+00,  4.1277e-01,\n",
      "          2.0820e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.6001e-02,  1.3325e+00,  2.3691e-01, -5.3976e-01, -4.0561e-01,\n",
      "         -2.6158e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.4763e-02,  1.0329e+00,  2.5186e-01, -7.7486e-01, -1.4489e-01,\n",
      "          3.5543e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1342e-01,  1.1267e+00, -5.7855e-01, -4.8138e-01,  3.3565e-01,\n",
      "          1.8834e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.4252e-02,  3.1501e-01, -5.6638e-02, -1.1973e+00, -4.3531e-02,\n",
      "         -3.9959e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.4995e-02,  1.3144e+00, -4.1979e-01, -2.2751e-01,  1.3272e-01,\n",
      "          1.3325e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.9172e-01,  3.9420e-01,  1.2715e+00, -1.0044e+00, -7.8989e-01,\n",
      "         -3.7062e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1208e-01,  1.0033e+00, -3.7093e-01, -6.3116e-01,  2.0781e-01,\n",
      "          2.0129e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.9434e-02,  8.0174e-01, -2.6178e-01, -8.1067e-01,  2.7570e-01,\n",
      "          2.7412e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.3024e-03,  8.1456e-01, -7.2717e-02, -8.7615e-01,  3.8910e-02,\n",
      "          1.0001e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4383e-02,  1.4137e+00, -1.4597e-01, -8.4886e-02, -2.3691e-03,\n",
      "         -3.8120e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.8586e-02,  1.4759e+00, -2.2752e-01,  2.7846e-01,  1.6033e-02,\n",
      "         -6.6646e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0438e-01,  1.1772e+00, -6.8087e-01, -4.7833e-01,  9.1385e-02,\n",
      "          6.5232e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.4527e-02,  1.3866e+00, -2.5176e-02, -4.4704e-01, -5.9355e-03,\n",
      "         -2.1494e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1033e-01,  3.3133e-01, -2.9186e-01, -1.2353e+00, -7.4760e-02,\n",
      "          7.9770e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2712e-03,  1.3954e+00, -5.7644e-02, -3.5796e-01, -6.7024e-04,\n",
      "         -2.9300e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9858e-01,  1.5038e+00, -4.9483e-01, -3.6907e-01,  3.0376e-01,\n",
      "          2.2260e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.4614e-02,  1.1354e-01,  4.5956e-01, -1.3755e+00, -6.9188e-01,\n",
      "         -1.2298e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0950e-02,  1.3645e+00, -1.0823e-01, -2.0265e-01, -8.2849e-03,\n",
      "         -2.2849e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8558e-02,  1.2348e+00,  1.1429e-01, -4.9011e-01, -1.7299e-01,\n",
      "         -2.4237e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.6417e-03,  1.3930e+00, -1.7949e-01, -3.9373e-01,  4.8152e-03,\n",
      "          5.2754e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1391e-01,  7.0653e-01, -6.1968e-01, -1.1552e+00,  4.1044e-01,\n",
      "          2.1817e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8920e-02,  1.5331e+00,  1.0678e-01, -8.7414e-02, -1.2557e-01,\n",
      "         -1.6118e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.2812e-01,  2.3253e-01, -1.0560e+00, -1.3501e+00,  6.6976e-01,\n",
      "          8.5957e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.4797e-01,  2.2000e-01,  1.1877e+00, -1.5951e+00, -1.1630e+00,\n",
      "         -2.2314e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.3916e-01,  5.1451e-02, -6.1355e-01, -1.0022e-01,  1.8082e+00,\n",
      "          2.9069e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.5320e-01,  3.8454e-01, -1.1761e+00, -1.2024e+00,  7.3649e-01,\n",
      "          1.6802e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3532e-02,  1.4134e+00,  4.5797e-01,  3.1580e-02, -1.4764e-02,\n",
      "         -9.5894e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.5744e-02,  1.1250e+00,  1.2138e-01, -6.8823e-01,  3.9483e-02,\n",
      "          1.1064e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0418e-01,  1.0379e+00, -2.3612e-01, -8.5108e-01, -5.7981e-03,\n",
      "         -1.1346e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.6262e-01,  3.1078e-02,  9.3480e-01, -8.3434e-01, -6.3384e-01,\n",
      "          5.4575e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.5550e-01, -1.1754e-01, -1.1231e+00, -2.8144e-01,  8.8515e-01,\n",
      "          1.8933e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [-8.1919e-02,  7.8295e-01, -2.6177e-01, -8.3736e-01,  2.8940e-01,\n",
      "          2.7411e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.7108e-02,  1.1414e+00, -1.3063e-01, -7.5298e-01,  1.3068e-02,\n",
      "          2.0687e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3996e-01,  1.5663e+00,  8.7597e-01, -2.2621e-02, -4.3637e-01,\n",
      "         -3.1086e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.8171e-01,  7.2740e-03,  1.0438e+00, -1.4668e+00, -1.0538e+00,\n",
      "         -7.3372e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6239e-01,  4.4685e-01, -2.3723e-01, -1.1449e+00, -1.4020e-03,\n",
      "          1.1510e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.7167e-02,  1.4689e+00,  8.1252e-01,  3.6287e-01, -6.6069e-02,\n",
      "         -2.8043e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0387e-01,  1.1123e+00, -8.5471e-01, -6.6527e-01,  3.6219e-01,\n",
      "          1.7717e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.9309e-02,  1.0802e+00, -1.0446e-01, -6.8080e-01,  1.4772e-01,\n",
      "          6.7999e-03,  0.0000e+00,  0.0000e+00]]), tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [0]]), tensor([[-1.7428e+00],\n",
      "        [-8.4591e-01],\n",
      "        [-2.5127e+00],\n",
      "        [-1.9599e+00],\n",
      "        [-2.2315e+00],\n",
      "        [-4.3610e-01],\n",
      "        [ 1.7356e+00],\n",
      "        [-1.3558e-01],\n",
      "        [-2.0177e+00],\n",
      "        [ 2.5088e-02],\n",
      "        [-1.1846e+00],\n",
      "        [-1.9125e+00],\n",
      "        [-2.5401e+00],\n",
      "        [-1.9047e+00],\n",
      "        [-1.9148e+00],\n",
      "        [ 7.9332e+00],\n",
      "        [-1.5106e+00],\n",
      "        [-3.5737e+00],\n",
      "        [-3.7498e+00],\n",
      "        [-2.9216e+00],\n",
      "        [-2.5147e+00],\n",
      "        [ 2.7984e+00],\n",
      "        [-8.7758e-01],\n",
      "        [-1.8345e+00],\n",
      "        [-3.8210e-01],\n",
      "        [-1.6244e+00],\n",
      "        [-5.8233e-01],\n",
      "        [-1.6650e+00],\n",
      "        [ 3.1912e+00],\n",
      "        [-1.3850e-01],\n",
      "        [-4.8487e+00],\n",
      "        [-1.8919e+00],\n",
      "        [-2.0699e+00],\n",
      "        [-8.4045e-01],\n",
      "        [-1.4267e+00],\n",
      "        [-3.1499e+00],\n",
      "        [-8.8719e-01],\n",
      "        [-2.6100e+00],\n",
      "        [ 3.3194e-03],\n",
      "        [-1.9183e+00],\n",
      "        [-2.9175e+00],\n",
      "        [-9.6181e-01],\n",
      "        [-2.3179e+00],\n",
      "        [-2.2368e+00],\n",
      "        [ 7.6272e-01],\n",
      "        [-1.0979e+00],\n",
      "        [-2.3784e+00],\n",
      "        [-3.4940e+00],\n",
      "        [-3.7329e+00],\n",
      "        [-1.5213e+01],\n",
      "        [-2.4246e+00],\n",
      "        [-1.3429e+00],\n",
      "        [ 2.7017e+00],\n",
      "        [ 2.8988e+00],\n",
      "        [-1.0000e+02],\n",
      "        [-5.5652e+00],\n",
      "        [ 2.0544e+00],\n",
      "        [-5.4755e-01],\n",
      "        [-6.4420e+00],\n",
      "        [ 2.0842e+00],\n",
      "        [-1.2153e+00],\n",
      "        [-2.3998e+00],\n",
      "        [-6.6447e-01],\n",
      "        [-1.0842e+00]]), tensor([[ 8.2323e-03,  1.3731e+00,  2.1714e-01, -4.3968e-01, -1.3388e-02,\n",
      "         -7.0638e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.4869e-02,  8.7529e-01, -1.8141e-01, -9.3859e-01,  3.1342e-01,\n",
      "          6.5574e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7471e-01,  1.5389e+00, -4.8823e-01, -2.3328e-01,  2.5719e-01,\n",
      "          1.9205e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6333e-01,  1.5085e+00,  4.6237e-01, -1.3662e-01, -1.4072e-01,\n",
      "         -6.3465e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.5654e-04,  6.2889e-01,  3.3268e-01, -1.0164e+00, -5.4379e-01,\n",
      "         -2.7380e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0164e-01,  1.2471e+00, -7.3565e-01, -4.5923e-01,  2.5846e-01,\n",
      "          1.4076e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.7297e-01,  1.1668e+00,  7.6313e-01, -4.7507e-01, -1.4550e-01,\n",
      "         -1.6897e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8978e-01,  9.0077e-01,  5.1674e-01, -9.3081e-01, -1.9524e-01,\n",
      "         -4.5657e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.5423e-01,  1.1572e+00,  6.1855e-01, -4.9240e-01,  6.7231e-02,\n",
      "          8.7463e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7286e-01,  7.6444e-01,  9.7690e-01, -1.1978e+00, -1.1527e+00,\n",
      "         -6.8298e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0874e-01,  1.4493e+00,  4.6505e-01, -3.4063e-01, -1.5816e-01,\n",
      "         -6.8633e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9085e-02,  1.4252e+00, -2.2940e-01, -3.0719e-02,  3.2000e-02,\n",
      "          1.1423e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.5320e-01,  3.8454e-01, -1.1761e+00, -1.2024e+00,  7.3649e-01,\n",
      "          1.6802e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.6254e-02,  1.4976e+00, -2.8294e-01,  2.7292e-01, -6.1239e-03,\n",
      "         -4.0401e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.8269e-02,  1.2525e+00,  2.6644e-01, -5.6368e-01, -1.0139e-01,\n",
      "         -1.5452e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.7123e-01, -3.7516e-02,  5.8703e-01, -1.4448e+00, -3.1899e-01,\n",
      "          9.6780e-02,  1.0000e+00,  0.0000e+00],\n",
      "        [ 1.2479e-02,  1.3984e+00,  1.0435e-01, -1.2068e-01,  5.8309e-03,\n",
      "          1.0364e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0038e-01,  1.3636e-02, -2.8618e-01, -1.3972e+00,  1.5810e-01,\n",
      "          2.4248e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.5478e-01,  3.8866e-01, -5.0070e-01, -9.9622e-01,  6.3758e-01,\n",
      "          4.7739e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4351e-02,  1.1740e+00,  1.4187e-01, -5.7762e-01, -2.2863e-01,\n",
      "         -2.3622e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.8941e-01,  1.3569e-01, -2.6079e-01, -1.3469e+00,  1.0925e-01,\n",
      "          2.1576e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7823e-01,  1.2469e-01,  2.4551e-01, -1.1613e+00,  1.1342e-01,\n",
      "          2.4202e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.7730e-02,  7.1589e-02, -4.4053e-02, -1.4679e+00,  5.4272e-01,\n",
      "          1.6680e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.1123e-01,  3.0703e-01, -9.4744e-01, -1.4733e+00,  9.5539e-01,\n",
      "          2.4746e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.6398e-02,  1.3737e-01, -2.0337e-01, -1.3295e+00,  4.2067e-01,\n",
      "          1.5782e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.8161e-02,  1.3198e+00,  2.2592e-01, -5.6365e-01, -4.1626e-01,\n",
      "         -2.1282e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.7299e-02,  1.0149e+00,  2.5186e-01, -8.0153e-01, -1.4311e-01,\n",
      "          3.5543e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1911e-01,  1.1153e+00, -5.7855e-01, -5.0805e-01,  3.4507e-01,\n",
      "          1.8834e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.4862e-02,  2.8833e-01, -5.8716e-02, -1.1861e+00, -4.5750e-02,\n",
      "         -4.4381e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.9201e-02,  1.3099e+00, -4.2740e-01, -2.0335e-01,  1.3950e-01,\n",
      "          1.3570e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.0436e-01,  3.7111e-01,  1.2786e+00, -1.0367e+00, -8.1093e-01,\n",
      "         -4.2078e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1569e-01,  9.8855e-01, -3.7093e-01, -6.5784e-01,  2.1788e-01,\n",
      "          2.0129e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.1919e-02,  7.8295e-01, -2.6177e-01, -8.3736e-01,  2.8940e-01,\n",
      "          2.7411e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.8882e-03,  7.9425e-01, -6.1337e-02, -9.0276e-01,  4.1632e-02,\n",
      "          5.4450e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.5862e-02,  1.4112e+00, -1.4596e-01, -1.1155e-01, -4.2751e-03,\n",
      "         -3.8123e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0964e-02,  1.4826e+00, -2.3704e-01,  2.9964e-01,  1.5282e-02,\n",
      "         -1.5022e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1115e-01,  1.1659e+00, -6.8087e-01, -5.0500e-01,  9.4646e-02,\n",
      "          6.5232e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.4956e-02,  1.3759e+00, -3.3729e-02, -4.7397e-01, -1.4970e-02,\n",
      "         -1.8070e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1321e-01,  3.0293e-01, -2.9186e-01, -1.2620e+00, -7.0772e-02,\n",
      "          7.9770e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.8624e-03,  1.3867e+00, -5.7640e-02, -3.8465e-01, -2.1341e-03,\n",
      "         -2.9280e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0349e-01,  1.4949e+00, -5.0302e-01, -3.9795e-01,  3.1671e-01,\n",
      "          2.5891e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.9162e-02,  8.2048e-02,  4.5956e-01, -1.4022e+00, -6.9803e-01,\n",
      "         -1.2298e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.2131e-02,  1.3594e+00, -1.1927e-01, -2.2971e-01, -7.2167e-03,\n",
      "          2.1365e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9506e-02,  1.2232e+00,  1.0496e-01, -5.1610e-01, -1.8321e-01,\n",
      "         -2.0452e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2972e-03,  1.3842e+00, -1.6876e-01, -3.9304e-01,  8.0027e-03,\n",
      "          6.3757e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2001e-01,  6.8000e-01, -6.1967e-01, -1.1819e+00,  4.2135e-01,\n",
      "          2.1817e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9907e-02,  1.5306e+00,  1.0678e-01, -1.1409e-01, -1.3363e-01,\n",
      "         -1.6118e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.3908e-01,  2.0217e-01, -1.0993e+00, -1.3509e+00,  6.7358e-01,\n",
      "          7.6410e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6031e-01,  1.8372e-01,  1.2338e+00, -1.6126e+00, -1.1628e+00,\n",
      "          3.2614e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.4572e-01,  5.0820e-02, -6.1297e-01, -1.1987e-01,  1.9506e+00,\n",
      "          2.8514e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.6490e-01,  3.5697e-01, -1.1761e+00, -1.2290e+00,  7.4490e-01,\n",
      "          1.6802e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8125e-02,  1.4135e+00,  4.6567e-01,  4.5517e-03, -2.1101e-02,\n",
      "         -1.2675e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.6844e-02,  1.1099e+00,  1.0508e-01, -6.7080e-01,  4.4351e-02,\n",
      "          9.7371e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0646e-01,  1.0191e+00, -2.2230e-01, -8.3512e-01, -1.0819e-02,\n",
      "         -1.0041e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.7193e-01,  1.6505e-02,  7.5935e-01, -7.2597e-02, -5.9691e-01,\n",
      "          1.7190e+00,  1.0000e+00,  0.0000e+00],\n",
      "        [-8.6596e-01, -1.2192e-01, -1.0962e+00, -2.3804e-01,  9.6589e-01,\n",
      "          1.6143e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [-8.4648e-02,  7.6482e-01, -2.8624e-01, -8.0863e-01,  3.0312e-01,\n",
      "          2.7436e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.8307e-02,  1.1239e+00, -1.1853e-01, -7.7933e-01,  1.1678e-02,\n",
      "         -2.7804e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4902e-01,  1.5667e+00,  9.2043e-01,  1.0995e-02, -4.5181e-01,\n",
      "         -3.0884e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.9201e-01, -2.5941e-02,  1.0480e+00, -1.4994e+00, -1.0929e+00,\n",
      "         -7.8056e-01,  1.0000e+00,  0.0000e+00],\n",
      "        [-2.6478e-01,  4.2048e-01, -2.4655e-01, -1.1719e+00,  6.2195e-03,\n",
      "          1.5243e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.5240e-02,  1.4765e+00,  8.2368e-01,  3.3572e-01, -8.2322e-02,\n",
      "         -3.2509e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.1265e-01,  1.0981e+00, -8.8590e-01, -6.3354e-01,  3.7114e-01,\n",
      "          1.7899e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.0351e-02,  1.0642e+00, -1.0446e-01, -7.0746e-01,  1.4806e-01,\n",
      "          6.7999e-03,  0.0000e+00,  0.0000e+00]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) exps.shape\n",
      "*** AttributeError: 'tuple' object has no attribute 'shape'\n",
      "(Pdb) len(exps)\n",
      "5\n",
      "(Pdb) states, actions, rewards, next_states, dones = exps\n",
      "(Pdb) states\n",
      "tensor([[ 6.0966e-03,  1.3830e+00,  2.1713e-01, -4.1300e-01, -9.8569e-03,\n",
      "         -7.0632e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.3087e-02,  8.9639e-01, -1.8141e-01, -9.1193e-01,  3.1014e-01,\n",
      "          6.5574e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.6992e-01,  1.5441e+00, -4.7929e-01, -2.0485e-01,  2.4759e-01,\n",
      "          1.5405e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5873e-01,  1.5116e+00,  4.5047e-01, -1.0888e-01, -1.3755e-01,\n",
      "         -1.5146e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2511e-03,  6.5165e-01,  3.2420e-01, -9.8647e-01, -5.3010e-01,\n",
      "         -2.3200e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9436e-01,  1.2574e+00, -7.4399e-01, -4.3366e-01,  2.5142e-01,\n",
      "          1.7521e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6542e-01,  1.1775e+00,  7.6149e-01, -5.1593e-01, -1.3705e-01,\n",
      "         -1.5712e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8463e-01,  9.2171e-01,  5.2515e-01, -9.0506e-01, -1.9296e-01,\n",
      "         -8.0051e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4800e-01,  1.1683e+00,  6.0748e-01, -4.6594e-01,  6.2858e-02,\n",
      "          1.3179e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6310e-01,  7.9135e-01,  9.7690e-01, -1.1712e+00, -1.1493e+00,\n",
      "         -6.8299e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0412e-01,  1.4569e+00,  4.6505e-01, -3.1396e-01, -1.5473e-01,\n",
      "         -6.8633e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.6848e-02,  1.4259e+00, -2.1764e-01, -3.6407e-03,  2.6289e-02,\n",
      "          6.7064e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.4150e-01,  4.1150e-01, -1.1228e+00, -1.2278e+00,  7.2809e-01,\n",
      "          1.5617e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.3404e-02,  1.4915e+00, -2.9461e-01,  2.4831e-01, -4.1041e-03,\n",
      "         -5.1662e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.5682e-02,  1.2652e+00,  2.6642e-01, -5.3701e-01, -9.3669e-02,\n",
      "         -1.5457e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6525e-01, -4.9481e-03,  6.2342e-01, -1.5217e+00, -3.2421e-01,\n",
      "         -2.0857e-01,  1.0000e+00,  0.0000e+00],\n",
      "        [ 1.1383e-02,  1.4011e+00,  1.1335e-01, -9.3926e-02,  6.4951e-04,\n",
      "          6.7619e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.9764e-01,  4.5046e-02, -2.9541e-01, -1.3711e+00,  1.4598e-01,\n",
      "          2.7966e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4997e-01,  4.1086e-01, -4.9066e-01, -9.6503e-01,  6.1372e-01,\n",
      "          4.2491e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3049e-02,  1.1869e+00,  1.3105e-01, -5.4934e-01, -2.1682e-01,\n",
      "         -1.9131e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.8691e-01,  1.6598e-01, -2.6079e-01, -1.3202e+00,  9.8460e-02,\n",
      "          2.1576e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7576e-01,  1.5081e-01,  2.4193e-01, -1.1806e+00,  1.1221e-01,\n",
      "          1.3253e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8098e-02,  1.0455e-01, -4.4058e-02, -1.4413e+00,  5.3438e-01,\n",
      "          1.6680e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.0182e-01,  3.4003e-01, -9.5505e-01, -1.4529e+00,  9.4302e-01,\n",
      "          3.0405e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.4437e-02,  1.6723e-01, -2.1451e-01, -1.3059e+00,  4.1277e-01,\n",
      "          2.0820e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.6001e-02,  1.3325e+00,  2.3691e-01, -5.3976e-01, -4.0561e-01,\n",
      "         -2.6158e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.4763e-02,  1.0329e+00,  2.5186e-01, -7.7486e-01, -1.4489e-01,\n",
      "          3.5543e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1342e-01,  1.1267e+00, -5.7855e-01, -4.8138e-01,  3.3565e-01,\n",
      "          1.8834e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.4252e-02,  3.1501e-01, -5.6638e-02, -1.1973e+00, -4.3531e-02,\n",
      "         -3.9959e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.4995e-02,  1.3144e+00, -4.1979e-01, -2.2751e-01,  1.3272e-01,\n",
      "          1.3325e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.9172e-01,  3.9420e-01,  1.2715e+00, -1.0044e+00, -7.8989e-01,\n",
      "         -3.7062e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1208e-01,  1.0033e+00, -3.7093e-01, -6.3116e-01,  2.0781e-01,\n",
      "          2.0129e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.9434e-02,  8.0174e-01, -2.6178e-01, -8.1067e-01,  2.7570e-01,\n",
      "          2.7412e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.3024e-03,  8.1456e-01, -7.2717e-02, -8.7615e-01,  3.8910e-02,\n",
      "          1.0001e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4383e-02,  1.4137e+00, -1.4597e-01, -8.4886e-02, -2.3691e-03,\n",
      "         -3.8120e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.8586e-02,  1.4759e+00, -2.2752e-01,  2.7846e-01,  1.6033e-02,\n",
      "         -6.6646e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0438e-01,  1.1772e+00, -6.8087e-01, -4.7833e-01,  9.1385e-02,\n",
      "          6.5232e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.4527e-02,  1.3866e+00, -2.5176e-02, -4.4704e-01, -5.9355e-03,\n",
      "         -2.1494e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1033e-01,  3.3133e-01, -2.9186e-01, -1.2353e+00, -7.4760e-02,\n",
      "          7.9770e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2712e-03,  1.3954e+00, -5.7644e-02, -3.5796e-01, -6.7024e-04,\n",
      "         -2.9300e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9858e-01,  1.5038e+00, -4.9483e-01, -3.6907e-01,  3.0376e-01,\n",
      "          2.2260e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.4614e-02,  1.1354e-01,  4.5956e-01, -1.3755e+00, -6.9188e-01,\n",
      "         -1.2298e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0950e-02,  1.3645e+00, -1.0823e-01, -2.0265e-01, -8.2849e-03,\n",
      "         -2.2849e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8558e-02,  1.2348e+00,  1.1429e-01, -4.9011e-01, -1.7299e-01,\n",
      "         -2.4237e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.6417e-03,  1.3930e+00, -1.7949e-01, -3.9373e-01,  4.8152e-03,\n",
      "          5.2754e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1391e-01,  7.0653e-01, -6.1968e-01, -1.1552e+00,  4.1044e-01,\n",
      "          2.1817e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.8920e-02,  1.5331e+00,  1.0678e-01, -8.7414e-02, -1.2557e-01,\n",
      "         -1.6118e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.2812e-01,  2.3253e-01, -1.0560e+00, -1.3501e+00,  6.6976e-01,\n",
      "          8.5957e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.4797e-01,  2.2000e-01,  1.1877e+00, -1.5951e+00, -1.1630e+00,\n",
      "         -2.2314e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.3916e-01,  5.1451e-02, -6.1355e-01, -1.0022e-01,  1.8082e+00,\n",
      "          2.9069e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.5320e-01,  3.8454e-01, -1.1761e+00, -1.2024e+00,  7.3649e-01,\n",
      "          1.6802e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3532e-02,  1.4134e+00,  4.5797e-01,  3.1580e-02, -1.4764e-02,\n",
      "         -9.5894e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.5744e-02,  1.1250e+00,  1.2138e-01, -6.8823e-01,  3.9483e-02,\n",
      "          1.1064e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0418e-01,  1.0379e+00, -2.3612e-01, -8.5108e-01, -5.7981e-03,\n",
      "         -1.1346e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.6262e-01,  3.1078e-02,  9.3480e-01, -8.3434e-01, -6.3384e-01,\n",
      "          5.4575e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.5550e-01, -1.1754e-01, -1.1231e+00, -2.8144e-01,  8.8515e-01,\n",
      "          1.8933e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [-8.1919e-02,  7.8295e-01, -2.6177e-01, -8.3736e-01,  2.8940e-01,\n",
      "          2.7411e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.7108e-02,  1.1414e+00, -1.3063e-01, -7.5298e-01,  1.3068e-02,\n",
      "          2.0687e-02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3996e-01,  1.5663e+00,  8.7597e-01, -2.2621e-02, -4.3637e-01,\n",
      "         -3.1086e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.8171e-01,  7.2740e-03,  1.0438e+00, -1.4668e+00, -1.0538e+00,\n",
      "         -7.3372e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6239e-01,  4.4685e-01, -2.3723e-01, -1.1449e+00, -1.4020e-03,\n",
      "          1.1510e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.7167e-02,  1.4689e+00,  8.1252e-01,  3.6287e-01, -6.6069e-02,\n",
      "         -2.8043e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0387e-01,  1.1123e+00, -8.5471e-01, -6.6527e-01,  3.6219e-01,\n",
      "          1.7717e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.9309e-02,  1.0802e+00, -1.0446e-01, -6.8080e-01,  1.4772e-01,\n",
      "          6.7999e-03,  0.0000e+00,  0.0000e+00]])\n",
      "(Pdb) states.shape\n",
      "torch.Size([64, 8])\n",
      "(Pdb) actions\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) next_states.shape\n",
      "torch.Size([64, 8])\n",
      "(Pdb) qnxt = agent.qnetwork_target(next_states)\n",
      "(Pdb) qnxt.size\n",
      "<built-in method size of Tensor object at 0x0000021D09D50D80>\n",
      "(Pdb) qnxt\n",
      "tensor([[-7.6255e-01, -6.5656e-01,  1.2808e-01, -7.9559e-01],\n",
      "        [-8.1147e-01, -9.5351e-01, -3.8339e-03, -7.9012e-01],\n",
      "        [-5.7803e-01, -8.2411e-01, -1.5337e-01, -3.9225e-01],\n",
      "        [-8.0277e-01, -5.4181e-01, -1.0770e-01, -7.0364e-01],\n",
      "        [-1.3801e+00, -8.4314e-01, -4.7596e-01, -1.2253e+00],\n",
      "        [-6.5929e-01, -9.1847e-01, -1.3469e-01, -4.8043e-01],\n",
      "        [-1.0432e+00, -5.9242e-01,  3.1152e-02, -1.0348e+00],\n",
      "        [-1.1509e+00, -7.6306e-01, -1.0010e-01, -1.1649e+00],\n",
      "        [-9.0782e-01, -6.8485e-01,  3.7526e-02, -9.1933e-01],\n",
      "        [-2.3293e+00, -1.0873e+00, -1.4693e+00, -1.8580e+00],\n",
      "        [-8.5909e-01, -5.8156e-01,  3.2812e-02, -8.4297e-01],\n",
      "        [-5.2436e-01, -6.4652e-01, -1.9113e-01, -3.5277e-01],\n",
      "        [-1.7466e+00, -2.0224e+00, -1.9633e+00, -9.5808e-01],\n",
      "        [-4.7873e-01, -5.3508e-01, -3.5256e-01, -1.9826e-01],\n",
      "        [-8.2526e-01, -6.4182e-01,  1.8899e-01, -8.9619e-01],\n",
      "        [-3.2852e+00, -1.6091e+00, -2.9978e+00, -2.3426e+00],\n",
      "        [-6.0998e-01, -6.1762e-01, -1.1663e-01, -5.0914e-01],\n",
      "        [-2.1334e+00, -1.8819e+00, -2.3672e+00, -1.3459e+00],\n",
      "        [-1.5593e+00, -1.7106e+00, -1.7221e+00, -9.5725e-01],\n",
      "        [-8.2826e-01, -6.2586e-01,  1.9182e-01, -8.9127e-01],\n",
      "        [-1.9238e+00, -1.7212e+00, -1.9932e+00, -1.2615e+00],\n",
      "        [-1.6758e+00, -1.2501e+00, -1.3480e+00, -1.3040e+00],\n",
      "        [-2.0243e+00, -1.8273e+00, -2.0479e+00, -1.3763e+00],\n",
      "        [-2.0257e+00, -2.2624e+00, -2.3564e+00, -1.1535e+00],\n",
      "        [-1.7934e+00, -1.6955e+00, -1.7889e+00, -1.2005e+00],\n",
      "        [-9.1599e-01, -6.1860e-01,  1.1626e-01, -9.2717e-01],\n",
      "        [-9.0101e-01, -7.5244e-01,  8.0586e-02, -9.5530e-01],\n",
      "        [-6.6261e-01, -9.3670e-01, -1.5274e-01, -5.0225e-01],\n",
      "        [-1.4642e+00, -1.2221e+00, -1.0409e+00, -1.1367e+00],\n",
      "        [-5.3342e-01, -7.4395e-01, -1.2528e-01, -3.8750e-01],\n",
      "        [-2.5907e+00, -1.0802e+00, -1.5981e+00, -2.0350e+00],\n",
      "        [-6.8589e-01, -8.9943e-01, -8.5478e-02, -6.0984e-01],\n",
      "        [-8.7575e-01, -1.0386e+00, -3.4050e-01, -7.3115e-01],\n",
      "        [-8.6690e-01, -8.7751e-01, -7.8638e-02, -8.4633e-01],\n",
      "        [-5.7292e-01, -6.1230e-01, -8.8226e-02, -4.6383e-01],\n",
      "        [-4.7743e-01, -5.3037e-01, -3.7646e-01, -1.8821e-01],\n",
      "        [-6.4833e-01, -8.6774e-01, -8.2277e-02, -5.1753e-01],\n",
      "        [-7.1984e-01, -6.7210e-01,  1.7414e-01, -7.5604e-01],\n",
      "        [-1.6081e+00, -1.4365e+00, -1.3558e+00, -1.1362e+00],\n",
      "        [-6.6651e-01, -6.8254e-01,  8.7904e-02, -6.6246e-01],\n",
      "        [-6.5613e-01, -9.1443e-01, -1.3013e-01, -4.8564e-01],\n",
      "        [-2.3918e+00, -1.3047e+00, -1.9648e+00, -1.8065e+00],\n",
      "        [-5.8845e-01, -6.5557e-01, -2.5484e-02, -5.2253e-01],\n",
      "        [-7.8274e-01, -6.2451e-01,  1.7633e-01, -8.3792e-01],\n",
      "        [-6.2708e-01, -7.2338e-01,  6.4732e-02, -6.0859e-01],\n",
      "        [-1.2261e+00, -1.4543e+00, -8.6303e-01, -8.4878e-01],\n",
      "        [-6.8320e-01, -5.4391e-01, -7.2168e-02, -5.8938e-01],\n",
      "        [-1.8768e+00, -2.0965e+00, -2.1527e+00, -1.0396e+00],\n",
      "        [-3.2269e+00, -1.4900e+00, -2.6452e+00, -2.4371e+00],\n",
      "        [-5.7574e+00, -4.9265e+00, -8.3575e+00, -3.0052e+00],\n",
      "        [-1.7896e+00, -2.0574e+00, -2.0384e+00, -9.8018e-01],\n",
      "        [-7.2861e-01, -5.2014e-01, -1.7457e-01, -5.9220e-01],\n",
      "        [-7.5502e-01, -7.6056e-01,  1.4884e-01, -8.1854e-01],\n",
      "        [-7.7964e-01, -8.4647e-01,  8.8948e-02, -7.8368e-01],\n",
      "        [-3.5582e+00, -2.1406e+00, -4.6106e+00, -2.0581e+00],\n",
      "        [-5.1444e+00, -4.2804e+00, -7.5003e+00, -2.5970e+00],\n",
      "        [-8.6209e-01, -1.0400e+00, -3.5725e-01, -7.0587e-01],\n",
      "        [-7.5385e-01, -7.8633e-01,  1.7144e-01, -8.0968e-01],\n",
      "        [-1.0806e+00, -4.8197e-01, -3.1544e-01, -8.4348e-01],\n",
      "        [-4.0996e+00, -1.6205e+00, -3.1901e+00, -2.8760e+00],\n",
      "        [-1.4294e+00, -1.3364e+00, -1.1328e+00, -1.0458e+00],\n",
      "        [-8.7456e-01, -4.5416e-01, -4.5581e-01, -5.5520e-01],\n",
      "        [-8.0610e-01, -1.1365e+00, -3.4567e-01, -5.1891e-01],\n",
      "        [-7.0668e-01, -7.7785e-01,  1.4890e-01, -7.5001e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "(Pdb) qnxt.size()\n",
      "torch.Size([64, 4])\n",
      "(Pdb) qnxt.detach()\n",
      "tensor([[-7.6255e-01, -6.5656e-01,  1.2808e-01, -7.9559e-01],\n",
      "        [-8.1147e-01, -9.5351e-01, -3.8339e-03, -7.9012e-01],\n",
      "        [-5.7803e-01, -8.2411e-01, -1.5337e-01, -3.9225e-01],\n",
      "        [-8.0277e-01, -5.4181e-01, -1.0770e-01, -7.0364e-01],\n",
      "        [-1.3801e+00, -8.4314e-01, -4.7596e-01, -1.2253e+00],\n",
      "        [-6.5929e-01, -9.1847e-01, -1.3469e-01, -4.8043e-01],\n",
      "        [-1.0432e+00, -5.9242e-01,  3.1152e-02, -1.0348e+00],\n",
      "        [-1.1509e+00, -7.6306e-01, -1.0010e-01, -1.1649e+00],\n",
      "        [-9.0782e-01, -6.8485e-01,  3.7526e-02, -9.1933e-01],\n",
      "        [-2.3293e+00, -1.0873e+00, -1.4693e+00, -1.8580e+00],\n",
      "        [-8.5909e-01, -5.8156e-01,  3.2812e-02, -8.4297e-01],\n",
      "        [-5.2436e-01, -6.4652e-01, -1.9113e-01, -3.5277e-01],\n",
      "        [-1.7466e+00, -2.0224e+00, -1.9633e+00, -9.5808e-01],\n",
      "        [-4.7873e-01, -5.3508e-01, -3.5256e-01, -1.9826e-01],\n",
      "        [-8.2526e-01, -6.4182e-01,  1.8899e-01, -8.9619e-01],\n",
      "        [-3.2852e+00, -1.6091e+00, -2.9978e+00, -2.3426e+00],\n",
      "        [-6.0998e-01, -6.1762e-01, -1.1663e-01, -5.0914e-01],\n",
      "        [-2.1334e+00, -1.8819e+00, -2.3672e+00, -1.3459e+00],\n",
      "        [-1.5593e+00, -1.7106e+00, -1.7221e+00, -9.5725e-01],\n",
      "        [-8.2826e-01, -6.2586e-01,  1.9182e-01, -8.9127e-01],\n",
      "        [-1.9238e+00, -1.7212e+00, -1.9932e+00, -1.2615e+00],\n",
      "        [-1.6758e+00, -1.2501e+00, -1.3480e+00, -1.3040e+00],\n",
      "        [-2.0243e+00, -1.8273e+00, -2.0479e+00, -1.3763e+00],\n",
      "        [-2.0257e+00, -2.2624e+00, -2.3564e+00, -1.1535e+00],\n",
      "        [-1.7934e+00, -1.6955e+00, -1.7889e+00, -1.2005e+00],\n",
      "        [-9.1599e-01, -6.1860e-01,  1.1626e-01, -9.2717e-01],\n",
      "        [-9.0101e-01, -7.5244e-01,  8.0586e-02, -9.5530e-01],\n",
      "        [-6.6261e-01, -9.3670e-01, -1.5274e-01, -5.0225e-01],\n",
      "        [-1.4642e+00, -1.2221e+00, -1.0409e+00, -1.1367e+00],\n",
      "        [-5.3342e-01, -7.4395e-01, -1.2528e-01, -3.8750e-01],\n",
      "        [-2.5907e+00, -1.0802e+00, -1.5981e+00, -2.0350e+00],\n",
      "        [-6.8589e-01, -8.9943e-01, -8.5478e-02, -6.0984e-01],\n",
      "        [-8.7575e-01, -1.0386e+00, -3.4050e-01, -7.3115e-01],\n",
      "        [-8.6690e-01, -8.7751e-01, -7.8638e-02, -8.4633e-01],\n",
      "        [-5.7292e-01, -6.1230e-01, -8.8226e-02, -4.6383e-01],\n",
      "        [-4.7743e-01, -5.3037e-01, -3.7646e-01, -1.8821e-01],\n",
      "        [-6.4833e-01, -8.6774e-01, -8.2277e-02, -5.1753e-01],\n",
      "        [-7.1984e-01, -6.7210e-01,  1.7414e-01, -7.5604e-01],\n",
      "        [-1.6081e+00, -1.4365e+00, -1.3558e+00, -1.1362e+00],\n",
      "        [-6.6651e-01, -6.8254e-01,  8.7904e-02, -6.6246e-01],\n",
      "        [-6.5613e-01, -9.1443e-01, -1.3013e-01, -4.8564e-01],\n",
      "        [-2.3918e+00, -1.3047e+00, -1.9648e+00, -1.8065e+00],\n",
      "        [-5.8845e-01, -6.5557e-01, -2.5484e-02, -5.2253e-01],\n",
      "        [-7.8274e-01, -6.2451e-01,  1.7633e-01, -8.3792e-01],\n",
      "        [-6.2708e-01, -7.2338e-01,  6.4732e-02, -6.0859e-01],\n",
      "        [-1.2261e+00, -1.4543e+00, -8.6303e-01, -8.4878e-01],\n",
      "        [-6.8320e-01, -5.4391e-01, -7.2168e-02, -5.8938e-01],\n",
      "        [-1.8768e+00, -2.0965e+00, -2.1527e+00, -1.0396e+00],\n",
      "        [-3.2269e+00, -1.4900e+00, -2.6452e+00, -2.4371e+00],\n",
      "        [-5.7574e+00, -4.9265e+00, -8.3575e+00, -3.0052e+00],\n",
      "        [-1.7896e+00, -2.0574e+00, -2.0384e+00, -9.8018e-01],\n",
      "        [-7.2861e-01, -5.2014e-01, -1.7457e-01, -5.9220e-01],\n",
      "        [-7.5502e-01, -7.6056e-01,  1.4884e-01, -8.1854e-01],\n",
      "        [-7.7964e-01, -8.4647e-01,  8.8948e-02, -7.8368e-01],\n",
      "        [-3.5582e+00, -2.1406e+00, -4.6106e+00, -2.0581e+00],\n",
      "        [-5.1444e+00, -4.2804e+00, -7.5003e+00, -2.5970e+00],\n",
      "        [-8.6209e-01, -1.0400e+00, -3.5725e-01, -7.0587e-01],\n",
      "        [-7.5385e-01, -7.8633e-01,  1.7144e-01, -8.0968e-01],\n",
      "        [-1.0806e+00, -4.8197e-01, -3.1544e-01, -8.4348e-01],\n",
      "        [-4.0996e+00, -1.6205e+00, -3.1901e+00, -2.8760e+00],\n",
      "        [-1.4294e+00, -1.3364e+00, -1.1328e+00, -1.0458e+00],\n",
      "        [-8.7456e-01, -4.5416e-01, -4.5581e-01, -5.5520e-01],\n",
      "        [-8.0610e-01, -1.1365e+00, -3.4567e-01, -5.1891e-01],\n",
      "        [-7.0668e-01, -7.7785e-01,  1.4890e-01, -7.5001e-01]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) lqag = agent.qnetwork_local(states)\n",
      "(Pdb) lqag.size()\n",
      "torch.Size([64, 4])\n",
      "(Pdb) lqag[1,:]\n",
      "tensor([-0.5405, -1.7728,  1.9306, -1.2535], grad_fn=<SliceBackward>)\n",
      "(Pdb) lqag[1]\n",
      "tensor([-0.5405, -1.7728,  1.9306, -1.2535], grad_fn=<SelectBackward>)\n",
      "(Pdb) lqag[1].sum()\n",
      "tensor(-1.6362, grad_fn=<SumBackward0>)\n",
      "(Pdb) lqag.gather(1, actions)\n",
      "tensor([[ -0.4736],\n",
      "        [ -0.5405],\n",
      "        [ -1.9309],\n",
      "        [ -0.9552],\n",
      "        [ -2.7738],\n",
      "        [ -0.3571],\n",
      "        [  1.2218],\n",
      "        [ -1.0693],\n",
      "        [ -1.8128],\n",
      "        [ -7.0004],\n",
      "        [ -0.9802],\n",
      "        [ -1.4320],\n",
      "        [ -2.1784],\n",
      "        [ -1.4248],\n",
      "        [ -0.6030],\n",
      "        [-16.3591],\n",
      "        [ -1.2763],\n",
      "        [ -5.9096],\n",
      "        [ -4.2970],\n",
      "        [ -1.2719],\n",
      "        [ -6.1727],\n",
      "        [ -2.7181],\n",
      "        [ -6.7118],\n",
      "        [ -3.8659],\n",
      "        [ -4.0901],\n",
      "        [ -0.9469],\n",
      "        [ -0.7936],\n",
      "        [ -0.6786],\n",
      "        [ -0.1471],\n",
      "        [  0.1700],\n",
      "        [-10.0394],\n",
      "        [ -0.5723],\n",
      "        [ -0.8167],\n",
      "        [ -1.3829],\n",
      "        [ -0.2481],\n",
      "        [ -1.5677],\n",
      "        [ -0.3617],\n",
      "        [ -1.2634],\n",
      "        [ -3.2507],\n",
      "        [ -0.2262],\n",
      "        [ -2.1093],\n",
      "        [-10.7917],\n",
      "        [ -1.3361],\n",
      "        [ -1.0698],\n",
      "        [  0.9712],\n",
      "        [ -1.5944],\n",
      "        [ -0.4796],\n",
      "        [ -2.8456],\n",
      "        [-11.3379],\n",
      "        [-19.9973],\n",
      "        [ -4.5807],\n",
      "        [ -0.7430],\n",
      "        [  1.9409],\n",
      "        [  2.0524],\n",
      "        [-13.5627],\n",
      "        [-31.1540],\n",
      "        [  1.2433],\n",
      "        [ -1.1594],\n",
      "        [ -1.0006],\n",
      "        [-13.8214],\n",
      "        [ -2.5529],\n",
      "        [ -0.9366],\n",
      "        [  0.6806],\n",
      "        [ -0.3856]], grad_fn=<GatherBackward>)\n",
      "(Pdb) final = lqag.gather(1, actions)\n",
      "(Pdb) final.size()\n",
      "torch.Size([64, 1])\n",
      "(Pdb) lqag\n",
      "tensor([[-4.7361e-01, -1.2424e+00,  1.1932e+00, -1.0459e+00],\n",
      "        [-5.4051e-01, -1.7728e+00,  1.9306e+00, -1.2535e+00],\n",
      "        [-3.0384e-01, -1.9309e+00, -2.4054e-02, -3.7799e-02],\n",
      "        [-9.5944e-01, -1.0767e+00, -2.4877e-01, -9.5517e-01],\n",
      "        [-2.4953e+00, -1.1816e+00,  7.8187e-01, -2.7738e+00],\n",
      "        [-5.5209e-01, -2.2333e+00,  5.1643e-01, -3.5714e-01],\n",
      "        [-1.8305e+00, -9.3799e-01,  1.2218e+00, -2.4447e+00],\n",
      "        [-1.5533e+00, -1.0693e+00,  1.8603e+00, -2.4556e+00],\n",
      "        [-1.1829e+00, -1.2055e+00,  1.1967e+00, -1.8128e+00],\n",
      "        [-7.0004e+00, -1.6772e+00, -2.6323e+00, -5.9601e+00],\n",
      "        [-9.8021e-01, -1.0559e+00,  5.5498e-01, -1.3271e+00],\n",
      "        [-2.8105e-01, -1.4320e+00, -5.1170e-01,  2.3760e-02],\n",
      "        [-4.2508e+00, -5.3074e+00, -2.1784e+00, -2.4036e+00],\n",
      "        [-3.1736e-01, -1.3173e+00, -1.4248e+00,  4.1218e-01],\n",
      "        [-6.0296e-01, -1.1268e+00,  1.6441e+00, -1.3621e+00],\n",
      "        [-2.2031e+01, -6.6180e+00, -1.6359e+01, -1.6050e+01],\n",
      "        [-4.7134e-01, -1.2763e+00, -1.3226e-01, -4.3915e-01],\n",
      "        [-8.2790e+00, -5.7286e+00, -5.7148e+00, -5.9096e+00],\n",
      "        [-3.5887e+00, -4.2970e+00, -1.3596e+00, -2.5322e+00],\n",
      "        [-5.4800e-01, -1.0824e+00,  1.6246e+00, -1.2719e+00],\n",
      "        [-6.1727e+00, -4.6794e+00, -3.5084e+00, -4.5817e+00],\n",
      "        [-6.1606e+00, -3.1879e+00, -2.7181e+00, -5.1000e+00],\n",
      "        [-6.7118e+00, -4.9938e+00, -3.3217e+00, -5.2140e+00],\n",
      "        [-5.9645e+00, -6.4165e+00, -3.3669e+00, -3.8659e+00],\n",
      "        [-5.3035e+00, -4.5550e+00, -2.3796e+00, -4.0901e+00],\n",
      "        [-8.0529e-01, -9.4692e-01,  1.3779e+00, -1.4660e+00],\n",
      "        [-7.9361e-01, -1.2236e+00,  2.0625e+00, -1.7403e+00],\n",
      "        [-6.7864e-01, -2.2322e+00,  7.7004e-01, -6.1193e-01],\n",
      "        [-3.2441e+00, -2.4526e+00, -1.4707e-01, -2.9289e+00],\n",
      "        [-2.7150e-01, -1.7368e+00,  1.7004e-01, -1.3556e-01],\n",
      "        [-1.2962e+01, -2.9760e+00, -7.6964e+00, -1.0039e+01],\n",
      "        [-5.7226e-01, -1.9503e+00,  1.2099e+00, -8.4640e-01],\n",
      "        [-8.1669e-01, -2.0856e+00,  1.2501e+00, -1.1550e+00],\n",
      "        [-6.2479e-01, -1.5609e+00,  1.8542e+00, -1.3829e+00],\n",
      "        [-2.4810e-01, -1.3101e+00, -7.4442e-02, -1.7306e-01],\n",
      "        [-4.0760e-01, -1.3254e+00, -1.5677e+00,  3.7582e-01],\n",
      "        [-3.6174e-01, -1.9241e+00,  8.6942e-01, -3.9762e-01],\n",
      "        [-2.5599e-01, -1.2634e+00,  1.4412e+00, -8.6270e-01],\n",
      "        [-3.2507e+00, -3.0103e+00, -4.4942e-01, -2.7192e+00],\n",
      "        [-2.2623e-01, -1.3510e+00,  9.8073e-01, -6.3890e-01],\n",
      "        [-4.3063e-01, -2.1093e+00,  4.3173e-01, -3.1157e-01],\n",
      "        [-1.0792e+01, -3.5570e+00, -7.0318e+00, -8.3154e+00],\n",
      "        [-2.2851e-01, -1.3361e+00,  3.8448e-01, -3.6174e-01],\n",
      "        [-5.0294e-01, -1.0698e+00,  1.4821e+00, -1.1610e+00],\n",
      "        [-2.0217e-01, -1.4547e+00,  9.7120e-01, -5.6314e-01],\n",
      "        [-1.5944e+00, -2.9813e+00,  8.2597e-01, -1.4468e+00],\n",
      "        [-4.7956e-01, -1.1150e+00, -9.8345e-02, -4.7362e-01],\n",
      "        [-5.0623e+00, -5.6540e+00, -2.8456e+00, -3.1132e+00],\n",
      "        [-1.6131e+01, -4.3711e+00, -1.1338e+01, -1.2304e+01],\n",
      "        [-3.0747e+01, -2.0119e+01, -2.8487e+01, -1.9997e+01],\n",
      "        [-4.5807e+00, -5.5097e+00, -2.6096e+00, -2.5666e+00],\n",
      "        [-9.4836e-01, -1.1237e+00, -6.0317e-01, -7.4302e-01],\n",
      "        [-5.7255e-01, -1.4184e+00,  1.9409e+00, -1.3959e+00],\n",
      "        [-2.9576e-01, -1.4985e+00,  2.0524e+00, -1.0694e+00],\n",
      "        [-1.3563e+01, -3.7179e+00, -9.7955e+00, -1.0250e+01],\n",
      "        [-3.1154e+01, -1.9205e+01, -2.9683e+01, -1.9671e+01],\n",
      "        [-8.6330e-01, -2.1222e+00,  1.2433e+00, -1.1932e+00],\n",
      "        [-3.8041e-01, -1.4719e+00,  2.0122e+00, -1.1594e+00],\n",
      "        [-2.1465e+00, -8.2065e-01, -1.0006e+00, -1.7897e+00],\n",
      "        [-1.8865e+01, -4.6519e+00, -1.3042e+01, -1.3821e+01],\n",
      "        [-2.0200e+00, -2.5529e+00,  5.8769e-01, -1.9522e+00],\n",
      "        [-1.8102e+00, -1.0076e+00, -2.0503e+00, -9.3657e-01],\n",
      "        [-8.7096e-01, -2.5643e+00,  6.8063e-01, -6.5811e-01],\n",
      "        [-3.8558e-01, -1.5039e+00,  1.8608e+00, -1.0926e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "(Pdb) type(lqag)\n",
      "<class 'torch.Tensor'>\n",
      "(Pdb) lqag.detach().max(1)\n",
      "torch.return_types.max(\n",
      "values=tensor([  1.1932,   1.9306,  -0.0241,  -0.2488,   0.7819,   0.5164,   1.2218,\n",
      "          1.8603,   1.1967,  -1.6772,   0.5550,   0.0238,  -2.1784,   0.4122,\n",
      "          1.6441,  -6.6180,  -0.1323,  -5.7148,  -1.3596,   1.6246,  -3.5084,\n",
      "         -2.7181,  -3.3217,  -3.3669,  -2.3796,   1.3779,   2.0625,   0.7700,\n",
      "         -0.1471,   0.1700,  -2.9760,   1.2099,   1.2501,   1.8542,  -0.0744,\n",
      "          0.3758,   0.8694,   1.4412,  -0.4494,   0.9807,   0.4317,  -3.5570,\n",
      "          0.3845,   1.4821,   0.9712,   0.8260,  -0.0983,  -2.8456,  -4.3711,\n",
      "        -19.9973,  -2.5666,  -0.6032,   1.9409,   2.0524,  -3.7179, -19.2054,\n",
      "          1.2433,   2.0122,  -0.8207,  -4.6519,   0.5877,  -0.9366,   0.6806,\n",
      "          1.8608]),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        1, 3, 3, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 3, 2, 2]))\n",
      "(Pdb) lqag.detach()\n",
      "tensor([[-4.7361e-01, -1.2424e+00,  1.1932e+00, -1.0459e+00],\n",
      "        [-5.4051e-01, -1.7728e+00,  1.9306e+00, -1.2535e+00],\n",
      "        [-3.0384e-01, -1.9309e+00, -2.4054e-02, -3.7799e-02],\n",
      "        [-9.5944e-01, -1.0767e+00, -2.4877e-01, -9.5517e-01],\n",
      "        [-2.4953e+00, -1.1816e+00,  7.8187e-01, -2.7738e+00],\n",
      "        [-5.5209e-01, -2.2333e+00,  5.1643e-01, -3.5714e-01],\n",
      "        [-1.8305e+00, -9.3799e-01,  1.2218e+00, -2.4447e+00],\n",
      "        [-1.5533e+00, -1.0693e+00,  1.8603e+00, -2.4556e+00],\n",
      "        [-1.1829e+00, -1.2055e+00,  1.1967e+00, -1.8128e+00],\n",
      "        [-7.0004e+00, -1.6772e+00, -2.6323e+00, -5.9601e+00],\n",
      "        [-9.8021e-01, -1.0559e+00,  5.5498e-01, -1.3271e+00],\n",
      "        [-2.8105e-01, -1.4320e+00, -5.1170e-01,  2.3760e-02],\n",
      "        [-4.2508e+00, -5.3074e+00, -2.1784e+00, -2.4036e+00],\n",
      "        [-3.1736e-01, -1.3173e+00, -1.4248e+00,  4.1218e-01],\n",
      "        [-6.0296e-01, -1.1268e+00,  1.6441e+00, -1.3621e+00],\n",
      "        [-2.2031e+01, -6.6180e+00, -1.6359e+01, -1.6050e+01],\n",
      "        [-4.7134e-01, -1.2763e+00, -1.3226e-01, -4.3915e-01],\n",
      "        [-8.2790e+00, -5.7286e+00, -5.7148e+00, -5.9096e+00],\n",
      "        [-3.5887e+00, -4.2970e+00, -1.3596e+00, -2.5322e+00],\n",
      "        [-5.4800e-01, -1.0824e+00,  1.6246e+00, -1.2719e+00],\n",
      "        [-6.1727e+00, -4.6794e+00, -3.5084e+00, -4.5817e+00],\n",
      "        [-6.1606e+00, -3.1879e+00, -2.7181e+00, -5.1000e+00],\n",
      "        [-6.7118e+00, -4.9938e+00, -3.3217e+00, -5.2140e+00],\n",
      "        [-5.9645e+00, -6.4165e+00, -3.3669e+00, -3.8659e+00],\n",
      "        [-5.3035e+00, -4.5550e+00, -2.3796e+00, -4.0901e+00],\n",
      "        [-8.0529e-01, -9.4692e-01,  1.3779e+00, -1.4660e+00],\n",
      "        [-7.9361e-01, -1.2236e+00,  2.0625e+00, -1.7403e+00],\n",
      "        [-6.7864e-01, -2.2322e+00,  7.7004e-01, -6.1193e-01],\n",
      "        [-3.2441e+00, -2.4526e+00, -1.4707e-01, -2.9289e+00],\n",
      "        [-2.7150e-01, -1.7368e+00,  1.7004e-01, -1.3556e-01],\n",
      "        [-1.2962e+01, -2.9760e+00, -7.6964e+00, -1.0039e+01],\n",
      "        [-5.7226e-01, -1.9503e+00,  1.2099e+00, -8.4640e-01],\n",
      "        [-8.1669e-01, -2.0856e+00,  1.2501e+00, -1.1550e+00],\n",
      "        [-6.2479e-01, -1.5609e+00,  1.8542e+00, -1.3829e+00],\n",
      "        [-2.4810e-01, -1.3101e+00, -7.4442e-02, -1.7306e-01],\n",
      "        [-4.0760e-01, -1.3254e+00, -1.5677e+00,  3.7582e-01],\n",
      "        [-3.6174e-01, -1.9241e+00,  8.6942e-01, -3.9762e-01],\n",
      "        [-2.5599e-01, -1.2634e+00,  1.4412e+00, -8.6270e-01],\n",
      "        [-3.2507e+00, -3.0103e+00, -4.4942e-01, -2.7192e+00],\n",
      "        [-2.2623e-01, -1.3510e+00,  9.8073e-01, -6.3890e-01],\n",
      "        [-4.3063e-01, -2.1093e+00,  4.3173e-01, -3.1157e-01],\n",
      "        [-1.0792e+01, -3.5570e+00, -7.0318e+00, -8.3154e+00],\n",
      "        [-2.2851e-01, -1.3361e+00,  3.8448e-01, -3.6174e-01],\n",
      "        [-5.0294e-01, -1.0698e+00,  1.4821e+00, -1.1610e+00],\n",
      "        [-2.0217e-01, -1.4547e+00,  9.7120e-01, -5.6314e-01],\n",
      "        [-1.5944e+00, -2.9813e+00,  8.2597e-01, -1.4468e+00],\n",
      "        [-4.7956e-01, -1.1150e+00, -9.8345e-02, -4.7362e-01],\n",
      "        [-5.0623e+00, -5.6540e+00, -2.8456e+00, -3.1132e+00],\n",
      "        [-1.6131e+01, -4.3711e+00, -1.1338e+01, -1.2304e+01],\n",
      "        [-3.0747e+01, -2.0119e+01, -2.8487e+01, -1.9997e+01],\n",
      "        [-4.5807e+00, -5.5097e+00, -2.6096e+00, -2.5666e+00],\n",
      "        [-9.4836e-01, -1.1237e+00, -6.0317e-01, -7.4302e-01],\n",
      "        [-5.7255e-01, -1.4184e+00,  1.9409e+00, -1.3959e+00],\n",
      "        [-2.9576e-01, -1.4985e+00,  2.0524e+00, -1.0694e+00],\n",
      "        [-1.3563e+01, -3.7179e+00, -9.7955e+00, -1.0250e+01],\n",
      "        [-3.1154e+01, -1.9205e+01, -2.9683e+01, -1.9671e+01],\n",
      "        [-8.6330e-01, -2.1222e+00,  1.2433e+00, -1.1932e+00],\n",
      "        [-3.8041e-01, -1.4719e+00,  2.0122e+00, -1.1594e+00],\n",
      "        [-2.1465e+00, -8.2065e-01, -1.0006e+00, -1.7897e+00],\n",
      "        [-1.8865e+01, -4.6519e+00, -1.3042e+01, -1.3821e+01],\n",
      "        [-2.0200e+00, -2.5529e+00,  5.8769e-01, -1.9522e+00],\n",
      "        [-1.8102e+00, -1.0076e+00, -2.0503e+00, -9.3657e-01],\n",
      "        [-8.7096e-01, -2.5643e+00,  6.8063e-01, -6.5811e-01],\n",
      "        [-3.8558e-01, -1.5039e+00,  1.8608e+00, -1.0926e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) lagq\n",
      "*** NameError: name 'lagq' is not defined\n",
      "(Pdb) lqag.max(1)\n",
      "torch.return_types.max(\n",
      "values=tensor([  1.1932,   1.9306,  -0.0241,  -0.2488,   0.7819,   0.5164,   1.2218,\n",
      "          1.8603,   1.1967,  -1.6772,   0.5550,   0.0238,  -2.1784,   0.4122,\n",
      "          1.6441,  -6.6180,  -0.1323,  -5.7148,  -1.3596,   1.6246,  -3.5084,\n",
      "         -2.7181,  -3.3217,  -3.3669,  -2.3796,   1.3779,   2.0625,   0.7700,\n",
      "         -0.1471,   0.1700,  -2.9760,   1.2099,   1.2501,   1.8542,  -0.0744,\n",
      "          0.3758,   0.8694,   1.4412,  -0.4494,   0.9807,   0.4317,  -3.5570,\n",
      "          0.3845,   1.4821,   0.9712,   0.8260,  -0.0983,  -2.8456,  -4.3711,\n",
      "        -19.9973,  -2.5666,  -0.6032,   1.9409,   2.0524,  -3.7179, -19.2054,\n",
      "          1.2433,   2.0122,  -0.8207,  -4.6519,   0.5877,  -0.9366,   0.6806,\n",
      "          1.8608], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        1, 3, 3, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 3, 2, 2]))\n",
      "(Pdb) lqag.max(1)[0]\n",
      "tensor([  1.1932,   1.9306,  -0.0241,  -0.2488,   0.7819,   0.5164,   1.2218,\n",
      "          1.8603,   1.1967,  -1.6772,   0.5550,   0.0238,  -2.1784,   0.4122,\n",
      "          1.6441,  -6.6180,  -0.1323,  -5.7148,  -1.3596,   1.6246,  -3.5084,\n",
      "         -2.7181,  -3.3217,  -3.3669,  -2.3796,   1.3779,   2.0625,   0.7700,\n",
      "         -0.1471,   0.1700,  -2.9760,   1.2099,   1.2501,   1.8542,  -0.0744,\n",
      "          0.3758,   0.8694,   1.4412,  -0.4494,   0.9807,   0.4317,  -3.5570,\n",
      "          0.3845,   1.4821,   0.9712,   0.8260,  -0.0983,  -2.8456,  -4.3711,\n",
      "        -19.9973,  -2.5666,  -0.6032,   1.9409,   2.0524,  -3.7179, -19.2054,\n",
      "          1.2433,   2.0122,  -0.8207,  -4.6519,   0.5877,  -0.9366,   0.6806,\n",
      "          1.8608], grad_fn=<MaxBackward0>)\n",
      "(Pdb) lqag.max(1).shape\n",
      "*** AttributeError: 'torch.return_types.max' object has no attribute 'shape'\n",
      "(Pdb) lqag.max(1).size()\n",
      "*** AttributeError: 'torch.return_types.max' object has no attribute 'size'\n",
      "(Pdb) type(lqag.max(1))\n",
      "<class 'torch.return_types.max'>\n",
      "(Pdb) lqag.max(1)[0].unsqueeze(1)\n",
      "tensor([[  1.1932],\n",
      "        [  1.9306],\n",
      "        [ -0.0241],\n",
      "        [ -0.2488],\n",
      "        [  0.7819],\n",
      "        [  0.5164],\n",
      "        [  1.2218],\n",
      "        [  1.8603],\n",
      "        [  1.1967],\n",
      "        [ -1.6772],\n",
      "        [  0.5550],\n",
      "        [  0.0238],\n",
      "        [ -2.1784],\n",
      "        [  0.4122],\n",
      "        [  1.6441],\n",
      "        [ -6.6180],\n",
      "        [ -0.1323],\n",
      "        [ -5.7148],\n",
      "        [ -1.3596],\n",
      "        [  1.6246],\n",
      "        [ -3.5084],\n",
      "        [ -2.7181],\n",
      "        [ -3.3217],\n",
      "        [ -3.3669],\n",
      "        [ -2.3796],\n",
      "        [  1.3779],\n",
      "        [  2.0625],\n",
      "        [  0.7700],\n",
      "        [ -0.1471],\n",
      "        [  0.1700],\n",
      "        [ -2.9760],\n",
      "        [  1.2099],\n",
      "        [  1.2501],\n",
      "        [  1.8542],\n",
      "        [ -0.0744],\n",
      "        [  0.3758],\n",
      "        [  0.8694],\n",
      "        [  1.4412],\n",
      "        [ -0.4494],\n",
      "        [  0.9807],\n",
      "        [  0.4317],\n",
      "        [ -3.5570],\n",
      "        [  0.3845],\n",
      "        [  1.4821],\n",
      "        [  0.9712],\n",
      "        [  0.8260],\n",
      "        [ -0.0983],\n",
      "        [ -2.8456],\n",
      "        [ -4.3711],\n",
      "        [-19.9973],\n",
      "        [ -2.5666],\n",
      "        [ -0.6032],\n",
      "        [  1.9409],\n",
      "        [  2.0524],\n",
      "        [ -3.7179],\n",
      "        [-19.2054],\n",
      "        [  1.2433],\n",
      "        [  2.0122],\n",
      "        [ -0.8207],\n",
      "        [ -4.6519],\n",
      "        [  0.5877],\n",
      "        [ -0.9366],\n",
      "        [  0.6806],\n",
      "        [  1.8608]], grad_fn=<UnsqueezeBackward0>)\n",
      "(Pdb) actions\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [0]])\n",
      "(Pdb) n\n",
      "> <ipython-input-50-4b71072aa82e>(29)dqn()\n",
      "-> eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
      "(Pdb) c\n",
      "Episode 1\tAverage Score: -235.10> <ipython-input-50-4b71072aa82e>(26)dqn()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) c\n",
      "Episode 2\tAverage Score: -166.01> <ipython-input-50-4b71072aa82e>(27)dqn()\n",
      "-> scores_window.append(score)       # save most recent score\n",
      "(Pdb) r\n",
      "Episode 3\tAverage Score: -276.21> <ipython-input-50-4b71072aa82e>(27)dqn()\n",
      "-> scores_window.append(score)       # save most recent score\n",
      "(Pdb) r\n",
      "Episode 4\tAverage Score: -257.40> <ipython-input-50-4b71072aa82e>(27)dqn()\n",
      "-> scores_window.append(score)       # save most recent score\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-4b71072aa82e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# plot the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-4b71072aa82e>\u001b[0m in \u001b[0;36mdqn\u001b[1;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mscores_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# save most recent score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# save most recent score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_decay\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# decrease epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-4b71072aa82e>\u001b[0m in \u001b[0;36mdqn\u001b[1;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mscores_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# save most recent score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# save most recent score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_decay\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# decrease epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda2\\envs\\pytorch\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda2\\envs\\pytorch\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        pdb.set_trace()\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        env.render()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore\n",
    "\n",
    "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
    "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN! \n",
    "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
